[
  {
    "objectID": "docs/setting-up/setup_2_github.html",
    "href": "docs/setting-up/setup_2_github.html",
    "title": "Hello, GitHub! (Need)",
    "section": "",
    "text": "GitHub is an online service to help develop and maintain code. It is called GitHub because it is based on a version control tool called Git. A key feature of Git and GitHub is how it helps keep track of the changes to code. You can think of GitHub as a sophisticated version of Google Drive or Dropbox. The know-how to use Git and GitHub is a plus for tech employees.\n73 will use the educational branch of GitHub called GitHub Classroom. We will only use the simplest features of GitHub Classroom that allow you to share your code and solicit instructor feedback. In this chapter, I will take you through the setup process for GitHub Classroom. If you are already familiar with GitHub, feel free to jump ahead."
  },
  {
    "objectID": "docs/setting-up/setup_2_github.html#footnotes",
    "href": "docs/setting-up/setup_2_github.html#footnotes",
    "title": "Hello, GitHub! (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nor the End of the Universe↩︎"
  },
  {
    "objectID": "docs/setting-up/setup_0_main.html",
    "href": "docs/setting-up/setup_0_main.html",
    "title": "Tools of the Trade",
    "section": "",
    "text": "Overview\nIt is not surprising that 73 will have to use technology. Some of the key requirements of technology in this module are:\n\nEasy access to Python,\nEase of incorporating a scientific discussion with the Python code,\nEase of sharing Python code for feedback and collaborative work.\nEase of starting a discussion about the content.\n\nNo single platform can fulfill all these requirements, so we must use several different tools. However, I have organised the course to have an easy workflow for you to learn by doing and getting feedback. So here are the platforms we will use.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlatform\nHow it will help us\n\n\n\n\n\nJupyter Notebooks\nEasy access to Python with ample features for scientific discussions.\n\n\n\nGitHub Classroom\nSharing the Jupyter Notebooks\n\n\n\nHypothesis\nAnnotate, discuss centred on course notes.\n\n\n\nCanvas\nOfficial Learning Management System (LMS) of NUS\n\n\n\nGoogle Docs\nScheduling and grading.\n\n\n\nTEAMMATES\nFor within group feedback\n\n\n\n\nIn this section, I will show you how to set up three essential tools, namely:\n\nHypothesis,\nGitHub classrooms and\nJupyter Notebooks.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/about/instructions.html",
    "href": "docs/about/instructions.html",
    "title": "Instructions",
    "section": "",
    "text": "Need, Good and Nice:When possible, I have categorized the content as Need to Know, Good to Know and Nice to Know. You should typically know everything that is Need to Know and Good to Know. You should look at the Nice to Know portions once you are more comfortable with Python.\nExercises & Problems:\n\nExercises(Simple): These will only reinforce Python syntax and best suit those who are new to Python.\nExercises: These general tasks will help you practice using Python for simple scientific problems.\nProblems: More demanding tasks tailored specifically for this seminar, ranging from straightforward problems to more challenging and longer tasks.\n\nThe website has a search option that accommodates free text. This can help locate things (most of the time).\n\n\n\n\nDay 1 is mostly about developing and enhancing your Python knowledge. I think this is also the most demanding day of the seminar because you need to pick and choose from several topics and exercises to match your current knowledge and interest in Python.\nOverall, by the end of the first day, I hope you know enough Python so we can focus on using Python to solve problems in the following days. However, please don’t rush; this is an opportunity to slowly strengthen your command of Python, so take it easy and enjoy!\n\n\nIf you are a beginner, and new to Python, start by working on the examples and simple exercises in sections (A) Setting up and (B) Python | Basics\nIf you are an intermediate used and already know your way around Python,"
  },
  {
    "objectID": "docs/about/instructions.html#things-to-note-about-the-website",
    "href": "docs/about/instructions.html#things-to-note-about-the-website",
    "title": "Instructions",
    "section": "",
    "text": "Need, Good and Nice:When possible, I have categorized the content as Need to Know, Good to Know and Nice to Know. You should typically know everything that is Need to Know and Good to Know. You should look at the Nice to Know portions once you are more comfortable with Python.\nExercises & Problems:\n\nExercises(Simple): These will only reinforce Python syntax and best suit those who are new to Python.\nExercises: These general tasks will help you practice using Python for simple scientific problems.\nProblems: More demanding tasks tailored specifically for this seminar, ranging from straightforward problems to more challenging and longer tasks.\n\nThe website has a search option that accommodates free text. This can help locate things (most of the time)."
  },
  {
    "objectID": "docs/about/instructions.html#recommended-workflow-for-day-1",
    "href": "docs/about/instructions.html#recommended-workflow-for-day-1",
    "title": "Instructions",
    "section": "",
    "text": "Day 1 is mostly about developing and enhancing your Python knowledge. I think this is also the most demanding day of the seminar because you need to pick and choose from several topics and exercises to match your current knowledge and interest in Python.\nOverall, by the end of the first day, I hope you know enough Python so we can focus on using Python to solve problems in the following days. However, please don’t rush; this is an opportunity to slowly strengthen your command of Python, so take it easy and enjoy!\n\n\nIf you are a beginner, and new to Python, start by working on the examples and simple exercises in sections (A) Setting up and (B) Python | Basics\nIf you are an intermediate used and already know your way around Python,"
  },
  {
    "objectID": "docs/about/overview.html",
    "href": "docs/about/overview.html",
    "title": "Overview",
    "section": "",
    "text": "Python is a popular and versatile programming language that is easy to learn and read. It enables quick and efficient work in tasks like plotting, data analysis, and simulations. Although not the fastest or most efficient (like, for instance, C++), it is versatile and fun to use, particularly for science applications.\nIn this seminar, we will explore how Python can implement various techniques for solving physics problems. This seminar is not exhaustive but aims to cover a few concepts so you can be exposed to different methods (such as Monte Carlo) and understand different programming approaches (such as object-oriented programming). This experience will complement and supplement what you will learn in your other courses.\n\n\n\nThe material is designed to accommodate varying levels of knowledge, from beginners to advanced users.\nThe goal is to progress from your starting point, regardless of where that may be. “…what ultimately matters in this [seminar] is not so much where you end up relative to your classmates but where you will end up relative to yourself when you began” (Quote from Harvard University’s CS50 course (“CS50” 2024))\nThe best way to learn programming is by doing, so expect to spend plenty of time experimenting and practicing.\nYou are not expected to work on the seminar content outside the seminar hours. The material introduced in the seminar has been intentionally reduced over time to accommodate carryover work from the previous day.\nYou also do not have to complete every topic and problem! Often, you will learn more by focusing on doing a few things well(the cliché less is more).\nYou can work on the material independently. The facilitator’s role will be to:\n\nExplain and clarify topics beyond the provided material.\nPersonalise the learning experience by spending time with each participant.\n\n\n\n\n\n\nDay 1: This is the most demanding day, covering various topics. If you are new to Python, focus on the basics by practicing examples and exercises. If you are more experienced, briefly review the basics before diving into the more advanced topics. Work through the exercises and try your best to complete as many as possible.\nDay 2: We’ll explore using random numbers to solve simple problems, including electron and Brownian motion.\nDay 3: Focus on interacting systems such as the Boltzmann distribution and the Ising model.\nDay 4: Work with differential equations.Start working on your group project.\nDay 5: Complete the group project and present."
  },
  {
    "objectID": "docs/about/overview.html#things-to-note",
    "href": "docs/about/overview.html#things-to-note",
    "title": "Overview",
    "section": "",
    "text": "The material is designed to accommodate varying levels of knowledge, from beginners to advanced users.\nThe goal is to progress from your starting point, regardless of where that may be. “…what ultimately matters in this [seminar] is not so much where you end up relative to your classmates but where you will end up relative to yourself when you began” (Quote from Harvard University’s CS50 course (“CS50” 2024))\nThe best way to learn programming is by doing, so expect to spend plenty of time experimenting and practicing.\nYou are not expected to work on the seminar content outside the seminar hours. The material introduced in the seminar has been intentionally reduced over time to accommodate carryover work from the previous day.\nYou also do not have to complete every topic and problem! Often, you will learn more by focusing on doing a few things well(the cliché less is more).\nYou can work on the material independently. The facilitator’s role will be to:\n\nExplain and clarify topics beyond the provided material.\nPersonalise the learning experience by spending time with each participant."
  },
  {
    "objectID": "docs/about/overview.html#tentative-schedule",
    "href": "docs/about/overview.html#tentative-schedule",
    "title": "Overview",
    "section": "",
    "text": "Day 1: This is the most demanding day, covering various topics. If you are new to Python, focus on the basics by practicing examples and exercises. If you are more experienced, briefly review the basics before diving into the more advanced topics. Work through the exercises and try your best to complete as many as possible.\nDay 2: We’ll explore using random numbers to solve simple problems, including electron and Brownian motion.\nDay 3: Focus on interacting systems such as the Boltzmann distribution and the Ising model.\nDay 4: Work with differential equations.Start working on your group project.\nDay 5: Complete the group project and present."
  },
  {
    "objectID": "docs/problems/monte-carlo-error-propgation.html",
    "href": "docs/problems/monte-carlo-error-propgation.html",
    "title": "MC Error Propagation",
    "section": "",
    "text": "Introduction\nIn this problem, we will use random numbers to create a simple simulation of radioactive decay. Let’s start with some basic observations:\n\nA given (unstable) nucleus has a fixed probability of decaying in a given time interval. This probability is different for nuclei of different elements. For example the probability of decaying (for a fixed time interval) for a U nucleus is (much) smaller than for a Th nucleus. This is characterized by the decay constant(\\(\\tau\\)) or half-life (\\(\\lambda\\)).\nSo the longer we have a sample, the greater the probability of its nuclei decaying. For example, the probability of decaying within 2s is greater than within 1s.\nThese probabilities do not scale linearly (i.e., the likelihood for 2s is not twice that for 1 s).\n\n\n\nTasks\n\nTask 1Task 2Task 3\n\n\nIt has been observed that the probability of nuclei decaying in a given time interval \\(\\Delta t\\) is \\(\\dfrac{1}{6}\\). This means after a time \\(\\Delta t\\)=1, about one-sixth of the nuclei would have disintegrated.\nSimulate and plot the change in the number of nuclei with time. Start with a 10000 nuclei. You should see a plot like the one below.\n\n\nRedo the previous task but this time adjust your parameteres so that you are simulation the decay of Th.\n\n\nThoroum decays into a daught nuclide X who is also unstable with a half-life of x. Simulate\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/pool-sampling_question.html",
    "href": "docs/problems/pool-sampling_question.html",
    "title": "04| Pool Sampling",
    "section": "",
    "text": "Introduction\nLet’s investigate a medical testing strategy that proved invaluable in coping with the huge number of COVID-19 tests required in the past pandemic. Specifically, we will be studying the strategy called Group or Pool sampling (Wikipedia). It was first proposed by the economist Robert Dorfman in 1943 to test syphilis in soldiers!\nTo get started, please download the following two files:\n\ntest_kit.py\n\nThis file contains a python function test(genome) that accepts a genome as a string (e.g., ATGAGAAT…) and returns True if there is an infection or False if not.\nThis function can only test one sample at a time.\nThere are no false positives.\nThe test is 100% accurate.\n\nperson-files.zip\n\nThis file contains (simulated ) genomics data for 500 people.\nThe files are named in the format person_###.txt where ### is a identifying number.\nJust for your information, each person’s file contains a million bases.\n\n\n\n\nTasks\n\nTask 1Task 2Task 3Task 4Task 5\n\n\n\nGetting started\n\nTo get started, import the function test() from test_kit.py.\ntest() is a straightforward function. However, you are not meant to understand how this function works. You just need to be able to use it. So, you can treat the function test() as a black-box.\nConfirm that Person 27 is infected and that person 17 and 37 are not infected. To use test() on a person, you need to:\n\nRead the person’s genomics data from her file and\nPass this genomics data into test()\n\n\n\n\n\n\nCreate a function\n\nCreate a function get_genome(person_id) that will take an (integer) person_id as input and return the corresponding genome data as output.\nUse get_genome() to apply test() to the first 100 people. (I.e. from person_00000.txt to person_00099.txt) You should see persons 1, 7, 8, 27, 47, 57, 62, 63, and 78 show infections.\n\n\n\n\n\nRandom testing\n\nUse test() on 100 random people to estimate the infection rate in this population. Print your result as a percentage.\n\n\n\n\n\nPool Sampling\n\nWrite some Python code to join/combine the genomics data of person 1 and person 2. I.e. given genome_1 and genome_2, you should end up with genome_1genome_2 What we are trying to simulate here is the mixing of blood samples.\nWrite a function called pool(list_of_id) that accepts a list of integers and returns (a string) of the joined genomes of the people identified by the integers.\nApply test() to the combined genomes of 20 and 21 and 21 and 22. Are the results as expected?\nFor the first 100 persons, use pool and test in groups of 10 to determine those infected. Please keep track of the number of tests you have performed and print it at the end.\nRepeat the previous part with groups of 5.\n\n\n\n\n\nOptimisation\nLet’s try to detect as many infections as possible using the least number of tests. Pick any grouping you like, and apply pool sampling to determine the number of infected people in the population of 500. Keep track of the number of tests you have performed.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/butterfly.html",
    "href": "docs/problems/butterfly.html",
    "title": "11| The Butterfly Effect",
    "section": "",
    "text": "Introduction\n\n\n\n\n\nI am sure you would have heard of the ‘butterfly effect’. This term is related to a phenomenon called (deterministic) chaos, where some systems exhibit strong variations in behaviour despite only minute changes in the outputs. In other words, chaotic systems are super sensitive to their input parameters.\nThe first chaotic system discovered is the Lorentz Attractor, which is related to a simple weather model created by Edward Lorentz. The system is governed by three coupled differential equations:\n\\[\n\\begin{align}\n\\dfrac{dx}{dt}&=\\sigma(y-x)\\\\\n\\dfrac{dy}{dt}&=x(\\rho-z)-y\\\\\n\\dfrac{dz}{dt}&=xy-\\beta z\\\\\n\\end{align}\n\\] Lorentz had used the values \\(\\sigma=10\\), \\(\\beta=8/3\\) and \\(\\rho=28\\).\n\n\nTasks\n\nSolve the differential equations of this system for the initial conditions \\((x,y,z) = (0,1,0)\\) from \\(t=0\\) to \\(t=50\\) using the Euler method and the SciPy’s odeint().\nUse your solutions \\((x,y,z)\\) values with the following code to get the the Lorentz’s Butterfly shown above.\nax = plt.axes(projection='3d')\nax.plot3D(x, y, z)\nplt.show()\nThis system is considered to be chaotic (i.e., highly sensitive to the initial conditions). Use your code to demonstrate this effect.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/yz-trapezium.html",
    "href": "docs/problems/yz-trapezium.html",
    "title": "03| Integrals & Areas",
    "section": "",
    "text": "Introduction\nThe definite integral of a function, \\(f(x)\\) with respect to \\(x\\) is the area bounded by the curve of the function and the x-axis, as shown in the figure below.\n\n\n\n\n\nOne way to estimate the integral of a function is by approximating the area bounded as a trapezium as shown in the figure below, where the slanted side connects the \\(y\\) values at the lower and upper limits. The integral can then be estimated by calculating the area of the trapezium.\n\n\n\n\n\nAs you can see, the estimation using one trapezium is rather off. In this case, there’s an overestimation. We can improve the accuracy by having more trapeziums, as shown in the figure below, where three trapeziums of equal width are used. The slanted side of each trapezium connects the \\(y\\) values at the \\(x\\)-boundaries of each trapezium.\n\n\n\n\n\nFrom here, we can deduce that if we have a large number of such trapeziums, each of very thin size, we can find the numerical value of the definite integral pretty accurately. This method of approximating definite integral is known as the trapezium rule.\n\n\nTasks\n\nWrite a Python function which can estimate the definite integral of a mathematical function \\(f(x)\\) using the trapezium rule.\nUse WolframAlpha to evaluate the integrals and complete the last column.\n\n\n\n\n\n\n\n\n\n\n\n\n#\n\\(f(x)\\)\n\\(a\\)\n\\(b\\)\n\\(\\displaystyle\\int_{x=a}^{x=b} f(x)dx\\)(Wolfram Alpha)\n\n\n\n\n1\n\\(f(x)=x^2+3x+2\\)\n\\(0\\)\n\\(5\\)\n\n\n\n2\n\\(f(x)=\\sin x\\)\n\\(0\\)\n\\(\\pi\\)\n\n\n\n3\n\\(f(x)=e^{-x^2}\\)\n\\(0\\)\n\\(1\\)\n\n\n\n4\n\\(f(x)=\\sin\\left(\\dfrac{1}{x}\\right)\\)\n\\(0.01\\)\n\\(0.1\\)\n\n\n\n\n\n\nNow use your function to evaluate the integrals. Add your results as a new column.Please highlight any strategies you used to enhance the quality of your answers.\nFor the above functions, you had the benefit of knowing the answers beforehand due to Wolfram Alpha. Can you describe a strategy that can be used to judge the quality of your answer if you did not have access to the answer beforehand?\n[Optional] Considering the power of services like WolframAlpha; is there a need to write your own code.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/bisection_question.html",
    "href": "docs/problems/bisection_question.html",
    "title": "02| Bisection Method",
    "section": "",
    "text": "Introduction\nThe values of \\(x\\) that satisfy \\(f(x) = 0\\) are called the roots of \\(f(x)\\). Finding the roots of equations is important in science and engineering, but some equations, such as \\(\\cos x - x = 0\\) (called transcendental equations), cannot be solved analytically. In such cases, numerical methods are needed. One such method is the Bisection method.\nTo understand how the Bisection method works, notice that the function has opposite signs on either side of the root. The Bisection method uses this fact to ‘box in’ the root. Here’s how it works:\n\nPick two values of \\(x\\) (let’s call them \\(x_\\text{left}\\) and \\(x_\\text{right}\\)) that we know lie on opposite sides of the root.\nDetermine the midpoint \\(x_\\text{mid}\\) of \\(x_\\text{left}\\) and \\(x_\\text{right}\\), and evaluate the function at this point.\nIf the sign of \\(f(x_\\text{mid})\\) is the same as the sign \\(f(x_\\text{left})\\), then replace \\(x_\\text{left}\\) with \\(x_\\text{mid}\\). Else, replace \\(x_\\text{right}\\) with the midpoint.\nNow you have narrowed the range of the root to \\((x_\\text{left}, x_\\text{mid})\\) or \\((x_\\text{mid}, x_\\text{right})\\). Continue steps 2-4 until you have achieved the desired accuracy for the root.\n\nThe Bisection method is a simple but effective root-finding algorithm that can be implemented using only basic Python programming.\n\n\nTasks\n\nPlot for an estimate\nGet an estimate for the root of \\(\\cos x - x =0\\) by plotting the functions \\(\\cos x\\) and \\(x\\).\nUse bisection\nUse the bisection method to determine the root of \\(\\cos x - x =0\\) to 10 decimal places.\n(Answer = 0.739_085_133_2)\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/monte-carlo-integration.html",
    "href": "docs/problems/monte-carlo-integration.html",
    "title": "MC Integration",
    "section": "",
    "text": "Introduction\nEvaluating integrals is necessary for most scientific modelling. So, many different integration methods have been developed. The Monte Carlo(MC) integration method is one of the most versatile. One of its charms is its ability to be scaled up to higher dimensions without much fuss. In this question, you will develop code to realise Monte Carlo integration.\n\n\nTasks\n\nTask 1Task 2Some theoryTask 3\n\n\n\nArea first\n\nThe image shows a plot of the function \\(f(x)=x^2\\sin^2(2x)\\). Let’s try to estimate the area of the region shaded in blue.\nHere is what you should do:\n\nGenerate \\((x,y)\\) coordinates for a large number (\\(n_\\text{all}\\)) of random points to evenly cover the area shaded in grey.\n\nAs you can see, this region is defined by \\(2 \\le x \\le 3\\) and \\(0 \\le y\\le 6\\).\nConsider using uniform() for this.\n\nAsk how many points you generated are below the curve (and therefore in the blue region). Let’s call this number \\(n_\\text{below}\\).\n\nNotice that all random points in the blue region satisfy \\(y_i \\leq f(x_i)\\)\n\nNow we can calculate the area of the blue region because: \\[\n  \\dfrac{\\text{Blue Area}}{\\text{Grey Area}} \\approx \\dfrac{n_\\text{below}}{n_\\text{all}}\\Rightarrow \\text{Blue Area}=\\dfrac{n_\\text{below}}{n_\\text{all}}\\times\\text{Grey Area}\n  \\]\n\n\n\n\n\nIntegration\nSince you now know the blue area, you also know the value of the following integral \\(\\displaystyle\\int_{x=2}^{x=3}f(x)dx\\)! So, what you have done in this exercise is develop a numerical technique for evaluating integrals.\n\nCheck how good your estimate is by comparing it to the actual value of the integral, which is \\(4.0647\\). (I used Wolfram Alpha).\nCheck if your accuracy improves by increasing \\(n_\\text{all}\\).\n\n\n\n\n\nA Monte Carlo Estimator\n\\[\n\\newcommand\\ex[1]{\\left\\langle #1 \\right\\rangle}\n\\]\nThere is another way! Let’s play with some maths to see how.\nConsider a function \\(f(x)\\) that we want to integrate over \\([a,b]\\). If \\(\\ex{f(x)}\\) is the expectation value of \\(f(x)\\) over \\([a,b]\\), it follows that:\n\\[\n\\ex{f(x)}= \\dfrac{1}{b-a}\\int_a^bf(x)dx\n\\] But, \\[\n\\ex{f(x)}\\approx \\dfrac{1}{N}\\sum_{i=0}^{N-1}f(X_i)\n\\] Where \\(X_i\\) are \\(N\\) points in the interval \\([a,b]\\).\nWhence, for \\(X_i\\) drawn uniformly,\n\\[\n\\begin{equation}\n\\int_a^bf(x)dx \\approx (b-a)\\dfrac{1}{N}\\sum_{i=0}^{N-1}f(X_i)\n\\end{equation}\n\\]\nThe term on the right-hand side is called a Monte Carlo estimator. Notice that the Law of Large Numbers tells us that this approximation improves with large values of \\(N\\)\n\n\n\n\nUsing an estimator\nEvaluate the following integral using an MC estimator based on a Uniform probability distribution.\n\\[\n\\int_{x=2}^{x=3} x^2\\sin^2(2x)\\,dx\n\\]\n\nCompare your answer with your previous MC algorithm.\nCompare the speed of the two algorithms.\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/grid-laplace.html",
    "href": "docs/problems/grid-laplace.html",
    "title": "12| Monte Carlo Integration",
    "section": "",
    "text": "Introduction\nEvaluating integrals is necessary for most scientific modelling. So, many different integration methods have been developed. The Monte Carlo(MC) integration method is one of the most versatile. One of its charms is its ability to be scaled up to higher dimensions without much fuss. In this question, you will develop code to realise Monte Carlo integration.\n\n\nTasks\n\nTask 1Task 2Some theoryTask 3\n\n\n\nArea first\n\nThe image shows a plot of the function \\(f(x)=x^2\\sin^2(2x)\\). Let’s try to estimate the area of the region shaded in blue.\nHere is what you should do:\n\nGenerate \\((x,y)\\) coordinates for a large number (\\(n_\\text{all}\\)) of random points to evenly cover the area shaded in grey.\n\nAs you can see, this region is defined by \\(2 \\le x \\le 3\\) and \\(0 \\le y\\le 6\\).\nConsider using uniform() for this.\n\nAsk how many points you generated are below the curve (and therefore in the blue region). Let’s call this number \\(n_\\text{below}\\).\n\nNotice that all random points in the blue region satisfy \\(y_i \\leq f(x_i)\\)\n\nNow we can calculate the area of the blue region because: \\[\n  \\dfrac{\\text{Blue Area}}{\\text{Grey Area}} \\approx \\dfrac{n_\\text{below}}{n_\\text{all}}\\Rightarrow \\text{Blue Area}=\\dfrac{n_\\text{below}}{n_\\text{all}}\\times\\text{Grey Area}\n  \\]\n\n\n\n\n\nIntegration\nSince you now know the blue area, you also know the value of the following integral \\(\\displaystyle\\int_{x=2}^{x=3}f(x)dx\\)! So what you have done in this exercise is develop a numerical technique for evaluating integrals.\n\nCheck how good your estimate is by comparing it to the actual value of the integral, which is \\(4.0647\\). (I used Wolfram Alpha).\nCheck if your accuracy improves by increasing \\(n_\\text{all}\\).\n\n\n\n\n\nA Monte Carlo Estimator\n\\[\n\\newcommand\\ex[1]{\\left\\langle #1 \\right\\rangle}\n\\]\nThere is another way! Let’s play with some maths to see how.\nConsider a function \\(f(x)\\) that we want to integrate over \\([a,b]\\). If \\(\\ex{f(x)}\\) is the expectation value of \\(f(x)\\) over \\([a,b]\\), it follows that:\n\\[\n\\ex{f(x)}= \\dfrac{1}{b-a}\\int_a^bf(x)dx\n\\] But, \\[\n\\ex{f(x)}\\approx \\dfrac{1}{N}\\sum_{i=0}^{N-1}f(X_i)\n\\] Where \\(X_i\\) are \\(N\\) points in the interval \\([a,b]\\).\nWhence, for \\(X_i\\) drawn uniformly,\n\\[\n\\begin{equation}\n\\int_a^bf(x)dx \\approx (b-a)\\dfrac{1}{N}\\sum_{i=0}^{N-1}f(X_i)\n\\end{equation}\n\\]\nThe term on the right-hand side is called a Monte Carlo estimator. Notice that the Law of Large Numbers tells us that this approximation improves with large values of \\(N\\)\n\n\n\n\nUsing an estimator\nEvaluate the following integral using an MC estimator based on a Uniform probability distribution.\n\\[\n\\int_{x=2}^{x=3} x^2\\sin^2(2x)\\,dx\n\\]\n\nCompare your answer with your previous MC algorithm.\nCompare the speed of the two algorithms.\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/about-plotting.html",
    "href": "docs/problems/about-plotting.html",
    "title": "01| About Plotting",
    "section": "",
    "text": "This challenge involves two mini-challenges related to plotting. Enjoy"
  },
  {
    "objectID": "docs/problems/about-plotting.html#introduction-1",
    "href": "docs/problems/about-plotting.html#introduction-1",
    "title": "01| About Plotting",
    "section": "Introduction",
    "text": "Introduction\nA simple model for the interaction potential between two atoms as a function of their distance, \\(r\\), is the Lennard-Jones potential given by:\n\\[\nU(r) = \\dfrac{B}{ r^{12}} − \\dfrac{A}{r^{6}}\n\\tag{1}\\]\nWhere \\(A\\) and \\(B\\) are positive constants.\nThis was popular in the early days of computing because \\(r^{−12}\\) is easy to compute as the square of \\(r^{−6}\\). So, it was also sometimes called the 6-12 potential."
  },
  {
    "objectID": "docs/problems/about-plotting.html#tasks",
    "href": "docs/problems/about-plotting.html#tasks",
    "title": "01| About Plotting",
    "section": "Tasks",
    "text": "Tasks\n\nPlot \\(U(r)\\) for Argon atoms where \\(A = 1.024 \\times 10^{−23}\\) J nm\\(^6\\) and \\(B = 1.582 \\times 10^{−26}\\) J nm\\(^{12}\\).\n\nYour plot should show the ‘interesting’ part of this curve, which tends rapidly to infinity for small values of \\(r\\) and zero for large \\(r\\).\nConsider swapping units by dividing \\(A\\) and \\(B\\) by the Boltzmann’s constant to measure \\(U(r)\\) in units of K.\n\nWhat is the depth, \\(\\epsilon\\), and location, \\(r_0\\), of the potential minimum for this system? Remember to think like a scientist, not a programmer! Indicate these values by drawing horizontal and vertical lines at these locations.\nOn the same figure show the interatomic force given by: \\[\nF(r) = −\\dfrac{dU}{dr} = \\dfrac{12 B}{ r^{13}} − \\dfrac{6 A}{r^{7}}\n  \\tag{2}\\]\nFor small displacements from the equilibrium interatomic separation (where \\(F = 0\\)), the potential may be approximated to the harmonic oscillator function,\n\\[\nV(r) = \\dfrac{1}{2}k(r-r_0)^2+ \\epsilon\n  \\tag{3}\\]\nwhere\n\\[\nk = \\left|\\dfrac{d^2U}{dr^2}\\right|_{r_0}= \\dfrac{156 B}{ {r_0}^{14}} − \\dfrac{42 A}{{r_0}^{8}}\n  \\tag{4}\\]\nPlot \\(U(r)\\) and \\(V(r)\\) on the same figure but as a separate subplot."
  },
  {
    "objectID": "docs/problems/yz-streamplots.html",
    "href": "docs/problems/yz-streamplots.html",
    "title": "08| All about plotting",
    "section": "",
    "text": "This challenge is about visualizing mathematical functions and vectors.\n\n\n\n\nIn case you need a reminder, we begin this problem with a recap on vectors. To put it simply, a vector is a physical quantity which consists of both magnitude and direction. Pictorially, vectors are represented by arrows, where the length of the arrow represents the magnitude and the arrowhead represents the direction. Mathematically, a vector can be represented through a combination of numbers and unit vectors (mathematical objects used to represent directions). For example, a vector \\(\\vec{v}\\) can be written as: \\[\n\\vec{v} = 2\\hat{i} - 3\\hat{j}\n\\] where \\(\\hat{i}\\) and \\(\\hat{j}\\) are unit vectors in the \\(x\\)- and \\(y\\)-axes, respectively. Physically, we can interpret \\(\\vec{v}\\) as an arrow which is equivalent to 2 steps in the direction of the positive x-axis, 3 steps in the direction of the negative y-axis. We say that 2 is the \\(x\\)-component of \\(\\vec{v}\\) while -3 is the \\(y\\)-component of \\(\\vec{v}\\). The figure below illustrates this physical picture.\n\n\n\n\n\n\n\n\nOne way to visualise vectors using Python is streamplot(). streamplot() is a function in matplotlib that draws the streamlines of a vector field. In simple terms, streamplot gives us the directions of vectors at different coordinates. It allows us to visualise many real-life phenomena including river flow, neural network, molecular velocity, and many others. This problem serves as an introduction to streamplot.\nFamiliarise yourself with streamplot(). You may read the write-up on streamplot on the matplotlib website as a start. Note that the write-up assumes that the vectors to be plotted are velocities, but all other vectors can be plotted the same way."
  },
  {
    "objectID": "docs/problems/yz-streamplots.html#a-quick-primer-in-vectors",
    "href": "docs/problems/yz-streamplots.html#a-quick-primer-in-vectors",
    "title": "08| All about plotting",
    "section": "",
    "text": "In case you need a reminder, we begin this problem with a recap on vectors. To put it simply, a vector is a physical quantity which consists of both magnitude and direction. Pictorially, vectors are represented by arrows, where the length of the arrow represents the magnitude and the arrowhead represents the direction. Mathematically, a vector can be represented through a combination of numbers and unit vectors (mathematical objects used to represent directions). For example, a vector \\(\\vec{v}\\) can be written as: \\[\n\\vec{v} = 2\\hat{i} - 3\\hat{j}\n\\] where \\(\\hat{i}\\) and \\(\\hat{j}\\) are unit vectors in the \\(x\\)- and \\(y\\)-axes, respectively. Physically, we can interpret \\(\\vec{v}\\) as an arrow which is equivalent to 2 steps in the direction of the positive x-axis, 3 steps in the direction of the negative y-axis. We say that 2 is the \\(x\\)-component of \\(\\vec{v}\\) while -3 is the \\(y\\)-component of \\(\\vec{v}\\). The figure below illustrates this physical picture.\n\n\n\n\n\n\n\n\nOne way to visualise vectors using Python is streamplot(). streamplot() is a function in matplotlib that draws the streamlines of a vector field. In simple terms, streamplot gives us the directions of vectors at different coordinates. It allows us to visualise many real-life phenomena including river flow, neural network, molecular velocity, and many others. This problem serves as an introduction to streamplot.\nFamiliarise yourself with streamplot(). You may read the write-up on streamplot on the matplotlib website as a start. Note that the write-up assumes that the vectors to be plotted are velocities, but all other vectors can be plotted the same way."
  },
  {
    "objectID": "docs/problems/jcamp-jdx_question.html",
    "href": "docs/problems/jcamp-jdx_question.html",
    "title": "07| Parsing JCAMP-JDX files",
    "section": "",
    "text": "Introduction\nIn this problem, we will focus on how to use JCAMP-DX files. JCAMP-DX is a file format for storing and exchanging data from spectroscopic measurements, such as infrared and Raman spectra. JCAMP stands for Joint Committee on Atomic and Molecular Physical Data (jcamp-dx.org), a committee responsible for developing and maintaining standards for the exchange of spectroscopic data.\nThe JCAMP-DX format is a text-based format that includes both data and metadata. It supports a wide range of spectroscopic techniques and allows storing many different data types, including spectra, chromatograms, and mass spectrometry. The format is widely used in the scientific community and is considered a standard for exchanging spectroscopic data. In particular, NIST uses the JCAMP-DX to share data in the NIST Chemistry WebBook.\nJCAMP-DX files typically have a .jdx file extension. Many software applications, such as Notepad or TextEdit, can open them. However, to be useful, the file needs to be parsed, i.e., its content analysed and any essential data extracted.\n\n\nTasks\n\nTask 1Task 2Task 3\n\n\n\nGet data\nVisit the NIST Chemistry WebBook and download the data in JCAMP-DX format for the IR spectra of:\n1. Carbon-dioxide\n2. Water\n3. Methane \n\n\n\n\nWrite your own parsing code\nWrite a Python script to extract the IR spectral data from your downloaded files.\nNote: \n\nUse only basic Python and Numpy. You cannot use any specialised packages or software.\nDo not modify the original file from NIST.\n\n\n\n\n\nTime to plot\nUse your previous code snippet to extract the relevant data and generate a plot similar to the following:\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#getting-a-feel",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#getting-a-feel",
    "title": "Numerical Solutions (Need)",
    "section": "1.1 Getting a feel",
    "text": "1.1 Getting a feel\nLet us start with a simple system consisting of a bucket filled with a faucet. Let’s say the tap provides water at a rate of 5 L/mins. I can get a feel for the dynamics of this system by creating a table like this.\n\n\n\n\n\n\n\n\n\n\n\n\n#\nTime Step(\\(\\Delta t\\))\nElasped Time(\\(t\\))\nRate(\\(R\\))\nChange in Volume(\\(\\Delta V\\))\nTotal Volume(\\(V\\))\n\n\n\n\n0\n.5 mins\n0.0 mins\n5 L/min\n0.00\n0.0 L\n\n\n1\n.5 mins\n0.5 mins\n5 L/min\n2.5 L\n2.5 L\n\n\n2\n.5 mins\n1.0 mins\n5 L/min\n2.5 L\n5.0 L\n\n\n3\n.5 mins\n1.5 mins\n5 L/min\n2.5 L\n7.5 L\n\n\n4\n.5 mins\n2.0 mins\n5 L/min\n2.5 L\n10.0 L\n\n\n5\n.5 mins\n2.5 mins\n5 L/min\n2.5 L\n12.5 L\n\n\n\n\n\\(R\\) is the rate and \\(\\Delta V\\) is the change in volume that corresponds to a time step of \\(\\Delta V\\). I.e.\n\\[\n\\Delta V = R \\Delta t\n\\]\nLet me do all this in Python.\n\nmax_time = 5                     # Maximum time (mins)\ndt = .5                          # Time step (mins)\nrate = 5                         # Rate (L/min)\nall_volume = []                  # To keep track of all volumes\nvolume = 0                       # Starting volume\n\nall_time = np.arange(start=0, stop=max_time, step=dt)\n\nfor time in all_time:\n    all_volume.append(volume)    # Record volume\n    dV = rate * dt               # Calculate change in volume\n    volume += dV                 # Update the new volume\n\n# Because we can...\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\n\n\n\n\n\n\nYou might think I have overly complicated something simple that can be done in a spreadsheet. However, once I have this basic structure in place, I can start having fun imagining other realities."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#an-overflowing-bucket",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#an-overflowing-bucket",
    "title": "Numerical Solutions (Need)",
    "section": "1.2 An overflowing bucket",
    "text": "1.2 An overflowing bucket\nLet’s imagine that our bucket has a maximum volume of 9 L. We can impose this condition with a simple if statement.\n\nmax_time = 5                     # Maximum time (mins)\ndt = .5                          # Time step (mins)\nrate = 5                         # Rate (L/min)\nbucket_capacity = 9              # L\nall_volume = []                  # To keep track of all volumes\nvolume = 0                       # Starting volume\n\nall_time = np.arange(start=0, stop=max_time, step=dt)\n\nfor time in all_time:\n    all_volume.append(volume)\n    dV = rate * dt\n    if volume &lt;= bucket_capacity:\n        volume += dV             # Update the new volume\n\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')\n\n\n\n\n\n\nOh no, the bucket still seems to fill beyond \\(9\\) L before it stops increasing. The problem here is that my timestep is too large. So let’s make it smaller. Since I don’t know what will work best, I will try a few with a for loop.\n\nmax_time = 5                     # Maximum time (mins)\ndt = .5                          # Time step (mins)\nrate = 5                         # Rate (L/min)\nbucket_capacity = 9              # L\n\nfor dt in [0.5, 0.1, 0.05, 0.01, 0.001]:\n    all_volume = []                  # To keep track of all volumes\n    volume = 0                       # Starting volume\n\n    all_time = np.arange(start=0, stop=max_time, step=dt)\n\n    for time in all_time:\n        all_volume.append(volume)\n        dV = rate * dt\n        if volume &lt;= bucket_capacity:\n            volume += dV\n\n    plt.plot(all_time, all_volume, label=f'dt={dt}')\n\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')\nplt.legend()\n\nI hope you are following what I have done. Since I want to change dt I have pushed everything that depends on it under the for loop. The way I initially set up the code with variables defined at the top and reused elsewhere makes it easy to make quick adjustments. If I run this code, I end up with:\n\n\n\n\n\nLooks like a timestep of 0.01 or 0.001 works best. I am going to pick 0.01 because this means the for loop runs fewer times."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#a-leaky-bucket",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#a-leaky-bucket",
    "title": "Numerical Solutions (Need)",
    "section": "1.3 A leaky bucket",
    "text": "1.3 A leaky bucket\nNow, let’s imagine a hole in the bucket is causing it to leak at a rate of 1.5 L/min.\n\nmax_time = 5                     # Maximum time (mins)\ndt = .001                        # Time step (mins)\nrate = 5                         # Filling rate (L/min)\nleak_rate = 1.5                  # L/min\nbucket_capacity = 9              # L\nall_volume = []                  # To keep track of all volumes\nvolume = 0                       # Starting volume\n\nall_time = np.arange(start=0, stop=max_time, step=dt)\n\nfor time in all_time:\n    all_volume.append(volume)\n\n    dV = rate * dt\n    leak_volume = leak_rate * dt\n    volume -= leak_volume\n\n    if volume &lt;= bucket_capacity:\n        volume += dV             # Update the new volume\n\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')\n\n\n\n\n\n\nNotice how it now takes longer for the bucket to fill up. But, even then, once it is filled, the inflow is sufficient to offset the leak and keep the bucket full."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#lets-turn-off-the-tap",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#lets-turn-off-the-tap",
    "title": "Numerical Solutions (Need)",
    "section": "1.4 Let’s turn off the tap",
    "text": "1.4 Let’s turn off the tap\nWhat will happen if we turn off the tap after 3 mins? I can impose this by simply modifying the if condition!\n\ntap_off_time = 3                 # When the tap goes off\nmax_time = 5                     # Maximum time (mins)\ndt = .001                        # Time step (mins)\nrate = 5                         # Filling rate (L/min)\nleak_rate = 1.5                  # L/min\nbucket_capacity = 9              # L\nall_volume = []                  # To keep track of all volumes\nvolume = 0                       # Starting volume\n\nall_time = np.arange(start=0, stop=max_time, step=dt)\n\nfor time in all_time:\n    all_volume.append(volume)\n    dV = rate * dt\n\n    leak_volume = leak_rate * dt\n    volume -= leak_volume\n\n    if (volume &lt;= bucket_capacity) and (time &lt; tap_off_time):\n        volume += dV             \n\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')\n\n\n\n\n\n\n\nUsing while\nBefore we move on let me show you how to use a while statement to run the same simulation. I prefer while for such cases because all variables (e.g. time and volume) are treated equally. Let me show you what I mean.\n\ntap_off_time = 3                 # When the tap goes off\nmax_time = 5                     # Maximum time (mins)\ndt = .001                        # Time step (mins)\nrate = 5                         # Filling rate (L/min)\nleak_rate = 1.5                  # L/min\nbucket_capacity = 9              # L\nall_volume = []                  # To keep track of all volumes\nall_time = []                    # To keep track of all times\nvolume = 0                       # Starting volume\ntime = 0\n\nwhile time &lt;= max_time:\n    all_time.append(time)\n    all_volume.append(volume)\n    dV = rate * dt\n\n    leak_volume = leak_rate * dt\n    volume -= leak_volume\n\n    if (volume &lt;= bucket_capacity) and (time &lt; tap_off_time):\n        volume += dV    \n\n    time += dt             \n\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#a-quick-summary",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#a-quick-summary",
    "title": "Numerical Solutions (Need)",
    "section": "1.5 A quick summary",
    "text": "1.5 A quick summary\nWe started with a bucket and slowly added more details to our story. I hope you noticed how little our code had to be altered to add these details. Also, you can easily see the ‘story’ just by looking at the code. Here you have a glimpse of the power of programming (with Python) over other methods (such as spreadsheets): simplicity of syntax, transparency of the processes and ease of making changes.\nI also like to point out that irrespective of how complicated the system or problem is, the strategy you need to adopt will be the same, simple one:\n\nEstablish a relationship that connects the changes of the variables.\nPick a starting value\nTake a step, and calculate the changes.\nUpdate the variables\nKeep on going until you have the desired number of points.\nIf you want to improve accuracy, take smaller steps.\n\nI will remind you of this again after the next example."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#we-just-solved-a-differential-equation",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#we-just-solved-a-differential-equation",
    "title": "Numerical Solutions (Need)",
    "section": "1.6 We just solved a differential equation!",
    "text": "1.6 We just solved a differential equation!\nThe example with the bucket is actually one related to a simple differential equation. Namely:\n\\[\n\\dfrac{dV}{dt} = R\n\\]\nMost mathematical equations are succinct ways of telling a story. For example, the above says that how fast the volume (\\(V\\)) changes as time passes equals a constant \\(R\\). More accurately, the symbol on the LHS reads as ‘rate of change of \\(V\\) with respect to \\(t\\)’.\nWe can approximate this relationship as the following fraction:\n\\[\n\\dfrac{\\Delta V}{\\Delta t} \\approx \\dfrac{dV}{dt} = R\n\\]\nAs you noticed earlier, the approximation becomes more accurate the smaller we make \\(\\Delta t\\).\nRearranging the above equation, we end up with:\n\\[\n\\Delta V = R \\Delta t\n\\]\nWhich is where we started everything about the bucket."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#introduction",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#introduction",
    "title": "Numerical Solutions (Need)",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\n\nLet’s solve the differential equation related to radioactive decay in this section. The experimentally observed mathematical relationship that governs the decay of a sample of radioactive material is given by:\n\\[\n\\dfrac{dN}{dt}=- \\lambda N\n\\]\n\\(N\\) is the number of radioactive nuclei and \\(\\lambda\\) is a characteristic number (called the ‘decay constant’) of the radioactive species. For example, \\(\\lambda = 142\\) per million year for \\(^{87}\\)Rb."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#approximating-the-differential-equation",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#approximating-the-differential-equation",
    "title": "Numerical Solutions (Need)",
    "section": "2.2 Approximating the differential equation",
    "text": "2.2 Approximating the differential equation\nLet’s follow our recipe and recast the differential equation in an approximate form:\n\\[\n\\begin{align*}\n\\dfrac{\\Delta N}{ \\Delta t}&\\approx- \\lambda N \\\\[10pt] \\Rightarrow \\Delta N &\\approx-\\lambda N \\Delta t\n\\end{align*}\n\\]\n\nGetting a feel\n\n\n\n\n\n\n\n\n\n\n\nStep\nTime\nN(t) \\((\\times 10^9)\\)\n\\(\\Delta t\\) (million years)\n\\(\\Delta N\\) (\\(\\times10^9\\))\n\n\n\n\n0\n\\(t_0 = 0\\)\n1\n\\(0.001\\)\n\\(-0.142\\)\n\n\n1\n\\(t_1 = t_0 + \\Delta t  = 0.001\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n2\n\\(t_2 = t_1 + \\Delta t =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n3\n\\(t_3 = t_2 + \\Delta t  =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n4\n\\(t_4 = t_3 + \\Delta t  =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n5\n\\(t_5 = t_4 + \\Delta t  =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n6\n\\(t_6 = t_5 + \\Delta t  =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n\n\nWe will re-create this data using Python in a bit. But, for the moment, if you are still not yet very confident about how we solve differential equations, try to complete the \\(?\\) of the table by hand."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#lets-write-some-code",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#lets-write-some-code",
    "title": "Numerical Solutions (Need)",
    "section": "2.3 Let’s write some code",
    "text": "2.3 Let’s write some code\n\ndecay_constant = 142       # For 85 Rb (per Myr)\nstop_fraction = 1E-3       # stop when the sample has shrunk to\n                           # this fraction of the starting value\nN0 = 1                     # Starting value of N (in billions of atoms)\ndt = .001\ntime, N = 0, N0            # Starting values\n\nall_N, all_time = [], []\n\nwhile True:\n    all_time.append(time)\n    all_N.append(N)\n\n    dN = -decay_constant*N*dt\n    N += dN\n\n    if N &lt; N0*stop_fraction:\n        break\n\n    time += dt\n\n\nplt.plot(all_time, all_N)\nplt.ylabel('$N$')\nplt.xlabel('Time(Millions of years)')\n\n\n\n\n\n\n\nSome things to note about the code\nI want to draw your attention to how I am using a True condition with the while loop. So, it will run until the end of The Universe until I break out on my own. To break out, I check if the \\(N\\) has been reduced to a negligible amount, which I have defined using stop_fraction."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/1_numerical_need.html#a-quick-summary-1",
    "href": "docs/knowledge-lake/numerical/1_numerical_need.html#a-quick-summary-1",
    "title": "Numerical Solutions (Need)",
    "section": "2.4 A quick summary",
    "text": "2.4 A quick summary\nYet, again, I draw your attention to the strategy we use to solve the differential equation.\n\nRewrite the equation in an approximate form that connects the changes of one variable to another. i.e. \\[\n\\dfrac{dN}{dt}=- \\lambda N \\Rightarrow \\Delta N \\approx - \\lambda N \\Delta t\n\\]\nPick starting values for the variables.\nStep the control variable (time in the previous case) and calculate the corresponding changes in the other variables.\nUpdate the variables\nRepeat until you reach the desired end.\nMake the step size smaller if you want greater accuracy.\n\nThis method you have been using is named the Euler Method (pronounced o-e-le).\n\n\n\n\n\n\nRemember\n\n\n\nRemember that the easiest (although not necessarily the best) way to solve a differential equation is using the Euler method."
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/need/1_random_need.html#a-simple-graphical-test",
    "href": "docs/knowledge-lake/random_numbers/need/1_random_need.html#a-simple-graphical-test",
    "title": "Random Numbers (Need)",
    "section": "3.1 A simple graphical test",
    "text": "3.1 A simple graphical test\nAlternatively, we can convince ourselves of the uniformity of the PRNG by plotting the numbers as a scatter plot or a histogram.\n\n\n\n\n\nHere is the code.\n\nn = 10000\nrandom_numbers = np.random.rand(n)\n\nfig, ax = plt.subplots(nrows=1, ncols=2)\n\naxis = ax[0]\naxis.hist(random_numbers, bins=100, alpha=.25)\naxis.set_xlabel(\"Value of random number\")\naxis.set_ylabel(\"Frequency\")\n\naxis = ax[1]\naxis.scatter(range(n), random_numbers, alpha=.25)\naxis.set_xlabel(\"Position in the random number list\")\naxis.set_ylabel(\"Value of random number\")\n\nPlease stop for a moment and make sure you understand what the plots are and what each is telling you. You should talk to someone if you are not sure."
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/need/1_random_need.html#uniformly-beyond-01",
    "href": "docs/knowledge-lake/random_numbers/need/1_random_need.html#uniformly-beyond-01",
    "title": "Random Numbers (Need)",
    "section": "3.2 Uniformly beyond \\([0,1)\\)",
    "text": "3.2 Uniformly beyond \\([0,1)\\)\nOften we need random numbers distributed over a range other than 0 and 1. We can use np.random.uniform() for this. Let’s generate a large set of random numbers in the interval \\([50,100]\\) using np.random.uniform() and create a histogram and scatter plot as we did earlier.\nI don’t need to show the code for plotting again. So, here is the most essential part.\nn = 10000\nrandom_numbers = np.random.uniform(low=50, high=100, size=n)\n\n\n\n\n\nNotice that the numbers are now between 50 and 100!"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/need/1_random_need.html#seeding-a-prng",
    "href": "docs/knowledge-lake/random_numbers/need/1_random_need.html#seeding-a-prng",
    "title": "Random Numbers (Need)",
    "section": "3.3 ‘seeding’ a PRNG",
    "text": "3.3 ‘seeding’ a PRNG\nSometimes, we need PRNG to generate the same set of numbers. For example, when we are debugging some code. You can achieve this by specifying a seed, the integer number that ‘kicks off’ the PRNG algorithm. You do not usually have to seed the PRNG. Instead, it does it automatically by using ‘some’ number (e.g. the number of milliseconds since January 1970) internally.\nYou will better understand what the seed does with the following code.\n\nnp.random.randint(0, 100, 10)     # Ten integers between 0 and 100\n\narray([49, 56,  3, 35, 76, 21, 94, 43, 21, 60])\n\n\n\nnp.random.randint(0, 100, 10)     # Another ten integers between 0 and 100\n\narray([84, 91, 42, 50, 40, 98, 43, 59, 93, 72])\n\n\n\nnp.random.seed(1234)              # Specifying a seed\nnp.random.randint(0, 100, 10)     # Ten integers between 0 and 100\n\narray([47, 83, 38, 53, 76, 24, 15, 49, 23, 26])\n\n\n\nnp.random.seed(1234)\nnp.random.randint(0, 100, 10)     # Same ten integers between 0 and 100\n\narray([47, 83, 38, 53, 76, 24, 15, 49, 23, 26])\n\n\nThat’s enough basic stuff. Let’s start using random numbers!"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/need/1_random_need.html#simulating-a-magic-8-ball",
    "href": "docs/knowledge-lake/random_numbers/need/1_random_need.html#simulating-a-magic-8-ball",
    "title": "Random Numbers (Need)",
    "section": "4.1 Simulating a Magic-8 Ball",
    "text": "4.1 Simulating a Magic-8 Ball\nLet me show you some examples of using random numbers. I want to start with a simple, frivolous one that simulates a Magic-8 ball.\nI will put my simulation in a function called shake_magic_8() as shown below. I borrowed the information on the 20 options of the original Magic-8 ball from the relevant Wikipedia page.\n\ndef shake_magic_8():\n    '''\n    Function to simulate a Magic-8 ball!\n    '''\n    options = ['It is certain.', 'It is decidedly so.',\n               'Without a doubt.', 'Yes definitely.',\n               'You may rely on it.', 'As I see it, yes.',\n               'Most likely.', 'Outlook good.',\n               'Yes.', 'Signs point to yes.',\n               'Reply hazy, try again.', 'Ask again later.',\n               'Better not tell you now.', 'Cannot predict now.',\n               'Concentrate and ask again.', 'Don\\'t count on it.',\n               'My reply is no.', 'My sources say no.',\n               'Outlook not so good.', 'Very doubtful.']\n\n    return np.random.choice(options)\n\nLet’s see if it works.\n\nquestions = ['Will I be pretty?',\n             'Will I be rich?',\n             'Will I be in trouble?']\n\nfor question in questions:\n    print(f'Q: {question}')\n    print(f'A: {shake_magic_8()}\\n')\n\nQ: Will I be pretty?\nA: Outlook not so good.\n\nQ: Will I be rich?\nA: Don't count on it.\n\nQ: Will I be in trouble?\nA: Yes.\n\n\nAlthough the outlook does not look too good for me, I hope you understand what is going on. np.random.choice() picks one of the options randomly. So, getting each is equally likely."
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/need/1_random_need.html#flipping-coins",
    "href": "docs/knowledge-lake/random_numbers/need/1_random_need.html#flipping-coins",
    "title": "Random Numbers (Need)",
    "section": "4.2 Flipping Coins",
    "text": "4.2 Flipping Coins\nNow let us look at flipping coins.\n\nA fair coin\nI can simulate a flip of a fair coin by:\n\nnp.random.choice(['Head', 'Tails'])\n\n'Head'\n\n\nIf I want 10 flips:\n\nno_of_coins = 10\nnp.random.choice(['Head', 'Tails'], no_of_coins)\n\narray(['Head', 'Head', 'Head', 'Head', 'Tails', 'Tails', 'Head', 'Head',\n       'Head', 'Tails'], dtype='&lt;U5')\n\n\nAlternatively, if you and I agree to consider any number in (0, .5] to be Tails and any number in (.5, 1) to be Heads, then the following works too.\n\ndef flip_coins(no_of_coins=1, probability=.5):\n    '''\n    Returns the number of values greater that \n    `probability` (considered as 'Heads').\n    '''\n    results = np.random.rand(no_of_coins)\n    no_of_heads = np.sum(results &gt; probability)\n    return no_of_heads\n\n\nno_of_coins = 1_000\nno_of_heads = flip_coins(no_of_coins)\nprint(f'Number of heads: {no_of_heads/no_of_coins*100:.2f}%')\n\nNumber of heads: 50.80%\n\n\nSince I plan to flip coins a bit more, I have created a function that gives me the number of heads. I have also used probability=.5 because we are dealing with a fair coin.\n\n\nA biased coin\nThe advantage of the second way of simulating coins is that we can easily simulate a biased coin simply by messing with probability. For example, let’s say I want a probability of .7 for a Head. Since we need to increase the chance of a number being considered a Head, we have to make probability=.3. Please make sure this makes sense to you or have a chat with someone to convince yourself.\n\nno_of_coins = 1_000\nno_of_heads = flip_coins(no_of_coins, probability = .3)\nprint(f'Number of heads: {no_of_heads/no_of_coins*100:.2f}%')\n\nNumber of heads: 72.10%\n\n\n\n\nA flipping experiment\nAccess to a good PRNG will allow you to run quick experiments. These will help you gain insights into more theoretical models of the same experiments. So, you can start using computers to better understand science and sometimes even see how the cogs tick in the machine.\nLet me demonstrate this with a simple experiment. Say we flip 10 fair coins in one go. What is the probability that 7 of them will come out Heads? There is an elegant theoretical answer to this question; I will come to that later. But first, let’s see if we can get a solution using our PRNG.\nWe can get an answer if we flip 10 coins several thousand times and count the number of heads. I.e. use flip_coins(10) many times and keep score.\n\nno_of_repeats = 10_000\nresult = [flip_coins(no_of_coins=10) for _ in range(no_of_repeats)]\nno_of_heads, heads_counts = np.unique(result, return_counts=True)\n\nnp.unique() with return_counts=True returns the unique values (of Heads) in the list and how many times they occur. We can get the probabilities by dividing the array with the counts by the number of repeats.\n\nheads_probability = heads_counts/no_of_repeats\n\nLet’s plot this data.\nplt.rcParam['figure.figsize'] = (10,5)\nplt.bar(no_of_heads, heads_counts);\nplt.xlabel('No of heads')\nplt.ylabel(f'Frequency out of {no_of_repeats}')\nplt.table([no_of_heads, heads_counts, heads_probability],\n          rowLabels=['No of Heads', 'Frequency', 'PRNG Probability'],\n          loc='bottom',\n          bbox=[0, -0.5, 1, 0.3])\n\n\n\n\n\nAs you can see, I have also included the various numbers in a Matplotlib table below (I adjusted the bbox values by trial and error.)\nThe theoretical explanation of how many times each head should appear is described by the binomial distribution. Understanding the basics of distributions (i.e. what they are and how to use them) is a critical bit of knowledge for anyone in a university.\nSciPy has various functions to calculate many of these important distributions. Let me show you how to do that now. First, let’s import the machinery for the binomial distribution.\n\nfrom scipy.stats import binom\n\nThe binomial distribution is discrete (i.e. because you have Heads or Tails, no half or quarter Heads). For such distributions, you get the various probabilities using the distribution’s pmf() (probability mass function or discrete density function). Don’t get distracted by the funky names; the pmf() just gives the probabilities for the various possibilities of the discrete distributions.\nThe probability we want is:\n\nbinom.pmf(k=7, n=10, p=.5)\n\n0.11718749999999999\n\n\nI will repeat: the binomial distribution gives us the probability of getting 7 heads when you throw 10 fair (p=.5) coins.\nFor the same completion, I will also calculate the rest of the values. This is absurdly easy:\n\nbinomial_probabilities = binom.pmf(k=no_of_heads, n=10, p=.5)\n\nLet me include these values in the plot to complete the story1"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/need/1_random_need.html#footnotes",
    "href": "docs/knowledge-lake/random_numbers/need/1_random_need.html#footnotes",
    "title": "Random Numbers (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you like to know how, please look for Matplotlib table().↩︎"
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#convert-the-image-to-grayscale",
    "href": "docs/knowledge-lake/image/2_images_good.html#convert-the-image-to-grayscale",
    "title": "Image Analysis (Good)",
    "section": "2.1 Convert the image to grayscale",
    "text": "2.1 Convert the image to grayscale\nGrayscale images (with just one layer) are more straightforward to analyze than RGB ones (with three layers). This is because a grayscale image has the same RGB values for each pixel. So, the first step is to convert the image into grayscale.\n\nResultCode\n\n\n \n\n\n\nfig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n\nax_original, ax_red, ax_green, ax_blue = ax\n\nax_original.imshow(img)\nax_original.set_title('Original (RGB)')\n\n# ALL row & ALL columns of layer 0\nax_red.imshow(img[:, :, 0], cmap='gray')\nax_red.set_title('Red Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 1\nax_green.imshow(img[:, :, 1], cmap='gray')\nax_green.set_title('Green Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 2\nax_blue.imshow(img[:, :, 2], cmap='gray')\nax_blue.set_title('Blue Channel(in Grayscale)')"
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#binarise",
    "href": "docs/knowledge-lake/image/2_images_good.html#binarise",
    "title": "Image Analysis (Good)",
    "section": "2.2 Binarise",
    "text": "2.2 Binarise\nThresholding, or binarising, converts an image into black and white depending on what features you want to analyse. For example, to separate the foreground (our subject, such as a cell) from the background.\nThe threshold(\\(t\\)) separates the image into background and foreground. I.e., everything below (\\(&lt;t\\)) will be black, and those values equal or above (\\(\\geq t\\)) will be white.\n\nFinding a threshold\nscikit-image offers some functions to help us find a threshold. You can pick one (I will try Otsu and Yen) or try all. Here is how it works.\nfrom skimage.filters import threshold_otsu, threshold_yen\n\nimg_original = io.imread('three-circles.png')\nimg_grey = rgb2grey(img_original)\n\nprint('{threshold_otsu(img_grey)=}')\nprint('{threshold_yen(img_grey)=}') \nWe can also try all the available methods using try_all_threshold()!\nfrom skimage.filters import try_all_threshold  \n\nfig, ax = try_all_threshold(img_grey, figsize=(10, 8), verbose=False)\nplt.show()\n\n\n\n\n\nYen seems to be the best.\n\n\nApplying a threshold\nOnce we have a threshold, we can apply it to binarise the image.\n\nResultCode\n\n\n \n\n\n\nthreshold = threshold_yen(img_grey)\nimg_binarised = img_grey &lt; threshold\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_original, ax_grey, ax_binarised = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape= {img_original.shape}')\n\nax_grey.imshow(img_grey, cmap='gray')\nax_grey.set_title(f'Grayscale: shape= {img_grey.shape}')\n\nax_binarised.imshow(img_binarised, cmap='gray')\nax_binarised.set_title(f'Binarised (Using Otsu)')"
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#labelling",
    "href": "docs/knowledge-lake/image/2_images_good.html#labelling",
    "title": "Image Analysis (Good)",
    "section": "2.3 Labelling",
    "text": "2.3 Labelling\nNote that skimage function measure.label() requires an image of type int\nOnce you have a binarised image, we can label features. More specifically, labeling ‘fills’ connected areas with an integer. For example, if you have three distinct regions, one will be filled with 1s, the next with 2s, and the third with 3s. This enables us to visualize the segments by a simple heat map.\nLet me first show you what happens. I will then explain a bit more.\n:::{.panel-tabset}"
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#result-2",
    "href": "docs/knowledge-lake/image/2_images_good.html#result-2",
    "title": "Image Analysis (Good)",
    "section": "2.4 Result",
    "text": "2.4 Result"
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#code-2",
    "href": "docs/knowledge-lake/image/2_images_good.html#code-2",
    "title": "Image Analysis (Good)",
    "section": "2.5 Code",
    "text": "2.5 Code\n\n# measure.label() requires an image of type int\nimg_labelled = measure.label(img_binarised.astype('uint8'))\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_original, ax_binarised, ax_labelled = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape= {img_original.shape}')\n\nax_binarised.imshow(img_binarised, cmap='gray')\nax_binarised.set_title(f'Binarised (Using Yen)')\n\n# Using jet to colour the different regions\nax_labelled.imshow(img_labelled, cmap='jet')\nax_labelled.set_title(f'Labelled Objects')\n\n\nMaking sense of labelling\nI mentioned that labeling simply ‘fills’ distinct regions with integer numbers. This means we should be able to use masking to isolate these regions."
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#st-region",
    "href": "docs/knowledge-lake/image/2_images_good.html#st-region",
    "title": "Image Analysis (Good)",
    "section": "2.6 1st region",
    "text": "2.6 1st region\nimg_masked = img_labelled == 1\nplt.imshow(img_masked)"
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#nd-region",
    "href": "docs/knowledge-lake/image/2_images_good.html#nd-region",
    "title": "Image Analysis (Good)",
    "section": "2.7 2nd region",
    "text": "2.7 2nd region\nimg_masked = img_labelled == 2\nplt.imshow(img_masked)"
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#rd-region",
    "href": "docs/knowledge-lake/image/2_images_good.html#rd-region",
    "title": "Image Analysis (Good)",
    "section": "2.8 3rd region",
    "text": "2.8 3rd region\nimg_masked = img_labelled == 3\nplt.imshow(img_masked)"
  },
  {
    "objectID": "docs/knowledge-lake/image/2_images_good.html#measuring",
    "href": "docs/knowledge-lake/image/2_images_good.html#measuring",
    "title": "Image Analysis (Good)",
    "section": "2.9 Measuring",
    "text": "2.9 Measuring"
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/2_images_good.html#convert-the-image-to-grayscale",
    "href": "docs/knowledge-lake/image_analysis/2_images_good.html#convert-the-image-to-grayscale",
    "title": "Image Analysis (Good)",
    "section": "2.1 Convert the image to grayscale",
    "text": "2.1 Convert the image to grayscale\nGrayscale images (with just one layer) are more straightforward to analyze than RGB ones (with three layers). This is because a grayscale image has the same RGB values for each pixel. So, the first step is to convert the image into grayscale.\n\nResultCode\n\n\n \n\n\n\nfrom skimage import io\nfrom skimage.color import rgb2grey\nimg_original = io.imread('three-circles.png')\nimg_grey = rgb2grey(img_original)\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\nax_original, ax_grey = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape={img_original.shape}')\n\nax_grey.imshow(img_grey, cmap='gray')\nax_grey.set_title(f'Grayscale: shape={img_grey.shape}')\n\nfor a in ax.flat:\n    a.axis('off')"
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/2_images_good.html#binarise",
    "href": "docs/knowledge-lake/image_analysis/2_images_good.html#binarise",
    "title": "Image Analysis (Good)",
    "section": "2.2 Binarise",
    "text": "2.2 Binarise\nThresholding, or binarising, converts an image into black and white depending on what features you want to analyse. For example, to separate the foreground (our subject, such as a cell) from the background.\nThe threshold(\\(t\\)) separates the image into background and foreground. I.e., everything below (\\(&lt;t\\)) will be black, and those values equal or above (\\(\\geq t\\)) will be white.\n\nFinding a threshold\nscikit-image offers some functions to help us find a threshold. You can pick one (I will try Otsu and Yen) or try all. Here is how it works.\nfrom skimage.filters import threshold_otsu, threshold_yen\n\nimg_original = io.imread('three-circles.png')\nimg_grey = rgb2grey(img_original)\n\nprint('{threshold_otsu(img_grey)=}')\nprint('{threshold_yen(img_grey)=}') \nWe can also try all the available methods using try_all_threshold()!\nfrom skimage.filters import try_all_threshold  \n\nfig, ax = try_all_threshold(img_grey, figsize=(10, 8), verbose=False)\nplt.show()\n\n\n\n\n\nYen seems to be the best.\n\n\nApplying a threshold\nOnce we have a threshold, we can apply it to binarise the image.\n\nResultCode\n\n\n \n\n\n\nthreshold = threshold_yen(img_grey)\nimg_binarised = img_grey &lt; threshold\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_original, ax_grey, ax_binarised = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape= {img_original.shape}')\n\nax_grey.imshow(img_grey, cmap='gray')\nax_grey.set_title(f'Grayscale: shape= {img_grey.shape}')\n\nax_binarised.imshow(img_binarised, cmap='gray')\nax_binarised.set_title(f'Binarised (Using Otsu)')"
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/2_images_good.html#labelling",
    "href": "docs/knowledge-lake/image_analysis/2_images_good.html#labelling",
    "title": "Image Analysis (Good)",
    "section": "2.3 Labelling",
    "text": "2.3 Labelling\nNote that skimage function measure.label() requires an image of type int\nOnce you have a binarised image, we can label features. More specifically, labeling ‘fills’ connected areas with an integer. For example, if you have three distinct regions, one will be filled with 1s, the next with 2s, and the third with 3s. This enables us to visualize the segments by a simple heat map.\nLet me first show you what happens. I will then explain a bit more.\n\nResultCode\n\n\n \n\n\n\n# measure.label() requires an image of type int\nimg_labelled = measure.label(img_binarised.astype('uint8'))\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_original, ax_binarised, ax_labelled = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape= {img_original.shape}')\n\nax_binarised.imshow(img_binarised, cmap='gray')\nax_binarised.set_title(f'Binarised (Using Yen)')\n\n# Using jet to colour the different regions\nax_labelled.imshow(img_labelled, cmap='jet')\nax_labelled.set_title(f'Labelled Objects')\n\n\n\n\n\nMaking sense of labelling\nI mentioned that labeling simply ‘fills’ distinct regions with integer numbers. This means we should be able to use masking to isolate these regions.\n\n\n\n\n\n\n1st region\nimg_masked = img_labelled == 1\nplt.imshow(img_masked)\n\n\n2nd region\nimg_masked = img_labelled == 2\nplt.imshow(img_masked)\n\n\n3rd region\nimg_masked = img_labelled == 3\nplt.imshow(img_masked)"
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/2_images_good.html#measuring",
    "href": "docs/knowledge-lake/image_analysis/2_images_good.html#measuring",
    "title": "Image Analysis (Good)",
    "section": "2.4 Measuring",
    "text": "2.4 Measuring\nNow that we have separated and labelled the regions, we can measure important characteristics (e.g. area, centroid) of these regions. Let me show you how.\n\nResultCode\n\n\n---------- Region 0 ----------\nCentre  : (87.0, 168.0)\nArea    : 20565\n\n\n---------- Region 1 ----------\nCentre  : (317.0, 283.0)\nArea    : 15193\n\n\n---------- Region 2 ----------\nCentre  : (317.0, 53.0)\nArea    : 6793\n\n\n\n# measure.label() requires an image of type int\nimg_labelled = measure.label(img_binarised.astype('uint8'))\nregion_info = measure.regionprops(img_labelled)\n\nno_of_regions = len(region_info)\n\nfor count, region in enumerate(region_info):\n    print('-'*10, f'Region {count}', '-'*10)\n    print(f'Centre\\t: {region.centroid}')\n    print(f'Area\\t: {region.area}')             # What is the area\n    print('\\n')\n\n\n\n\nThere are many more properties you can measure. Please see here for more information."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#reading-data-from-csv-or-excel-files.",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#reading-data-from-csv-or-excel-files.",
    "title": "Pandas (Need)",
    "section": "1.1 Reading data from csv or excel files.",
    "text": "1.1 Reading data from csv or excel files.\nOne of the most common file formats used to hold data that you will encounter are Excel files (.xls or .xlsx), csv(comma-separated-values) files or text files (.txt or .dat). Pandas offer ways to read all these files and (many) more. Let’s read in the data in dummy-class.xlsx.\n\ndf_class = pd.read_excel(\"dummy-class-1-of-2.xlsx\", skiprows = 1)\n\nI have used the option skiprows=1 because the first row of the Excel file contains a description that is not data. skiprows is one of many options we can specify.\nI have used the variable df_class to hold the dataframe. With Jupyter you can see the dataframe in a nicely formatted output by simply running:\n\nCodeOutput\n\n\ndf_class\n\n\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n0\n\n\n0\n\n\nBraiden Henson\n\n\nA3028967J\n\n\nPHY\n\n\nM\n\n\n‘18.96’\n\n\n20.205\n\n\n\n\n1\n\n\n1\n\n\nGustavo Vang\n\n\nA1282849W\n\n\nCHM\n\n\nF\n\n\n‘17.44’\n\n\n13.470\n\n\n\n\n2\n\n\n2\n\n\nRonin Christian\n\n\nA5408925A\n\n\nPHY\n\n\nM\n\n\n‘15.56’\n\n\n18.366\n\n\n\n\n3\n\n\n3\n\n\nOwen Anderson\n\n\nA6973859L\n\n\nLS\n\n\nF\n\n\n‘16.36’\n\n\n18.366\n\n\n\n\n4\n\n\n4\n\n\nKyla Young\n\n\nA5410124H\n\n\nPHY\n\n\nM\n\n\nNaN\n\n\n15.306\n\n\n\n\n5\n\n\n5\n\n\nWyatt Oliver\n\n\nA9568373Q\n\n\nPHY\n\n\nM\n\n\n‘14.088’\n\n\n12.246\n\n\n\n\n6\n\n\n6\n\n\nEssence Bauer\n\n\nA6824244G\n\n\nLS\n\n\nM\n\n\n‘16.72’\n\n\n16.530\n\n\n\n\n7\n\n\n7\n\n\nMaryjane Sandoval\n\n\nA9194090U\n\n\nLS\n\n\nF\n\n\n‘16.4’\n\n\n18.981\n\n\n\n\n8\n\n\n8\n\n\nCarl Trujillo\n\n\nA4828364M\n\n\nLS\n\n\nNB\n\n\n‘13.68’\n\n\n15.306\n\n\n\n\n9\n\n\n9\n\n\nHalle Fritz\n\n\nA4607700C\n\n\nLS\n\n\nF\n\n\n‘9.04’\n\n\n17.754\n\n\n\n\n10\n\n\n10\n\n\nMarie Hoffman\n\n\nA7067766E\n\n\nLS\n\n\nF\n\n\n‘16.88’\n\n\n19.593\n\n\n\n\n11\n\n\n11\n\n\nLilianna Kaufman\n\n\nA5569996J\n\n\nLS\n\n\nM\n\n\n‘17.0’\n\n\n26.328\n\n\n\n\n12\n\n\n12\n\n\nJaxon Chung\n\n\nA3202548I\n\n\nPHY\n\n\nM\n\n\n‘16.68’\n\n\n14.082\n\n\n\n\n13\n\n\n13\n\n\nZoey Oconnell\n\n\nA6131593U\n\n\nLS\n\n\nF\n\n\n‘14.128’\n\n\n22.041\n\n\n\n\n14\n\n\n14\n\n\nQuentin Kemp\n\n\nA7653832E\n\n\nCHM\n\n\nF\n\n\n‘15.72’\n\n\nNaN\n\n\n\n\n15\n\n\n15\n\n\nLeo Mayo\n\n\nA9462811I\n\n\nPHY\n\n\nF\n\n\n‘14.68’\n\n\n20.817\n\n\n\n\n16\n\n\n16\n\n\nCamden Williams\n\n\nA1218599T\n\n\nCHM\n\n\nF\n\n\n‘17.648’\n\n\n22.653\n\n\n\n\n17\n\n\n17\n\n\nSidney Wiggins\n\n\nA7210476B\n\n\nPHY\n\n\nNB\n\n\n‘14.68’\n\n\n19.593\n\n\n\n\n18\n\n\n18\n\n\nSolomon Fletcher\n\n\nA1512479K\n\n\nCHM\n\n\nF\n\n\n‘15.0’\n\n\n18.981\n\n\n\n\n19\n\n\n19\n\n\nRiley Christensen\n\n\nA7986368Y\n\n\nCHM\n\n\nF\n\n\n‘16.016’\n\n\n15.306\n\n\n\n\n20\n\n\n20\n\n\nMalik Becker\n\n\nA2727061A\n\n\nPHY\n\n\nM\n\n\nNaN\n\n\n12.858\n\n\n\n\n21\n\n\n21\n\n\nSkylar Hensley\n\n\nA2999472W\n\n\nCHM\n\n\nM\n\n\n‘17.648’\n\n\n23.877\n\n\n\n\n22\n\n\n22\n\n\nBraydon Duran\n\n\nA7116486E\n\n\nLS\n\n\nF\n\n\n‘14.36’\n\n\n15.918\n\n\n\n\n23\n\n\n23\n\n\nJalen Harmon\n\n\nA6931452S\n\n\nLS\n\n\nF\n\n\n‘16.88’\n\n\n22.041\n\n\n\n\n24\n\n\n24\n\n\nEan Haas\n\n\nA9649096H\n\n\nLS\n\n\nF\n\n\n‘14.36’\n\n\n19.593\n\n\n\n\n25\n\n\n25\n\n\nCarolina Mcmahon\n\n\nA1643380L\n\n\nPHY\n\n\nM\n\n\n‘18.08’\n\n\n12.858\n\n\n\n\n26\n\n\n26\n\n\nElian Potter\n\n\nA6787293E\n\n\nPHY\n\n\nM\n\n\n‘14.36’\n\n\n23.265\n\n\n\n\n27\n\n\n27\n\n\nLitzy White\n\n\nA5975988J\n\n\nPHY\n\n\nNB\n\n\n‘15.92’\n\n\n20.817\n\n\n\n\n28\n\n\n28\n\n\nNorah Miles\n\n\nA3699958T\n\n\nCHM\n\n\nM\n\n\nNaN\n\n\nNaN\n\n\n\n\n29\n\n\n29\n\n\nMariela Sheppard\n\n\nA1956366U\n\n\nLS\n\n\nNB\n\n\n‘11.0’\n\n\n18.366\n\n\n\n\n30\n\n\n30\n\n\nIsabela Stokes\n\n\nA1468689D\n\n\nCHM\n\n\nM\n\n\n‘16.8’\n\n\n18.366\n\n\n\n\n31\n\n\n31\n\n\nKathleen Rodriguez\n\n\nA3217320C\n\n\nPHY\n\n\nM\n\n\n‘17.76’\n\n\n22.653\n\n\n\n\n32\n\n\n32\n\n\nKatie Ayers\n\n\nA6867791C\n\n\nCBIO\n\n\nF\n\n\n‘10.28’\n\n\n16.530\n\n\n\n\n33\n\n\n33\n\n\nTucker Sloan\n\n\nA4080490P\n\n\nLS\n\n\nM\n\n\n‘15.04’\n\n\n17.754\n\n\n\n\n34\n\n\n34\n\n\nCarter Crane\n\n\nA7667457P\n\n\nLS\n\n\nM\n\n\n‘13.816’\n\n\n20.817"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#characteristics-to-notice",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#characteristics-to-notice",
    "title": "Pandas (Need)",
    "section": "1.2 Characteristics to notice",
    "text": "1.2 Characteristics to notice\nOkay, now you are bound to think that the above dataframe is no different from a typical spreadsheet. First, however, let me draw your attention to three different characteristics.\n\nThe first is the use of an index (leftmost column in bold) for each row (0 1 2 3...). This simple fact simplifies doing things with your data. I will show you some examples later.\nThe second is that a column (called a Pandas Series) can only have a single type of data. So, for example, you can have numbers or text; but not both.\nThe third is the presence of NaN (‘Not-a-Number’) when data is missing. Missing data is a common bane of real data; Pandas offers powerful ways to deal with such missing numbers transparently. I will show more later in this chapter.\n\nFor the moment,\n\n\n\n\n\n\nRemember\n\n\n\nRemember that a dataframe is like a spreadsheet but has an additional unique index for each row. This index plays an important role."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#head-and-tail",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#head-and-tail",
    "title": "Pandas (Need)",
    "section": "2.1 Head and Tail",
    "text": "2.1 Head and Tail\nReal data sets are bound to have more rows than the dummy class toy data set. You can take a quick peek at the top or bottom of the dataframe by using the head() and tail() methods, respectively.\ndf_class.head(3)\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n0\n\n\n0\n\n\nBraiden Henson\n\n\nA3028967J\n\n\nPHY\n\n\nM\n\n\n‘18.96’\n\n\n20.205\n\n\n\n\n1\n\n\n1\n\n\nGustavo Vang\n\n\nA1282849W\n\n\nCHM\n\n\nF\n\n\n‘17.44’\n\n\n13.470\n\n\n\n\n2\n\n\n2\n\n\nRonin Christian\n\n\nA5408925A\n\n\nPHY\n\n\nM\n\n\n‘15.56’\n\n\n18.366\n\n\n\n\ndf_class.tail(3)\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n32\n\n\n32\n\n\nKatie Ayers\n\n\nA6867791C\n\n\nCBIO\n\n\nF\n\n\n‘10.28’\n\n\n16.530\n\n\n\n\n33\n\n\n33\n\n\nTucker Sloan\n\n\nA4080490P\n\n\nLS\n\n\nM\n\n\n‘15.04’\n\n\n17.754\n\n\n\n\n34\n\n\n34\n\n\nCarter Crane\n\n\nA7667457P\n\n\nLS\n\n\nM\n\n\n‘13.816’\n\n\n20.817\n\n\n\n\nIf you do not specify the number of rows, it defaults to five."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#size-and-shape",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#size-and-shape",
    "title": "Pandas (Need)",
    "section": "2.2 Size and Shape",
    "text": "2.2 Size and Shape\nWe can get the size and shape of the dataframe by using shape, len() and columns.\n\ndf_class.shape\n\n(35, 7)\n\n\n\nlen(df_class)\n\n35\n\n\n\ndf_class.columns\n\nIndex(['Unnamed: 0', 'Name', 'Student No', 'Major', 'Gender', 'Test 2 (20%)',\n       'Test 1 (30%)'],\n      dtype='object')"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#summaries-i",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#summaries-i",
    "title": "Pandas (Need)",
    "section": "2.3 Summaries (I)",
    "text": "2.3 Summaries (I)\nPandas offer more powerful ways to get more valuable summaries of your dataset with the methods info() and describe().\n\ndf_class.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 35 entries, 0 to 34\nData columns (total 7 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Unnamed: 0    35 non-null     int64  \n 1   Name          35 non-null     object \n 2   Student No    35 non-null     object \n 3   Major         35 non-null     object \n 4   Gender        35 non-null     object \n 5   Test 2 (20%)  32 non-null     object \n 6   Test 1 (30%)  33 non-null     float64\ndtypes: float64(1), int64(1), object(5)\nmemory usage: 2.0+ KB\n\n\nThis information is very useful. You can quickly see the various columns, what type of data they contain and how many data points are present. This is a good place to spot missing data like in ‘Test 1’ and ‘Test 2’. The type object means str or English-like data. float64 is floating point data (i.e. decimal numbers). We also note that ‘Test 2’ is not a numerical type despite their data having numerical significance. So, one of the first things we should do is convert these to numerical types. I will focus on type conversion a bit later. However, let me ‘parachute’ some code here to continue our discussion.\n\nA quick digression\n\nThe problemCodeAfter the conversion\n\n\nPandas do not see ‘Test 2’ data as numbers because its data has additional' '.\n\ndf_class['Test 2 (20%)'].head(3)\n\n0    '18.96'\n1    '17.44'\n2    '15.56'\nName: Test 2 (20%), dtype: object\n\n\n\n\nHere, I first replace the ' with nothing and then convert the data using pd.to_numeric()\n\ndf_class['Test 2 (20%)'] = df_class['Test 2 (20%)'].str.replace(\"'\", \"\")\ndf_class['Test 2 (20%)'] = pd.to_numeric(df_class['Test 2 (20%)'])\n\n\n\n\ndf_class.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 35 entries, 0 to 34\nData columns (total 7 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Unnamed: 0    35 non-null     int64  \n 1   Name          35 non-null     object \n 2   Student No    35 non-null     object \n 3   Major         35 non-null     object \n 4   Gender        35 non-null     object \n 5   Test 2 (20%)  32 non-null     float64\n 6   Test 1 (30%)  33 non-null     float64\ndtypes: float64(2), int64(1), object(4)\nmemory usage: 2.0+ KB\n\n\n\n\n\n\n\nBack to the original discussion\nOkay, let’s continue discussing ways to peek into the file.\n\ndf_class.describe()\n\n       Unnamed: 0  Test 2 (20%)  Test 1 (30%)\ncount   35.000000     32.000000     33.000000\nmean    17.000000     15.405750     18.534455\nstd     10.246951      2.229394      3.487934\nmin      0.000000      9.040000     12.246000\n25%      8.500000     14.360000     15.918000\n50%     17.000000     15.820000     18.366000\n75%     25.500000     16.880000     20.817000\nmax     34.000000     18.960000     26.328000\n\n\ndescribe() gives us some summary statistics. By default, it only shows information relevant to the numerical columns. But let’s ask for more!\n\ndf_class.describe(include=\"all\")\n\n        Unnamed: 0            Name  ... Test 2 (20%) Test 1 (30%)\ncount    35.000000              35  ...    32.000000    33.000000\nunique         NaN              35  ...          NaN          NaN\ntop            NaN  Braiden Henson  ...          NaN          NaN\nfreq           NaN               1  ...          NaN          NaN\nmean     17.000000             NaN  ...    15.405750    18.534455\nstd      10.246951             NaN  ...     2.229394     3.487934\nmin       0.000000             NaN  ...     9.040000    12.246000\n25%       8.500000             NaN  ...    14.360000    15.918000\n50%      17.000000             NaN  ...    15.820000    18.366000\n75%      25.500000             NaN  ...    16.880000    20.817000\nmax      34.000000             NaN  ...    18.960000    26.328000\n\n[11 rows x 7 columns]\n\n\nunique tells us how many unique entries are present. It also shows information about the top one with the highest frequency. For example, there are four ‘Majors’ and LS appears 14 times. Gender has three unique values, with M appearing 16 times."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#summaries-ii",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#summaries-ii",
    "title": "Pandas (Need)",
    "section": "2.4 Summaries (II)",
    "text": "2.4 Summaries (II)\nI can also do the following to get quick summaries.\n\n\n\nData for a single column.\n\ndf_class['Test 1 (30%)'].mean()\n\n18.534454545454548\n\n\n\n\nData for multiple columns.\n\ndf_class[['Test 1 (30%)', 'Test 2 (20%)']].mean()\n\nTest 1 (30%)    18.534455\nTest 2 (20%)    15.405750\ndtype: float64\n\n\n\n\nShow me all the values\n\ndf_class['Major'].values\n\narray(['PHY', 'CHM', 'PHY', 'LS', 'PHY', 'PHY', 'LS', 'LS', 'LS', 'LS',\n       'LS', 'LS', 'PHY', 'LS', 'CHM', 'PHY', 'CHM', 'PHY', 'CHM', 'CHM',\n       'PHY', 'CHM', 'LS', 'LS', 'LS', 'PHY', 'PHY', 'PHY', 'CHM', 'LS',\n       'CHM', 'PHY', 'CBIO', 'LS', 'LS'], dtype=object)\n\n\n\n\n\ndf_class['Major'].unique()\n\narray(['PHY', 'CHM', 'LS', 'CBIO'], dtype=object)\n\n\n\n\n\ndf_class['Major'].value_counts()\n\nMajor\nLS      14\nPHY     12\nCHM      8\nCBIO     1\nName: count, dtype: int64\n\n\nWe can typecast these outputs to more familiar lists or dictionaries by:\n\ndf_class['Major'].value_counts().to_dict()\n\n{'LS': 14, 'PHY': 12, 'CHM': 8, 'CBIO': 1}\n\n\n\ndf_class['Major'].value_counts().to_list()\n\n[14, 12, 8, 1]\n\n\nThe following is useful too:\n\ndf_class['Major'].value_counts().index.to_list()\n\n['LS', 'PHY', 'CHM', 'CBIO']"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#dropping-unnecessary-columns",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#dropping-unnecessary-columns",
    "title": "Pandas (Need)",
    "section": "3.1 Dropping unnecessary columns",
    "text": "3.1 Dropping unnecessary columns\nLet me start by dropping the unnecessary column Unnamed: 0.\n\ndf_class.drop(columns=['Unnamed: 0'])\n\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n0\n\n\n0\n\n\nBraiden Henson\n\n\nA3028967J\n\n\nPHY\n\n\nM\n\n\n18.96\n\n\n20.205\n\n\n\n\n1\n\n\n1\n\n\nGustavo Vang\n\n\nA1282849W\n\n\nCHM\n\n\nF\n\n\n17.44\n\n\n13.470\n\n\n\n\n2\n\n\n2\n\n\nRonin Christian\n\n\nA5408925A\n\n\nPHY\n\n\nM\n\n\n15.56\n\n\n18.366\n\n\n\n\n3\n\n\n3\n\n\nOwen Anderson\n\n\nA6973859L\n\n\nLS\n\n\nF\n\n\n16.36\n\n\n18.366\n\n\n\n\n4\n\n\n4\n\n\nKyla Young\n\n\nA5410124H\n\n\nPHY\n\n\nM\n\n\nNaN\n\n\n15.306\n\n\n\n\nOkay, it seems to have worked but, if you look at df_class, you will see nothing has changed!\ndf_class.head()\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n0\n\n\n0\n\n\nBraiden Henson\n\n\nA3028967J\n\n\nPHY\n\n\nM\n\n\n18.96\n\n\n20.205\n\n\n\n\n1\n\n\n1\n\n\nGustavo Vang\n\n\nA1282849W\n\n\nCHM\n\n\nF\n\n\n17.44\n\n\n13.470\n\n\n\n\n2\n\n\n2\n\n\nRonin Christian\n\n\nA5408925A\n\n\nPHY\n\n\nM\n\n\n15.56\n\n\n18.366\n\n\n\n\n3\n\n\n3\n\n\nOwen Anderson\n\n\nA6973859L\n\n\nLS\n\n\nF\n\n\n16.36\n\n\n18.366\n\n\n\n\n4\n\n\n4\n\n\nKyla Young\n\n\nA5410124H\n\n\nPHY\n\n\nM\n\n\nNaN\n\n\n15.306\n\n\n\n\nWhat is happening is that the drop() command drops, but gives us a new dataframe without changing the original. There are two ways to change our original dataframe.\nOne is simply to update the variable.\ndf_class = df_class.drop(columns=['Unnamed: 0'])\nAnother is to set the option inplace=True so that drop() makes the modifications to the original dataframe, inplace.\n\ndf_class.drop(columns=['Unnamed: 0'], inplace=True)\n\nIf you do this, there will be no output displayed. Note also that not all methods offer the option inplace.\n\n\n\n\n\n\nRemember\n\n\n\nRemember to update the original dataframe if you make changes by either updating the variable or using inplace\n\n\nI find this behaviour of not modifying the original dataframe until we explicitly say so very useful. I can mess with the dataframe as I like and only update when I know I am ready."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#reorganising-columns",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#reorganising-columns",
    "title": "Pandas (Need)",
    "section": "3.2 Reorganising columns",
    "text": "3.2 Reorganising columns\nI like to reorganise my columns so that the student number is the first column. I can do it like this:\n\ncolumns_to_keep = ['Student No', 'Name', 'Major', 'Gender',\n                   'Test 1 (30%)', 'Test 2 (20%)']\n\ndf_class = df_class[columns_to_keep]\n\nIncidentally, I could have done the reorganisation and dropping with this single step. However, this can get tedious if you have a lot of columns."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#renaming-columns",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#renaming-columns",
    "title": "Pandas (Need)",
    "section": "3.3 Renaming columns",
    "text": "3.3 Renaming columns\nLet’s now rename some of the columns. This is very easy; we just have to supply a dictionary with the columns we want to update. The changes I want are:\n\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 1 (30%)': 'Test 1',\n                   'Test 2 (20%)': 'Test 2'}\n\ndf_class.rename(columns=new_column_info, inplace=True)\n\ndf_class.head()\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\n\n\n\n\n0\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPHY\n\n\nM\n\n\n20.205\n\n\n18.96\n\n\n\n\n1\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nCHM\n\n\nF\n\n\n13.470\n\n\n17.44\n\n\n\n\n2\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPHY\n\n\nM\n\n\n18.366\n\n\n15.56\n\n\n\n\n3\n\n\nA6973859L\n\n\nOwen Anderson\n\n\nLS\n\n\nF\n\n\n18.366\n\n\n16.36\n\n\n\n\n4\n\n\nA5410124H\n\n\nKyla Young\n\n\nPHY\n\n\nM\n\n\n15.306\n\n\nNaN"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#setting-the-index",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#setting-the-index",
    "title": "Pandas (Need)",
    "section": "3.4 Setting the index",
    "text": "3.4 Setting the index\nAt the moment, the indices are just numbers from 0 to 34. You can check this with\n\ndf_class.index\n\nRangeIndex(start=0, stop=35, step=1)\n\n\nHowever, I want to change it so I can refer to my rows using the MATRIC_NO (I will show you why this is useful later).\n\ndf_class.set_index('MATRIC_NO', drop=False, inplace=True)\n\nI am asking Pandas to use the values of the column ‘MATRIC_NO’ as indices for the rows. I put drop=False to prevent Pandas from dropping the column because I still like to keep it.\ndf_class.head()\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPHY\n\n\nM\n\n\n20.205\n\n\n18.96\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nCHM\n\n\nF\n\n\n13.470\n\n\n17.44\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPHY\n\n\nM\n\n\n18.366\n\n\n15.56\n\n\n\n\nA6973859L\n\n\nA6973859L\n\n\nOwen Anderson\n\n\nLS\n\n\nF\n\n\n18.366\n\n\n16.36\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPHY\n\n\nM\n\n\n15.306\n\n\nNaN"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#applying-changes",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#applying-changes",
    "title": "Pandas (Need)",
    "section": "3.5 Applying changes",
    "text": "3.5 Applying changes\nThere are a few things I like to change with the data.\n\nReplacing the abbreviation for the majors with full names,\nReplacing the abbreviation for the ‘M’, ‘F’, ‘NB’ with their full forms.\n\nThe Test 2 column has all its numbers between inverted commas (e.g. ‘16.36’ ). I like to remove these inverted commas.\n\nThe first two are very simple. But before we do anything, let’s get a list of all the unique items in the columns Majors and Gender.\n\ndf_class['Major'].unique()\n\narray(['PHY', 'CHM', 'LS', 'CBIO'], dtype=object)\n\ndf_class['Gender'].unique()\n\narray(['M', 'F', 'NB'], dtype=object)\n\n\nNow that we know the unique values, let’s make the changes.\n\nreplace_info = {\n    'PHY': 'Physics',\n    'CHM': 'Chemistry',\n    'LS': 'Life Sciences',\n    'CBIO': 'Comp. Biology',\n    'F': 'Female',\n    'M': 'Male',\n    'NB': 'Non-binary'\n}\n\ndf_class.replace(to_replace=replace_info, inplace=True)\n\nThere are a few ways to do the third. Let me show you the method that is the most versatile and uses the apply() method.\n\ndef clean(text):\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\ndf_class['Test 2'] = df_class['Test 2'].apply(clean)\n\nHere we use the apply() method to apply my function clean to the column ‘Test 2’. The missing numbers in this column are a bit annoying because they are replaced with NaN, which is a float, while everything else is a string (i.e. English). So, I have included a try-except statement to get around this. Again, I know the exact error because Python screamed it at me when I did not account for the error. The apply() method is super useful and can be used to do more complicated things. This is good enough for now.\nLet’s see what our handiwork looks like:\ndf_class.head()\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPhysics\n\n\nMale\n\n\n20.205\n\n\n18.96\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n13.470\n\n\n17.44\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPhysics\n\n\nMale\n\n\n18.366\n\n\n15.56\n\n\n\n\nA6973859L\n\n\nA6973859L\n\n\nOwen Anderson\n\n\nLife Sciences\n\n\nFemale\n\n\n18.366\n\n\n16.36\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#changing-column-type",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#changing-column-type",
    "title": "Pandas (Need)",
    "section": "3.6 Changing Column Type",
    "text": "3.6 Changing Column Type\nLet’s now change the column type for some of our columns so that they are more representative of the data they carry. First, remember that we have a problem with column ‘Test 2’ in that it is in English and not in number format viz.\n\ndf_class.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 35 entries, A3028967J to A7667457P\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   MATRIC_NO  35 non-null     object \n 1   Name       35 non-null     object \n 2   Major      35 non-null     object \n 3   Gender     35 non-null     object \n 4   Test 1     33 non-null     float64\n 5   Test 2     32 non-null     float64\ndtypes: float64(2), object(4)\nmemory usage: 1.9+ KB\n\n\nChanging type is done with a dictionary and is just as easy. I will also change the type of Major and Gender as they hold categorical data (i.e. data that are limited to a fixed number of options).\n\nnew_type_info = {'Major': 'category',\n                 'Gender': 'category',\n                 'Test 2': 'float'}\n\n# atype does NOT have an inplace option\ndf_class = df_class.astype(new_type_info)      \n\nLet’s check if this worked.\n\ndf_class.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 35 entries, A3028967J to A7667457P\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype   \n---  ------     --------------  -----   \n 0   MATRIC_NO  35 non-null     object  \n 1   Name       35 non-null     object  \n 2   Major      35 non-null     category\n 3   Gender     35 non-null     category\n 4   Test 1     33 non-null     float64 \n 5   Test 2     32 non-null     float64 \ndtypes: category(2), float64(2), object(2)\nmemory usage: 1.8+ KB\n\n\nYup, looks good."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#adding-a-new-column",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#adding-a-new-column",
    "title": "Pandas (Need)",
    "section": "3.7 Adding a new column",
    "text": "3.7 Adding a new column\nWe should create a new column called Total to hold the total score. This is laughably simple.\n\ndf_class[\"Total\"] = df_class[\"Test 1\"] + df_class[\"Test 2\"]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPhysics\n\n\nMale\n\n\n20.205\n\n\n18.96\n\n\n39.165\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n13.470\n\n\n17.44\n\n\n30.910\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPhysics\n\n\nMale\n\n\n18.366\n\n\n15.56\n\n\n33.926\n\n\n\n\nA6973859L\n\n\nA6973859L\n\n\nOwen Anderson\n\n\nLife Sciences\n\n\nFemale\n\n\n18.366\n\n\n16.36\n\n\n34.726\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#saving-to-file",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#saving-to-file",
    "title": "Pandas (Need)",
    "section": "3.8 Saving to file",
    "text": "3.8 Saving to file\nLet’s export our dataframe as an Excel file (many other options are possible!).\ndf_class.to_excel('finalised_scores.xlsx', index=False)\nI have used the index=False to tell Pandas not to write the index column."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#the-recipe-so-far",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#the-recipe-so-far",
    "title": "Pandas (Need)",
    "section": "3.9 The recipe so far",
    "text": "3.9 The recipe so far\nIdeally, what should follow now is fixing any missing data. However, I will postpone that discussion to the next chapter and move on to another important thing to do with dataframes. Before that, however, let me show you the full recipe we have so far been building.\n\ndf_class = pd.read_excel('dummy-class-1-of-2.xlsx', skiprows=1)\n\n#------------------ Drop and reorganise columns  -----------------#\ncolumns_to_keep = ['Student No', 'Name', 'Major', 'Gender',\n                   'Test 1 (30%)', 'Test 2 (20%)']\n\ndf_class = df_class[columns_to_keep]\n\n#------------------------- Rename columns ------------------------#\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 1 (30%)': 'Test 1',\n                   'Test 2 (20%)': 'Test 2'}\n\ndf_class.rename(columns=new_column_info, inplace=True)\n\n#--------------------- Set index to MATRIC_NO --------------------#\ndf_class.set_index('MATRIC_NO', drop=False, inplace=True)\n\n#-------------------------- Rename stuff -------------------------#\nreplace_info = {\n    'PHY': 'Physics',\n    'CHM': 'Chemistry',\n    'LS': 'Life Sciences',\n    'CBIO': 'Comp. Biology',\n    'F': 'Female',\n    'M': 'Male',\n    'NB': 'Non-binary'\n}\n\ndf_class.replace(to_replace=replace_info, inplace=True)\n\n#---------------- Remove the ' ' from column Test 2 --------------#\n\n\ndef clean(text):\n    '''\n    Function to remove ' ' from column 'Test 2'.\n    To be applied using apply()\n    '''\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\n\ndf_class['Test 2'] = df_class['Test 2'].apply(clean)\n\n#--------------- Convert column Test 2 to type float -------------#\nnew_type_info = {'Major': 'category',\n                 'Gender': 'category',\n                 'Test 2': 'float'}\n\ndf_class = df_class.astype(new_type_info)\n\n#------------------------ Add a new column -----------------------#\ndf_class[\"Total\"] = df_class[\"Test 1\"] + df_class[\"Test 2\"]\n\n#------------------------- Export the file -----------------------#\ndf_class.to_excel('finalised_scores.xlsx', index=False)\n\ndf_class.head()"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#locating-data",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#locating-data",
    "title": "Pandas (Need)",
    "section": "4.1 Locating data",
    "text": "4.1 Locating data\nPandas offer us two ways (loc and iloc) to access and locate the data in our dataframe.\n\nUsing iloc\nWe use iloc by specifying an index (like with a NumPy array). So, the following will show the contents from rows 11, 12, and 13 of columns 3 and 4 (Remember that Python is zero-indexed!).\ndf_class.iloc[10:13, 2:4]\n\n\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\nA7067766E\n\n\nLife Sciences\n\n\nFemale\n\n\n\n\nA5569996J\n\n\nLife Sciences\n\n\nMale\n\n\n\n\nA3202548I\n\n\nPhysics\n\n\nMale\n\n\n\n\n\n\nUsing loc\nWe use loc by specifying a names of rows (i.e. the indexes) or a mask. I will explain the mask part in a bit; for the moment, here is how to get the same output as above. Please note that the ‘numbers’ corresponding to rows from 11 to 14, in this case, are ‘names’.\ndf_class.loc[[\"A7067766E\", \"A5569996J\", \"A3202548I\"], [\"Major\", \"Gender\"]]\n\n\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\nA7067766E\n\n\nLife Sciences\n\n\nFemale\n\n\n\n\nA5569996J\n\n\nLife Sciences\n\n\nMale\n\n\n\n\nA3202548I\n\n\nPhysics\n\n\nMale"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#asking-questions-with-masks",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#asking-questions-with-masks",
    "title": "Pandas (Need)",
    "section": "4.2 Asking questions with masks",
    "text": "4.2 Asking questions with masks\nloc is most powerful with a mask (like NumPy) array. You can create a mask of (True and False) by asking a simple question. Here are some examples. \n\n\n\n\ndf_class[\"Major\"] == \"Chemistry\"\n\nMATRIC_NO\nA3028967J    False\nA1282849W     True\nA5408925A    False\nA6973859L    False\nA5410124H    False\nA9568373Q    False\nA6824244G    False\nA9194090U    False\nA4828364M    False\nA4607700C    False\nA7067766E    False\nA5569996J    False\nA3202548I    False\nA6131593U    False\nA7653832E     True\nA9462811I    False\nA1218599T     True\nA7210476B    False\nA1512479K     True\nA7986368Y     True\nA2727061A    False\nA2999472W     True\nA7116486E    False\nA6931452S    False\nA9649096H    False\nA1643380L    False\nA6787293E    False\nA5975988J    False\nA3699958T     True\nA1956366U    False\nA1468689D     True\nA3217320C    False\nA6867791C    False\nA4080490P    False\nA7667457P    False\nName: Major, dtype: bool\n\n\nas you can see, the ‘answer’ is a bunch of True and False values for the whole dataframe. You can then apply these True and False values to mask the values that are False like this:\ndf_class.loc[df_class[\"Major\"] == \"Chemistry\"]\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n13.470\n\n\n17.440\n\n\n30.910\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.720\n\n\nNaN\n\n\n\n\nA1218599T\n\n\nA1218599T\n\n\nCamden Williams\n\n\nChemistry\n\n\nFemale\n\n\n22.653\n\n\n17.648\n\n\n40.301\n\n\n\n\nA1512479K\n\n\nA1512479K\n\n\nSolomon Fletcher\n\n\nChemistry\n\n\nFemale\n\n\n18.981\n\n\n15.000\n\n\n33.981\n\n\n\n\nA7986368Y\n\n\nA7986368Y\n\n\nRiley Christensen\n\n\nChemistry\n\n\nFemale\n\n\n15.306\n\n\n16.016\n\n\n31.322\n\n\n\n\nA2999472W\n\n\nA2999472W\n\n\nSkylar Hensley\n\n\nChemistry\n\n\nMale\n\n\n23.877\n\n\n17.648\n\n\n41.525\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1468689D\n\n\nA1468689D\n\n\nIsabela Stokes\n\n\nChemistry\n\n\nMale\n\n\n18.366\n\n\n16.800\n\n\n35.166\n\n\n\n\n\n\nYou can invert a mask with the ~ like this.\ndf_class.loc[~(df_class[\"Major\"] == \"Life Sciences\")]\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPhysics\n\n\nMale\n\n\n20.205\n\n\n18.960\n\n\n39.165\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n13.470\n\n\n17.440\n\n\n30.910\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPhysics\n\n\nMale\n\n\n18.366\n\n\n15.560\n\n\n33.926\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9568373Q\n\n\nA9568373Q\n\n\nWyatt Oliver\n\n\nPhysics\n\n\nMale\n\n\n12.246\n\n\n14.088\n\n\n26.334\n\n\n\n\nA3202548I\n\n\nA3202548I\n\n\nJaxon Chung\n\n\nPhysics\n\n\nMale\n\n\n14.082\n\n\n16.680\n\n\n30.762\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.720\n\n\nNaN\n\n\n\n\nA9462811I\n\n\nA9462811I\n\n\nLeo Mayo\n\n\nPhysics\n\n\nFemale\n\n\n20.817\n\n\n14.680\n\n\n35.497\n\n\n\n\nA1218599T\n\n\nA1218599T\n\n\nCamden Williams\n\n\nChemistry\n\n\nFemale\n\n\n22.653\n\n\n17.648\n\n\n40.301\n\n\n\n\nA7210476B\n\n\nA7210476B\n\n\nSidney Wiggins\n\n\nPhysics\n\n\nNon-binary\n\n\n19.593\n\n\n14.680\n\n\n34.273\n\n\n\n\nA1512479K\n\n\nA1512479K\n\n\nSolomon Fletcher\n\n\nChemistry\n\n\nFemale\n\n\n18.981\n\n\n15.000\n\n\n33.981\n\n\n\n\nA7986368Y\n\n\nA7986368Y\n\n\nRiley Christensen\n\n\nChemistry\n\n\nFemale\n\n\n15.306\n\n\n16.016\n\n\n31.322\n\n\n\n\nA2727061A\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\nNaN\n\n\nNaN\n\n\n\n\nA2999472W\n\n\nA2999472W\n\n\nSkylar Hensley\n\n\nChemistry\n\n\nMale\n\n\n23.877\n\n\n17.648\n\n\n41.525\n\n\n\n\nA1643380L\n\n\nA1643380L\n\n\nCarolina Mcmahon\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\n18.080\n\n\n30.938\n\n\n\n\nA6787293E\n\n\nA6787293E\n\n\nElian Potter\n\n\nPhysics\n\n\nMale\n\n\n23.265\n\n\n14.360\n\n\n37.625\n\n\n\n\nA5975988J\n\n\nA5975988J\n\n\nLitzy White\n\n\nPhysics\n\n\nNon-binary\n\n\n20.817\n\n\n15.920\n\n\n36.737\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1468689D\n\n\nA1468689D\n\n\nIsabela Stokes\n\n\nChemistry\n\n\nMale\n\n\n18.366\n\n\n16.800\n\n\n35.166\n\n\n\n\nA3217320C\n\n\nA3217320C\n\n\nKathleen Rodriguez\n\n\nPhysics\n\n\nMale\n\n\n22.653\n\n\n17.760\n\n\n40.413\n\n\n\n\nA6867791C\n\n\nA6867791C\n\n\nKatie Ayers\n\n\nComp. Biology\n\n\nFemale\n\n\n16.530\n\n\n10.280\n\n\n26.810\n\n\n\n\n\n\nLet’s create another mask for all the Chemistry students who identify as Female.\n\n# Create mask\nmask = (df_class[\"Major\"] == \"Chemistry\") & (df_class[\"Gender\"] == 'Female')\n\n# Using mask\ndf_class.loc[mask, [\"Name\", \"Major\", \"Gender\"]]    \n\n\n\n\n\n\n\nName\n\n\nMajor\n\n\nGender\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\n\n\nA1218599T\n\n\nCamden Williams\n\n\nChemistry\n\n\nFemale\n\n\n\n\nA1512479K\n\n\nSolomon Fletcher\n\n\nChemistry\n\n\nFemale\n\n\n\n\nA7986368Y\n\n\nRiley Christensen\n\n\nChemistry\n\n\nFemale\n\n\n\n\nCool right!\n\n\nLet’s do another one. How about all students who scored less than 15% on Test 1?\n\nmask = df_class[\"Test 1\"] &lt; 15\ndf_class.loc[mask, [\"Name\", \"Major\", \"Test 1\"]]   \n\n\n\n\n\n\n\nName\n\n\nMajor\n\n\nTest 1\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\n13.470\n\n\n\n\nA9568373Q\n\n\nWyatt Oliver\n\n\nPhysics\n\n\n12.246\n\n\n\n\nA3202548I\n\n\nJaxon Chung\n\n\nPhysics\n\n\n14.082\n\n\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\n12.858\n\n\n\n\nA1643380L\n\n\nCarolina Mcmahon\n\n\nPhysics\n\n\n12.858"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/1_pandas_need.html#the-magic-of-groupby",
    "href": "docs/knowledge-lake/pandas/1_pandas_need.html#the-magic-of-groupby",
    "title": "Pandas (Need)",
    "section": "4.3 The magic of groupby()",
    "text": "4.3 The magic of groupby()\nLet me show you how to use the mesmerising, extremely powerful function groupby(). It is absurd how simple some things become with the right tools.\nHere are some examples.\n\n\n\nWhat are the means of the scores for the various test, according to Major?\ndf_class.groupby(by=[\"Major\"]).mean(numeric_only=True)\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMajor\n\n\n\n\n\n\n\n\n\n\n\n\nChemistry\n\n\n18.7755\n\n\n16.610286\n\n\n35.534167\n\n\n\n\nComp. Biology\n\n\n16.5300\n\n\n10.280000\n\n\n26.810000\n\n\n\n\nLife Sciences\n\n\n19.2420\n\n\n14.690286\n\n\n33.932286\n\n\n\n\nPhysics\n\n\n17.7555\n\n\n16.076800\n\n\n34.567000\n\n\n\n\nWe use numeric_only=True to tell Pandas not to try evaluating a mean for non-numeric (‘Gender’ in this case) columns. However, I find this a tad annoying and non-intuitive for other (see agg() below) actions. So, I prefer to explicitly ask for the columns I want.\ndf_class.groupby(by=[\"Major\"])[['Test 1', 'Test 2', 'Total']].mean()\n\n\nLet’s group-by Major and Gender.\ndf_class.groupby(by=[\"Major\", \"Gender\"])[['Test 1', 'Test 2', 'Total']].mean()\n\n\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\n\n\n\n\n\n\n\n\nChemistry\n\n\nFemale\n\n\n17.602500\n\n\n16.364800\n\n\n34.128500\n\n\n\n\nMale\n\n\n21.121500\n\n\n17.224000\n\n\n38.345500\n\n\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nComp. Biology\n\n\nFemale\n\n\n16.530000\n\n\n10.280000\n\n\n26.810000\n\n\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\nFemale\n\n\n19.285875\n\n\n14.801000\n\n\n34.086875\n\n\n\n\nMale\n\n\n20.357250\n\n\n15.644000\n\n\n36.001250\n\n\n\n\nNon-binary\n\n\n16.836000\n\n\n12.340000\n\n\n29.176000\n\n\n\n\nPhysics\n\n\nFemale\n\n\n20.817000\n\n\n14.680000\n\n\n35.497000\n\n\n\n\nMale\n\n\n16.871000\n\n\n16.498286\n\n\n34.166143\n\n\n\n\nNon-binary\n\n\n20.205000\n\n\n15.300000\n\n\n35.505000\n\n\n\n\n\n\nIf you don’t want the grouping parameters as indices, you can use as_index=False.\ndf_class.groupby(by=[\"Major\", \"Gender\"], as_index=False)[['Test 1', 'Test 2', 'Total']].mean()\n\n\n\n\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\n\n\n0\n\n\nChemistry\n\n\nFemale\n\n\n17.602500\n\n\n16.364800\n\n\n34.128500\n\n\n\n\n1\n\n\nChemistry\n\n\nMale\n\n\n21.121500\n\n\n17.224000\n\n\n38.345500\n\n\n\n\n2\n\n\nChemistry\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n3\n\n\nComp. Biology\n\n\nFemale\n\n\n16.530000\n\n\n10.280000\n\n\n26.810000\n\n\n\n\n4\n\n\nComp. Biology\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n5\n\n\nComp. Biology\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n6\n\n\nLife Sciences\n\n\nFemale\n\n\n19.285875\n\n\n14.801000\n\n\n34.086875\n\n\n\n\n7\n\n\nLife Sciences\n\n\nMale\n\n\n20.357250\n\n\n15.644000\n\n\n36.001250\n\n\n\n\n8\n\n\nLife Sciences\n\n\nNon-binary\n\n\n16.836000\n\n\n12.340000\n\n\n29.176000\n\n\n\n\n9\n\n\nPhysics\n\n\nFemale\n\n\n20.817000\n\n\n14.680000\n\n\n35.497000\n\n\n\n\n10\n\n\nPhysics\n\n\nMale\n\n\n16.871000\n\n\n16.498286\n\n\n34.166143\n\n\n\n\n11\n\n\nPhysics\n\n\nNon-binary\n\n\n20.205000\n\n\n15.300000\n\n\n35.505000\n\n\n\n\n\n\nIf you are only interested in a specific column, you can do this:\ndf_class.groupby(by=[\"Major\", \"Gender\"])[\"Test 1\"].mean()\n\n\n\n\n\n\n\n\nTest 1\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\n\n\n\n\nChemistry\n\n\nFemale\n\n\n17.602500\n\n\n\n\nMale\n\n\n21.121500\n\n\n\n\nNon-binary\n\n\nNaN\n\n\n\n\nComp. Biology\n\n\nFemale\n\n\n16.530000\n\n\n\n\nMale\n\n\nNaN\n\n\n\n\nNon-binary\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\nFemale\n\n\n19.285875\n\n\n\n\nMale\n\n\n20.357250\n\n\n\n\nNon-binary\n\n\n16.836000\n\n\n\n\nPhysics\n\n\nFemale\n\n\n20.817000\n\n\n\n\nMale\n\n\n16.871000\n\n\n\n\nNon-binary\n\n\n20.205000\n\n\n\n\n\n\nOther ‘in-built’ function you can use are count(), sum(), mean(), median(), min(), max(), mode(), std(), var(). However, you can far more out of groupby() by using agg() to apply any function. Let me show you how to apply some functions from NumPy.\ndf_class.groupby(by=[\"Major\", \"Gender\"])[['Test 1', 'Test 2', 'Total']].agg([np.mean, np.std]).round(2)\n\n\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\n\n\n\n\nmean\n\n\nstd\n\n\nmean\n\n\nstd\n\n\nmean\n\n\nstd\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChemistry\n\n\nFemale\n\n\n17.60\n\n\n4.07\n\n\n16.36\n\n\n1.14\n\n\n34.13\n\n\n4.33\n\n\n\n\nMale\n\n\n21.12\n\n\n3.90\n\n\n17.22\n\n\n0.60\n\n\n38.35\n\n\n4.50\n\n\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nComp. Biology\n\n\nFemale\n\n\n16.53\n\n\nNaN\n\n\n10.28\n\n\nNaN\n\n\n26.81\n\n\nNaN\n\n\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\nFemale\n\n\n19.29\n\n\n2.07\n\n\n14.80\n\n\n2.61\n\n\n34.09\n\n\n3.84\n\n\n\n\nMale\n\n\n20.36\n\n\n4.37\n\n\n15.64\n\n\n1.49\n\n\n36.00\n\n\n4.95\n\n\n\n\nNon-binary\n\n\n16.84\n\n\n2.16\n\n\n12.34\n\n\n1.90\n\n\n29.18\n\n\n0.27\n\n\n\n\nPhysics\n\n\nFemale\n\n\n20.82\n\n\nNaN\n\n\n14.68\n\n\nNaN\n\n\n35.50\n\n\nNaN\n\n\n\n\nMale\n\n\n16.87\n\n\n4.35\n\n\n16.50\n\n\n1.89\n\n\n34.17\n\n\n5.15\n\n\n\n\nNon-binary\n\n\n20.20\n\n\n0.87\n\n\n15.30\n\n\n0.88\n\n\n35.50\n\n\n1.74\n\n\n\n\n\n\nYou can even combine groupby() with a mask. For example, let’s see how all the Female students are doing.\n\nmask = df_class['Gender'] == 'Female'\ndf_class[mask].groupby(by=['Major']).mean(numeric_only=True)\n\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMajor\n\n\n\n\n\n\n\n\n\n\n\n\nChemistry\n\n\n17.602500\n\n\n16.3648\n\n\n34.128500\n\n\n\n\nComp. Biology\n\n\n16.530000\n\n\n10.2800\n\n\n26.810000\n\n\n\n\nLife Sciences\n\n\n19.285875\n\n\n14.8010\n\n\n34.086875\n\n\n\n\nPhysics\n\n\n20.817000\n\n\n14.6800\n\n\n35.497000\n\n\n\n\nJust for comparison,\ndf_class.groupby(by=[\"Gender\", \"Major\"]).mean(numeric_only=True)\n\n\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nGender\n\n\nMajor\n\n\n\n\n\n\n\n\n\n\n\n\nFemale\n\n\nChemistry\n\n\n17.602500\n\n\n16.364800\n\n\n34.128500\n\n\n\n\nComp. Biology\n\n\n16.530000\n\n\n10.280000\n\n\n26.810000\n\n\n\n\nLife Sciences\n\n\n19.285875\n\n\n14.801000\n\n\n34.086875\n\n\n\n\nPhysics\n\n\n20.817000\n\n\n14.680000\n\n\n35.497000\n\n\n\n\nMale\n\n\nChemistry\n\n\n21.121500\n\n\n17.224000\n\n\n38.345500\n\n\n\n\nComp. Biology\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\n20.357250\n\n\n15.644000\n\n\n36.001250\n\n\n\n\nPhysics\n\n\n16.871000\n\n\n16.498286\n\n\n34.166143\n\n\n\n\nNon-binary\n\n\nChemistry\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nComp. Biology\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\n16.836000\n\n\n12.340000\n\n\n29.176000\n\n\n\n\nPhysics\n\n\n20.205000\n\n\n15.300000\n\n\n35.505000"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#all-missing-data",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#all-missing-data",
    "title": "Pandas (Good)",
    "section": "1.1 All missing data",
    "text": "1.1 All missing data\nFirst, let’s see if we can get the exact locations of the missing data. Let’s start with the method isna().\ndf_class.isna()\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1282849W\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA5408925A\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6973859L\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA5410124H\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nTrue\n\n\nTrue\n\n\n\n\nA9568373Q\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6824244G\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA9194090U\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA4828364M\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA4607700C\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7067766E\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA5569996J\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA3202548I\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6131593U\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7653832E\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nTrue\n\n\nFalse\n\n\nTrue\n\n\n\n\nA9462811I\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1218599T\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7210476B\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1512479K\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7986368Y\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA2727061A\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nTrue\n\n\nTrue\n\n\n\n\nA2999472W\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7116486E\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6931452S\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA9649096H\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1643380L\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6787293E\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA5975988J\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA3699958T\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nTrue\n\n\nTrue\n\n\nTrue\n\n\n\n\nA1956366U\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1468689D\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA3217320C\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6867791C\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA4080490P\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7667457P\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nThe missing data is where you see True. I hope that you will agree that this information is overwhelming and utterly useless. So, we need to have a way to get more refined information."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#columns-and-rows-of-the-missing-data",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#columns-and-rows-of-the-missing-data",
    "title": "Pandas (Good)",
    "section": "1.2 Columns and rows of the missing data",
    "text": "1.2 Columns and rows of the missing data\nWe can exercise more finesse by combining isna() with any(). any() in this case just asks if there are any True values. The axis option will allow us to pick the rows or columns (Honestly, I can never remember which is which, so I just try 0 or 1 and see what I get).\n\ndf_class.isna().any(axis=0)      # Are there any True in the columns?\n\nMATRIC_NO    False\nName         False\nMajor        False\nGender       False\nTest 1        True\nTest 2        True\nTotal         True\ndtype: bool\n\n\n\ndf_class.isna().any(axis=1)      # Are there any True in the rows?\n\nMATRIC_NO\nA3028967J    False\nA1282849W    False\nA5408925A    False\nA6973859L    False\nA5410124H     True\nA9568373Q    False\nA6824244G    False\nA9194090U    False\nA4828364M    False\nA4607700C    False\nA7067766E    False\nA5569996J    False\nA3202548I    False\nA6131593U    False\nA7653832E     True\nA9462811I    False\nA1218599T    False\nA7210476B    False\nA1512479K    False\nA7986368Y    False\nA2727061A     True\nA2999472W    False\nA7116486E    False\nA6931452S    False\nA9649096H    False\nA1643380L    False\nA6787293E    False\nA5975988J    False\nA3699958T     True\nA1956366U    False\nA1468689D    False\nA3217320C    False\nA6867791C    False\nA4080490P    False\nA7667457P    False\ndtype: bool"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#more-details-of-the-missing-numbers",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#more-details-of-the-missing-numbers",
    "title": "Pandas (Good)",
    "section": "1.3 More details of the missing numbers",
    "text": "1.3 More details of the missing numbers\nDo you see that we can use the last output as a mask to locate the rows that have missing numbers? Let me show you the following:\n\nmask_for_nan = df_class.isna().any(axis=1)\ndf_class[mask_for_nan]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.72\n\n\nNaN\n\n\n\n\nA2727061A\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#dealing-with-missing-numbers",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#dealing-with-missing-numbers",
    "title": "Pandas (Good)",
    "section": "1.4 Dealing with missing numbers?",
    "text": "1.4 Dealing with missing numbers?\nHow you handle missing numbers must depend on what type of data you are dealing with.\nHere are a few things you can do:\n\nReplacing the missing data with a constant value\nFor our dummy class, the numbers are missing because the students were missing from the tests. So, it is easy; we give them zero (the fourth option). The easiest way to do this is using fillna(). I will use a crazy value first so that you can see what is going on.\n\ndf_class.loc[:, ['Test 1', 'Test 2', 'Total']].fillna(99999, inplace=True)\ndf_class[mask_for_nan]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.72\n\n\nNaN\n\n\n\n\nA2727061A\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nDo you see it? Yes, it’s that easy.\nLet me first replace the crazy number with 0 before I forget.\n\ndf_class.replace(99999, 0, inplace = True)\ndf_class[mask_for_nan]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.72\n\n\nNaN\n\n\n\n\nA2727061A\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nYes, there is a problem with the ‘Total’ column, but we can deal with that later since we have to modify it anyway.\n\n\nExpunging all columns that have missing data (Drastic!)\nI am not going to do this right now, but here is one way you can:\nmask_for_nan_columns = df_class.isna().any(axis=0)\ncolumns_to_keep = df_class.columns[~mask_for_nan_columns].values\ndf_class = df_class[columns_to_keep]\nI inverted (using ~) the mask to pick those columns that are NaN free. Then I just updated df_class with only those columns.\nThis works too:\ndf_class.dropna(axis = 0, inplace=True)\n\n\nExpunging all rows that have missing data (Drastic!)\nAgain, I am not going to do this right now, but here is one way you can:\ndf_class = df_class[~mask_for_nan]\nAgain, I just inverted my mask. And, yet again, the following works too:\ndf_class.dropna(axis = 1, inplace=True)\n\n\nReplace missing data with a representative value (like an average)\nYet, again, I am not going to do this right now, but here is one way you can:\ntest_mean = df_class.loc['Test 1'].mean()\ndf.loc['Test 1'].fillna(test_mean)"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#itterating-over-a-dataframe",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#itterating-over-a-dataframe",
    "title": "Pandas (Good)",
    "section": "1.5 Itterating over a dataframe",
    "text": "1.5 Itterating over a dataframe\nI was looking for a way to introduce iterating (looping) over a dataframe. Now is an excellent opportunity because we can use it to replace the missing data. But this is certainly not the best way because there are highly optimised weapons in the Panda’s arsenal like apply(), fillna() and so on. However, I (lazily) often find myself using loops because they are plain and simple to get started and understand.\nYou can loop through your dataframe using the method itterrows() as follows. It spits out the index and the row for every iteration.\nfor index, row in df_class.iterrows():\n    name = row['Name']\n\n    for column in ['Test 1', 'Test 2']:\n        if np.isnan(row[column]):\n            print(f'{index}: {name:&lt;15}  missing data for {column}')\n            df_class.loc[index, column] = 0\nIf you run this, you should end up with the following:\n    A5410124H: Kyla Young       missing data for Test 2\n    A7653832E: Quentin Kemp     missing data for Test 1\n    A2727061A: Malik Becker     missing data for Test 2\n    A3699958T: Norah Miles      missing data for Test 1\n    A3699958T: Norah Miles      missing data for Test 2\nYou can extract the various columns from the row variable just as you do with a dataframe (loc and iloc works too). I have used isnan() from NumPy to check for NaN because you cannot use ==. I am also using the index to update the original value of the dataframe. There are cautionary tales (e.g. see Nice of Loops) about changing something while iterating over it. However, it is safe in this case."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#the-complete-recipe",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#the-complete-recipe",
    "title": "Pandas (Good)",
    "section": "2.1 The complete recipe",
    "text": "2.1 The complete recipe\nLet me show you the complete recipe for everything we have done in this part. I have reordered some actions (e.g. creation of the ‘Total’ column) and modified a few things (e.g. df_class_1 instead of df_class). I have also removed the excessive comments from the previous version. Everything should flow nicely and make sense to you.\n\n\n# -----------------------------------------------------------------#\n#                           First file                            #\n# -----------------------------------------------------------------#\ndf_class_1 = pd.read_excel('dummy-class-1-of-2.xlsx', skiprows=1)\n\ncolumns_to_keep = ['Student No', 'Name', 'Major', 'Gender',\n                   'Test 1 (30%)', 'Test 2 (20%)']\ndf_class_1 = df_class_1[columns_to_keep]\n\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 1 (30%)': 'Test 1',\n                   'Test 2 (20%)': 'Test 2'}\ndf_class_1.rename(columns=new_column_info, inplace=True)\n\ndf_class_1.set_index('MATRIC_NO', drop=False, inplace=True)\n\nreplace_info = {\n    'PHY': 'Physics',\n    'CHM': 'Chemistry',\n    'LS': 'Life Sciences',\n    'CBIO': 'Comp. Biology',\n    'F': 'Female',\n    'M': 'Male',\n    'NB': 'Non-binary'\n}\ndf_class_1.replace(to_replace=replace_info, inplace=True)\n\n\ndef clean(text):\n    '''\n    Function to remove ' ' from column 'Test 2'.\n    To be applied using apply()\n    '''\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\n\ndf_class_1['Test 2'] = df_class_1['Test 2'].apply(clean)\n\nnew_type_info = {'Major': 'category',\n                 'Gender': 'category',\n                 'Test 2': 'float'}\ndf_class_1 = df_class_1.astype(new_type_info)\n\n# -----------------------------------------------------------------#\n#                           Second file                           #\n# -----------------------------------------------------------------#\ndf_class_2 = pd.read_excel('dummy-class-2-of-2.xlsx')\n\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 3 (50%)': 'Test 3'}\ndf_class_2.rename(columns=new_column_info, inplace=True)\n\ndf_class_2.set_index('MATRIC_NO', inplace=True)\n\n# ---------- Concatenate the two dataframes along columns ---------#\ndf_combined = pd.concat([df_class_1, df_class_2], axis=1)\n\n# -----------------------------------------------------------------#\ndf_combined.loc[:, [\"Test 1\", \"Test 2\", \"Test 3\"]].fillna(0, inplace=True)\ndf_combined[\"Total\"] = df_combined[[\"Test 1\", \"Test 2\", \"Test 3\"]].sum(axis=1)\ndf_combined.sort_values(by='Total', inplace=True)\ndf_combined = df_combined.round(2)\ndf_combined.to_excel('finalised_scores.xlsx', index=False)\ndf_combined.head()\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTest 3\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n0.00\n\n\n\n\nA6867791C\n\n\nA6867791C\n\n\nKatie Ayers\n\n\nComp. Biology\n\n\nFemale\n\n\n16.53\n\n\n10.28\n\n\nNaN\n\n\n26.81\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.31\n\n\nNaN\n\n\n17.5\n\n\n32.81\n\n\n\n\nA7210476B\n\n\nA7210476B\n\n\nSidney Wiggins\n\n\nPhysics\n\n\nNon-binary\n\n\n19.59\n\n\n14.68\n\n\nNaN\n\n\n34.27\n\n\n\n\nA7667457P\n\n\nA7667457P\n\n\nCarter Crane\n\n\nLife Sciences\n\n\nMale\n\n\n20.82\n\n\n13.82\n\n\nNaN\n\n\n34.63"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#barcharts",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#barcharts",
    "title": "Pandas (Good)",
    "section": "3.1 Barcharts",
    "text": "3.1 Barcharts\n\n\n\n\ngrp = df_combined.groupby(['Gender'])[\"Total\"]\ngrp.mean().plot(kind='barh');\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ngrp = df_combined.groupby(['Major'])[[\"Test 1\", \"Test 2\", \"Test 3\"]]\ngrp.mean().plot(kind='barh')\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#histograms",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#histograms",
    "title": "Pandas (Good)",
    "section": "3.2 Histograms",
    "text": "3.2 Histograms\n\n\n\nIf we like, we can create the axes that Pandas will use. Then, you can pass the axis using the ax option. Let me show you.\n\nfix, ax = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=(10,8))\ndf_combined['Total'].plot.hist(ax=ax[0, 0])\ndf_combined['Test 1'].plot.hist(ax=ax[0, 1])\ndf_combined['Test 2'].plot.hist(ax=ax[1, 0])\ndf_combined['Test 3'].plot.hist(ax=ax[1, 1])\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#pie",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#pie",
    "title": "Pandas (Good)",
    "section": "3.3 Pie",
    "text": "3.3 Pie\n\n\n\n\ndf_combined.groupby('Major').size().plot.pie(autopct=\"%d\")\n\n\n\n\n\n\n\n\nautopct specifies the format in which the percentages are displayed."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#boxplots",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#boxplots",
    "title": "Pandas (Good)",
    "section": "3.4 Boxplots",
    "text": "3.4 Boxplots\nBoxplots are amazing at conveying a lot of statistical information efficiently. You will not go wrong if you get into the habit of using them often.\n\n\n\nThis plots all the numerical columns as boxplots.\n\ndf_combined.boxplot()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndf_combined.boxplot(by='Major', column=['Total'], vert=False);\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndf_combined.boxplot(by='Major',\n                    column=['Test 1', 'Test 2', 'Test 3', 'Total'],\n                    vert=False, figsize=(8, 6));\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThere is more that you can do; you can find more details about plotting with Pandas at visualisation page of the Pandas documentation."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/2_pandas_good.html#footnotes",
    "href": "docs/knowledge-lake/pandas/2_pandas_good.html#footnotes",
    "title": "Pandas (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI dare you that the same using two spreadsheets is going to be inefficient, error-prone, and a headache.↩︎\nActually, Seaborn is a wonderful package that add on to Matplotlib.↩︎"
  },
  {
    "objectID": "docs/python-basics/05_functions/2_functions_good.html#assert",
    "href": "docs/python-basics/05_functions/2_functions_good.html#assert",
    "title": "Functions (Good)",
    "section": "1.1 assert",
    "text": "1.1 assert\nPython has a command called assert that can check a condition and halt execution if necessary. It also gives the option of printing a message.\nThe basic syntax is as follows:\nassert condition-to-check, message\nassert stops the flow if the condition fails. Here is an example.\nassert x &gt;= 0, \"x is becoming negative!\"\nThe program will run for as long as the condition is True. If it fails, then an AssertationError is raised, and the program stops running!\n\n\n\n\n\n\nThe following will run without a problem.\nx = 10\nassert x &gt;= 0, \"x is becoming negative!\"\n\n\nThe following will throw an error and stop.\nx = -1\nassert x &gt;= 0, \"x is becoming negative!\""
  },
  {
    "objectID": "docs/python-basics/05_functions/2_functions_good.html#try-except",
    "href": "docs/python-basics/05_functions/2_functions_good.html#try-except",
    "title": "Functions (Good)",
    "section": "1.2 try-except",
    "text": "1.2 try-except\nA technical name for things going wrong is exceptions. For example, division by zero will raise a ZeroDivisionError. An exception left unhandled will halt the flow of the programme. However, if you are a control freak, Python offers an (absurdly) simple ‘try-except’ structure to catch and handle these exceptions yourself.\nThe try-except syntax can also ensure that your programme can handle some situations beyond your control. For example, when I use Python to speak to the Canvas server, I use try-except to handle situations when the server does not respond.\nLet me show you how to use the try-except flow control statement.\nWe can solicit a user response using the input() function. Let’s say we do this and ask for a number, as shown in the snippet below.\nnumber=input(\"Give me a number and I will calculate its square.\")\nsquare=int(number)**2              # Convert English to number\nprint(f'The square of {number} is {square}!')\nThis will work fine if the typecasting int(number) makes sense. What if the input is not a number but something else like ‘hahaha’?\nLet’s use the try-except to get around this problem.\ntry:\n    number=input(\"Give me a number and I will calculate its square.\")\n    square=int(number)**2\n    print(f'The square of {number} is {square}!')\nexcept:\n    print(f\"Oh oh! I cannot square {number}!\")\nNotice how I have enclosed (and protected) that part of the code that we think can potentially lead to trouble in the try block. If something (anything) goes wrong, Python will ignore the error and run the code in the except block.\nYou can have more control over how the expetions are handled with a try-except block. However, we do not have to worry about that at this point."
  },
  {
    "objectID": "docs/python-basics/05_functions/2_functions_good.html#a-simple-suggestion",
    "href": "docs/python-basics/05_functions/2_functions_good.html#a-simple-suggestion",
    "title": "Functions (Good)",
    "section": "1.3 A simple suggestion",
    "text": "1.3 A simple suggestion\nWhen starting out with some code, it is always good for your code to signal to the outside world that it has finished certain milestones. A ‘soft’ way to do this is to include ‘print()’ statements here and there to let the outside world know what is happening in the innards of your program. Otherwise, you will stare at a blank cell, wondering what is happening."
  },
  {
    "objectID": "docs/python-basics/05_functions/2_functions_good.html#positional-keyword-and-default-arguments",
    "href": "docs/python-basics/05_functions/2_functions_good.html#positional-keyword-and-default-arguments",
    "title": "Functions (Good)",
    "section": "2.1 Positional, keyword and default arguments",
    "text": "2.1 Positional, keyword and default arguments\nIn the past chapter, some of you may have noticed that I was (carelessly) switching between passing two styles of passing arguments to the function greeting(). I wrote greeting('Super Man') or greeting(name='Super Man'). We need to talk a bit more about this so that you are not bewildered when you see other people’s code.\nThere are three ‘ways’ to pass a value to an argument. I will call them positional, keyword or default. To make this clearer, consider the following function.\n\ndef side_by_side(a, b, c=42):\n    return f'{a: 2d}|{b: 2d}|{c: 2d}'\n\nHere are three ways I can use this function.\n\n\n\n\n\n\nPositional\nside_by_side(1, 2, 3)\nHere, I am telling Python to assign 1, 2, 3 to a, b, c using the positional order of the arguments.\n\n\nKeywords\nside_by_side(c=3, b=1, a=2)\nHere, I explicitly specify the keyword to assign the values to each of a, b, c. (No, the order does not matter)\n\n\nDefault\nside_by_side(1, b=2)\nHere, since c is optional, I can choose not to specify it (of course, provided I want c to be 1).\n\n\n\nBelow are some examples of how you can combine these three styles. However, one style (keyword followed by positional) confuses Python and won’t work.\n\nside_by_side(1, 2)           # Two positional, 1 default\n## ' 1| 2| 42'\nside_by_side(1, 2, 3)        # Three positional\n## ' 1| 2| 3'\nside_by_side(a=1, b=2)       # Two keyword, 1 default\n## ' 1| 2| 42'\nside_by_side(c=3, b=1, a=2)  # Three keyword\n## ' 2| 1| 3'\nside_by_side(1, c=3, b=2)    # One positional, 2 keyword\n## ' 1| 2| 3'\nside_by_side(1, b=2)         # One positional, 1 keyword, 1 default\n## ' 1| 2| 42'\n\nLet me reiterate that the following will not work because Python cannot unambiguously determine the position of 1?\n# Keywords cannot be followed \n# by positional arguments\nside_by_side(a=2, 1)      # Won't work."
  },
  {
    "objectID": "docs/python-basics/05_functions/2_functions_good.html#docstrings",
    "href": "docs/python-basics/05_functions/2_functions_good.html#docstrings",
    "title": "Functions (Good)",
    "section": "2.2 Docstrings",
    "text": "2.2 Docstrings\nPython has a docstring feature that allows us to document what a function does inside the function. This documentation (i.e., the docstring) is displayed when we ask Python to show us the help info using help().\nHere is a simple example.\n\ndef side_by_side(a, b, c=42):\n    '''\n    A test function to demonstrate how \n    positional, keyword and default arguments \n    work.\n    '''\n    return f'{a: 2d}|{b: 2d}|{c: 2d}'\n\nA docstring needs to be sandwiched between a pair of ''' (or \"\"\") and can span multiple lines.\nLet’s see if it works by asking for help.\n\nhelp(side_by_side)\n\nHelp on function side_by_side in module __main__:\n\nside_by_side(a, b, c=42)\n    A test function to demonstrate how \n    positional, keyword and default arguments \n    work.\n\n\nDocstrings can be used for writing multiline comments, but the practice is frowned upon by Puritans; so if you misuse it be ready for their ire!"
  },
  {
    "objectID": "docs/python-basics/05_functions/2_functions_good.html#function-are-first-class-citizens",
    "href": "docs/python-basics/05_functions/2_functions_good.html#function-are-first-class-citizens",
    "title": "Functions (Good)",
    "section": "2.3 Function are first-class citizens",
    "text": "2.3 Function are first-class citizens\nPython functions are called first-class citizens because they have the same privileges as variables. This opens up useful possibilities for scientific programming because we can pass a function as an argument to another function!\nConsider this:\n\ndef my_function(angle, trig_function):\n        return trig_function(angle)\n\n# Let's use the function\nmy_function(np.pi/2, np.sin)        \n## 1.0\nmy_function(np.pi/2, np.cos)        \n## 6.123233995736766e-17\nmy_function(np.pi/2, lambda x: np.cos(2*x))  \n## -1.0\n\nNote: When we pass a function as an argument, we do not include the parenthesis ()."
  },
  {
    "objectID": "docs/python-basics/05_functions/2_functions_good.html#more-about-unpacking",
    "href": "docs/python-basics/05_functions/2_functions_good.html#more-about-unpacking",
    "title": "Functions (Good)",
    "section": "2.4 More about unpacking",
    "text": "2.4 More about unpacking\nThere is more to unpacking. For example, unpacking can make extracting information from lists and arrays a breeze. Here are some examples.\n\n\n\n\nx, y, z = [1, 2, 3]\nx, y, z\n\n(1, 2, 3)\n\n\n\n\n\nx, y, z = np.array([1, 2, 3])\nx, y, z\n\n(1, 2, 3)\n\n\n\n\n\nx, *y, z = np.array([1, 2, 3, 4, 5])\nx, y, z\n\n(1, [2, 3, 4], 5)\n\n\n\n\n\nx, *_, y = [1, 2, 3, 4, 5]\nx, y\n\n(1, 5)"
  },
  {
    "objectID": "docs/python-basics/05_functions/1_functions_need_exercises.html",
    "href": "docs/python-basics/05_functions/1_functions_need_exercises.html",
    "title": "Functions (Need) Exercises",
    "section": "",
    "text": "Exercise 1 (Do you know why?) ☻\nThe following code works as expected despite not having an else statement. Please use a Markdown cell to explain why?\ndef greeting(name):\n    if name == 'Batman':\n        return 'Hello Batman! So, nice to meet you!'\n    return f'Hello {name}!'\n\n\nExercise 2 (Chubby or not) ☻\nWrite a Python function named calculate_bmi.\n\nThe function should take two parameters:\nweight (in kilograms) and height (in meters).\nThe function should calculate the BMI (Body Mass Index) using the formula BMI = weight / (height ** 2).\nBased on the calculated BMI, the function should return a string indicating the BMI category based on the following criteria:\n\n\n\n\n\nCategory\nBMI Range\n\n\n\n\nUnderweight\nBMI less than 18.5\n\n\nNormal weight\nBMI between 18.5 and 24.9\n\n\nOverweight\nBMI between 25 and 29.9\n\n\nObesity\nBMI 30 or more\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#lets-compare",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#lets-compare",
    "title": "Storing Data (Need)",
    "section": "1.1 Let’s compare",
    "text": "1.1 Let’s compare\nLet me show you how to store the same information (in this case, some superhero data) using lists, arrays and dictionaries.\nPython Lists\n\npy_super_names = [\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\npy_real_names = [\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\nNumpy Arrays\n\nnp_super_names = np.array([\"Black Widow\", \"Iron Man\", \"Doctor Strange\"])\nnp_real_names = np.array([\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"])\n\nDictionary\n\nsuperhero_info = {\n    \"Natasha Romanoff\": \"Black Widow\",\n    \"Tony Stark\": \"Iron Man\",\n    \"Stephen Strange\": \"Doctor Strange\"\n}\n\nNotice:\n\nDictionaries use a key and an associated value separated by a :\nThe dictionary very elegantly holds the real and superhero names in one structure while we need two lists (or arrays) for the same data.\nFor lists and arrays, the order matters. I.e. ‘Iron Man’ must be in the same position as ‘Tony Stark’ for things to work.\n\nLists (and arrays) offer many features that dictionaries don’t and vice versa. I will demonstrate these in a bit. Which data storage strategy to choose will depend on the problem you are trying to solve. More on this later; for the moment…\n\n\n\n\n\n\nRemember\n\n\n\nThere are three basic ways of storing data:\n\nlists,\nNumPy arrays and\ndictionaries.\n\n\n\nBy the way,\n\nI added py and np in front of the variable for clarity. You can choose any name for the variables (provided that they are not a Python keyword like for, if).\nI am being lazy; when I say ‘arrays’, I mean ‘NumPy arrays’, and when I say ‘lists’, I mean ‘Python lists’."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#accessing-data-from-a-list-or-array",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#accessing-data-from-a-list-or-array",
    "title": "Storing Data (Need)",
    "section": "1.2 Accessing data from a list (or array)",
    "text": "1.2 Accessing data from a list (or array)\nTo access data from lists (and arrays), we need to use an index corresponding to the data’s position. Python is a zero-indexed language, meaning it starts counting at 0. So if you want to access a particular element in the list (or array), you need to specify the relevant index starting from zero. The image below shows the relationship between the position and index.\n\n\n\n\n\n\npy_super_names = [\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\npy_real_names = [\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\n\n\n\n\npy_real_names[0]\n\n'Natasha Romanoff'\n\n\n\n\n\npy_super_names[0]\n\n'Black Widow'\n\n\n\n\nUsing a negative index allows us to count from the back of the list. For instance, using the index -1 will give the last element. This is super useful because we can easily access the last element without knowing the list size.\n\npy_super_names[2]    # Forward indexing \n                     # We need to know the size \n                     # beforehand for this to work.\n\n'Doctor Strange'\n\npy_super_names[-1]   # Reverse indexing\n\n'Doctor Strange'\n\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nData in lists (and arrays) must be accessed using a zero-based index."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#accessing-data-from-a-dictionary",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#accessing-data-from-a-dictionary",
    "title": "Storing Data (Need)",
    "section": "1.3 Accessing data from a dictionary",
    "text": "1.3 Accessing data from a dictionary\nDictionaries hold data (values) paired with a key. i.e. you can access the value (in this case, the superhero name) using the real name as a key. Here is how it works:\n\nsuperhero_info = {\n    \"Natasha Romanoff\": \"Black Widow\",\n    \"Tony Stark\": \"Iron Man\",\n    \"Stephen Strange\": \"Doctor Strange\"\n}                  \n\n\nsuperhero_info[\"Natasha Romanoff\"]\n\n'Black Widow'\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember that dictionaries have a key-value structure.\n\n\nIf you want, you can access all the keys and all the values as follows:\n\nsuperhero_info.keys()\n\ndict_keys(['Natasha Romanoff', 'Tony Stark', 'Stephen Strange'])\n\n\n\nsuperhero_info.values()\n\ndict_values(['Black Widow', 'Iron Man', 'Doctor Strange'])"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#higher-dimensional-lists",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#higher-dimensional-lists",
    "title": "Storing Data (Need)",
    "section": "1.4 Higher dimensional lists",
    "text": "1.4 Higher dimensional lists\nUnlike with a dictionary, we needed two lists to store the corresponding real and superhero names. An obvious way around the need to have two lists is to have a 2D list (or array) as follows.\npy_superhero_info = [['Natasha Romanoff', 'Black Widow'],\n                     ['Tony Stark', 'Iron Man'],\n                     ['Stephen Strange', 'Doctor Strange']]"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#size",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#size",
    "title": "Storing Data (Need)",
    "section": "2.1 Size",
    "text": "2.1 Size\nOften, you need to know how many elements there are in lists or arrays. We can use the len() function for this purpose for both lists and arrays. However, arrays also offer other options.\n\npy_list_2d = [[1, \"A\"], [2, \"B\"], [3, \"C\"], [4, \"D\"],\n              [5, \"E\"], [6, \"F\"], [7, \"G\"], [8, \"H\"],\n              [9, \"I\"], [10, \"J\"]]\n\nnp_array_2d = np.array(py_list_2d)      # Reusing the Python list \n                                        # to create a NEW\n                                        # NumPy array\n\nlen(py_list_2d)\nlen(np_array_2d)\nnp_array_2d.shape\n\n\n\nLists\n\n\n10\n\n\n\n\nArrays\n\n\n10\n\n\n\n\n(10, 2)\n\n\nNotice the absence of brackets ( ) in shape above. This is because shape is not a function. Instead, it is a property or attribute of the NumPy array."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#arrays-are-fussy-about-type",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#arrays-are-fussy-about-type",
    "title": "Storing Data (Need)",
    "section": "2.2 Arrays are fussy about type",
    "text": "2.2 Arrays are fussy about type\nPlease recall the previous discussion about data types (e.g., int, float, str). One prominent difference between lists and arrays is that arrays insist on having only a single data type; lists are more accommodating. Consider the following example and notice how the numbers are converted to English (' ') when we create the NumPy array.\n\npy_list = [1, 1.5, 'A']\nnp_array = np.array(py_list)\n\npy_list\nnp_array\n\n\n\nLists\n\n\n[1, 1.5, 'A']\n\n\n\n\nArrays\n\n\narray(['1', '1.5', 'A'], dtype='&lt;U32')\n\n\n\n\n\nWhen dealing with datasets with both numbers and text, you must be mindful of this restriction. However, this is just an annoyance and not a problem as we can easily change type (typecast) using the ‘hidden’ function astypes(). More about this in a later chapter. For the moment,\n\n\n\n\n\n\nRemember\n\n\n\nRemember that NumPy arrays tolerate only a single type."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#adding-a-number",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#adding-a-number",
    "title": "Storing Data (Need)",
    "section": "2.3 Adding a number",
    "text": "2.3 Adding a number\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)         # Reusing the Python list\n                                     # to create a NEW\n                                     # NumPy array\n\nnp_array + 10\n\n\n\nLists\npy_list + 10        # Won't work!\n\n\nArrays\n\n\narray([11, 12, 13, 14, 15])"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#adding-another-list",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#adding-another-list",
    "title": "Storing Data (Need)",
    "section": "2.4 Adding another list",
    "text": "2.4 Adding another list\n\npy_list_1 = [1, 2, 3, 4, 5]\npy_list_2 = [10, 20, 30, 40, 50]\n\nnp_array_1 = np.array(py_list_1)\nnp_array_2 = np.array(py_list_2)\n\npy_list_1 + py_list_2\nnp_array_1 + np_array_2\n\n\n\nLists\n\n\n[1, 2, 3, 4, 5, 10, 20, 30, 40, 50]\n\n\n\n\nArrays\n\n\narray([11, 22, 33, 44, 55])\n\n\n\n\n\nSo, adding lists causes them to grow while adding arrays is an element-wise operation."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#multiplying-by-a-number",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#multiplying-by-a-number",
    "title": "Storing Data (Need)",
    "section": "2.5 Multiplying by a Number",
    "text": "2.5 Multiplying by a Number\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)         \n\npy_list*2\nnp_array*2\n\n\n\nLists\n\n\n[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n\n\n\n\nArrays\n\n\narray([ 2,  4,  6,  8, 10])\n\n\n\n\n\nSo multiplying by a number makes a list grow, whereas an array multiplies its elements by the number!"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#squaring",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#squaring",
    "title": "Storing Data (Need)",
    "section": "2.6 Squaring",
    "text": "2.6 Squaring\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)\n\nnp_array**2\n\n\n\nLists\npy_list**2                      # Won't work!  \n\n\nArrays\n\n\narray([ 1,  4,  9, 16, 25])"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#asking-questions",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#asking-questions",
    "title": "Storing Data (Need)",
    "section": "2.7 Asking questions",
    "text": "2.7 Asking questions\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)         \n\npy_list == 3     # Works, but what IS the question?\nnp_array == 3  \nnp_array &gt; 3  \n\n\n\nLists\n\n\n\n\n\nFalse\n\n\n\n\npy_list &gt; 3      # Won't work!\n\n\n\n\n\nArrays\n\n\n\n\n\narray([False, False,  True, False, False])\n\n\n\n\n\n\narray([False, False, False,  True,  True])"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#mathematics",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#mathematics",
    "title": "Storing Data (Need)",
    "section": "2.8 Mathematics",
    "text": "2.8 Mathematics\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)         \n\nsum(py_list)     # sum() is a base Python function\nmax(py_list)     # max() is a base Python function\nmin(py_list)     # min() is a base Python function\nnp_array.sum()\nnp_array.max()\nnp_array.min()\nnp_array.mean()\nnp_array.std()\n\n\n\nLists\n\n\n\n\n\n15\n\n\n\n\n\n\n5\n\n\n\n\n\n\n1\n\n\n\n\npy_list.sum()   # Won't work!\n\n\n\n\n\nArrays\n\n\n\n\n\n15\n\n\n\n\n\n\n5\n\n\n\n\n\n\n1\n\n\n\n\n\n\n3.0\n\n\n\n\n\n\n1.4142135623730951\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\n(roughly speaking) an operation on a list works on the whole list. In contrast, an operation on an array works on the individual elements of the array."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need.html#footnotes",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need.html#footnotes",
    "title": "Storing Data (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor example, think of how easy it is to do row or column manipulations of data when put into a spreadsheet format↩︎"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/2_storing-data_good.html#lists-arrays-in-1d-subsetting-indexing",
    "href": "docs/python-basics/03_storing-data/2_storing-data_good.html#lists-arrays-in-1d-subsetting-indexing",
    "title": "Storing Data (Good)",
    "section": "1.1 Lists & Arrays in 1D | Subsetting & Indexing",
    "text": "1.1 Lists & Arrays in 1D | Subsetting & Indexing\nSince slicing gives us a range of elements, we must specify two indices to indicate where to start and end. The various syntaxes for these are shown in the table below.\nThe following applies to both lists and arrays.\n\npy_list=[\"a1\", \"b2\", \"c3\", \"d4\", \"e5\",\n         \"f6\", \"g7\", \"h8\", \"i9\", \"j10\"]\nnp_array=np.array(py_list)\n\n# Pick one\nx = py_list  # OR\nx = np_array\n\n\n\n\n\n\n\n\n\n\nSyntax\nResult\n\nNote\n\n\n\n\nx[0]\nFirst element\n'a1'\n\n\n\nx[-1]\nLast element\n'j10'\n\n\n\nx[0:3]\nIndex 0 to 2\n['a1','b2','c3']\nGives \\(3−0=3\\) elements\n\n\nx[1:6]\nIndex 1 to 5\n['b2','c3','d4','e5','f6']\nGives \\(6−1=5\\) elements\n\n\nx[1:6:2]\nIndex 1 to 5 in steps of 2\n['b2','d4','f6']\nGives every other of \\(6−1=5\\) elements\n\n\nx[5:]\nIndex 5 to the end\n['f6','g7','h8','i9','j10']\nGives len(x)\\(−5=5\\) elements\n\n\nx[:5]\nIndex 0 to 5\n['a1','b2','c3','d4','e5']\nGives \\(5−0=5\\) elements\n\n\nx[5:2:-1]\nIndex 5 to 3 (i.e., in reverse)\n['f6','e5','d4']\nGives \\(5−2=3\\) elements\n\n\nx[::-1]\nReverses the list\n['j10','i9','h8',...,'b2','a1']\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember slicing in Python can be a bit tricky.If you slice with [i:j], the slice will start at i and end at j-1, giving you a total of j-i elements."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/2_storing-data_good.html#arrays-only-subsetting-by-masking",
    "href": "docs/python-basics/03_storing-data/2_storing-data_good.html#arrays-only-subsetting-by-masking",
    "title": "Storing Data (Good)",
    "section": "1.2 Arrays only | Subsetting by masking",
    "text": "1.2 Arrays only | Subsetting by masking\nOne of the most powerful things you can do with NumPy arrays is subsetting by masking. To make sense of this, consider the following.\n\nnp_array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nmy_mask = np_array &gt; 3\nmy_mask\n\narray([False, False, False,  True,  True,  True,  True,  True,  True,\n        True])\n\n\nThe answer to my question is in the form of a ‘Yes’/‘No’ or True/False format. I can use this True/False format to ask NumPy to show me only those that are True by\n\nnp_array[my_mask]\n\narray([ 4,  5,  6,  7,  8,  9, 10])\n\n\nThis is why I used the term ‘masking’. The True/False answer acts like a mask allowing only the True subset to be seen.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that subsetting by masking only works with NumPy arrays.\n\n\nInstead of creating another variable, I can also do all of this succinctly as:\n\nnp_array[np_array &gt; 3]\n\narray([ 4,  5,  6,  7,  8,  9, 10])\n\n\nLet me show you a few more quick examples\n\n\n\nnp_array[~(np_array &gt; 3)]                 # '~' means 'NOT'\n\n\n\nWe can invert our mask by using the ~.~ is called the Bitwise Not operator.\n\n\n\narray([1, 2, 3])\n\n\n\n\n\n\nnp_array[(np_array &gt; 3) & (np_array &lt; 8)] # '&' means 'AND'\n\n\n\nWe can combine one mask AND another mask.(AND will show something only if both masks are true.)\n\n\n\narray([4, 5, 6, 7])\n\n\n\n\n\n\nnp_array[(np_array &lt; 3) | (np_array &gt; 8)] # '|' means 'OR'\n\n\n\nWe can combine one mask OR another mask.(OR will show something if either mask is true.)\n\n\n\narray([ 1,  2,  9, 10])\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember:\n\nAlways use the Bitwise NOT(~), Bitwise OR(|) and Bitwise AND(&) when combining masks with NumPy.\nAlways use brackets to clarify what you are asking the mask to do."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/2_storing-data_good.html#lists-arrays-in-2d-indexing-slicing",
    "href": "docs/python-basics/03_storing-data/2_storing-data_good.html#lists-arrays-in-2d-indexing-slicing",
    "title": "Storing Data (Good)",
    "section": "1.3 Lists & Arrays in 2D | Indexing & Slicing",
    "text": "1.3 Lists & Arrays in 2D | Indexing & Slicing\nThe differences between lists and arrays become even more apparent with higher dimensional lists and arrays. Especially when you try indexing and slicing in higher dimensions.\nLet’s consider the following 2D list.\n\npy_list_2d = [[1, \"A\"], [2, \"B\"], [3, \"C\"], [4, \"D\"],\n              [5, \"E\"], [6, \"F\"], [7, \"G\"], [8, \"H\"],\n              [9, \"I\"], [10, \"J\"]]\n\nnp_array_2d = np.array(py_list_2d)\n\n\n\n\nWhat is at position 4 (index 3)?\npy_list_2d[3]\nnp_array_2d[3]\n\n\n\n\n[4, 'D']\n\n\n\n\narray(['4', 'D'], dtype='&lt;U21')\n\n\n\n\n\n\nWhat is the FIRST element at position 4 (index 3)\npy_list_2d[3][0]\nnp_array_2d[3, 0]\n\n\n\n\n4\n\n\n\n\n\n'4'\n\n\nNotice how the syntax for arrays uses just a single pair of square brackets ([ ]).\n\n\n\n\n\nWhat are the first three elements?\npy_list_2d[:3]\nnp_array_2d[:3]\n\n\n\n\n[[1, 'A'], [2, 'B'], [3, 'C']]\n\n\n\n\narray([['1', 'A'],\n       ['2', 'B'],\n       ['3', 'C']], dtype='&lt;U21')\n\n\n\n\n\n\nHmmm…\npy_list_2d[:3][0]\nnp_array_2d[:3, 0]\n\n\n\n\n\n[1, 'A']\n\n\nYou might think that this will yield the first elements (i.e., [1, 2, 3]) of all the sub-lists up to index 2.No! Instead, it gives the first of the list you get from py_list_2d[:3].\n\n\n\n\narray(['1', '2', '3'], dtype='&lt;U21')\n\n\nNotice how differently NumPy arrays work.\n\n\n\n\n\npy_list_2d[3:6][0]\nnp_array_2d[3:6, 0]\nnp_array_2d[:, 0]\n\n\n\n\n\n[4, 'D']\n\n\n\n\n\n\narray(['4', '5', '6'], dtype='&lt;U21')\n\n\nIf you want ‘everything’ you just use :.\n\n\narray(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'], dtype='&lt;U21')"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/2_storing-data_good.html#growing-lists",
    "href": "docs/python-basics/03_storing-data/2_storing-data_good.html#growing-lists",
    "title": "Storing Data (Good)",
    "section": "1.4 Growing lists",
    "text": "1.4 Growing lists\nNumPy arrays are invaluable, and their slicing syntax (e.g. [:3,0]) is more intuitive than lists. So, why do we even bother with lists? One advantage of lists is their ease and efficiency in growing. NumPy arrays are fantastic for fast math operations, provided you do not change their size1. So, I will not discuss how to change the size of a NumPy array. Instead, let me show you how to grow a list. This will be useful later; for instance when you try to solve differential equations numerically.\n\n\n\nCreating a larger list from a smaller one.\n\nx=[1, 2]*5\nx\n\n[1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n\n\n\n\nThree ways to grow a list by appending one element at a time.\nx=[1]\nx= x + [2]\nx= x + [3]\nx= x + [4]\nx\nx=[1]\nx+= [2]\nx+= [3]\nx+= [4]\nx\nx=[1]\nx.append(2)\nx.append(3)\nx.append(4)\nx\n\n\n\n\n[1, 2, 3, 4]\n\n\n\n\n[1, 2, 3, 4]\n\n\n\n\n[1, 2, 3, 4]\n\n\n\n\nIf you are wondering, there are differences between these three versions. Their execution speeds are different; the version with append() runs about 1.5 times faster than the rest!\n\n\nHere are three ways of incorporating multiple elements.Notice the difference between the effects of extend() and append().\nx = [1, 2, 3]\nx += [4, 5, 6]\nx\nx=[1, 2, 3]\nx.extend([4, 5, 6])\nx\nx=[1, 2, 3]\nx.append([4, 5, 6])\nx\n\n\n\n\n[1, 2, 3, 4, 5, 6]\n\n\n\n\n[1, 2, 3, 4, 5, 6]\n\n\n\n\n[1, 2, 3, [4, 5, 6]]"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/2_storing-data_good.html#tuples",
    "href": "docs/python-basics/03_storing-data/2_storing-data_good.html#tuples",
    "title": "Storing Data (Good)",
    "section": "1.5 Tuples",
    "text": "1.5 Tuples\nBefore we end this section, I must introduce you to another data storage structure called a tuple. Tuples are similar to lists, except they use ( ) and cannot be changed after creation (i.e., they are immutable).\nLet me first create a simple tuple.\n\na=(1, 2, 3)     # Define tuple\n\nWe can access its data…\n\nprint(a[0])    # Access data\n\n1\n\n\nBut, we cannot change the data.\n# The following will NOT work\na[0]=-1\na[0]+= [10]"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/2_storing-data_good.html#be-very-careful-when-copying",
    "href": "docs/python-basics/03_storing-data/2_storing-data_good.html#be-very-careful-when-copying",
    "title": "Storing Data (Good)",
    "section": "1.6 Be VERY careful when copying",
    "text": "1.6 Be VERY careful when copying\nVariables in Python have subtle features that might make your life miserable if you are not careful. You should be particularly mindful when making copies of lists and arrays.\nFor example, if you want to copy a list, you might be tempted to do the following; PLEASE DON’T!\nx=[1, 2, 3]\ny=x           # DON'T do this!\nz=x           # DON'T do this!\nThe correct way to do this is as follows:\nx=[1, 2, 3]\ny=x.copy()\nz=x.copy()\nNote: At this stage, you only have to know that you must use copy() to be safe; you do not have to understand why. However, if you want to, please refer to the discussion on mutable and immutable objects."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/2_storing-data_good.html#footnotes",
    "href": "docs/python-basics/03_storing-data/2_storing-data_good.html#footnotes",
    "title": "Storing Data (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe gains in speed are due to NumPy doing things to all the elements in the array in one go. For this, the data needs to be stored in a specific order in memory. Adding or removing elements hinders this optimization. When you change the size of a NumPy array, NumPy destroys the existing array and creates a new one, making it extremely inefficient.↩︎"
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need_exercises.html",
    "href": "docs/python-basics/06_this-n-that/1_os_need_exercises.html",
    "title": "Files, Folders & OS (Need) Exercises",
    "section": "",
    "text": "Exercise 1 (Tidying a collaboration) ☻\n\nThe scenarioTask 1Task 2Task 3Task 4Task 5Task 6Task 7\n\n\nYou are a member of an international team analysing environmental pollution. The project involves ten cities: Cairo, Dhaka, Jakarta, Karachi, Manila, Melbourne, Osaka, Shanghai, Singapore, and Tokyo.\n\nYour task is to process and organise data from various environmental measurements. The provided zip file, os-collaboration-exercise-data.zip, contains all relevant data files for the past year.\nThings to note\n\nData Files: Each data file is named in the format month-date_city.txt (e.g., may-10_singapore.txt).\nData Collection: Data was recorded sporadically; not all days of each month have corresponding data files. The dates of data collection vary across the cities.\nExclusion of Files: Ignore any non-text files, such as those in .pdf, .png, or .jpg formats.\n\n\n\n\nWe like to convert the filename to a more useful numerical format. Specifically, we want to convert month-date-city.txt. (i.e. may-10-singapore.txt) to a mm-dd-city.txt (i.e. 05-10-singapore.txt) format.\nUsing the following dictionary (or otherwise), write a snippet of Python code to convert 'oct-08_singapore.txt' to 10-08-singapore.txt.\n{\n'jan': '01', 'feb': '02', 'mar': '03',\n'apr': '04', 'may': '05', 'jun': '06',\n'jul': '07', 'aug': '08', 'sep': '09',\n'oct': '10', 'nov': '11', 'dec': '12'\n}\n\n\n\n\nIncorporate your previous code into a function named rename_my_file(old_file_name) that accepts the old filename as the argument and returns the new file name.\n\n\n\n\nUse a for loop to apply the function rename_my_file() to the file list below.\n['oct-08_singapore.txt', 'jul-10_cairo.txt', 'may-15_dhaka.txt',\n 'may-13_cairo.txt', 'oct-21_cairo.txt', 'jan-10_singapore.txt',\n 'jun-20_tokyo.txt', 'aug-06_jakarta.txt', 'dec-21_karachi.txt',\n 'jan-01_tokyo.txt']\nPrint out your progress in the form old-file-name ----&gt; new-file-name\n\n\n\n\nWith the help of glob, use rename_my_file() to rename all the .txt files in the folder.\nNote that you might have to adjust your function rename_my_file() to accommodate the already renamed files.\n\n\n\n\nUse a for loop to create a folder for each city.The list of cities is provided below for your convenience.\n['Cairo', 'Dhaka', 'Jakarta', 'Karachi', 'Manila',\n 'Melbourne', 'Osaka', 'Shanghai', 'Singapore', 'Tokyo']\n\n\n\n\nUse glob to list all the files from Cairo.\nNow use a for loop and shutil.copy() to copy all the files related to Cairo to the corresponding folder you created.\n\n\n\n\nTweak your code to move all the files to the corresponding folders of all the cities.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/07_plotting/2_plotting_good_exercises.html",
    "href": "docs/python-basics/07_plotting/2_plotting_good_exercises.html",
    "title": "Plotting (Good) Exercises",
    "section": "",
    "text": "Exercise 1  \n\nPlotsTasksCode\n\n\nBefore\n\nAfter\n\n\n\nThe code shown in the Code tab generates the ‘Before’ figure shown in the Plots tab.\nYour task is to modify this code to end with the ‘After’ figure in jpg format.\nHere are some things to get you started:\n\nRemove the text ‘I am..’\nChange the colours used for filling.\nChange the limits of the filled areas.\nAdd titles to each subplot.\nShare the x axis across columns.\nAdd/Remove labels to the x-axis.\nMake the tick labels of the two bottom plots the same.\nAdd grids to all subplots.\nAdd a legend to all subplots in the upper right position.\nUse tight_layout() to improve the figure.\nSave the figure as a jpg file.\n\nYou might want to view the images in their full resolution by opening them in another tab.\n\n\n\n#--------- Generate cosine and sine values --------#\nx = np.linspace(-np.pi, np.pi, num=100, endpoint=True)\ncos_x = np.cos(x)\nsin_x = np.sin(x)\nfun1_x = np.exp(-x) * np.cos(5 * x)\nfun2_x = np.exp(-x) * np.sin(2 * x)\n\n#------- Plot the data -------#\nfig, axes = plt.subplots(nrows=2, ncols=2,\n                         figsize=(12, 8),  sharey='row')\n\n#------- Subplot 1 -------#\naxes[0, 0].plot(x, cos_x, color='r', label='$\\cos x$')\naxes[0, 0].plot(x, cos_x**2, color='r',\n                linestyle=':', label='$\\cos^2 x$')\naxes[0, 0].set_title('$\\cos x$ & $\\cos^2x$')\naxes[0, 0].set_ylabel('Cosine Value')\naxes[0, 0].fill_between(x, cos_x, -1, color='g', alpha=.125)\naxes[0, 0].set_xlabel('Angle (radians)')\naxes[0, 0].text(0, 0, 'I am [0, 0]!', fontsize=30,\n                horizontalalignment='center')\n\n#------- Subplot 2 -------#\naxes[0, 1].plot(x, sin_x, color='g', label='$\\sin x$')\naxes[0, 1].fill_between(x, cos_x, -2, color='r', alpha=.125)\naxes[0, 1].plot(x, sin_x**2, label='$\\sin^2 x$')\naxes[0, 1].set_ylabel('Cosine Value')\naxes[0, 1].set_ylim(-1.25, 1.25)\naxes[0, 1].legend(loc='lower right', frameon=False)\naxes[0, 1].text(0, 0, 'I am [0, 1]!', fontsize=30,\n                horizontalalignment='center')\n\n#------- Subplot 3 -------#\naxes[1, 0].plot(x, fun1_x, color='b', label='$e^{-x}\\cos 5x$')\naxes[1, 0].fill_between(x, fun1_x, 0, color='b', alpha=.125)\naxes[1, 0].set_title('$e^{-x}\\cos 5x$')\naxes[1, 0].set_xlabel('Angle (radians)')\naxes[1, 0].set_ylabel('Cosine Value')\naxes[1, 0].set_xticks([-np.pi, -np.pi / 2, 0, np.pi / 2, np.pi])\naxes[1, 0].set_xticklabels(['$-\\pi$', '$-\\pi/2$', '0', '$\\pi/2$', '$\\pi$'])\naxes[1, 0].legend()\naxes[1, 0].text(0, 0, 'I am [1, 0]!', fontsize=30,\n                horizontalalignment='center')\n\n#------- Subplot 4 -------#\naxes[1, 1].plot(x, fun2_x, color='y', label='$e^{-x}\\sin 2x$')\naxes[1, 1].set_title('$e^{-x}\\sin 2x$')\naxes[1, 1].fill_between(x, fun2_x, 10, color='y', alpha=.125)\naxes[1, 1].set_xticks([-np.pi, -np.pi / 2, 0, np.pi / 2, np.pi])\naxes[1, 1].legend()\naxes[1, 1].text(0, 0, 'I am [1, 1]!', fontsize=30,\n                horizontalalignment='center')\n\n# 'flatten', 'opens' the 2D array into a simple 1D array\nfor a in axes.flatten():\n    a.grid(alpha=.5)\n\n# plt.tight_layout()\nplt.show(block=False)\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/07_plotting/2_plotting_good.html#sharing-axes",
    "href": "docs/python-basics/07_plotting/2_plotting_good.html#sharing-axes",
    "title": "Plotting (Good)",
    "section": "5.1 Sharing axes",
    "text": "5.1 Sharing axes\nNotice I have asked Matplotlib to make the plots more compact by sharing the \\(x\\) and \\(y\\) axes using sharex and sharey.\nLet’s first see what happens if I do not specify how to share.\n\n\n\n\n\n\nfig, ax = plt.subplots(\n    nrows=2, ncols=2,\n    figsize=(5, 5)\n)\nYou see that Matplotlib has auto-scaled both axes. In particular, the plots on the left go from 0 to 4, and those on the right go from 0 to 5, as these are the lengths I used for the lines.\n\n\n\n\n\n\nNow, let me specify how to share the axes. I can do this in three ways:\n\n\n\n\nOption\nResult\n\n\n\n\nTrue\nMakes all the axes use the same range.\n\n\ncol\nUse the same range for all the columns\n\n\nrow\nUse the same range for all the rows\n\n\n\n\nLet’s try the following:\n\n\n\n\n\n\nfig, ax = plt.subplots(\n    nrows=2, ncols=2,\n    figsize=(5, 5),\n    sharex=True, sharey='row'\n)\nNotice how all the plots have the same range for the \\(x\\)-axis.\n\n\n\n\n\n\n\n\n\n\n\n\nHowever, sharex='col' is more suited for the data we are plotting, so let’s use that instead.\nfig, ax = plt.subplots(\n    nrows=2, ncols=2,\n    figsize=(5, 5),\n    sharex='col', sharey='row'\n)\nBy the way, how you decide on the most correct depends on what story you are trying to communicate with your plot."
  },
  {
    "objectID": "docs/python-basics/07_plotting/2_plotting_good.html#accessing-all-axes",
    "href": "docs/python-basics/07_plotting/2_plotting_good.html#accessing-all-axes",
    "title": "Plotting (Good)",
    "section": "5.2 Accessing all axes",
    "text": "5.2 Accessing all axes\nYou will often want to apply changes to all the axes, like in the case of the grid. You can do this by\ntop_left.grid(alpha=.25)\ntop_right.grid(alpha=.25)\nbottom_left.grid(alpha=.25)\nbottom_right.grid(alpha=.25)\nBut this is inefficient and requires a lot of work. It is much nicer to use a for loop.\nfor a in ax.flatten():\n    a.grid(alpha=.25)"
  },
  {
    "objectID": "docs/python-basics/07_plotting/2_plotting_good.html#histograms",
    "href": "docs/python-basics/07_plotting/2_plotting_good.html#histograms",
    "title": "Plotting (Good)",
    "section": "6.1 Histograms",
    "text": "6.1 Histograms\nA histogram is a valuable tool for showing distributions of data. For this example, I have extracted some actual data from sg.gov related to the mean monthly earnings of graduates from the various universities in Singapore.\n\nData\nHere are the links to my data files:\n\n\n\n\n\nMean basic monthly earnings by graduates\n\n\n\n\nAll\nsg-gov-graduate-employment-survey_basic_monthly_mean_all.csv\n\n\nNUS Only\nsg-gov-graduate-employment-survey_basic_monthly_mean_nus.csv\n\n\n\n\n\n\nA quick helper function\nI will need to read the data from these files several times. So, I will create a function called det_plot_data() that I can call. You must examine the file structure to understand the data and why I am skipping the first line.\n\nCodeData structure of the files\n\n\ndef get_plot_data():\n    data = {}\n    filename = 'sg-gov-graduate-employment-survey_basic_monthly_mean_all.csv'\n    data['All'] = np.loadtxt(filename, skiprows=1)\n\n    filename = 'sg-gov-graduate-employment-survey_basic_monthly_mean_nus.csv'\n    data['NUS'] = np.loadtxt(filename, skiprows=1)\n\n    return data\n\n\n\n\n\n\n\n\nsg-gov-graduate-employment-survey_basic_monthly_mean_all.csv\n\n\nbasic_monthly_mean\n3701\n2850\n3053\n3557\n3494\n2952\n3235\n3326\n3091\n\n\n\n\nsg-gov-graduate-employment-survey_basic_monthly_mean_nus.csv\n\n\nbasic_monthly_mean\n2741\n3057\n3098\n2960\n3404\n2740\n3065\n3350\n3933\n\n\n\n\n\n\n\n\n\n\nThe histogram\n\nFigureCode\n\n\n\n\n\n\nplt.style.use('bmh')\ndata = get_plot_data()\n\n# bins specifies how many bins to split the data\nplt.hist([data['All'], data['NUS']], bins=50, label=['All', 'NUS'])\nplt.xlabel('Mean of Basic Montly Earning (S$)')\nplt.ylabel('Number of Students')\nplt.legend()"
  },
  {
    "objectID": "docs/python-basics/07_plotting/2_plotting_good.html#scatter-plots",
    "href": "docs/python-basics/07_plotting/2_plotting_good.html#scatter-plots",
    "title": "Plotting (Good)",
    "section": "6.2 Scatter plots",
    "text": "6.2 Scatter plots\nScatter plots are created by putting a marker at an \\((x,y)\\) point you specify. They are simple yet powerful.\nI will be lazy and use the same data as the previous example. But, since I need some values for \\(x\\) I am going to use range() along with len() to generate a list [0,1,2...] appropriate to the dataset.\n\nFigureCode\n\n\n\n\n\n\nplt.style.use(\"seaborn-v0_8-darkgrid\")\n\ndata = get_plot_data()\n\nfor label, numbers in data.items():\n    x = range(len(numbers))\n    y = numbers\n    plt.scatter(x, y, label=label, alpha=.5)\n\nplt.xlabel('Position in the list')\nplt.ylabel('Mean of Basic Montly Eraning (S$)')\nplt.legend()"
  },
  {
    "objectID": "docs/python-basics/07_plotting/2_plotting_good.html#bar-charts",
    "href": "docs/python-basics/07_plotting/2_plotting_good.html#bar-charts",
    "title": "Plotting (Good)",
    "section": "6.3 Bar charts",
    "text": "6.3 Bar charts\nI am using some dummy data for a hypothetical class for this example. I extract the data and typecast to pass two lists to bar(). Use barh() if you want horizontal bars.\n\nFigureCode\n\n\n\n\n\n\nstudent_numbers = {'Life Sciences': 14,\n                   'Physics': 12,\n                   'Chemistry': 8,\n                   'Comp. Biology': 1}\nmajors = list(student_numbers.keys())\nnumbers = list(student_numbers.values())\n\nplt.style.use('ggplot')\nplt.bar(majors, numbers)\nplt.xlabel('Majors')\nplt.ylabel('Number of Students')"
  },
  {
    "objectID": "docs/python-basics/07_plotting/2_plotting_good.html#pie-charts",
    "href": "docs/python-basics/07_plotting/2_plotting_good.html#pie-charts",
    "title": "Plotting (Good)",
    "section": "6.4 Pie charts",
    "text": "6.4 Pie charts\nI am not a big fan of pie charts, but they have their uses. Let me reuse the previous data from the dummy class.\n\nFigureCode\n\n\n\n\n\n\nstudent_numbers = {'Life Sciences': 14,\n                   'Physics': 12,\n                   'Chemistry': 8,\n                   'Comp. Biology': 1}\nmajors = list(student_numbers.keys())\nnumbers = list(student_numbers.values())\n\nplt.style.use('fivethirtyeight')\nplt.pie(numbers, \n        labels=majors,\n        autopct='%1.1f%%',   # How to format the percentages\n        startangle=-90                \n        )\nplt.title('Percentage of each major')"
  },
  {
    "objectID": "docs/python-basics/02_basics/1_basics_need.html#some-context",
    "href": "docs/python-basics/02_basics/1_basics_need.html#some-context",
    "title": "Fundamentals (Need)",
    "section": "10.1 Some Context",
    "text": "10.1 Some Context\nI now like to talk about an essential, super-powerful feature of Python. For this, I will use the example of doing mathematics using Python. Let’s say we want to calculate:\n\\[\n\\dfrac{1 \\times ((2-3) + 4)^{5}}{6}\n\\]\nWe can do this by:\n\n1 * ((2 - 3) + 4) ** 5 / 6\n\n40.5\n\n\nHow about \\(\\sqrt{4}\\)?\n\nsqrt(4)      # Will NOT work because \n             # basic Python is limited\n\nError in py_call_impl(callable, dots$args, dots$keywords): NameError: name 'sqrt' is not defined\n\n\nOh, dear! Python cannot calculate square roots! However, this is not a problem because we can imbue Python with newer functionality by using packages. For instance, I can give Python more math skills by using (importing) the math package."
  },
  {
    "objectID": "docs/python-basics/02_basics/1_basics_need.html#importing-the-math-package",
    "href": "docs/python-basics/02_basics/1_basics_need.html#importing-the-math-package",
    "title": "Fundamentals (Need)",
    "section": "10.2 Importing the math package",
    "text": "10.2 Importing the math package\n\nimport math         # Adding(importing) the functions\n                    # of the 'math' package    \n\nNow we can use the sqrt() function of the math module.\n\nmath.sqrt(4)\n\n2.0"
  },
  {
    "objectID": "docs/python-basics/02_basics/1_basics_need.html#importing-the-numpy-package",
    "href": "docs/python-basics/02_basics/1_basics_need.html#importing-the-numpy-package",
    "title": "Fundamentals (Need)",
    "section": "10.3 Importing the numpy package",
    "text": "10.3 Importing the numpy package\nmath is one of many modules that offer the sqrt() functionality. So let me also import the super useful Numpy package to use its sqrt() function.\n\nimport numpy as np    # Importing Numpy and giving \n                      # it an alias np \n                      # because I am lazy\n\nNow we can also use the sqrt() function of the Numpy module. Since I imported it with an alias (np) I can be lazy and use np instead of the longer numpy.\n\nnp.sqrt(4)\n\n2.0"
  },
  {
    "objectID": "docs/python-basics/02_basics/1_basics_need.html#why-so-many-packages",
    "href": "docs/python-basics/02_basics/1_basics_need.html#why-so-many-packages",
    "title": "Fundamentals (Need)",
    "section": "10.4 Why so many packages?",
    "text": "10.4 Why so many packages?\nYou might wonder why we need multiple sqrt() functions. There are different versions because they have different capabilities and efficiencies. For example, the Numpy version can handle a list of numbers:\n\nnp.sqrt([4, 9, 16])\n\narray([2., 3., 4.])\n\n\nWe will talk a lot more about Numpy later. Before we move on, please note that you need to import packages only once(You do not have to teach Python the same thing twice!). Python will remember the functions until you restart the Python interpreter.\n\n\n\n\n\n\nRemember\n\n\n\n\nYou can give Python ‘superpowers’ by importing packages.\nYou must import a package only once.\nThere are different ways to import packages (e.g. with or without an ‘alias’)."
  },
  {
    "objectID": "docs/python-basics/02_basics/1_basics_need.html#footnotes",
    "href": "docs/python-basics/02_basics/1_basics_need.html#footnotes",
    "title": "Fundamentals (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe latest version of the interpreter is 3.12.↩︎\nExcept the keywords used in the Python language like if, for, while, is ↩︎"
  },
  {
    "objectID": "docs/python-basics/02_basics/3_basics_nice.html#the-problem",
    "href": "docs/python-basics/02_basics/3_basics_nice.html#the-problem",
    "title": "Fundamentals (Nice)",
    "section": "6.1 The Problem",
    "text": "6.1 The Problem\nSince we use variables all the time, it is good to understand how they work. This is particularly true for Python because certain Python variables can be sneaky!\nWhat do you think will be printed if you run the following code? Try to predict the answers before running the code.\nx = [1, 2]\ny = x\ny.append(3)\n\nprint(f\"x: {x}, y: {y}\")"
  },
  {
    "objectID": "docs/python-basics/02_basics/3_basics_nice.html#an-explanation",
    "href": "docs/python-basics/02_basics/3_basics_nice.html#an-explanation",
    "title": "Fundamentals (Nice)",
    "section": "6.2 An explanation",
    "text": "6.2 An explanation\nLet’s explore the root of this by first running the following code:\n\n'''CODE 1'''\n\n'CODE 1'\n\nx = 1\ny = 1\n\nprint(f\"x: {id(x)}, y: {id(y)}, 1: {id(1)}\")\n\nx: 133527160336072, y: 133527160336072, 1: 133527160336072\n\n\nThe above code tells us that x, y both have the same id as 1! The following figure tries to explain what is happening.\n\n\nBefore the code is run, Python has things or objects 1, 2 and a that have three properties type, value and id. For example, 1 can have the value 1, type int, and some id. a can have the value ‘a’, type str and some id.\nAfter the code is run, x and y are ‘looking at’ or bound to 1. So x and y are referred to as names that are bound to 11.\n\nNow run this code:\n\n'''CODE 2'''\n\n'CODE 2'\n\nx = 1\ny = x + 1\n\nprint(f\"x: {id(x)}, y: {id(y)}\")\n\nx: 133527160336072, y: 133527160336104\n\nprint(f\"1: {id(1)}, 2: {id(2)}\")\n\n1: 133527160336072, 2: 133527160336104\n\n\nSince the mathematical operation requires y to have the value 2, y now gets bound to object 2. This happens because the value of object 1 cannot be changed, so the binding is changed instead.\n\nObjects such as 1 whose values cannot be changed are called immutable. Other such immutable types are str(i.e., letters), float, bool.\nThere are also objects whose values can be changed. These types are called mutable and include lists and dictionaries and instances of classes. These behave differently, as highlighted in the problem above.\nHere is the code from the ‘problem’ with some explanations.\n# x is bound to a list object with a value [1 ,2]\nx = [1, 2]\n\n# y is bound to the SAME list object with a value [1 ,2]\ny = x\n\n# y is used to change the value of the object from  [1, 2] to [1, 2, 3]\ny.append(3)"
  },
  {
    "objectID": "docs/python-basics/02_basics/3_basics_nice.html#a-solution",
    "href": "docs/python-basics/02_basics/3_basics_nice.html#a-solution",
    "title": "Fundamentals (Nice)",
    "section": "6.3 A solution",
    "text": "6.3 A solution\nIf you really want y to have an independent copy of x, you should use:\ny = x.copy()\n\n\n\n\n\n\nMutable vs. immutable types\n\n\n\n\n\nBe very careful when you use mutable data types as variables."
  },
  {
    "objectID": "docs/python-basics/02_basics/3_basics_nice.html#footnotes",
    "href": "docs/python-basics/02_basics/3_basics_nice.html#footnotes",
    "title": "Fundamentals (Nice)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is the basis of the, sometimes contentious, statement that there are no variables in Python↩︎"
  },
  {
    "objectID": "docs/python-basics/02_basics/2_basics_good.html#asking-math-questions",
    "href": "docs/python-basics/02_basics/2_basics_good.html#asking-math-questions",
    "title": "Fundamentals (Good)",
    "section": "2.1 Asking Math questions",
    "text": "2.1 Asking Math questions\n\nYou will find the following useful when asking mathematical questions:\n\n\n\n\n\n\n\n\n\nQuestion/Condition\nMath Symbol\nPython Symbols\n\n\n\n\nEquals?\n=\n==\n\n\nNot equal?\n≠\n!=\n\n\nLess than?\n&lt;\n&lt;\n\n\nGreater than?\n&gt;\n&gt;\n\n\nLess than or equal?\n≤\n&lt;=\n\n\nGreater than or equal?\n≥\n&gt;=\n\n\n\n\n\n\n\n\n\nPython also (thankfully) accepts all the following syntax:\n\n\n\n\n\n\nx &gt; 5 and x &lt; 15\n\n\n(x &gt; 5) and (x &lt; 15)\n\n\n5 &lt; x &lt; 15\n\n\n\nClearly, the last format is the neatest and easiest to read. Notice also how the brackets increase the readability of the statement."
  },
  {
    "objectID": "docs/python-basics/02_basics/2_basics_good.html#the-problem",
    "href": "docs/python-basics/02_basics/2_basics_good.html#the-problem",
    "title": "Fundamentals (Good)",
    "section": "4.1 The Problem",
    "text": "4.1 The Problem\nwhen often need to compare numbers, especially for scientific work. Unfortunately, since computers have finite (hardware) resources, floating point numbers cannot be exactly stored in a computer3. This leads to errors called roundoff errors. Let me demonstrate:\nTry the following code which compares \\(0.1\\times 3\\) with \\(0.3\\).\n\na = 0.1\na3 = 0.3\na * 3 == a3\n\nFalse\n\n\nTo convince you further, let’s try printing \\(0.3\\) to 17 decimal places:\n\nf'{0.3:.17f}'\n\n'0.29999999999999999'"
  },
  {
    "objectID": "docs/python-basics/02_basics/2_basics_good.html#a-solution",
    "href": "docs/python-basics/02_basics/2_basics_good.html#a-solution",
    "title": "Fundamentals (Good)",
    "section": "4.2 A solution",
    "text": "4.2 A solution\nTo get around these types of issues, you should check if the variable is close to the expected values instead of checking for equality.\n\neps = 1E-10\nabs(a * 3 - a3) &lt; eps\n\nTrue\n\n\nOr just use Numpy\n\nnp.isclose(a * 3, a3)\n\nTrue"
  },
  {
    "objectID": "docs/python-basics/02_basics/2_basics_good.html#structure-of-f-strings",
    "href": "docs/python-basics/02_basics/2_basics_good.html#structure-of-f-strings",
    "title": "Fundamentals (Good)",
    "section": "5.1 Structure of f-strings",
    "text": "5.1 Structure of f-strings\nf-string formatting has the structure {X:&gt;0Y.ZW}. Here is more information about the letters X,Y,&gt;, 0,Z and W.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLetter\nAction\nPossible Options\n\n\n\n\nX\nVariable to format\nCan be a number or a string\n\n\n&gt;\nAlignment\n\n&lt; (Left justified)\n&gt; (Right justified)\n^ (Centre justified)\n\n\n\n0\nUse 0’s to pad the spaces\nYou can use other characters like a space .\n\n\nY\nTotal number of characters\n\n\n\nZ\nNumber of decimal places\n\n\n\nW\nSpecifies the type of variable.\n\nf (float)\nd (integer)\ns (string)\ng (Asks Python to figure out)\n\n\n\n\n\n\n\n\n\nYou can refer to this website for more information about f-strings."
  },
  {
    "objectID": "docs/python-basics/02_basics/2_basics_good.html#self-documenting-f-strings",
    "href": "docs/python-basics/02_basics/2_basics_good.html#self-documenting-f-strings",
    "title": "Fundamentals (Good)",
    "section": "6.1 Self-documenting f-strings",
    "text": "6.1 Self-documenting f-strings\nf-strings offer a neat self-documenting option that prints the variable and the value all on its own. This is obviously very useful, especially during debugging. Here is how you use it:\n\nx, y= 42, 24\nprint(f'{x=} and {y=}')\n\nx=42 and y=24\n\n\nFormatting works too!\n\nx, y= 42/5, 24/5\nprint(f'{x=:.3f} and {y=:.6f}')\n\nx=8.400 and y=4.800000"
  },
  {
    "objectID": "docs/python-basics/02_basics/2_basics_good.html#footnotes",
    "href": "docs/python-basics/02_basics/2_basics_good.html#footnotes",
    "title": "Fundamentals (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ndespite the English phrase↩︎\nE.g. with an OCR table of numbers.↩︎\ndue to issues related to the precision of the IEEE 754 standard↩︎\ncalled augmented assignment↩︎"
  },
  {
    "objectID": "docs/python-basics/04_loops/1_loops_need.html#for-with-a-list",
    "href": "docs/python-basics/04_loops/1_loops_need.html#for-with-a-list",
    "title": "Loops (Need)",
    "section": "1.1 for with a list",
    "text": "1.1 for with a list\nI can achieve the same result using a for loop as follows:\n\nfor name in real_names:\n    print(f\"{name} is a Marvel superhero!\")\n\nNatasha Romanoff is a Marvel superhero!\nTony Stark is a Marvel superhero!\nStephen Strange is a Marvel superhero!\n\n\nNotice the structure of the for loop;\n\nit goes through the list and assigns name the value of each element of the list.\nit then runs the code-block using this value of name.\nthe code block is deginted by using : and tabs like with if.\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember that for can be used to directly loop through a list.\n\n\nBy the way, there is nothing special about the names of the variables I have used. The following will work too. However, it will not be very readable because x is a bit cryptic in this context.\nfor x in real_names:\n    print(f\"{x} is a Marvel superhero!\")"
  },
  {
    "objectID": "docs/python-basics/04_loops/1_loops_need.html#for-with-enumerate",
    "href": "docs/python-basics/04_loops/1_loops_need.html#for-with-enumerate",
    "title": "Loops (Need)",
    "section": "1.2 for with enumerate",
    "text": "1.2 for with enumerate\nLet’s say we want to do a bit more, like using the information in both of the following lists.\n\nsuper_names = [\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\nreal_names = [\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\nSince the for loop only accepts one list, we need to do something else to access the data in both lists. One option is to use enumerate(). Let me first show you how enumerate() works.\n\nfor count, name in enumerate(real_names):\n    print(f'{count}: {name} is a Marvel superhero!')\n\n0: Natasha Romanoff is a Marvel superhero!\n1: Tony Stark is a Marvel superhero!\n2: Stephen Strange is a Marvel superhero!\n\n\nYou can think of enumerate() as something that keeps count. In the above example, enumerate() not only gives the elements of the list, it also gives you a number (that is stored in count).\nOther than counting, we can use the count given by enumerate() to index the other list!\n\nfor index, name in enumerate(real_names):\n    superhero_name = super_names[index]\n    print(f'{name} is {superhero_name}!')\n\nNatasha Romanoff is Black Widow!\nTony Stark is Iron Man!\nStephen Strange is Doctor Strange!\n\n\nBefore we move on, I would like to highlight two things:\n\nNotice how I changed the variable name used with enumerate() to (count and index) to match their logical use. This makes it easy to iimediately see what you are doing (i.e., the intention) wiht the code. Python does not really care abot this, but remember that we write programmes for humans!\nAlthough by default, enumerate() starts counting from 0, we can easily change it to start at another value, say 100.\n\nfor count, name in enumerate(real_names, 100):\n    print(f'{count}: {name} is a Marvel superhero!')\n\n100: Natasha Romanoff is a Marvel superhero!\n101: Tony Stark is a Marvel superhero!\n102: Stephen Strange is a Marvel superhero!\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember that for can be combined with enumerate() to count while looping through a list."
  },
  {
    "objectID": "docs/python-basics/04_loops/1_loops_need.html#for-with-range",
    "href": "docs/python-basics/04_loops/1_loops_need.html#for-with-range",
    "title": "Loops (Need)",
    "section": "1.3 for with range",
    "text": "1.3 for with range\nYet, another way to achieve the result above is by using the function range(). But, first lets see what range() can do.\n\n\n\nfor i in range(5):\n    print(i)\n\n\n\nWe can use range() to get the for loop to run a given number of loops (5 in this example).\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\n\n\nfor i in range(5, 10):\n    print(i)\n\n\n\nWe can tailor the starting and ending values…\n\n\n\n5\n6\n7\n8\n9\n\n\n\n\n\n\nfor i in range(1, 10, 3):\n    print(i)\n\n\n\nWe can even adjust the step size.\n\n\n\n1\n4\n7\n\n\n\n\n\n\n\nNote:\n\nFunctions like range() and enumerate() only work with looping structures.\nrange() always ends one short of the ending number.\n\nNow, let’s return to our initial problem of printing superhero names. We can use range() as follows:\n\nfor i in range(len(real_names)):\n    real_name = real_names[i]\n    super_name = super_names[i]        \n    print(f\"{real_name} is Marvel's {super_name}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!\n\n\nNotice that I have used the len(real_names) to get how many times the loop should run.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that for can be run a given number of times using range()."
  },
  {
    "objectID": "docs/python-basics/04_loops/2_loops_good_exercises.html",
    "href": "docs/python-basics/04_loops/2_loops_good_exercises.html",
    "title": "Loops (Good) Exercises",
    "section": "",
    "text": "Exercise 1 (Make me an odd list) ☻\nWith your knowledge of growing lists, use a for loop with range() and continue to generate a list of the squares of the odd integers from 0 to 9.\nHint: You can check for ‘evenness’ using number % 2 == 0.\n\n\nExercise 2 (Make me another odd list) ☻\nRedo the previous exercise using list comprehension.\n\n\nExercise 3 (Time me!) ☻\nUse the cell magic command %%timeit to time the previous solutions. Which of the two is faster?\n\n\nExercise 4 (A problem of decay) ☻\nThe initial quantity of a sample of a radioactive substance is 100 units, and it decays by 5% each year. Use a while loop to determine how long the sample will take to reduce to half its original amount.\n\n\nExercise 5 (Changes in CO\\(_2\\)) ☻\nThe following is data about atmospheric CO\\(_2\\) levels for several years in a (year, CO2_level) format. The units are ppm.\nco2_data = [\n    (2000, 369.55), (2001, 371.14), (2002, 373.28), \n    (2003, 375.80), (2004, 377.52), (2005, 379.80), \n    (2006, 381.90), (2007, 383.79), (2008, 385.60), \n    (2009, 387.43), (2010, 389.90), (2011, 391.65), \n    (2012, 393.85), (2013, 396.52), (2014, 398.65),\n    (2015, 400.83), (2016, 404.24), (2017, 406.55), \n    (2018, 408.52), (2019, 411.44), (2020, 414.24)\n]\nIdentify those years that showed an increase of CO\\(_2\\) of 3 ppm or more compared to the previous year.\nPlease print out these years along with the corresponding change in concentration.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need_exercises.html#quadratic-equations",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need_exercises.html#quadratic-equations",
    "title": "Using Jupyter (Need), Exercises",
    "section": "1 Quadratic Equations",
    "text": "1 Quadratic Equations\n\nIntroduction\n\n(Image from the Wikipedia page on Quadratic equations)\nThe general form of a quadratic equation is:\n\\[\nax^2 + bx + c = 0\n\\]\n\n\nSolutions\nProvided \\(a\\ne0\\), we can use an elementary algebraic method called completing the square to show that a quadratic equation has the following solution: \\[\nx = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}\n\\]\n\n\nDiscriminant\nThe quantity \\(\\Delta = b^2-4ac\\) is called the discriminant of the equation and decides the nature of its solutions. The table below shows the various possibilities.\n\n\n\nDiscriminant\nRoots\n\n\n\n\n\\(\\Delta = b^2-4ac = 0\\)\nA single solution of \\(-b/(2a)\\)\n\n\n\\(\\Delta = b^2-4ac \\gt 0\\)\nTwo distinct solutions\n\n\n\\(\\Delta = b^2-4ac \\lt 0\\)\nNo real solutions; both are complex."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#it-is-all-about-running-cells",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#it-is-all-about-running-cells",
    "title": "Using Jupyter (Need)",
    "section": "2.1 It is all about running cells",
    "text": "2.1 It is all about running cells\nThe basic unit of a Jupyter Notebook is a cell. A cell can either accept Python code or text in a format called Markdown.\nA cell ready to accept Python is called a code cell, while one ready for Markdown is called a Markdown cell. To ‘get things done’, we Run a cell by using the Run button or the keyboard shortcut CTRL + ENTER (or CMD + ENTER).\n\n\n\n\n\nRunning a code cell invokes Python while running a Markdown cell renders (i.e., makes it look pretty) your Markdown text. You will see how all this works in a bit, so don’t worry if things sound a tad cryptic at the moment."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#a-traditional-start",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#a-traditional-start",
    "title": "Using Jupyter (Need)",
    "section": "2.2 A traditional start",
    "text": "2.2 A traditional start\nLet’s follow a programming tradition and use Jupyter to print Hello World!.\n\nSelect a cell and convert it into a code cell.Actually, all new cells are, by default, code cells.\n\n\n\n\n\nThen type the following and run the command (i.e., pass the instruction to Python) by pressing the run button or using the keyboard shortcut CTRL + ENTER (or CMD + ENTER).\nprint('Hello World!')\nSurprise, surprise! You should see the words Hello World! as the output.\n\n\nHello world!\n\n\nYou will also see that the number before your code cell changes. This number is used to keep track of the history of the commands you have issued. It helps keep track of which input corresponds to which output."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#rendering-markdown-cells",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#rendering-markdown-cells",
    "title": "Using Jupyter (Need)",
    "section": "3.1 Rendering Markdown cells",
    "text": "3.1 Rendering Markdown cells\nTo render your text:\n\nSelect a cell and convert it to a Markdown cell (If you like, you can use the keyboard shortcut ESC + M),\nInput your text and\nRun.\n\nTo start, copy and paste the following (from the Guide1) and run the cell.\nThe ships hung in the sky in much the same way that bricks don’t.\nYou should see the text rendered."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#some-basic-syntax",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#some-basic-syntax",
    "title": "Using Jupyter (Need)",
    "section": "3.2 Some basic syntax",
    "text": "3.2 Some basic syntax\nThe table shows some basic Markdown syntax to modify how some text is rendered.\n\n\n\n\nStyle\nSyntax\n\n\n\n\nBold\n** ** or __ __\n\n\nItalic\n* * or _ _\n\n\nAll bold and italic\n*** ***\n\n\nSubscript\n&lt;sub&gt; &lt;/sub&gt;\n\n\nSuperscript\n&lt;sup&gt; &lt;/sup&gt;\n\n\n\n\nLet’s use it to modify our previous text as follows. (By the way, no more copying and pasting!)\nThe ships *hung in the sky* in much the same way that **bricks don’t.**&lt;sup&gt;1&lt;/sup&gt;&lt;sub&gt;QUOTE&lt;/sub&gt;\nThis will be rendered as:\nThe ships hung in the sky in much the same way that bricks don’t.1QUOTE"
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#headings",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#headings",
    "title": "Using Jupyter (Need)",
    "section": "3.3 Headings",
    "text": "3.3 Headings\nMarkdown uses # for headings as follows.\n# The largest heading\n\n## The second-largest heading\n\n### The third-largest heading\n\n#### The smallest heading"
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#displaying-code",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#displaying-code",
    "title": "Using Jupyter (Need)",
    "section": "3.4 Displaying Code",
    "text": "3.4 Displaying Code\nIf you want to mention code inline, you can enclose it between two backticks (`), like `print('Hello World')`. This will be rendered as print('Hello World!').\nYou can also have a block of code by using the following syntax.\n```python\nprint('Hello World!')\n```\nThis will be rendered as:\nprint('Hello World!')"
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#links",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#links",
    "title": "Using Jupyter (Need)",
    "section": "3.5 Links",
    "text": "3.5 Links\nCreating links with Markdown is trivial. You just enclose the display text in [ ] followed by the link-address in ( ) like\n[SP2273 Website](https://sps.nus.edu.sg/sp2273)\nThis will be rendered as SP2273 Website. Things won’t work if you don’t include the https:// part. So, be careful."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#images",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#images",
    "title": "Using Jupyter (Need)",
    "section": "3.6 Images",
    "text": "3.6 Images\nMarkdown also lets you easily include images from your computer or the web. The syntax is similar to links, except there is a ! in front.\nLet me show you by inserting the NUS logo from the University’s front page (You can get the link to any image by right-clicking and copying the image address).\nThe syntax is:\n![](https://nus.edu.sg/images/default-source/base/logo.png)\nThis will give you:\n\nYou can also similarly include images on your computer. Just put the filename instead of the address. Again, you need to give enough information (full or relative path, see chapter os) for Jupyter to be able to find the file.\n\n\n\n\n\n\nA fly in the ointment\n\n\n\nSometimes, you might have to copy the image file to the folder/directory containing the .ipynb to successfully include local images.\nI think this happens mainly for Windows users. I am sorry2."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#tables",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#tables",
    "title": "Using Jupyter (Need)",
    "section": "3.7 Tables",
    "text": "3.7 Tables\nMarkdown following syntax to create tables:\n| A    |  B   |    C |\n| :--- | :--: | ---: |\n| a1   |  b1  |   c1 |\n| a2   |  b2  |   c2 |\n| a3   |  b3  |   c3 |\nWhich will be rendered as:\n\n\n\n\nA\nB\nC\n\n\n\n\na1\nb1\nc1\n\n\na2\nb2\nc2\n\n\na3\nb3\nc3\n\n\n\n\nIn my experience, tables are the most annoying things to create and format in a document3. So I find it easier to organise the information in Excel or Sheets and then use a web tool like Table Generator to create the tables."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#lists",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#lists",
    "title": "Using Jupyter (Need)",
    "section": "3.8 Lists",
    "text": "3.8 Lists\nYou can have numbered or unnumbered lists in Markdown. Below are a few examples. I have shown the code first and then what it will look like when rendered.\n\nNumberedUnnumberedNumbered-numberedNumbered-unnumbered\n\n\n\n\n\n\n\n\n1. Master Yoda\n1. Luke Skywalker\n1. Anakin Skywalker\n\n\n\nMaster Yoda\nLuke Skywalker\nAnakin Skywalker\n\n\n\n\n\n\n\n\n\n\n\n\n- Master Yoda\n- Luke Skywalker\n- Anakin Skywalker\n\n\n\nMaster Yoda\nLuke Skywalker\nAnakin Skywalker\n\n\n\n\n\n\n\n\n\n\n\n\n1. Master Yoda\n   1. Was a Jedi\n   1. Was a bit green\n1. Luke Skywalker\n   1. Was a Jedi\n   1. Is Anakin's son.\n1. Anakin Skywalker\n   1. Was a Jedi then became a baddie\n   1. Is famous for saying 'Luke, I am your father'\n\n\n\nMaster Yoda\n\nWas a Jedi\nWas a bit green\n\nLuke Skywalker\n\nWas a Jedi\nIs Anakin’s son.\n\nAnakin Skywalker\n\nWas a Jedi then became a baddie\nIs famous for saying ‘Luke, I am your father’\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Master Yoda\n   - Was a Jedi\n   - Was a bit green\n1. Luke Skywalker\n   - Was a Jedi\n   - Is Anakin's son.\n1. Anakin Skywalker\n   - Was a Jedi then, became a baddie\n   - Is famous for saying, _'Luke, I am your father'_.\n\n\n\nMaster Yoda\n\nWas a Jedi\nWas a bit green\n\nLuke Skywalker\n\nWas a Jedi\nIs Anakin’s son.\n\nAnakin Skywalker\n\nWas a Jedi then, became a baddie\nIs famous for saying, ‘Luke, I am your father’."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#equations",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#equations",
    "title": "Using Jupyter (Need)",
    "section": "3.9 Equations",
    "text": "3.9 Equations\nMarkdown can produce phenomenal math equations4.\n\nIf you want to have inline math use two $ signs like $\\sqrt{b^2-4ac}$, which will be rendered as \\(\\sqrt{b^2-4ac}\\).\nIf you want a math block, you can use the following:\n$$\nx = \\dfrac{-b \\pm \\sqrt{b^2-4ac}}{2a}\n$$\nWhich will be rendered as:\n\n\\[\nx = \\dfrac{-b \\pm \\sqrt{b^2-4ac}}{2a}\n\\]\nHere are some helpful math commands that you can use. For more details, refer to the mathematical documentation at Overleaf.\n\n\n\n\n\n\n\n\n\n\nInput\nRendered\n\n\n\n\nFraction\n$\\dfrac{y}{x}$\n\\(\\dfrac{y}{x}\\)\n\n\nSubscript\n$x_{a}$\n\\(x_{a}\\)\n\n\nPower\n$x^{(y+z)}$\n\\(x^{(y+z)}\\)\n\n\nSquareroot\n$\\sqrt{a+b+c}$\n\\(\\sqrt{a+b+c}\\)\n\n\nSum\n$\\sum_{n=1}^{n=\\infty} x_n$\n\\(\\sum_{n=1}^{n=\\infty} x_n\\)\n\n\nIntegral\n$\\int_{x=1}^{x=\\infty} f(x)dx$\n\\(\\int_{x=1}^{x=\\infty} f(x)dx\\)\n\n\nNot equal\na \\ne b\n\\(a \\ne b\\)\n\n\nLess than\n$a \\lt b$\n\\(a \\lt b\\)\n\n\nLess than or equal to\n$a \\leq b$\n\\(a \\leq b\\)\n\n\nGreater than\n$a \\gt b$\n\\(a \\gt b\\)\n\n\nGreater than or equal to\n$a \\geq b$\n\\(a \\geq b\\)\n\n\nGreek letters\n$\\alpha, \\beta, \\gamma, \\pi, \\lambda$\n\\(\\alpha, \\beta, \\gamma, \\pi, \\lambda\\)"
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#footnotes",
    "href": "docs/python-basics/01_using_jupyter/1_using-jupyter_need.html#footnotes",
    "title": "Using Jupyter (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou and I will have problems if you do not know about The Hitchhiker’s Guide to the Galaxy.↩︎\nthat you are using Windows.↩︎\nespecially with doubly annoying software like Word↩︎\nUsing a \\(\\LaTeX\\) engine called MathJax↩︎"
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/2_using-jupyter_good_exercises.html#footnotes",
    "href": "docs/python-basics/01_using_jupyter/2_using-jupyter_good_exercises.html#footnotes",
    "title": "Using Jupyter (Good), Exercises",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOkay, okay it was me, but you pressed the button.↩︎"
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/2_using-jupyter_good.html#keyboard-shortcuts",
    "href": "docs/python-basics/01_using_jupyter/2_using-jupyter_good.html#keyboard-shortcuts",
    "title": "Using Jupyter (Good)",
    "section": "1.1 Keyboard Shortcuts",
    "text": "1.1 Keyboard Shortcuts\nUsing keyboard shortcuts will make your workflow smooth and efficient. Here are some essential shortcuts. It will help you to practice using all these keyboard shortcuts.\n\n\n\n\n\n\n\n\nAction\nShortcut\n\n\n\n\nRun cell\nCTRL + ENTER or CMD + ENTER\n\n\nRun cell and move to the next\nSHIFT + ENTER\n\n\nConvert cell to code cell\nESC + Y\n\n\nConvert cell to Markdown cell\nESC + M\n\n\nCreate new cell\nESC + A (above)ESC + B (below)\n\n\nCopy cell(s)\nESC + C\n\n\nPaste cell(s)\nESC + V\n\n\nMerge cells\nSHIFT + M\n\n\nDelete cell\nESC + D + D\n\n\nShow shortcuts\nESC + H\n\n\n\n\nYou will notice that many shortcut commands use the escape button (ESC). This is because typing ESC puts Jupyter into command mode, ready for a command, not code or text.\n\nThings to note\n\nYou can select one or more cells using SHIFT and the up and down arrow keys.\nBe careful with the delete shortcut; it can be ruthless.\nYou can view (and set) shortcuts for Jupyter Notebooks by typing ESC + H."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/2_using-jupyter_good.html#shell-commands",
    "href": "docs/python-basics/01_using_jupyter/2_using-jupyter_good.html#shell-commands",
    "title": "Using Jupyter (Good)",
    "section": "1.2 Shell commands",
    "text": "1.2 Shell commands\nYou can run ‘terminal’ commands (called shell commands) from Jupyter without switching to the terminal. The only thing you need to do is to add a ! in front of the command.\nTo test out this feature, run the following:\n\nWindows macOS \n\n\n\nThis will print the current working directory.\n!cd\nThis will show you a list of all the files in your folder.\n!dir\n\n\n\n\nThis will print the current working directory.\n!pwd\nThis will show you a list of all the files in your folder.\n!ls\n\n\n\n\n\n\n\n\n\n\nSkip ‘Jupyter Extensions’\n\n\n\nJupyter Notebooks are transitioning to Notebook version 7. As a consequence, it seems that Jupyter Extensions no longer work properly. Therefore, I have decided to skip the following step (Jupyter Extensions) in your setup.\nNote that this will only cause minor differences in your coding experience."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/2_using-jupyter_good.html#installing-the-extensions",
    "href": "docs/python-basics/01_using_jupyter/2_using-jupyter_good.html#installing-the-extensions",
    "title": "Using Jupyter (Good)",
    "section": "Installing the extensions",
    "text": "Installing the extensions\nYou can add several useful features (e.g., code formatting, TOC, equation numbers) to your Jupyter notebooks by installing jupyter_contrib_nbextensions (documentation).\nYou can do this in the terminal by invoking the following.\nconda install -c conda-forge jupyter_contrib_nbextensions\njupyter contrib nbextension install --user\nOnce you have finished installing, log out and restart Jupyter. You will then see a new tab, as shown in the image below."
  },
  {
    "objectID": "docs/python-basics/01_using_jupyter/2_using-jupyter_good.html#enabling-the-extensions",
    "href": "docs/python-basics/01_using_jupyter/2_using-jupyter_good.html#enabling-the-extensions",
    "title": "Using Jupyter (Good)",
    "section": "Enabling the extensions",
    "text": "Enabling the extensions\nYou will also see details of what each extension does by clicking on the name in the list. Finally, you can enable them simply by checking the box on the list. Here are some of the extensions I recommend.\n\nEquation Auto Numbering\nTable of Contents (2)\nVariable Inspector\nCode folding\nAutopep8 You must install the package autopep8 using conda for this to work.\n\nDiscover what features these have added by creating a new Jupyter Notebook. You will see several new buttons in the toolbar corresponding to some extensions. For instance, if you run x=10 in a code cell the Variable Inspector will show the details of the variable."
  },
  {
    "objectID": "docs/python-basics/04_loops/3_loops_nice.html",
    "href": "docs/python-basics/04_loops/3_loops_nice.html",
    "title": "Loops (Nice)",
    "section": "",
    "text": "Warning\n\n\n\nThe material in this ‘Nice’ chapter is optional. The discussion typically deals with content beyond what a novice should know. So, please finish all the ‘Need’ and ‘Good’ portions before you go through this chapter.\n\n\n\n1 There is more to list comprehension\n\n\n\n\n\n\n\n\n\nYou can have more than one loop in a list comprehension.\n\n\n[[a,b] for a in range(5) for b in ['A', 'B', 'C']]\n\n\n[[0, 'A']\n [0, 'B']\n [0, 'C']\n [1, 'A']\n [1, 'B']\n [1, 'C']\n [2, 'A']\n [2, 'B']\n [2, 'C']\n [3, 'A']\n [3, 'B']\n [3, 'C']\n [4, 'A']\n [4, 'B']\n [4, 'C']]\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can even incorporate a condition!\n\n\n[[a,b] for a in range(5) for b in ['A', 'B', 'C'] if a % 2 != 0]\n\n\n[[1, 'A']\n [1, 'B']\n [1, 'C']\n [3, 'A']\n [3, 'B']\n [3, 'C']]\n\n\n\n\n\n\n\nnested_list=[[1, 2, 3], [4, 5, 6, 7]]\n[y for x in nested_list for y in x]\nnested_list=[[1, 2, 3], [4, 5, 6, 7]]\n\noutput =[]\nfor x in nested_list:\n    for y in x:\n        output.append(y)\n\n\n\nHere is a slightly more complicated use of list comprehension to flatten a list.\n\n\n\n\n[1, 2, 3, 4, 5, 6, 7]\n\n\nThis does the same as:\n\n\n\n\n\n\n\n\n2 Zipping a dictionary\nzip() offers one of the easiest ways to combine two lists into a dictionary:\n\nsuper_names=[\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\nreal_names=[\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\ndict(zip(real_names, super_names))\n\n{'Natasha Romanoff': 'Black Widow', 'Tony Stark': 'Iron Man', 'Stephen Strange': 'Doctor Strange'}\n\n\nIn the above dict() is used to recast zip()’s output into a dictionary.\n\n\n3 for and while has an else\nnumbers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nfor i in numbers:\n    if i &lt; 0: break\nelse:\n    print('No negative numbers in the list')\n\n\n\nThe for and while loops in Python come with an optional else statement! The code in the else block is executed only if the loops are completed. The else code-block will not run if you exit the loop prematurely (e.g. by using break).\nShown alongside is a trivial example. You should add a negative number to the list, and re-run the snippet. There will be no message this time.\nSo, the else statement can be used to distinguish between the loops completing as planned or if there was a break (or return or an exception).\n\n\n\n\nNo negative numbers in the list\n\n\n\n\n\n\n\nExercises\n\nExercise 1 (Changing a list)  \n\nProblemA solution\n\n\nWe want a snippet of code based on a for loop to remove fruits starting with the letter ‘p’ from the following list.\nfruits = [\"apple\", \"banana\", \"jackfruit\",\n          \"pineapple\", \"papaya\", \"watermelons\",\n          \"peaches\", \"durian\",  \"mangoes\",\n          \"strawberries\", \"passionfruit\"\n          ]\nThe following has been suggested as a solution. However, it does not work!\nfor fruit in fruits:\n    if fruit[0] == \"p\":\n        fruits.remove(fruit)\nIdentify, understand and fix the error.\n\n\nfor fruit in fruits:\n    if fruit[0] == \"p\":\n        fruits.remove(fruit)\nAlthough the above code is elegant it has a serious flaw which you can see by using pythontutor.com to visualise the flow of the script.\nA safer solution is the following:\n\nfruits = [\"apple\", \"banana\", \"jackfruit\",\n          \"pineapple\", \"papaya\", \"watermelons\",\n          \"peaches\", \"durian\",  \"mangoes\",\n          \"strawberries\", \"passionfruit\"\n          ]\n\ncopy_of_fruits = fruits.copy()\n\n# Not that we are looping(iterating) over the copy\nfor fruit in copy_of_fruits:\n    if fruit[0] == \"p\":\n        fruits.remove(fruit)\nAn even better, clean and elegant solutions is:\nfruits = [\"apple\", \"banana\", \"jackfruit\",\n          \"pineapple\", \"papaya\", \"watermelons\",\n          \"peaches\", \"durian\",  \"mangoes\",\n          \"strawberries\", \"passionfruit\"\n          ]\n\n[fruit for fruit in fruits if fruit[0] != \"p\"]\n\n\n\n\n\n\n\n\nExercise 2 (A list of powers)  \n\nProblemA Solution\n\n\nThe following code is an attempt to create a list \\([n, n^2,n^3]\\) for several values of \\(n\\). We can specify the maximum value of \\(n\\) by changing maximum_n.\nmaximum_n = 5\nresult = [[]] * maximum_n\n\nfor n in range(1, maximum_n + 1):\n    result[n - 1].append(n)\n    result[n - 1].append(n**2)\n    result[n - 1].append(n**3)\nFor maximum_n = 5 the content of result should be as shown below.\n[[1, 1, 1],\n [2, 4, 8],\n [3, 9, 27],\n [4, 16, 64],\n [5, 25, 125]]\nHowever, the code does not produce this expected result!Identify, understand, explain and fix the bug.\n\n\n\nAn explantion\nThe problem arises because [[]] * 5 creates 5 references to the same empty list []. Running a list comprehension will create 5 different empty lists [].\nLet’s check if what I have said is true.\nmaximum_n = 5\n\nresult = [[]] * maximum_n\n\nfor count, element in enumerate(result):\n    print(count, id(element))\nmaximum_n = 5\n\nresult = [[] for _ in range(maximum_n)]\n\nfor count, element in enumerate(result):\n    print(count, id(element))\n\n\n\n\n0 124743296740672\n1 124743296740672\n2 124743296740672\n3 124743296740672\n4 124743296740672\n\n\n\n\n0 124743296821888\n1 124743296822080\n2 124743296824384\n3 124743296822528\n4 124743296822272\n\n\n\n\n\n\nA solution\n\nmaximum_n = 5\n# result = [[]] * maximum_n\nresult = [[] for _ in range(maximum_n)]\n\nfor n in range(1, maximum_n + 1):\n    result[n - 1].append(n)\n    result[n - 1].append(n**2)\n    result[n - 1].append(n**3)\n\n\n\n[[1, 1, 1]\n [2, 4, 8]\n [3, 9, 27]\n [4, 16, 64]\n [5, 25, 125]]\n\n\n\n\n\n\n\n\nExercise 3 (Time profiling)  \n\nProblem\n\n\nUse %%timeit to compare the execution speeds of the following:\n\n\n\n\n\n\n\n\n\n\n#\nOption 1\nOption 2\nResult\n\n\n\n\n1\nCreating a list of squares with for loop\nCreating a list of squares with while loop\n\n\n\n2\nCreating a list of squares with a for loop.\nCreating a list of squares with a list comprehension loop.\n\n\n\n3\nCreating a list of squares using list append()\nCreating a list of squares using list +=\n\n\n\n4\nCreating a list of squares using list append()\nCreating a list of squares using append()of Numpy\n\n\n\n5\nCreating a list of squares using Numpy\nCreating a list of squares using List comprehension loop.\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/04_loops/1_loops_need_exercises.html",
    "href": "docs/python-basics/04_loops/1_loops_need_exercises.html",
    "title": "Loops (Need) Exercises",
    "section": "",
    "text": "Exercise 1 (Celcius to Farenheit) ☻\nYou are provided with the following list of temperatures in Celsius. Write a quick Python snippet that converts each temperature to Fahrenheit and prints both temperatures as a Celsius, Fahrenheit pair.\ntemperatures_celsius = [\n    0, 5, 10, 15, 20, 25,\n    30, 35, 40, 45, 50\n]\n\n\n\nExercise 2 (Multiplication table) ☻\n\nExampleTask\n\n\nYou can put a loop within a loop to do doubly loopy stuff. Here is an example:\n\nfor letter in ['A', 'B', 'C']:\n    for number in [1, 2, 3]:\n        print(f'{letter}{number}', end='\\t')\n    print('\\n')\n\nA1  A2  A3  \n\nB1  B2  B3  \n\nC1  C2  C3  \n\n\nTry this out and explore.\n\n\nWrite a Python snippet that prints a multiplication table (up to 5) for numbers 1 through 5 using nested for loops. The output should be formatted as shown below:\n\n\n1 : 1   2   3   4   5   \n2 : 2   4   6   8   10  \n3 : 3   6   9   12  15  \n4 : 4   8   12  16  20  \n5 : 5   10  15  20  25  \n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/04_loops/2_loops_good.html#basic-syntax",
    "href": "docs/python-basics/04_loops/2_loops_good.html#basic-syntax",
    "title": "Loops (Good)",
    "section": "2.1 Basic syntax",
    "text": "2.1 Basic syntax\n[number for number in range(5)]\n\n\n\nThe adjoining creates a simple list with numbers from 0 to 4.The syntax is very similar to that of a for loop. You just need to put the thing you want as an output at the front.\n\n\n\n[0, 1, 2, 3, 4]\n\n\n\n\n[number**2 for number in range(5)]\n\n\n\nIf you want to create a list of squares, we just have to:\n\n\n\n[0, 1, 4, 9, 16]"
  },
  {
    "objectID": "docs/python-basics/04_loops/2_loops_good.html#list-comprehension-with-conditions",
    "href": "docs/python-basics/04_loops/2_loops_good.html#list-comprehension-with-conditions",
    "title": "Loops (Good)",
    "section": "2.2 List comprehension with conditions",
    "text": "2.2 List comprehension with conditions\n[number for number in range(10) if number % 2 ==0]\n\n\n\nList comprehension has several useful features. One such allows us to specify a condition. Here is an example:\n\n\n\n[0, 2, 4, 6, 8]"
  },
  {
    "objectID": "docs/python-basics/04_loops/2_loops_good.html#for-with-unpacking",
    "href": "docs/python-basics/04_loops/2_loops_good.html#for-with-unpacking",
    "title": "Loops (Good)",
    "section": "3.1 for with unpacking",
    "text": "3.1 for with unpacking\nPython allows a neat trick called unpacking, which works like this:\n\nx, y, z=[1, 2, 3]\nprint(f'x = {x}, y = {y}, z = {z}')\n\nx = 1, y = 2, z = 3\n\n\nUnpacking can be put to good use (for example) when we are dealing with 2D list. We can combine unpacking with a for loop to extract elements as follows:\n\npy_superhero_info = [['Natasha Romanoff', 'Black Widow'],\n                     ['Tony Stark', 'Iron Man'],\n                     ['Stephen Strange', 'Doctor Strange']]\n\nfor real_name, super_name in py_superhero_info:\n    print(f\"{real_name} is Marvel's {super_name}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!"
  },
  {
    "objectID": "docs/python-basics/04_loops/2_loops_good.html#for-with-zip",
    "href": "docs/python-basics/04_loops/2_loops_good.html#for-with-zip",
    "title": "Loops (Good)",
    "section": "3.2 for with zip()",
    "text": "3.2 for with zip()\nLet’s revisit the example from the previous chapter that had two lists of real and superhero names that we used to print. There is yet another way to solve this task using a function called zip(). zip() is a neat function that can do some cool things. For the moment let me show you how to use zip() to combine two lists.\n\nsuper_names = [\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\nreal_names = [\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\nfor real_name, super_name in zip(real_names,super_names):\n    print(f\"{real_name} is Marvel's {super_name}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!\n\n\nThis is by far the most elegant solution we have for using multiple lists with a for loop."
  },
  {
    "objectID": "docs/python-basics/04_loops/2_loops_good.html#for-with-dictionaries",
    "href": "docs/python-basics/04_loops/2_loops_good.html#for-with-dictionaries",
    "title": "Loops (Good)",
    "section": "3.3 for with dictionaries",
    "text": "3.3 for with dictionaries\nYou will invariably need to loop through dictionaries in your programming career. Here is how you can do it with a for loop.\n\nsuperhero_info={\"Natasha Romanoff\": \"Black Widow\",\n                \"Tony Stark\": \"Iron Man\",\n                \"Stephen Strange\": \"Doctor Strange\"}\n\nfor key, value in superhero_info.items():\n    print(f\"{key} is Marvel's {value}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!\n\n\nThe ‘hidden’ function items() spits out both the key and the corresponding value.\nIf you like, you can directly access the keys as follows:\n\nfor key in superhero_info.keys():\n    value=superhero_info[key]\n    print(f\"{key} is Marvel's {value}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!\n\n\nBy the way, I have used the variable names key and value to highlight their roles in the dictionary. You can use whatever you like. In fact, using real_name and super_name is preferred."
  },
  {
    "objectID": "docs/python-basics/04_loops/2_loops_good.html#footnotes",
    "href": "docs/python-basics/04_loops/2_loops_good.html#footnotes",
    "title": "Loops (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nor the end of the Universe↩︎"
  },
  {
    "objectID": "docs/python-basics/02_basics/1_basics_need_exercises.html",
    "href": "docs/python-basics/02_basics/1_basics_need_exercises.html",
    "title": "Fundamentals (Need) Exercises",
    "section": "",
    "text": "Exercise 1 (Total recall?) ☻\n\nPurely from memory, list as many of the basic Python features I mentioned in my notes as you remember.\nUse a Markdown cell for this list.\nNow, visit the notes and complete the list with the ones you missed.\nIndicate those you missed by putting them in italics.\n\n\n\nExercise 2 (Debug me) ☻\nFix (debug) the following code to create a Pythagorean triple 3, 4, 5 (because \\(3^2+4^2=5^2\\)).\nx, y = 3, 4\n        z = sqrt(x*2 + y**2)\n    Print(x, y, z)\n\n\nExercise 3 (In your own words) ☻\nUsing your own words, write a single sentence to describe what each of the following means or the role they serve in Python.\nPlease use a Markdown table for this.\n\n\n\n\n\n\n#\nTerm\nDescription\n\n\n\n\n1\nFunction\n\n\n\n2\nArguments\n\n\n\n3\nComments\n\n\n\n4\nIndentations\n\n\n\n5\nPackages\n\n\n\n6\n.\n\n\n\n7\n:\n\n\n\n8\n[]\n\n\n\n9\n[[[]]]\n\n\n\n10\n{}\n\n\n\n\n\n\n\n\n\nExercise 4 (More than one way to divide) ☻\nProgramming languages usually offer multiple options for dividing one number by another. Shown below are three such options. Either by observation (i.e., trial and error), Googling or discussing with a friend, figure out what each one does.\nI recommended the trial and error approach first so that you get a feel for how to use Python.\nIndicate your answer by writing a comment.\n5/2           # What do I do?\n5//2          # What do I do?\n5%2           # What do I do?\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/02_basics/2_basics_good_exercises.html",
    "href": "docs/python-basics/02_basics/2_basics_good_exercises.html",
    "title": "Fundamentals (Good) Exercises",
    "section": "",
    "text": "Exercise 1 (What is your grade?)  \n\nStep 1Task\n\n\nPython allows you to solicit information from the user.\nOne way to do this is using the input() function. Here is an example of how to use it.\nuser_input = input('Give me a number?')\nprint('You entered', user_input)\nRun this code and explore.\n\n\nWrite a Python program that takes a numerical grade (0-100) as input and outputs the corresponding letter grade based on the following criteria:\n\n\n\n\nGrade\nScore Range\n\n\n\n\nA\n70 - 100\n\n\nB\n50 - 69\n\n\nC\n35 - 49\n\n\nFail\n0 - 34\n\n\n\n\nNote:\n\nHere is an example of the type of exchange expected.\nEnter the student's score: 85\nThe student's letter grade is: A\nEnsure your program handles unexpected inputs gracefully and displays a relevant error message.\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need_exercises.html",
    "href": "docs/python-basics/07_plotting/1_plotting_need_exercises.html",
    "title": "Plotting (Need) Exercises",
    "section": "",
    "text": "Exercise 1 (Fill in the blanks) Fill in the blanks(indicated with a ?), so the code below will produce the plot shown.\n\n\n\n\n\n\n# Some data for plotting\nx = [0, 1, 2, 3, 4, 5]\ny = [0, 4, 8, 12, 16, 20]\ny_err = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5]\nx_err = .25\n\nplt.errorbar(x, y, \n             xerr=?, yerr=?,\n             color=?, linestyle=?,\n             marker=?, markerfacecolor=?,\n             ecolor=?,capsize=5,\n             label=?)\nplt.xlabel('x-values')\nplt.ylabel('y-values')\nplt.title('X vs Y')\nplt.grid(alpha=.25)\nplt.legend(?)\nplt.show()\n\n\n\n\n\n\n\n\nExercise 2 (A simple mathematical plot)  \n\n\n\n\n\n\n\nUse NumPy to generate \\(x\\) and \\(y\\) data suitable for plotting the graph of the function: \\[ y = e^{-x/10}\\sin(x)\\]\nfor values of \\(x\\) in the range \\(0\\) to \\(50\\).\nCustomise your plot so that:\n\nThe x and y axes have labels of fontsize of 15\nThe x and y axes labels are in the color, darkorange.\nThere is a grid with an opacity of 25%.\nIndicate the equation of the function in the title with a font size of 20.Hint: Look at Writing mathematical expressions in Matplotlib.\nChange the \\(y\\) limit (using ylim) to \\([-1,1]\\)\n\n\nIn the end, your plot should look like the one shown alongside.\n\n\n\n\n\n\n\nContributed by Darren Teo\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need.html",
    "href": "docs/python-basics/07_plotting/1_plotting_need.html",
    "title": "Plotting (Need)",
    "section": "",
    "text": "Matplotlib unleashed! (Image from Python Data Visualization with Matplotlib — Part 1)"
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need.html#lets-look-at-some-code.",
    "href": "docs/python-basics/07_plotting/1_plotting_need.html#lets-look-at-some-code.",
    "title": "Plotting (Need)",
    "section": "1.1 Let’s look at some code.",
    "text": "1.1 Let’s look at some code.\nShown below is some code and the resulting plot.\n# Some data for plotting\nx = [0, 1, 2, 3, 4, 5, 6]\ny_1 = [0, 2, 4, 6, 8, 10, 12]\ny_2 = [0, 3, 6, 9, 12, 15, 18]\n\n# Let's start plotting\nplt.plot(x, y_1, label='Y values',\n         color='red', linestyle='dashed')\nplt.xlabel('x-values')\nplt.ylabel('y-values')\nplt.title('X vs Y')\nplt.grid(alpha=.25)\nplt.legend(loc='upper left')\n\n\n\n\n\n\n\n\n\n\nCopy, paste, and run this code snippet to generate the plot. Then, spend a few minutes perusing the code to figure out what each line achieves in the plot. A simple way to do this is by commenting out some lines to turn off their contributions or changing some parameters (e.g., loc to bottom left) and numbers (e.g., alpha to .8). It will help you learn faster if you try to predict what will happen before running the code.\n\nThings to note\n\nYou can use the following abbreviations if you like:\n\n\n\n\n\nLong form\nAbbreviation\n\n\n\n\ncolor\nc\n\n\nlinestyle\nls\n\n\nlinewidth\nlw\n\n\n\n\nso, both the following lines produce the same result.\nplt.plot(x, y, color='red', linestyle='dashed', linewidth=2)\nplt.plot(x, y, c='red', ls='dashed', lw=2)\n\nJupyter is an interactive environment, so you will see an output even if you omit plt.show(). However, it is good practice to include this line anyway so your code will also work in non-interactive environments (for instance, when the script is run directly from the command line).\n\n\n\n\n\n\n\n\nThe plotting functions usually have default values for the styling parameters. So, if you wish, you can keep it simple and plot just using:\nplt.plot(x, y_1, y_2)\nThe resulting plot is shown alongside.\nYou can split the arguments into separate lines to improve readability.So, both of the following forms are acceptable.\n\n\n\n\n\n\n\n\nplt.plot(x, y, color='red', linestyle='dashed', linewidth=2)\nplt.plot(x, y_1, label='Y values',\n           color='red', linestyle='dashed')\n\nThe order of how you specify the keyword arguments (color, linewidth, …) does not matter."
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need.html#adding-another-plot",
    "href": "docs/python-basics/07_plotting/1_plotting_need.html#adding-another-plot",
    "title": "Plotting (Need)",
    "section": "1.2 Adding another plot",
    "text": "1.2 Adding another plot\n\n\n\n\n\n\nYou can add another plot command to the graph to plot the data of y_2 in blue by adding the following line.\nplt.plot(x, y_2,\n         label='Y2 values', color='blue')\nOnce you do this, the code will look like this:\n\n\n\n\n\n\n\n# Some data for plotting\nx = [0, 1, 2, 3, 4, 5, 6]\ny_1 = [0, 2, 4, 6, 8, 10, 12]\ny_2 = [0, 3, 6, 9, 12, 15, 18]\n\n# Lets start plotting\nplt.plot(x, y_1, label='Y1 values', color='red', linestyle='dashed')\nplt.plot(x, y_2, label='Y2 values', color='blue')\nplt.xlabel('x-values')\nplt.ylabel('y-values')\nplt.title('X vs Y')\nplt.grid(alpha=.25)\nplt.legend(loc='upper left')"
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need.html#yet-another-plot-but-with-error-bars",
    "href": "docs/python-basics/07_plotting/1_plotting_need.html#yet-another-plot-but-with-error-bars",
    "title": "Plotting (Need)",
    "section": "1.3 Yet another plot but with error bars",
    "text": "1.3 Yet another plot but with error bars\n\n\n\n\n\n\nLet me add another plot, but this time I will also include \\(x\\) and \\(y\\) error bars for the points. The plotting command I need to use for this is called errorbar().\nplt.errorbar(x, y_3,\n             xerr=x_error, yerr=y_error,\n             label=\"Y3 with errors\",\n             color=\"green\")\nOnce you do this, the code will look like this:\n\n\n\n\n\n\n\n# Some data for plotting\nx = [0, 1, 2, 3, 4, 5, 6]\ny_1 = [0, 2, 4, 6, 8, 10, 12]\ny_2 = [0, 3, 6, 9, 12, 15, 18]\ny_3 = [0, 4, 8, 12, 16, 20, 24]\nx_error, y_error = .1, 0.75\n\n# Lets start plotting\nplt.plot(x, y_1, label='Y1 values', color='red', linestyle='dashed',)\nplt.plot(x, y_2, label='Y2 values', color='blue', )\nplt.errorbar(x, y_3, xerr=x_error, yerr=y_error,\n             label='Y3 with errors', color='green')\nplt.xlabel('x-values')\nplt.ylabel('y-values')\nplt.title('X vs Y')\nplt.grid(alpha=.25)\nplt.legend(loc='upper left')\n\nIn this example, I have provided constant errors for all the points. However, you can also provide a list of errors so that each will have a different length.\n\n\n\n\n\n\n\nPlease note\n\n\n\nFrom here onwards, I will show a minimum of code related to styling to reduce clutter. You should, however, still retain them to get nice-looking plots."
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need.html#adding-mathematical-functions",
    "href": "docs/python-basics/07_plotting/1_plotting_need.html#adding-mathematical-functions",
    "title": "Plotting (Need)",
    "section": "2.1 Adding mathematical functions",
    "text": "2.1 Adding mathematical functions\nOne of the advantages of NumPy arrays is that they allow us to generate data-related mathematical functions easily. Let’s reuse our previous code to plot \\(x^2\\) and \\(\\sin(x)\\)\nx = np.array([0, 1, 2, 3, 4, 5, 6])\n\nx2 = x**2                  # The math stuff\nsin_x = np.sin(x)\n\nplt.plot(x, x2, label='x^2',\n         color='red', linestyle='dashed', )\nplt.plot(x, sin_x, label='sin(x)',\n         color='blue')\nplt.legend()                                 \n\n\n\n\n\n\n\n\n\n\nAlas, our plot does not look good because \\(\\sin(x)\\) lies between \\(\\pm 1\\), but \\(x^2\\) has no such bounds. One way to fix this is to add another y-axis that shares the same x-axis."
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need.html#plotting-twinx",
    "href": "docs/python-basics/07_plotting/1_plotting_need.html#plotting-twinx",
    "title": "Plotting (Need)",
    "section": "We need another axis!",
    "text": "We need another axis!\nMatplotlib offers a variety of ways to have multiple axes. The simplest way is to have another y-axis that shares the same x-axis. We can use the command twinx() for this.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Two y-axes and fewer points.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Using np.linspace().\n\n\n\n\n\n\n\nx = np.array([0, 1, 2, 3, 4, 5, 6])\nx2 = x**2\nsin_x = np.sin(x)\n\nplt.plot(x, x2, label='x^2',color='red', linestyle='dashed')\nplt.legend(loc='lower left')                                  # For y-axis 1\n\nplt.twinx()                                                   # This creates a new y-axis \n                                                              # for the plots that comes after\nplt.plot(x, sin_x, label='sin(x)',color='blue', )\nplt.legend(loc='lower right')                                 # For y-axis 2\n\n\nThings to note\n\nWe now have two legend() calls, one for each axis.\nour plot still does not look good because we have only a few points. Let’s use np.linspace to fix this with:\nx = np.linspace(0, 6, 100)\nThe improvement is seen in the plot on the right."
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need.html#plotting-data-from-files",
    "href": "docs/python-basics/07_plotting/1_plotting_need.html#plotting-data-from-files",
    "title": "Plotting (Need)",
    "section": "4.1 Plotting data from files",
    "text": "4.1 Plotting data from files\nPlotting data stored in a file (e.g., spreadsheet, text file, database) is a routine task for a scientist. In fact, the first thing you should do with any data is to look at it with a simple plot.\nFor the rest of this section, I will use the Earth’s land temperature data from the Berkeley Earth website. Please visit the site (Global Warming \\(\\rightarrow\\) Data Overview) and download the average temperature data for Daily Land. The original name of the file should be Complete_TAVG_daily.txt\n\n\n\n\n\n\ndata = np.loadtxt('Complete_TAVG_daily.txt',\n                   skiprows=24)\ndate = data[:, 0]\nanomaly = data[:, -1]\n\nplt.plot(date, anomaly, alpha=.5)\nplt.ylim([-8, 8])\nI have used a small alpha value to soften the colour of the plot and made the plot range symmetrical in the \\(y\\) direction.\n\n\n\n\n\n\nLet’s add a horizontal line at the zero value to highlight the trend shown by the data.The hlines() function needs a \\(y\\)-value and starting and ending values for \\(x\\).\nplt.hlines(0, date[0], date[-1], linestyle='--', colors='grey')"
  },
  {
    "objectID": "docs/python-basics/07_plotting/1_plotting_need.html#styles",
    "href": "docs/python-basics/07_plotting/1_plotting_need.html#styles",
    "title": "Plotting (Need)",
    "section": "4.2 Styles",
    "text": "4.2 Styles\nUnlike myself, most people (very sensibly) might just want a decent-looking plot without spending time customising it. To facilitate this Matplotlib offers some standard style templates (see here). I am going to use the one called fivethirtyeight.\nplt.style.use('fivethirtyeight')\nThis line must be included right at the top!\nEt voila! Do you see global warming?!\n\nHere is the complete code for the final product.\n\nplt.style.use('fivethirtyeight')\n\ndata = np.loadtxt('Complete_TAVG_daily.txt', skiprows=24)\n\ndate = data[:, 0]\nanomaly = data[:, -1]\n\nplt.plot(date, anomaly, alpha=.5)\nplt.hlines(0, date[0], date[-1], linestyle='--', colors='grey')\nplt.ylim([-8, 8])\n\nplt.xlabel('Date')\nplt.ylabel('Temperature Anomaly')\nplt.title('Temperature anomaly\\n(Relative to  average from Jan 1951 - Dec 1980.)')\n\n\nxkcd!\nOkay, since we are talking about styles, I must tell you that the developers of Matplotlib have a healthy sense of humour and have included the option of making your plots in the xkcd style. To enable this, just run plt.xkcd() instead of setting a style. Here is what the previous plot looks like using the xkcd style. Cool!\n\n\n\nResetting styles\nIf you want to reset things and jump out of this style, you need to set the default style using:\nplt.style.use('default')"
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html",
    "title": "Files, Folders & OS (Need)",
    "section": "",
    "text": "From xkcd"
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#path",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#path",
    "title": "Files, Folders & OS (Need)",
    "section": "1.1 Path",
    "text": "1.1 Path\nWhen dealing with computers, you will often encounter the term ‘path’. The path is simply a way to specify a location on your computer. It is like an address, and if you follow the path, it will take you to your file or folder.\nLike specifying location, you can specify your path absolutely or relatively. So, for example, I can specify that SPS is located on level 3 of block S16. However, if I am already on Level 5 of S16, I can say, go two floors down. The former is an absolute path, and the latter is relative. I have always found it easier to use relative paths, especially if I later want to move my folders about.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that the path tells us how to find a file or folder and that you can specify it absolutely or relatively.\n\n\nFor example, here is an absolute path to a file on the Desktop on a Windows machine.\nC:\\\\Users\\Chammika\\Desktop\\data-01.txt"
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#more-about-relative-paths",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#more-about-relative-paths",
    "title": "Files, Folders & OS (Need)",
    "section": "1.2 More about relative paths",
    "text": "1.2 More about relative paths\nWhen dealing with relative paths, you will find it helpful to know . and .. notation.\n\n\n\n\nNotation\nMeaning\n\n\n\n\n.\n‘this folder’\n\n\n..\n‘one folder above’\n\n\n\n\nSo,\n\n.\\data-files\\data-01.txt means the file data-01.txt in the folder data-files in the current folder.\n..\\data-files\\data-01.txt means the file data-01.txt in the folder data-files located in the folder above.\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember . means current folder, and .. means one folder up.\n\n\n\n\nmacOS or Linux\nmacOS and Linux allow you to use ~ to refer to your home directory. So, for example, you can access the Desktop in these systems ‘relatively’ with ~/Desktop. So, I can look for a file in my Desktop using:\n~\\Desktop\\data-01.txt"
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#path-separator",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#path-separator",
    "title": "Files, Folders & OS (Need)",
    "section": "1.3 Path separator",
    "text": "1.3 Path separator\nToday’s major OSs (Windows, macOS, Linux) offer similar graphical environments. However, one of the most striking differences between Windows and macOS (or Linux) is the path separator.\nWindows uses \\ as the path separator while macOS (or Linux) uses /. So, the absolute path to a file on the Desktop on each of these systems will look like this:\n\n\n\nWindows\nC:\\\\Users\\chammika\\Desktop\\data-01.txt\n\n\nmacOS (or Linux)\n/Users/chammika/Desktop/data-01.txt\n\n\n\nIf you want to share your code and want it to work on both systems, you must not hardcode either path separator. Later, I will show you how to use the Python os package to fix this problem."
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#text-files-vs.-binary-files",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#text-files-vs.-binary-files",
    "title": "Files, Folders & OS (Need)",
    "section": "1.4 Text files vs. Binary files",
    "text": "1.4 Text files vs. Binary files\nYou can think of all files on your computer as being either text files or binary files. Text files are simple and can be opened, and their contents examined by almost any software (e.g., Notepad, TextEdit, Jupiter,…). Examples of text file formats are .txt, .md or .csv.\nBinary files, in contrast, require some processing to make sense of what they contain. For example, if you look at the raw data in a .png file, you will see gibberish. In addition, some binary files will only run on specific OSs. For example, the Excel.app on a Mac will not run on Windows, nor will the Excel.exe file run on macOS (or Linux). Some reasons for having binary files are speed and size; text files, though simple, can get bulky."
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#extensions",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#extensions",
    "title": "Files, Folders & OS (Need)",
    "section": "1.5 Extensions",
    "text": "1.5 Extensions\nFiles are usually named to end with an extension separated from the name by a . like name.extension. This extension lets the OS know what software or app to use to extract the details in a file. For example, a .xlsx means use Excel or .pptx means use PowerPoint. Be careful about changing the extension of a file, as it will make your OS cough and throw a fit. If you don’t believe me, try changing a .xlsx to .txt and double-click."
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#reading-data",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#reading-data",
    "title": "Files, Folders & OS (Need)",
    "section": "2.1 Reading data",
    "text": "2.1 Reading data\nHere is what you would typically do to read a text file.\nwith open('spectrum-01.txt', 'r') as file:\n    file_content = file.read()\n\nprint(file_content)\nThe open() function ‘opens’ your file. The 'r' specifies that I only want to read from the file. Using with frees you from worrying about closing the file after you are done."
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#writing-data",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#writing-data",
    "title": "Files, Folders & OS (Need)",
    "section": "2.2 Writing data",
    "text": "2.2 Writing data\nNow, let’s write the following into a file.\n\ntext = 'Far out in the uncharted backwaters of the unfashionable end of the western spiral arm of the Galaxy lies a small unregarded yellow sun.\\nOrbiting this at a distance of roughly ninety-two million miles is an utterly insignificant little blue green planet whose ape-descended life forms are so amazingly primitive that they still think digital watches are a pretty neat idea.'\n\nI will use two writing methods just so that I can show you how they work.\n\nWriting to a file in one go\nFirst, let’s write everything in one go.\nwith open('my-text-once.txt', 'w') as file:\n    file.write(text)\nYou should now have a file my-text-once.txt in your directory. You should open it to take a look. By the way, the 'w' indicates that I am opening the file for writing.\n\n\nWriting to a file, line by line\nLet me show you how to write a line at a time. This is useful when dealing with data generated on the fly. Since I don’t have such data now, I will split the lines of the previous text [The contents in both files will be slightly different. However, this is not a time to worry about that.].\nwith open('my-text-lines.txt', 'w') as file:\n    for line in text.splitlines():\n        file.writelines(line)\nI must add that writing to a file is a very slow operation. So, it will slow things down if you do it in a loop."
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#creating-folders",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#creating-folders",
    "title": "Files, Folders & OS (Need)",
    "section": "5.1 Creating folders",
    "text": "5.1 Creating folders\nYou can create a folder programmatically using os.mkdir(). This is very useful because you can write a tiny bit of code to quickly organise your data. For example, let’s say we need to store information about the people ‘John’, ‘Paul’ and ‘Ringo’. I can quickly create some folders for this by:\n\nos.mkdir('people')\n\nfor person in ['John', 'Paul', 'Ringo']:\n    path = os.path.join('people', person)\n    print(f'Creating {path}')\n    os.mkdir(path)\n\nCreating people/John\nCreating people/Paul\nCreating people/Ringo\n\n\nYou don’t need the print() statement. I have included it so I have some feedback on what is (or is not) happening."
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#checking-for-existence",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#checking-for-existence",
    "title": "Files, Folders & OS (Need)",
    "section": "5.2 Checking for existence",
    "text": "5.2 Checking for existence\nPython will complain if you try to run this code twice, saying that the file (yes, Python refers to folders as files) already exists. So, when you create resources, it is a good idea to check if they already exist. There are two ways to do this: use try-except with the FileExistsError or use os.path.exists().\n\nUsing try-except\nfor person in ['John', 'Paul', 'Ringo']:\n    path = os.path.join('people', person)\n    try:\n        os.mkdir(path)\n        print(f'Creating {path}')\n    except FileExistsError:\n        print(f'{path} already exists; skipping creation.')\n\n\nUsing os.path.exists()\nfor person in ['John', 'Paul', 'Ringo']:\n    path = os.path.join('people', person)\n    if os.path.exists(path):\n        print(f'{path} already exists; skipping creation.')\n    else:\n        os.mkdir(path)\n        print(f'Creating {path}')"
  },
  {
    "objectID": "docs/python-basics/06_this-n-that/1_os_need.html#copying-files",
    "href": "docs/python-basics/06_this-n-that/1_os_need.html#copying-files",
    "title": "Files, Folders & OS (Need)",
    "section": "5.3 Copying files",
    "text": "5.3 Copying files\nLet me show you how to copy files programmatically.\nFirst, there should be a copy of the 73 logo (sp2273_logo.png) in the current folder. Then, I will copy this into the folders I created for ‘John’, ‘Paul,’ and ‘Ringo’.\n\nfor person in ['John', 'Paul', 'Ringo']:\n    path_to_destination = os.path.join('people', person)\n    shutil.copy('sp2273_logo.png', path_to_destination)\n    print(f'Copied file to {path_to_destination}')\n\n'people/John/sp2273_logo.png'\nCopied file to people/John\n'people/Paul/sp2273_logo.png'\nCopied file to people/Paul\n'people/Ringo/sp2273_logo.png'\nCopied file to people/Ringo\n\n\nLet’s say I want all the images in a sub-folder called imgs in each person’s directory. I can do this by first creating the folders imgs and then moving the logo file into that folder.\n\nfor person in ['John', 'Paul', 'Ringo']:\n    # Create folder 'imgs'\n    path_to_imgs = os.path.join('people', person, 'imgs')\n    if not os.path.exists(path_to_imgs):\n        os.mkdir(path_to_imgs)\n\n    # Move logo file\n    current_path_of_logo = os.path.join('people', person, 'sp2273_logo.png')\n    new_path_of_logo = os.path.join('people', person, 'imgs', 'sp2273_logo.png')\n\n    shutil.move(current_path_of_logo, new_path_of_logo)\n    print(f'Moved logo to {new_path_of_logo}')\n\n'people/John/imgs/sp2273_logo.png'\nMoved logo to people/John/imgs/sp2273_logo.png\n'people/Paul/imgs/sp2273_logo.png'\nMoved logo to people/Paul/imgs/sp2273_logo.png\n'people/Ringo/imgs/sp2273_logo.png'\nMoved logo to people/Ringo/imgs/sp2273_logo.png\n\n\n\n\n\n\n\n\nFYI\n\n\n\nYou can do all these extremely fast using only the terminal and its loops structure. Just letting you know if you want to explore on your own."
  },
  {
    "objectID": "docs/python-basics/03_storing-data/1_storing-data_need_exercises.html",
    "href": "docs/python-basics/03_storing-data/1_storing-data_need_exercises.html",
    "title": "Storing Data (Need) Exercises",
    "section": "",
    "text": "Exercise 1 (Total recall?) ☻\nPurely from memory, jot down:\n\nTwo similarities between lists and arrays.\nTwo differences between lists and arrays.\nWhat is a dictionary?\n\nIf you cannot recall the answers, please refer to the course notes and put this information you could not recall in italics.\n\n\nExercise 2 (Indexing) ☻\nModify the following code to print out all elements with an odd number. I have done the one corresponding to i9 for you.\n\npy_list = [\"a1\", \"b2\", \"c3\", \"d4\", \"e5\", \"f6\", \"g7\", \"h8\", \"i9\", \"j10\"]\n                    # Prints 'a1'\n                    # Prints 'c3'\n                    # Prints 'e5'\n                    # Prints 'g7'\nprint(py_list[8])   # Prints 'i9'\n\ni9\n\n\n\n\nExercise 3 (Index again) ☻\nGiven the following list in Python:\nelements = ['Hydrogen',\n            'Helium', 'Lithium',\n            'Beryllium', 'Boron', 'Carbon',\n            'Nitrogen', 'Oxygen',\n            'Fluorine',\n            'Neon']\n\nAccess and print the element at index 4 using forward indexing.\nAccess and print the element at index 4 from the end of the list using reverse indexing.\n\n\n\nExercise 4 (How many ones) ☻\nUse the concepts you learned in this chapter to determine the number of 1’s in the following list of numbers.\nnumbers=[45, 60, 1, 30, 96, 1, 96, 57, 16, 1,\n        99, 62, 86, 43, 42, 60, 59, 1, 1, 35,\n        83, 47, 34, 28, 68, 23, 22, 92, 1, 79,\n        1, 29, 94, 72, 46, 47, 1, 74, 32, 20,\n        8, 37, 35, 1, 89, 29, 86, 19, 43, 61]                  \nHere are some hints:\n\nUse a NumPy array.\nAsk a question.\nFalse is considered 0, and True is considered 1 by sum().\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/03_storing-data/2_storing-data_good_exercises.html",
    "href": "docs/python-basics/03_storing-data/2_storing-data_good_exercises.html",
    "title": "Storing Data (Good) Exercises",
    "section": "",
    "text": "Exercise 1 (Total recall) ☻\nPurely from memory, write short descriptions of the following terms:\n\n\n\n\nTerm\nBrief description\n\n\n\n\nSubsetting\n\n\n\nIndexing\n\n\n\nSlicing\n\n\n\nMasking\n\n\n\n\n\nIf you cannot recall the answers, please refer to the notes and put this information you could not recall in italics.\n\n\nExercise 2 (Show me the ‘odd’ letters) ☻\nnp_array_2d = np.array([[1, \"A\"], [3, \"C\"], [2, \"B\"], [4, \"D\"],\n                        [5, \"E\"], [7, \"G\"], [6, \"F\"], [8, \"H\"],\n                        [10, \"J\"], [9, \"I\"]])\nUse masking to subset the letters that correspond to the odd numbers. I.e., get the result [A, C, E, G, I].\nThis is a slightly tricky problem because arrays are fussy about type. So, let me give you a recipe to solve this problem.\n\nSubset all the first elements.\n\nYou should get array(['1', '3', '2', ..., '10', '9'])\n\nConvert this to integers using astype(int)\n\nYou must look up how astype() works.\n\nUse % to get the remainder for division by 2.\n\nYou should get array([1, 1, 0, ..., 0, 1]).\n\nUse the previous result to create a mask that checks if the remainder is zero or not\n\nYou should get array([True, True, False, ..., False, True]).\nNow you have identified the locations of the odd numbers.\n\nUse the mask and extract the corresponding second elements.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-basics/05_functions/3_functions_nice.html#args-kwarg",
    "href": "docs/python-basics/05_functions/3_functions_nice.html#args-kwarg",
    "title": "Functions (Nice)",
    "section": "2.1 *args & **kwarg",
    "text": "2.1 *args & **kwarg\nYou will often see the syntax *args and **kwarg. These stand for arguments and keyword arguments, respectively. They allow us flexible ways of using unpacking and dictionaries to pass information to functions. Let’s see how to do this.\n\n*args\n\n\n\ndef multiply(x, y):\n    return x * y\n\nnumbers = [1, 2]\nmultiply(*numbers)\n\n\n\nWe can use unpacking to make passing arguments to functions a breeze!\nThe * is essential! Without this, Python will assign x=numbers and complain that y is missing.\n\n\n\n2\n\n\n\n\n\n\ndef multiply(*args):\n    result = 1\n    for number in args:\n        result *= number\n\n    return result\n\nnumbers = [1, 2, 3]\nmultiply(*numbers)\nmultiply(1, 2, 3, 4, 5)\n\n\n\nWhat if we want our function to multiply more than two numbers?\n\n\n\n\n6\n\n\nThis will work, too!\n\n\n120\n\n\n\n\n\n\n\n\n\n\n**kwargs\n\n\n\ndef multiply(x, y, z):\n    return x * y * z\n\n# Let's use the function\nnumbers = {'x': 1, 'y': 2, 'z': 3}\nmultiply(**numbers)\n\n\n\nWe can also pass keyword arguments using a dictionary:\nThe ** is essential!\n\n\n\n6\n\n\n\n\n\n\ndef multiply(x, y, z):\n    return x * y * z\n\n# Let's use the function\nnumbers = {'y': 2, 'z': 3}\nmultiply(1, **numbers)\n\n\n\nWe can mix positional arguments and a dictionary!\n\n\n\n6\n\n\n\n\n\n\ndef add_powers(numbers, power):\n    result = 0\n    for number in numbers:\n        result += number**power\n\n    return result\n\n# Let's use the function\nkwargs = {'numbers': [1, 2, 3], 'power': 2}\nadd_powers(**kwargs)\n\n\n\n\n\n\n\n14\n\n\n\n\n\n\ndef add_powers(**kwargs):\n    numbers = kwargs['numbers']\n    power = kwargs['power']\n\n    result = 0\n    for number in numbers:\n        result += number**power\n\n    return result\n\n\n# Let's use the function\nadd_powers(numbers=[1, 2, 3], power=2)\nkwargs = {'numbers': [1, 2, 3], 'power': 2}\nadd_powers(**kwargs)\n\n\n\nWe can also set up our function to accept any keyword arguments!\n\n\n\n\n14\n\n\nThis works too!\n\n\n14"
  },
  {
    "objectID": "docs/python-basics/05_functions/3_functions_nice.html#the-problem",
    "href": "docs/python-basics/05_functions/3_functions_nice.html#the-problem",
    "title": "Functions (Nice)",
    "section": "3.1 The Problem",
    "text": "3.1 The Problem\nUsing functions to modularise your code (and your thinking) is good. However, you need to be careful with the type of variables that you pass as arguments. To see what I am talking about, try running the following code. Can you see what is happening?\n\ndef do_something(inside_number, inside_array, inside_list):\n    print('Doing something!')\n    inside_number *= 2\n    inside_array *= 2\n    inside_list *= 2\n\n    print(f\"INSIDE|\\tNumber: {inside_number}(id: {id(inside_number)}), Array: {inside_array}(id: {id(inside_array)}), List: {inside_list}(id: {id(inside_list)})\")\n\noutside_number = 10\noutside_array = np.array([10])\noutside_list = [10]\n\nprint(f\"BEFORE|\\tNumber: {outside_number}(id: {id(outside_number)}), Array: {outside_array}(id: {id(outside_array)}), List: {outside_list}(id: {id(outside_list)})\")\ndo_something(outside_number, outside_array, outside_list)\nprint(f\"AFTER|\\tNumber: {outside_number}(id: {id(outside_number)}), Array: {outside_array}(id: {id(outside_array)}), List: {outside_list}(id: {id(outside_list)})\")\n\n\n\nBEFORE| Number: 10(id: 129429423894504), Array: [10](id: 129428331495472), List: [10](id: 129428150553728)\n\n\nDoing something!\nINSIDE| Number: 20(id: 129429423894824), Array: [20](id: 129428331495472), List: [10, 10](id: 129428150553728)\n\n\nAFTER|  Number: 10(id: 129429423894504), Array: [20](id: 129428331495472), List: [10, 10](id: 129428150553728)\n\n\nSo, the function has changed the values of some variable outside the function! But, not all variables are affected."
  },
  {
    "objectID": "docs/python-basics/05_functions/3_functions_nice.html#an-explanation",
    "href": "docs/python-basics/05_functions/3_functions_nice.html#an-explanation",
    "title": "Functions (Nice)",
    "section": "3.2 An Explanation",
    "text": "3.2 An Explanation\nFor ‘immutable’ variables, what happens inside the function does not change the variable outside. In other languages, this behaviour is called passing by value.\nFor ‘mutable’ variables, what happens inside the function does change the variable outside. In other languages, this behaviour is called passing by reference.\nSo, in Python, you must be very careful about the mutability of the variable you are passing. Otherwise, you will spend a long time trying to understand why your code is acting weird."
  },
  {
    "objectID": "docs/python-basics/05_functions/3_functions_nice.html#a-list-of-exceptions",
    "href": "docs/python-basics/05_functions/3_functions_nice.html#a-list-of-exceptions",
    "title": "Functions (Nice)",
    "section": "4.1 A list of exceptions",
    "text": "4.1 A list of exceptions\nHere is an incomplete list of exceptions2. You can find more details at the Python documentation pages.\n\n\n\n\n\n\n\n\nException\nDescription\n\n\n\n\nAssertionError\nRaised when the assert statement fails.\n\n\nAttributeError\nRaised on the attribute assignment or reference fails.\n\n\nEOFError\nRaised when the input() function hits the end-of-file condition.\n\n\nFloatingPointError\nRaised when a floating point operation fails.\n\n\nImportError\nRaised when the imported module is not found.\n\n\nIndexError\nRaised when the index of a sequence is out of range.\n\n\nKeyError\nRaised when a key is not found in a dictionary.\n\n\nNameError\nRaised when a variable is not found in the local or global scope.\n\n\nOSError\nRaised when a system operation causes a system-related error.\n\n\nOverflowError\nRaised when the result of an arithmetic operation is too large to be represented.\n\n\nRuntimeError\nRaised when an error does not fall under any other category.\n\n\nSyntaxError\nRaised by the parser when a syntax error is encountered.\n\n\nIndentationError\nRaised when there is an incorrect indentation.\n\n\nSystemError\nRaised when the interpreter detects internal error.\n\n\nSystemExit\nRaised by the sys.exit() function.\n\n\nTypeError\nRaised when a function or operation is applied to an object of an incorrect type.\n\n\nUnboundLocalError\nRaised when a reference is made to a local variable in a function or method, but no value has been bound to that variable.\n\n\nValueError\nRaised when a function gets an argument of correct type but improper value.\n\n\nZeroDivisionError\nRaised when the second operand of a division or module operation is zero."
  },
  {
    "objectID": "docs/python-basics/05_functions/3_functions_nice.html#handling-specific-exceptions",
    "href": "docs/python-basics/05_functions/3_functions_nice.html#handling-specific-exceptions",
    "title": "Functions (Nice)",
    "section": "4.2 Handling specific exceptions",
    "text": "4.2 Handling specific exceptions\nI was sloppy in my try-exept example in the last chapter. I could have been more specific about the type of exception. A better version of the code is:\ntry:\n    number=input(\"Give me a number and I will calculate its square.\")\n    square=int(number)**2\n    print(f'The square of {number} is {square}!')\nexcept ValueError:\n    print(f\"Oh oh! I cannot square {number}!\")"
  },
  {
    "objectID": "docs/python-basics/05_functions/3_functions_nice.html#try-also-has-an-else-and-finally",
    "href": "docs/python-basics/05_functions/3_functions_nice.html#try-also-has-an-else-and-finally",
    "title": "Functions (Nice)",
    "section": "4.3 try also has an else and finally",
    "text": "4.3 try also has an else and finally\nThe try-except statement also has optional else and finally blocks. else runs only if everything works smoothly, and finally always runs at the end.\nHere is an example:\ntry:\n    number=input(\"Give me a number and I will calculate its square.\")\n    square=int(number)**2\n    print(f'The square of {number} is {square}!')\nexcept ValueError:\n    print(f\"Oh oh! I cannot square {number}!\")\nelse:\n    print('Yeah! Things ran without a problem!')\nfinally:\n    print('Okay, looks like everything is done!')"
  },
  {
    "objectID": "docs/python-basics/05_functions/3_functions_nice.html#footnotes",
    "href": "docs/python-basics/05_functions/3_functions_nice.html#footnotes",
    "title": "Functions (Nice)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nand classes↩︎\nborrowed from here↩︎"
  },
  {
    "objectID": "docs/python-basics/05_functions/1_functions_need.html#named-functions",
    "href": "docs/python-basics/05_functions/1_functions_need.html#named-functions",
    "title": "Functions (Need)",
    "section": "1.1 Named Functions",
    "text": "1.1 Named Functions\n\nNamed functions that return\nWe define the function by using the keyword def as follows:\n\ndef greeting(name):\n    if name == 'Batman':\n        return 'Hello Batman! So, nice to meet you!'\n    else:\n        return f'Hello {name}!'\n\nThe function’s name is greeting and it accepts a single argument called name. We can then use the function as:\ngreeting(\"Super Man\")\nor\ngreeting(name=\"Super Man\")\nAs with all structures in Python, notice the keyword def, the colon (:) and the indentation that demarcates the function’s code block. Notice also that I have used the keyword return to get an output from the function. When Python sees a return keyword it jumps out of the function with the return value. You can pick up the returned value by assigning it to a variable or even use it directly like:\ngreet=greeting(name='Super Man')\nprint(greet)\nor this works too:\nprint(greeting(name='Super Man'))\nIncidentally, you can use return only within a function.\nI also like to point out that you can return almost anything! Here is an example of a function that accepts a list and returns the maximum, minimum and mean.\n\ndef basic_stats(numbers):\n    np_numbers = np.array(numbers)\n    my_min = np_numbers.min()\n    my_max = np_numbers.max()\n    my_mean = np_numbers.mean()\n    return my_max, my_min, my_mean\n\nHere is how you can use it:\nlist_min, list_max, list_mean = basic_stats([1, 2, 3, 4, 5])\n\n\nNamed functions that don’t return\nA function does not have to return anything. A good example is print(), which does something but does not return a value. You will often also need functions like these, for instance, to save data to a file. I will show you a few of such functions in later chapters."
  },
  {
    "objectID": "docs/python-basics/05_functions/1_functions_need.html#anonymous-functions",
    "href": "docs/python-basics/05_functions/1_functions_need.html#anonymous-functions",
    "title": "Functions (Need)",
    "section": "1.2 Anonymous functions",
    "text": "1.2 Anonymous functions\nAnonymous or lambda functions are suitable for short one-liners. Let me show you two examples.\n\n\n\nThis function accepts a single argument called name.\nmy_short_function = lambda name: f\"Hello {name}!\"\nWe can use it like\nmy_short_function(name=\"Super Man\")\nA lambda function always returns the value of the last statement.\n\n\nThe above example is not a very good ‘anonymous’ one because I have used a name! So let me show you another one where things are really anonymous.\nLet’s say I want to sort the following 2D list.\n\nnumbers=[[9, 0, -10],\n         [8, 1, -11],\n         [7, 2, -12],\n         [6, 3, -13],\n         [5, 4, -14],\n         [4, 5, -15],\n         [3, 6, -16],\n         [2, 7, -17],\n         [1, 8, -18],\n         [0, 9, -19]]\n\nI can use the sorted() function for this. Here are three ways I can use it.\n\n\n\n\n\n\n# Sort by comparing the default key\n# (i.e., the 1st element)\nsorted(numbers)\n\n\n[[0, 9, -19]\n [1, 8, -18]\n [2, 7, -17]\n [3, 6, -16]\n [4, 5, -15]\n [5, 4, -14]\n [6, 3, -13]\n [7, 2, -12]\n [8, 1, -11]\n [9, 0, -10]]\n\n\nNotice that this sorting is based on comparing the first elements of the sub-lists.\n\n\n# Sort by comparing a custom key\n# that uses the 2nd element (index=1)\nsorted(numbers, key=lambda x: x[1])\n\n\n[[9, 0, -10]\n [8, 1, -11]\n [7, 2, -12]\n [6, 3, -13]\n [5, 4, -14]\n [4, 5, -15]\n [3, 6, -16]\n [2, 7, -17]\n [1, 8, -18]\n [0, 9, -19]]\n\n\nIf I want to use some other criteria, then I need to specify a key that sorted() can be used for comparison. As you can see, I have used a lambda function for this.\n\n\n# Sort by comparing a custom key\n# that uses the sum of the elements.\nsorted(numbers, key=lambda x: sum(x))   \n\n\n[[0, 9, -19]\n [1, 8, -18]\n [2, 7, -17]\n [3, 6, -16]\n [4, 5, -15]\n [5, 4, -14]\n [6, 3, -13]\n [7, 2, -12]\n [8, 1, -11]\n [9, 0, -10]]\n\n\nThis is really powerful as I can specify almost any criterion I like. For example, I can sort according to the sum of the elements of the sub-lists."
  },
  {
    "objectID": "docs/python-basics/05_functions/1_functions_need.html#optional-arguments",
    "href": "docs/python-basics/05_functions/1_functions_need.html#optional-arguments",
    "title": "Functions (Need)",
    "section": "1.3 Optional arguments",
    "text": "1.3 Optional arguments\nPython allows us to make arguments to our function optional. To do this, we need to give the argument a default value so that it always has something to work with.\n\ndef greeting(name='no one'):\n    if name == 'Batman':\n        return 'Hello Batman! So, nice to meet you!'\n    else:\n        return f'Hello {name}!'\n\nNow we can run this function without an argument, and it will still work without throwing an error.\n\ngreeting()\n\n'Hello no one!'\n\n\nFor another example, let’s look at the documentation for print().\n?print\n    Docstring:\n    print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n\n    Prints the values to a stream, or to sys.stdout by default.\n    Optional keyword arguments:\n    file:  a file-like object (stream); defaults to the current sys.stdout.\n    sep:   string inserted between values, default a space.\n    end:   string appended after the last value, default a newline.\n    flush: whether to forcibly flush the stream.\n    Type:      builtin_function_or_method\nYou see that print() can accept other arguments that are optional with default values. However, we can specify them if we like; here goes.\n# Using default values\nprint('I', 'am', 'Batman!')\n# Specifying an optional argument\nprint('I', 'am', 'Batman!', sep='---')  \n\n\n\n\nI am Batman!\n\n\n\n\nI---am---Batman!\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember:\n\nyou can define your own functions,\nfunctions can have optional arguments,\nfunctions don’t always have to return anything."
  },
  {
    "objectID": "docs/python-basics/05_functions/1_functions_need.html#the-importance-of-functions",
    "href": "docs/python-basics/05_functions/1_functions_need.html#the-importance-of-functions",
    "title": "Functions (Need)",
    "section": "1.4 The importance of functions?",
    "text": "1.4 The importance of functions?\n\nAn argument for functions\nNow that you know a bit about creating functions, let me highlight why functions are a good idea.\nAbstraction of details The most important benefit of functions goes beyond programming and relates to your ability to strategize. If you break up a complicated solution into modular chunks (i.e., functions), it becomes easier to think about it because you are not dealing with all the details all at once. As a result, it is easier to focus on your overall solution because you are not distracted by unnecessary information. This hiding of ‘stuff’ is called abstraction in computer science lingo. The concept of abstraction can be tricky to grasp. So, let me share an analogy related to driving.\nA vehicle has many ‘abstracted’ systems, amongst which the engine is a good example. You do not need to know the engine’s details (e.g. electric, petrol, diesel, guineapig) to use it. You can use the engine of almost any car because you are not required to know what happens inside. This frees up your resources because you are not distracted by unnecessary details. Of course, there will be times when you want to know how an engine works to pick the best engine.\nReusability of code If you encapsulate a chunk of code in a function, it becomes straightforward to reuse it instead of copying and pasting at different places. This means your code will be shorter and more compact.\nMaintainability of code With functions, your code is easier to change and maintain because you need only make changes in one place, at the function definition.\n\n\nA word of caution\nI have seen many instances where functions are abused; for example, by trying to do too many things or having too many arguments. They can also be overused. Having too many functions can make it difficult to read your code and also increase computational overheads. You will get a better feel for when to use functions with experience, but please bear in mind that functions can be misused."
  },
  {
    "objectID": "docs/python-basics/05_functions/2_functions_good_exercises.html",
    "href": "docs/python-basics/05_functions/2_functions_good_exercises.html",
    "title": "Functions (Good) Exercises",
    "section": "",
    "text": "Exercise 1 (Celsius to Fahrenheit or Kelvin) ☻\n\nDevelop a function named convert_celsius() to convert temperatures from Celsius to either Fahrenheit or Kelvin.\nThe function should take two arguments:\n\ntemperature_celsius: The temperature in Celsius.\ntarget_scale (string): The target scale for conversion, with the default value set to 'Fahrenheit'.\n\nThe function should return the temperature in Kelvin if target_scale is 'Kelvin'; otherwise, it should return the temperature in Fahrenheit.\n\n\n\nExercise 2 (Fahrenheit to Celsius or Kelvin) ☻\n\nDevelop a function called convert_fahrenheit() for converting temperatures from Fahrenheit to either Celsius or Kelvin.\nThe function should take two arguments:\n\ntemperature_fahrenheit: The temperature in Fahrenheit.\ntarget_scale (string): The target scale for conversion, defaulting to 'Celsius'.\n\nThe function should return the temperature in Kelvin if target_scale is 'Kelvin'; otherwise, return it in Celsius.\n\n\n\nExercise 3 (General Temperature Conversion) ☻\n\nImplement a function named convert_temperature() to perform general temperature conversions.\nThe function should take three arguments:\n\ntemperature: The temperature to be converted.\nsource_scale (string): The scale of the input temperature (either 'Celsius', 'Fahrenheit', or 'Kelvin').\ntarget_scale (string): The desired scale for the output temperature.\n\nRemember to reuse your previous functions!\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/3_pandas_nice.html#setting-the-context",
    "href": "docs/knowledge-lake/pandas/3_pandas_nice.html#setting-the-context",
    "title": "Pandas (Nice)",
    "section": "1.1 Setting the context",
    "text": "1.1 Setting the context\nSeaborn can help tweak our plots based on where we want to use them. This is done with set_context(). The options we have are paper, talk and poster. You can also set a theme (i.e. plotting style).\n\nsns.set_context(\"paper\")\nsns.set_style(\"darkgrid\")"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/3_pandas_nice.html#some-examples",
    "href": "docs/knowledge-lake/pandas/3_pandas_nice.html#some-examples",
    "title": "Pandas (Nice)",
    "section": "1.2 Some Examples",
    "text": "1.2 Some Examples\n\n\n\nWe use catplot() is used for categorical data. Show me a bar chart for (the numbers in) column Total based on the categorical variables in column Major. Split the plots into columns according to the categories in Gender.\n\nsns.catplot(data=df, x=\"Major\", y=\"Total\", col=\"Gender\", kind=\"bar\")\n\n\n\n\n\n\n\nplt.show()\n\n\n\n\n\n\n\n\nTry the following:\n\nSwap x and y\nUse row instead of col\nUse hue instead of col\n\n\n\n\nsns.catplot(data=df, x=\"Major\", y=\"Total\", col=\"Gender\", kind=\"box\")\n\n\n\n\n\n\n\n\nTry the following:\n\nSwap x and y.\nUse row instead of col.\nUse hue instead of col.\n\n\n\nUse displot() for plotting distributions. Show me the histogram for the scores in Total separated out based on the Major. Dodge the bars so that they do not overlap.\n\nsns.displot(data=df, x='Total', hue='Major', multiple=\"dodge\")\n\n\n\n\n\n\n\n\nTry the following:\n\nUse row or col instead of hue.\nUse stack instead of dodge."
  },
  {
    "objectID": "docs/knowledge-lake/pandas/3_pandas_nice.html#merging-dataframes",
    "href": "docs/knowledge-lake/pandas/3_pandas_nice.html#merging-dataframes",
    "title": "Pandas (Nice)",
    "section": "2.1 Merging dataframes",
    "text": "2.1 Merging dataframes\nIn the last chapter, I used pd.concat() to join two dataframes. pd.concat() is nice because you can give it a list of dataframes to join in one go. However, I now would like to take you through another way of combining the two dummy class dataframes with less hassle using pd.merge(). I have shown the full code below. However, here is the part that deals with pd.merge().\n\nUnderstanding pd.merge()\ndf_combined = pd.merge(\n    left=df_class_1,           # dataframe 1\n    right=df_class_2,          # dataframe 2\n    how='outer',               # Join without losing any data\n    left_on='Student No',      # Use to align dataframe 1\n    right_on='Student No'      # Use to align dataframe 2\n)\nIn the last chapter, we set the dataframe index to the MATRIC_NO in both dataframes so that we could use it to align the various rows during pd.concat(). However, if you use pd.merge(), we can specify two dataframes (using left= and right=) and two columns in these dataframes that can be used for alignment. This is what left_on= and right_on= do.\npd.merge() also has a parameter how= that decides how these two data sets are combined. You must be careful with this one. Here are the\n\n\n\n\n\n\n\nOption\nEffect\n\n\n\n\nleft\nKeep all rows of the left dataframe. If the right has missing on values, fill the right part with NaN\n\n\nright\nKeep all rows of the right dataframe. If the left has missing on values, fill the left part with NaN\n\n\ninner\n(default) Keep only those rows with common left and right data.\n\n\nouter\nKeep all rows of both dataframes. Fill any missing values with NaN\n\n\n\nConvince yourself of how how= works by trying the various options. Here are the results you should get for df_combined.shape.\n\n\n\n\nOption\nEffect\n\n\n\n\nleft\n(35,8)\n\n\nright\n(31,8)\n\n\ninner\n(31,8)\n\n\nouter\n(35,8)\n\n\n\n\n\n\nThe full recipe\n\nfrom matplotlib import pyplot as plt\n\ndf_class_1 = pd.read_excel('dummy-class-1-of-2.xlsx', skiprows=1)\ndf_class_2 = pd.read_excel('dummy-class-2-of-2.xlsx')\n\n# Combine the two datasets\ndf_combined = pd.merge(\n    left=df_class_1,       # dataframe 1\n    right=df_class_2,      # dataframe 2\n    how='outer',           # Join without losing any data\n    left_on='Student No',  # Use to align dataframe 1\n    right_on='Student No'  # Use to align dataframe 2\n)\n\n# Rename columns\ndf_combined.rename(\n    columns={'Student No': 'MATRIC_NO',\n             'Test 1 (30%)': 'Test 1',\n             'Test 2 (20%)': 'Test 2',\n             'Test 3 (50%)': 'Test 3'},\n    inplace=True\n)\n\n# Reorgnise/drop columns\ndf_combined = df_combined[['MATRIC_NO',\n                           'Name', 'Major', 'Gender',\n                           'Test 1', 'Test 2', 'Test 3']\n                          ]\n\n# Replace text with long forms\ndf_combined.replace(\n    to_replace={\n        'PHY': 'Physics',\n        'CHM': 'Chemistry',\n        'LS': 'Life Sciences',\n        'CBIO': 'Comp. Biology',\n        'F': 'Female',\n        'M': 'Male',\n        'NB': 'Non-binary'\n    }, inplace=True\n)\n\n# Remove the ' from Test 2\n\n\ndef clean(text):\n    '''\n    Function to remove ' ' from column 'Test 2'.\n    To be applied using apply()\n    '''\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\n\ndf_combined['Test 2'] = df_combined['Test 2'].apply(clean)\n\n# Update column types\ndf_combined = df_combined.astype({\n    'Gender': 'category',\n    'Major': 'category',\n    'Test 2': 'float'\n}\n)\n\n# df_combined.fillna(0, inplace=True)                      # Fix missing scores\ndf_combined[\"Total\"] = df_combined[['Test 1', 'Test 2', 'Test 3']].sum(axis=1)\ndf_combined = df_combined.round(2)\ndf_combined.to_excel('finalised_scores.xlsx', index=False)\ndf_combined.head()\n\ndf_combined.boxplot(by='Major',\n                    column=['Test 1', 'Test 2', 'Test 3', 'Total'],\n                    vert=False, figsize=(8, 6))\nplt.show()"
  },
  {
    "objectID": "docs/knowledge-lake/pandas/3_pandas_nice.html#isin",
    "href": "docs/knowledge-lake/pandas/3_pandas_nice.html#isin",
    "title": "Pandas (Nice)",
    "section": "2.2 isin()",
    "text": "2.2 isin()\n\n\n\ndf_class = pd.read_excel('dummy-class-1-of-2.xlsx', skiprows=1)\n\n#------------------ Drop and reorganise columns  -----------------#\ncolumns_to_keep = ['Student No', 'Name', 'Major', 'Gender',\n                   'Test 1 (30%)', 'Test 2 (20%)']\n\ndf_class = df_class[columns_to_keep]\n\n#------------------------- Rename columns ------------------------#\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 1 (30%)': 'Test 1',\n                   'Test 2 (20%)': 'Test 2'}\n\ndf_class.rename(columns=new_column_info, inplace=True)\n\n#--------------------- Set index to MATRIC_NO --------------------#\ndf_class.set_index('MATRIC_NO', drop=False, inplace=True)\n\n#-------------------------- Rename stuff -------------------------#\nreplace_info = {\n    'PHY': 'Physics',\n    'CHM': 'Chemistry',\n    'LS': 'Life Sciences',\n    'CBIO': 'Comp. Biology',\n    'F': 'Female',\n    'M': 'Male',\n    'NB': 'Non-binary'\n}\n\ndf_class.replace(to_replace=replace_info, inplace=True)\n\n#---------------- Remove the ' ' from column Test 2 --------------#\n\n\ndef clean(text):\n    '''\n    Function to remove ' ' from column 'Test 2'.\n    To be applied using apply()\n    '''\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\n\ndf_class['Test 2'] = df_class['Test 2'].apply(clean)\n\n#--------------- Convert column Test 2 to type float -------------#\nnew_type_info = {'Major': 'category',\n                 'Gender': 'category',\n                 'Test 2': 'float'}\n\ndf_class = df_class.astype(new_type_info)\n\n#------------------------ Add a new column -----------------------#\ndf_class[\"Total\"] = df_class[\"Test 1\"] + df_class[\"Test 2\"]\n\n#------------------------- Export the file -----------------------#\ndf_class.to_excel('finalised_scores.xlsx', index=False)\n\ndf_class.head()\n\nLet’s say we want to find out if ‘Ronin Christian’ and ‘Maryjane Sandoval’ are in the class and how they are doing. Let me show you another way to generate a mask using the method isin(), which queries the whole dataframe.\n\nmask = df_class.isin(['Maryjane Sandoval', 'Ronin Christian'])\ndf_class[mask]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1282849W\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA5408925A\n\n\nNaN\n\n\nRonin Christian\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6973859L\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA5410124H\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9568373Q\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6824244G\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9194090U\n\n\nNaN\n\n\nMaryjane Sandoval\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA4828364M\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA4607700C\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7067766E\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA5569996J\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3202548I\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6131593U\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7653832E\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9462811I\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1218599T\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7210476B\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1512479K\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7986368Y\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA2727061A\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA2999472W\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7116486E\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6931452S\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9649096H\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1643380L\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6787293E\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA5975988J\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3699958T\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1956366U\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1468689D\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3217320C\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6867791C\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA4080490P\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7667457P\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nSince this output is overwhelming, we should use any() as any() will pick out the non-NaN locations. The axis option will allow us to specify if to apply it to rows or columns(I can never remember which is which, so I just try 0 or 1).\n\n\ndf_class[mask].any(axis=1)\n\nMATRIC_NO\nA3028967J    False\nA1282849W    False\nA5408925A     True\nA6973859L    False\nA5410124H    False\nA9568373Q    False\nA6824244G    False\nA9194090U     True\nA4828364M    False\nA4607700C    False\nA7067766E    False\nA5569996J    False\nA3202548I    False\nA6131593U    False\nA7653832E    False\nA9462811I    False\nA1218599T    False\nA7210476B    False\nA1512479K    False\nA7986368Y    False\nA2727061A    False\nA2999472W    False\nA7116486E    False\nA6931452S    False\nA9649096H    False\nA1643380L    False\nA6787293E    False\nA5975988J    False\nA3699958T    False\nA1956366U    False\nA1468689D    False\nA3217320C    False\nA6867791C    False\nA4080490P    False\nA7667457P    False\ndtype: bool\n\n\nWe can reuse the above as a mask.\ndf_class[df_class[mask].any(axis=1)]\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPhysics\n\n\nMale\n\n\n18.366\n\n\n15.56\n\n\n33.926\n\n\n\n\nA9194090U\n\n\nA9194090U\n\n\nMaryjane Sandoval\n\n\nLife Sciences\n\n\nFemale\n\n\n18.981\n\n\n16.40\n\n\n35.381\n\n\n\n\nA shorter way is to use any() to probe the mask directly.\ndf_class[mask.any(axis=1)]"
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/1_images_need.html#what-is-an-image",
    "href": "docs/knowledge-lake/image_analysis/1_images_need.html#what-is-an-image",
    "title": "Image Analysis (Need)",
    "section": "1.1 What is an image?",
    "text": "1.1 What is an image?\nConsider the following example where I read the image four-circles.jpg and plot it using Matplotlib.\n\n\n\n\n\n\nimg = plt.imread('four-circles.jpg')\nplt.imshow(img)                       \nplt.axis('off')                       \nplt.show()\n\n\n\n\n\n\nWhat I am really interested in right now is how this image is stored in the variable img\n\nprint(f'{type(img)=}', f'{img.shape=}')\n\ntype(img)=&lt;class 'numpy.ndarray'&gt; img.shape=(1000, 1000, 3)\n\n\nSo Matplotlib stores this image information as a \\(1000 \\times 1000 \\times 3\\), (multi-dimensional) NumPy array! I.e., the image comprises \\(3\\) stacked \\(1000 \\times 1000\\) NumPy arrays. These stacks contain information about the RGB (red, green, blue) channels that make up the image.\nWe can check this by visualizing the ‘layers’ or ‘channels’ separately. I will do this in a bit. But first, we need to check one more thing."
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/1_images_need.html#data-type",
    "href": "docs/knowledge-lake/image_analysis/1_images_need.html#data-type",
    "title": "Image Analysis (Need)",
    "section": "1.2 Data type",
    "text": "1.2 Data type\nLet’s see what data type has been used to store this image information. For this, I will look at the type of a single element (say the first one):\n\nprint(f'{type(img[0,0,0])=}')\n\ntype(img[0,0,0])=&lt;class 'numpy.uint8'&gt;\n\n\nSo, the values are stored as the uint8 type. I.e., as a 8-bit, unsigned integer. This means that uint8 can only accommodate unsigned (positive only) numbers from \\(0\\) to \\(2^8-1 = 255\\). So, this can be used to describe 256 distinct levels."
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/1_images_need.html#image-layers-or-channels",
    "href": "docs/knowledge-lake/image_analysis/1_images_need.html#image-layers-or-channels",
    "title": "Image Analysis (Need)",
    "section": "1.3 Image Layers (or Channels)",
    "text": "1.3 Image Layers (or Channels)\nI will plot the RBG layers (channels) separately to better understand how the image information is stored.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n\nax_original, ax_red, ax_green, ax_blue = ax\n\nax_original.imshow(img)\nax_original.set_title('Original (RGB)')\n\n# ALL row & ALL columns of layer 0\nax_red.imshow(img[:, :, 0], cmap='gray')\nax_red.set_title('Red Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 1\nax_green.imshow(img[:, :, 1], cmap='gray')\nax_green.set_title('Green Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 2\nax_blue.imshow(img[:, :, 2], cmap='gray')\nax_blue.set_title('Blue Channel(in Grayscale)')\n\n\n\n\nNotice:\n\nFor the red channel, we cannot see the green and blue circles. But we can still see the yellow; you need some red (and green) to make yellow.\nFor the green channel, we cannot see the red and blue circles. But we can still see the yellow; you need some green (and red) to make yellow.\nFor the blue channel, we cannot see the red and green circles. The yellow circle is also not visible. You don’t need blue to make yellow."
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/1_images_need.html#histograms",
    "href": "docs/knowledge-lake/image_analysis/1_images_need.html#histograms",
    "title": "Image Analysis (Need)",
    "section": "1.4 Histograms",
    "text": "1.4 Histograms\nQuantitative work with images is based on the understanding that the amount and intensity of a colour has can be related to something real like the amount of a protein. One good way to understand this idea is to create a histogram of the three channels. This is straightforward; we just need to convert the 2D array of numbers into a 1D array by using np.flatten(). Let me demonstrate on four-circles.jpg.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.style.use('bmh')\n\n# Convert the 2D array to a long 1D list using 'flatten'\nr_data = img[:, :, 0].flatten()\ng_data = img[:, :, 1].flatten()\nb_data = img[:, :, 2].flatten()\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_red, ax_green, ax_blue = ax\n\nax_red.hist(r_data, color='red', bins=50, density=True)\nax_red.set_title('Red values')\n\nax_green.hist(g_data, color='green', bins=50, density=True)\nax_green.set_title('Green values')\n\nax_blue.hist(b_data, color='blue', bins=50, density=True)\nax_blue.set_title('Blue values')\n\n\n\n\nNotice\n\nAll three channels have a lot of pixels close to zero intensity. This makes sense because most of the image is empty.\nFor all three channels, the (respective) rightmost peak represents the circles with the pure RGB colour. These have a high intensity (almost maximum, 255) of the colour.\nThe middle peak in the green channel represents the low-intensity green required to make the yellow circle!"
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/1_images_need.html#histograms-1",
    "href": "docs/knowledge-lake/image_analysis/1_images_need.html#histograms-1",
    "title": "Image Analysis (Need)",
    "section": "3.1 Histograms",
    "text": "3.1 Histograms\nIn images like this, colour has a quantitative meaning. They directly relate to the protein that has been stained. More colour (say green) means there is more of that protein. One good way to ‘see’ this is to create a histogram of the three channels.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.style.use('bmh')\nimg = plt.imread('golgi.jpg')\n\nr_data = img[:, :, 0].flatten()\ng_data = img[:, :, 1].flatten()\nb_data = img[:, :, 2].flatten()\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_red, ax_green, ax_blue = ax\n\nax_red.hist(r_data, color='red', bins=100, density=True)\nax_red.set_title('Red values')\n\nax_green.hist(g_data, color='green', bins=100, density=True)\nax_green.set_title('Green values')\n\nax_blue.hist(b_data, color='blue', bins=100, density=True)\nax_blue.set_title('Blue values')\n\n\n\n\nNotice\n\nThe intensities of all three channels are low, with blue being almost non-existent(it actually is).\nThere are a lot of pixels with almost no (close to zero) intensity. Again, this makes sense; the image is mostly black."
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/1_images_need.html#noise",
    "href": "docs/knowledge-lake/image_analysis/1_images_need.html#noise",
    "title": "Image Analysis (Need)",
    "section": "3.2 Noise",
    "text": "3.2 Noise\n\n\n\n\n\nTake a look at the above image (background.tif). Although it looks black, is it really full of zeros? Let’s take a look at the image data.\n\nimg = plt.imread('background.tif')\nprint(f'{img.shape=}',\n      f'{img.min()=}',\n      f'{img.max()=}',\n      f'{img.mean()=}',\n      f'{img.sum()=}',\n      sep='\\n')\n\nimg.shape=(512, 512, 3)\nimg.min()=0\nimg.max()=28\nimg.mean()=4.996832529703776\nimg.sum()=3929669\n\n\nSo, there are non-zero yet small values. These small values are called noise and are randomly generated due to camera thermal processes. In image processing, it is good to remove/correct noise before doing any quantitative work. This is especially relevant when your signal is weak. I.e., when your signal-to-noise ratio is poor.\nTo correct for noise, you need to decide on a threshold value; signals below this will be considered as noise. There are algorithms to calculate this threshold, but trial and error also works. We have to be careful not to delete too much, or else our signal also gets deleted. This is the reason why measurements should have a good signal-to-noise ratio.\n\nRemoving noise\nI am going to pick a threshold of 25 to ‘remove noise’\n\nthreshold = 20\nimg_no_noise = img.copy()\nimg_no_noise[img_no_noise &lt; threshold] = 0\nprint(f'{img_no_noise.shape=}',\n      f'{img_no_noise.min()=}',\n      f'{img_no_noise.max()=}',\n      f'{img_no_noise.mean()=}',\n      f'{img_no_noise.sum()=}',\n      sep='\\n')\n\nimg_no_noise.shape=(512, 512, 3)\nimg_no_noise.min()=0\nimg_no_noise.max()=28\nimg_no_noise.mean()=0.027776082356770832\nimg_no_noise.sum()=21844\n\n\nNotice how the mean and sum are now much smaller."
  },
  {
    "objectID": "docs/knowledge-lake/image_analysis/1_images_need.html#removing-noise-from-golgi.jpg",
    "href": "docs/knowledge-lake/image_analysis/1_images_need.html#removing-noise-from-golgi.jpg",
    "title": "Image Analysis (Need)",
    "section": "3.3 Removing noise from golgi.jpg",
    "text": "3.3 Removing noise from golgi.jpg\nNow let me remove noise from golgi.jpg. Since the zeros are not very useful information, in this round, I will remove them before producing the histogram.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# | echo: true\n# | eval: false\n# | file: __cleaned_scripts/golgi_single-frame_matplotlib_remove-noise.py"
  },
  {
    "objectID": "docs/knowledge-lake/image/1_images_need.html#what-is-an-image",
    "href": "docs/knowledge-lake/image/1_images_need.html#what-is-an-image",
    "title": "Image Analysis (Need)",
    "section": "1.1 What is an image?",
    "text": "1.1 What is an image?\nConsider the following example where I read the image four-circles.jpg and plot it using Matplotlib.\n\n\n\n\n\n\nimg = plt.imread('four-circles.jpg')\nplt.imshow(img)                       \nplt.axis('off')                       \nplt.show()\n\n\n\n\n\n\nWhat I am really interested in right now is how this image is stored in the variable img\n\nprint(f'{type(img)=}', f'{img.shape=}')\n\ntype(img)=&lt;class 'numpy.ndarray'&gt; img.shape=(1000, 1000, 3)\n\n\nSo Matplotlib stores this image information as a \\(1000 \\times 1000 \\times 3\\), (multi-dimensional) NumPy array! I.e., the image comprises \\(3\\) stacked \\(1000 \\times 1000\\) NumPy arrays. These stacks contain information about the RGB (red, green, blue) channels that make up the image.\nWe can check this by visualizing the ‘layers’ or ‘channels’ separately. I will do this in a bit. But first, we need to check one more thing."
  },
  {
    "objectID": "docs/knowledge-lake/image/1_images_need.html#data-type",
    "href": "docs/knowledge-lake/image/1_images_need.html#data-type",
    "title": "Image Analysis (Need)",
    "section": "1.2 Data type",
    "text": "1.2 Data type\nLet’s see what data type has been used to store this image information. For this, I will look at the type of a single element (say the first one):\n\nprint(f'{type(img[0,0,0])=}')\n\ntype(img[0,0,0])=&lt;class 'numpy.uint8'&gt;\n\n\nSo, the values are stored as the uint8 type. I.e., as a 8-bit, unsigned integer. This means that uint8 can only accommodate unsigned (positive only) numbers from \\(0\\) to \\(2^8-1 = 255\\). So, this can be used to describe 256 distinct levels."
  },
  {
    "objectID": "docs/knowledge-lake/image/1_images_need.html#image-layers-or-channels",
    "href": "docs/knowledge-lake/image/1_images_need.html#image-layers-or-channels",
    "title": "Image Analysis (Need)",
    "section": "1.3 Image Layers (or Channels)",
    "text": "1.3 Image Layers (or Channels)\nI will plot the RBG layers (channels) separately to better understand how the image information is stored.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n\nax_original, ax_red, ax_green, ax_blue = ax\n\nax_original.imshow(img)\nax_original.set_title('Original (RGB)')\n\n# ALL row & ALL columns of layer 0\nax_red.imshow(img[:, :, 0], cmap='gray')\nax_red.set_title('Red Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 1\nax_green.imshow(img[:, :, 1], cmap='gray')\nax_green.set_title('Green Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 2\nax_blue.imshow(img[:, :, 2], cmap='gray')\nax_blue.set_title('Blue Channel(in Grayscale)')\n\n\n\n\nNotice:\n\nFor the red channel, we cannot see the green and blue circles. But we can still see the yellow; you need some red (and green) to make yellow.\nFor the green channel, we cannot see the red and blue circles. But we can still see the yellow; you need some green (and red) to make yellow.\nFor the blue channel, we cannot see the red and green circles. The yellow circle is also not visible. You don’t need blue to make yellow."
  },
  {
    "objectID": "docs/knowledge-lake/image/1_images_need.html#histograms",
    "href": "docs/knowledge-lake/image/1_images_need.html#histograms",
    "title": "Image Analysis (Need)",
    "section": "1.4 Histograms",
    "text": "1.4 Histograms\nQuantitative work with images is based on the understanding that the amount and intensity of a colour has can be related to something real like the amount of a protein. One good way to understand this idea is to create a histogram of the three channels. This is straightforward; we just need to convert the 2D array of numbers into a 1D array by using np.flatten(). Let me demonstrate on four-circles.jpg.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.style.use('bmh')\n\n# Convert the 2D array to a long 1D list using 'flatten'\nr_data = img[:, :, 0].flatten()\ng_data = img[:, :, 1].flatten()\nb_data = img[:, :, 2].flatten()\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_red, ax_green, ax_blue = ax\n\nax_red.hist(r_data, color='red', bins=50, density=True)\nax_red.set_title('Red values')\n\nax_green.hist(g_data, color='green', bins=50, density=True)\nax_green.set_title('Green values')\n\nax_blue.hist(b_data, color='blue', bins=50, density=True)\nax_blue.set_title('Blue values')\n\n\n\n\nNotice\n\nAll three channels have a lot of pixels close to zero intensity. This makes sense because most of the image is empty.\nFor all three channels, the (respective) rightmost peak represents the circles with the pure RGB colour. These have a high intensity (almost maximum, 255) of the colour.\nThe middle peak in the green channel represents the low-intensity green required to make the yellow circle!"
  },
  {
    "objectID": "docs/knowledge-lake/image/1_images_need.html#histograms-1",
    "href": "docs/knowledge-lake/image/1_images_need.html#histograms-1",
    "title": "Image Analysis (Need)",
    "section": "3.1 Histograms",
    "text": "3.1 Histograms\nIn images like this, colour has a quantitative meaning. They directly relate to the protein that has been stained. More colour (say green) means there is more of that protein. One good way to ‘see’ this is to create a histogram of the three channels.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.style.use('bmh')\nimg = plt.imread('golgi.jpg')\n\nr_data = img[:, :, 0].flatten()\ng_data = img[:, :, 1].flatten()\nb_data = img[:, :, 2].flatten()\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_red, ax_green, ax_blue = ax\n\nax_red.hist(r_data, color='red', bins=100, density=True)\nax_red.set_title('Red values')\n\nax_green.hist(g_data, color='green', bins=100, density=True)\nax_green.set_title('Green values')\n\nax_blue.hist(b_data, color='blue', bins=100, density=True)\nax_blue.set_title('Blue values')\n\n\n\n\nNotice\n\nThe intensities of all three channels are low, with blue being almost non-existent(it actually is).\nThere are a lot of pixels with almost no (close to zero) intensity. Again, this makes sense; the image is mostly black."
  },
  {
    "objectID": "docs/knowledge-lake/image/1_images_need.html#noise",
    "href": "docs/knowledge-lake/image/1_images_need.html#noise",
    "title": "Image Analysis (Need)",
    "section": "3.2 Noise",
    "text": "3.2 Noise\n\n\n\n\n\nTake a look at the above image (background.tif). Although it looks black, is it really full of zeros? Let’s take a look at the image data.\n\nimg = plt.imread('background.tif')\nprint(f'{img.shape=}',\n      f'{img.min()=}',\n      f'{img.max()=}',\n      f'{img.mean()=}',\n      f'{img.sum()=}',\n      sep='\\n')\n\nimg.shape=(512, 512, 3)\nimg.min()=0\nimg.max()=28\nimg.mean()=4.996832529703776\nimg.sum()=3929669\n\n\nSo, there are non-zero yet small values. These small values are called noise and are randomly generated due to camera thermal processes. In image processing, it is good to remove/correct noise before doing any quantitative work. This is especially relevant when your signal is weak. I.e., when your signal-to-noise ratio is poor.\nTo correct for noise, you need to decide on a threshold value; signals below this will be considered as noise. There are algorithms to calculate this threshold, but trial and error also works. We have to be careful not to delete too much, or else our signal also gets deleted. This is the reason why measurements should have a good signal-to-noise ratio.\n\nRemoving noise\nI am going to pick a threshold of 25 to ‘remove noise’\n\nthreshold = 20\nimg_no_noise = img.copy()\nimg_no_noise[img_no_noise &lt; threshold] = 0\nprint(f'{img_no_noise.shape=}',\n      f'{img_no_noise.min()=}',\n      f'{img_no_noise.max()=}',\n      f'{img_no_noise.mean()=}',\n      f'{img_no_noise.sum()=}',\n      sep='\\n')\n\nimg_no_noise.shape=(512, 512, 3)\nimg_no_noise.min()=0\nimg_no_noise.max()=28\nimg_no_noise.mean()=0.027776082356770832\nimg_no_noise.sum()=21844\n\n\nNotice how the mean and sum are now much smaller."
  },
  {
    "objectID": "docs/knowledge-lake/image/1_images_need.html#removing-noise-from-golgi.jpg",
    "href": "docs/knowledge-lake/image/1_images_need.html#removing-noise-from-golgi.jpg",
    "title": "Image Analysis (Need)",
    "section": "3.3 Removing noise from golgi.jpg",
    "text": "3.3 Removing noise from golgi.jpg\nNow let me remove noise from golgi.jpg. Since the zeros are not very useful information, in this round, I will remove them before producing the histogram.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# | echo: true\n# | eval: false\n# | file: __cleaned_scripts/golgi_single-frame_matplotlib_remove-noise.py"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#random-numbers-from-the-normal-distribution",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#random-numbers-from-the-normal-distribution",
    "title": "Random Numbers (Good)",
    "section": "2.1 Random numbers from the Normal distribution",
    "text": "2.1 Random numbers from the Normal distribution\n\n\n\n\n\nBefore we draw random numbers from a Normal distribution (also known as a Gaussian distribution), let’s remind ourselves what the Normal distribution is. With the characteristic shape shown in the plots above (that I borrowed from Wikipedia), the Normal distribution is defined by two parameters. The mean \\(\\mu\\) and the standard deviation \\(\\sigma\\). The mean decides the centre’s location and the standard deviation decides the chubbiness. A feature of the Normal distribution (as indicated in the image above) is that 68% of the points lie between \\(\\mu\\pm\\sigma\\). The mathematical form of this distribution is:\n\\[\nf(x)=\\dfrac{1}{\\sigma \\sqrt{2\\pi}}{\\large e}^{-\\dfrac{1}{2}\\left(\\dfrac{x-\\mu}{\\sigma}\\right)^2}\n\\]\nThe function we need to draw normal random samples is np.random.normal(loc=, scale=, size=). loc is used to specify the mean and scale the standard deviation. For example:\n\nnp.random.normal(loc=5, scale=2, size=10)\n\narray([6.23467679, 5.69110152, 6.2548526 , 4.91412283, 5.26087859,\n       6.01631475, 3.54998986, 3.3420698 , 7.65130615, 6.00569723])"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#visualising-the-random-numbers",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#visualising-the-random-numbers",
    "title": "Random Numbers (Good)",
    "section": "2.2 Visualising the random numbers",
    "text": "2.2 Visualising the random numbers\nIt isn’t easy to see that the above numbers are from a Normal distribution. However, it is easier if we plot the data, as we did before.\n\n\n\n\n\n\nn = 1_000_0\nrandom_numbers = np.random.normal(loc=5, scale=2, size=n)\n\nfig, ax = plt.subplots(nrows=1, ncols=2)\n\naxis = ax[0]\naxis.hist(random_numbers, bins=100, alpha=.25)\naxis.set_xlabel(\"Value of random number\")\naxis.set_ylabel(\"Frequency\")\n\naxis = ax[1]\naxis.scatter(range(n), random_numbers, alpha=.25)\naxis.set_xlabel(\"Position in the random number list\")\naxis.set_ylabel(\"Value of random number\")\n\nI hope this visualisation will help you understand what I meant by drawing a number from a Normal distribution."
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#section",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#section",
    "title": "Random Numbers (Good)",
    "section": "2.3 68%?",
    "text": "2.3 68%?\nLet’s check if the Normal random numbers given to us satisfy the 68% condition?\n\nn = 10_000\nmean, sd = 5, 2\nrandom_numbers = np.random.normal(loc=mean, scale=sd, size=n)\n\nmask = (random_numbers &gt;= mean - sd) & (random_numbers &lt;= mean + sd)\n\nprint(f'% of points between 1 std.dev. from the mean: {np.sum(mask)/n*100:.2f}%')\n\n% of points between 1 std.dev. from the mean: 68.43%"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#the-scenario",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#the-scenario",
    "title": "Random Numbers (Good)",
    "section": "3.1 The scenario",
    "text": "3.1 The scenario\nLet’s simulate a simple random walk1 in 1D. The scenario is such that a particle is restricted to moving in 1D (i.e. only along a line). It moves in steps, either one unit to the left or one to the right. The choice of left or right is selected randomly. Let’s take the probability of going right as \\(p\\), and going left is \\(q\\) (\\(=1-p\\))."
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#the-simulation",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#the-simulation",
    "title": "Random Numbers (Good)",
    "section": "3.2 The simulation",
    "text": "3.2 The simulation\nI can encapsulate the above information as a function as follows:\ndef brown_1d(prob_right=.5, no_of_steps=10000):\n    ''' \n        This function returns the final position of the particle \n        after the number of steps.\n        prob_right is the probability of going right.\n    '''\n\n    step_size = 1    \n    x = 0                               # starting x position\n\n    for _ in range(no_of_steps):\n        if rnd.random() &lt; prob_right:   # Go right?\n            x += step_size\n        else:\n            x -= step_size\n\n    return x\nBefore going ahead, I am tired of having to type np.random.! Time to get lazy by:\n\nimport numpy.random as rnd\n\nNow I can just use rnd! So, back to the main story…\nEach time I run this function, I will get a different value. However, I like to see if there is a pattern. Let me repeat an experiment of 1000 steps 10,000 times to see what I get.\nno_of_steps, p = 1_000, .5\nrepeats = 10_000\nresults = [brown_1d(prob_right=p, no_of_steps=no_of_steps)\n           for _ in range(repeats)]\n\nplt.hist(results, bins=25, density=True)\nplt.xlabel(f'Distance from the origin after {no_of_steps} steps')\nplt.title(f'Probability distribution for 1D Random walk with p={p}')\nNote that I have put density=True to ask Matplotlib to normalise the area under the curve to 1.\n\n\n\n\n\nInteresting; the distribution looks familiar since \\(p=.5\\) is symmetrical about the starting position. I am curious to see what happens if I increase the probability \\(p\\) to 0.6. Then, the curve should shift to the right. Let’s see if this happens. I will not show the code because it is the same as above."
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#what-does-theory-say",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#what-does-theory-say",
    "title": "Random Numbers (Good)",
    "section": "3.3 What does theory say?",
    "text": "3.3 What does theory say?\nA theoretical analysis of 1D random walks predicts that the distribution of positions should have a mean of \\(N(p - q)\\) and a standard deviation of \\(\\sqrt{4N pq}\\) (where \\(N\\) is the total number of steps). The distribution is actually Binomial, but since we have a large number of steps, it approximates a Gaussian. So, let’s overlay a Normal distribution over our previous plots to see how well our simulation agrees with the theory.\nHere is the function I used for the Normal distribution, which is the equation I showed you earlier.\ndef normal(x, m=0, s=1):\n    '''\n    Probability density function for the\n    Gaussian distribution.\n    '''\n    s2 = s**2\n    output = np.exp(-(x-m)**2/(2*s2))\n    output /= np.sqrt(2*np.pi*s2)\n    return output\nI can use the following code to overlay this on my histogram:\nprob_left = 1 - prob_right                       # q = 1 -p\nmean = no_of_steps * (prob_right - prob_left)    # mean = N(p - q)\nsd = np.sqrt(4*no_of_steps*prob_right*prob_left) # sd = sqrt(4 N p q)\nx = np.unique(results)                           # Numbers that form \n                                                 # the x-axis\nplt.plot(x, normal(x, mean, sd), label='Theoretical')\nHere is what I got.\n \nNeat!\nBy the way, techniques such as the above that involve random numbers are called Monte Carlo methods. This is because random numbers are associated with gambling, and the city of Monte Carlo is famous for the latter."
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#the-method",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#the-method",
    "title": "Random Numbers (Good)",
    "section": "4.1 The method",
    "text": "4.1 The method\n\nConsider a circle inscribed on a square surface, as shown above. Let’s take the radius of the circle to be 1. Then, if we throw a large number (\\(N_{total}\\)) of grains of sand randomly onto this surface, the number of grains landing on the green, the circular area will be related to the number on the total area by:\n\\[\n\\begin{align*}\\frac{N_{green}}{N_{total}}\\approx \\frac{\\text{Area of green region}}{\\text{Area of square}}\n\\end{align*}\n\\]\nBut we know the formulae for the areas! So,\n\\[\n\\begin{align*}\n\\frac{\\text{Area of green region}}{\\text{Area of square}}&= \\frac{\\pi (1)^2}{2\\times 2}=\\frac{1}{4}\\pi \\quad\\Rightarrow \\quad\\pi  = 4\\left(\\frac{\\text{Area of green region}}{\\text{Area of square}}\\right)\n\\end{align*}\n\\]\n\\[\n\\text{i.e.}\\qquad\\pi  \\approx 4\\left(\\frac{N_{green}}{N_{total}}\\right)\n\\]\nWe can simulate this experiment by randomly ‘creating’ points (to represent where a grain of sand will land) by using NumPy’s PRNG. We can then decide if this grain of sand is inside or outside to get \\(N_{green}\\) and then go on to get an estimate for \\(\\pi\\)!"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#a-poor-but-intuitive-solution",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#a-poor-but-intuitive-solution",
    "title": "Random Numbers (Good)",
    "section": "4.2 A poor but intuitive solution",
    "text": "4.2 A poor but intuitive solution\nLet me start with a (poor) but intuitive solution by throwing one grain at a time.\n\nN_total = 100_000                             # Yes, Python allows the _\nN_green = 0\n\nfor _ in range(N_total):\n    x = rnd.uniform(low=-1, high=1, size=1)     \n    y = rnd.uniform(low=-1, high=1, size=1)\n    r = np.sqrt(x**2 + y**2)                   # Distance from the origin\n\n    if r &lt;= 1:\n        N_green += 1                           # In or out of the circle\n\n4 * N_green / N_total                          # Estimate for pi\n\n3.13552\n\n\nThis solution is slow because of the way we are drawing out the random number, one at a time"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#a-better-solution",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#a-better-solution",
    "title": "Random Numbers (Good)",
    "section": "4.3 A better solution",
    "text": "4.3 A better solution\nHere is a better solution that generates multiple random numbers at once.\n\nN_total=1_000_000\nx=rnd.uniform(low=-1, high=1, size=N_total)\ny=rnd.uniform(low=-1, high=1, size=N_total)\nN_green= np.sum((x**2+y**2) &lt;= 1)                # Oh! the ease of NumPy!\n\n4 * (N_green / N_total)\n\n3.145332"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#a-smarter-solution",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#a-smarter-solution",
    "title": "Random Numbers (Good)",
    "section": "4.4 A smarter solution",
    "text": "4.4 A smarter solution\nThere is room to improve our algorithm. Notice that if we limit our experiment to only the first quadrant of the circle and the related square, our equation remains the same!\n\\[\\begin{align*}\n\\frac{\\text{Area of green region}}{\\text{Area of square}}&= \\frac{\\pi (1)^2\\color{darkorange}{/4}}{2\\times 2\\color{darkorange}{/4}}=\\frac{1}{4}\\pi \\quad\\Rightarrow \\quad\\pi  = 4\\left(\\frac{\\text{Area of green region}}{\\text{Area of square}}\\right)\n\\end{align*}\\]\nHowever, the range for \\(x\\) and \\(y\\) becomes \\([0,1)\\). So, our statistics have improved drastically! We can now use the faster, simpler rand().\n\nN_total=1_000_000\nx=rnd.rand(N_total)\ny=rnd.rand(N_total)\nN_green=np.sum((x**2+y**2) &lt;= 1)\n\n4 * (N_green / N_total)\n\n3.140268"
  },
  {
    "objectID": "docs/knowledge-lake/random_numbers/good/2_random_good.html#footnotes",
    "href": "docs/knowledge-lake/random_numbers/good/2_random_good.html#footnotes",
    "title": "Random Numbers (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRandom walks are important in many branches of science. For example, see here.↩︎"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#what-do-we-mean-by-changes",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#what-do-we-mean-by-changes",
    "title": "Numerical Solutions (Good)",
    "section": "1.1 What do we mean by changes?",
    "text": "1.1 What do we mean by changes?\nI have often mentioned that differential equations allow us to model systems that change. They also help us capture some of these systems’ essential dynamical features. However, these changes do not necessarily need to be in time. Here are some examples of what we mean by ‘change’:\n\nchange in elevation as you walk along mountainous terrain,\nchange in the nutrients in the soil as you walk along a field,\nchange in nutrients as we dive into the ocean,\nchange in the concentration of a medicine in our blood as the day progresses,\nchange in the brightness of sunlight as the day progresses,\nchange in the population as time passes.\nchanges in how fast a chemical reaction occurs as the reagents’ concentration is depleted.\n\nThe first three examples relate to change in space while the latter three to changes in time. The last is a change in concentration. So, a system can change in almost any parameter that is available!"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#calculus-meaning-and-notation",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#calculus-meaning-and-notation",
    "title": "Numerical Solutions (Good)",
    "section": "1.2 Calculus: Meaning and Notation",
    "text": "1.2 Calculus: Meaning and Notation\nTo get the most out of differential equations, you must speak the language of calculus. This is because calculus allows us to describe changes mathematically. I will use a concrete example of a changing population to see how this works. Incidentally, this is a problem people thought about and solved about 200 years ago!\nSo, where to start? What is a simple model for the change of a population? We can start by assuming that the change in a population will depend on the current size of the population. The justification for this is that fewer people now will mean fewer people later, or more people now will mean even more people later. We can express this idea succinctly as:\n\\[\n\\dfrac{dN(t)}{dt} = r N(t)\\qquad\\qquad\\qquad\\qquad\\text{(1)}\n\\tag{1}\\]\nHere \\(N(t)\\) is the number of people at time \\(t\\) where \\(t\\) is time measured in a convenient unit, say years. \\(\\frac{dN(t)}{dt}\\) tells us how much the \\(N(t)\\) is changing. \\(r\\) is a constant (i.e. a simple number) representing the rate of growth. \\(r\\) is useful to distinguish between different types of populations (e.g. opulent ones with large \\(r\\) vs. less fortunate ones with lower values of \\(r\\)). To make it easier to read, we will write \\(N\\) instead of \\(N(t)\\), but keeping in mind that time \\(t\\) lurks in the background.\nThe symbol \\(\\frac{dN}{dt}\\) on the LHS is read as rate of change of \\(N\\) with respect to \\(t\\). The rate (i.e. \\(\\frac{dN}{dt}\\)) tells us how much \\(N\\) will change if we increase \\(t\\) by a unit (i.e. 1)."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#calculus-getting-a-feel-for-dfracdndt",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#calculus-getting-a-feel-for-dfracdndt",
    "title": "Numerical Solutions (Good)",
    "section": "1.3 Calculus: Getting a feel for \\(\\dfrac{dN}{dt}\\)",
    "text": "1.3 Calculus: Getting a feel for \\(\\dfrac{dN}{dt}\\)\nIf you like, you can get a feel for what this equation is saying by approximating the symbol as a fraction1.\n\\[\n\\dfrac{dN}{dt} \\approx \\dfrac{\\Delta N}{\\Delta t} \\Rightarrow \\Delta N = r N\\;\\Delta t\\qquad\\qquad\\qquad\\qquad\\text{(2)}\n\\tag{2}\\]\nPlease note the approximate sign(\\(\\approx\\)). Our approximation gets better the smaller we make \\(\\Delta t\\). Remember, you already saw this in action in the bucket example. We can use this approximation to build up how \\(N\\) will change as follows:\n\n\n\n\n\n\n\n\n\nTime\nPopulation\nChange for next step\n\n\n\n\n\\[t= 0\\]\n\\[N_0\\]\n\\[\\Delta N = rN_0 \\times \\Delta t\\]\n\n\n\\[t= \\Delta t\\]\n\\[N_1 = N_0 + \\Delta N\\]\n\\[\\Delta N = rN_1 \\times \\Delta t\\]\n\n\n\\[t= 2\\, \\Delta t\\]\n\\[N_2 = N_1 + \\Delta N\\]\n\\[\\Delta N = rN_2 \\times \\Delta t\\]\n\n\n\\[t= 3\\, \\Delta t\\]\n\\[N_3 = N_2 + \\Delta N\\]\n\\[\\Delta N = rN_3 \\times \\Delta t\\]\n\n\n\\[\\ldots\\]\n\\[\\ldots\\]\n\\[\\ldots\\]\n\n\n\n\nNote that \\(N_0\\) is the starting population at \\(t=0\\). So what we want to know is how the population will evolve from there.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that \\(\\dfrac{dy}{dx}\\) tells us how much \\(y\\) changes if you change \\(x\\) by a unit. You can make sense of \\(\\dfrac{dy}{dx}\\) by thinking of the approximation \\(\\dfrac{\\Delta y}{\\Delta x}\\).This approximation gets better the smaller the step.\n\n\n\nStopping a population explosion\nYou will notice that our ‘model’ says the population will keep growing faster and faster. But, this is unrealistic as other factors (such as resources) should come into play. So, an improved model for a population is2:\n\\[\n\\dfrac{dN}{dt} = r N \\left(1- \\dfrac{N}{K}\\right)\\qquad\\qquad\\qquad\\qquad\\text{(3)}\n\\tag{3}\\]\nHere \\(K\\) (called the carrying capacity) represents the maximum population that the system can hold sustainably. You should note how the equation (elegantly) leads to a reduction in population when the population exceeds the carrying capacity(i.e. \\(N &gt; K\\)). When \\(N &gt; K\\) the R.H.S. becomes negative, and the population starts to decrease!"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#the-euler-method",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#the-euler-method",
    "title": "Numerical Solutions (Good)",
    "section": "2.1 The Euler Method",
    "text": "2.1 The Euler Method\nThe Euler Method4 created by the prolific Leonhard Euler is based on equation (2). Here is the recipe that Euler proposed\\(\\ldots\\). I recommend you recall and draw parallels to how we solved our previous bucket problem. This is the one and the same method!\nLet’s say we want to solve the differential equation\n\\[\n\\dfrac{dy}{dt} = f(y,t)\n\\]\nWe approximate it with a fraction:\n\\[\n\\dfrac{dy}{dt} \\approx \\dfrac{\\Delta y}{\\Delta t} = f(y,t)\\Rightarrow \\boxed{\\Delta y= f(y,t)\\Delta t}\n\\tag{4}\\]\nWe can then start with an initial value (condition) \\(y(t=0) = y_a\\) and take small steps away like:\n\n\\[\\begin{array}{c|rcl|rcl}\n\\text{Initial condition} & y_0  &=& y_a & t_0 \\\\\n\\text{Step 1}& y_{1} &=& y_{0} + f(t_0,y_0) \\Delta t & t_1 &=& t_0 + \\Delta t\\\\\n\\text{Step 2}& y_{2} &=& y_{1} + f(t_1,y_1) \\Delta t & t_2 &=& t_1 + \\Delta t\\\\\n\\text{Step 3}& y_{3} &=& y_{2} + f(t_2,y_2) \\Delta t & t_3 &=& t_2 + \\Delta t\\\\\n& \\ldots &=& \\ldots  & \\ldots &=& \\ldots  \\\\\n\\text{Step $n+1$}& y_{n+1} &=& y_{n} + f(t_n,y_n) \\Delta t & t_{n+1} &=& t_{n} + \\Delta t\\\\\n\\end{array}\\]\n\nWhen we follow this recipe, we can get the numerical values of the solution. The more steps we have, the more accurate our values are. This is shown in the figure below. Again, you saw this in action with the bucket example.\n\n\n\n\n\nFinally, I would like to point out that irrespective of how complicated the system or problem is, the strategy you will adopt is the same simple one: Euler!"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#using-euler-for-the-logistic-equation",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#using-euler-for-the-logistic-equation",
    "title": "Numerical Solutions (Good)",
    "section": "2.2 Using Euler for the logistic equation",
    "text": "2.2 Using Euler for the logistic equation\nLet’s solve equation (3) using Euler to see how things work. Luckily for us, this equation can also be solved analytically. So, we can compare how Euler fairs with the ‘real’ solution. Here is the analytical solution:\n\\[\nN(t) = \\dfrac{K}{1+\\left(\\dfrac{K}{N_0}-1\\right)e^{-rt}}\n\\tag{5}\\]\n\ndef logistic(time, N0, carrying_capacity, rate):\n    '''\n    This outputs the exact solution to \n    the logistic differential equation.\n    '''\n    C = 1/N0-1/carrying_capacity\n    output = (1+C*carrying_capacity*np.exp(-rate*time))\n    output = carrying_capacity/output\n    return output\n\n\nN_stop_difference = 1E-2                # Stop running if the change in population\n                                        # between consecutive runs is less than this value\ndt = .1\nN0, K, rate = 10, 100, 3\ndata = {'time': [], 'N': []}\ntime, N = 0, N0\n\nwhile True:\n    data['time'].append(time)\n    data['N'].append(N)\n\n    dN = rate*N*(1-N/K)*dt\n    N += dN\n    time += dt\n\n    # Should we stop the loop?\n    try:\n        # The lists start empty so the following will raise an\n        # error the first two rounds. I am using try to get around it.\n        if np.abs(data['N'][-1]-data['N'][-2]) &lt;= N_stop_difference:\n            break\n    except IndexError:\n        # I am being paranoid and checking if there is an error even\n        # when the list has more than two elements\n        if len(data['N']) &lt; 2:\n            pass\n        else:\n            print('Trouble')\n            quit()\n\nexact_data = logistic(time=np.array(data['time']),\n                      N0=N0,\n                      carrying_capacity=K,\n                      rate=rate)\n\nplt.plot(data['time'], data['N'], '.', label='Numerical')\nplt.plot(data['time'], exact_data,\n         label='Exact', zorder=1)  # zorder pushes the plot back\nplt.legend(loc='lower right')\nplt.ylabel('Population($N$)')\nplt.xlabel('Time')\nplt.hlines(K, 0, data['time'][-1],\n           colors='grey', ls='dashed', zorder=1)\n\n\n\n\n\n\n\nSome things to note about the code\nI like to draw your attention to some programmatically features in the above code that you may not have seen before:\n\nI have used a dictionary to hold the time and population data. Isn’t it more elegant?\nI use a True condition with the while loop. So, it will run until the end of The Universe until I break out on my own.\nTo break out, I check if the population has changed significantly?\n\nThe threshold I am using is \\(0.01\\). To check this, I do not compare the two numbers (Never ever compare two floats!). Instead, I check if the difference between the two is as small as I want.\nI use np.abs() to not worry if the difference is negative.\n\nSince I need to compare two numbers, I will have to wait for at least two rounds for the condition to work. I use try-except to step around the hissy-fit that Python would otherwise throw.\n\nI know what error (IndexError) to use because when I didn’t, Python screamed it at me!"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#the-equations",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#the-equations",
    "title": "Numerical Solutions (Good)",
    "section": "3.1 The equations",
    "text": "3.1 The equations\nIn this section, I will show you how to solve coupled differential equations. The one I have picked is called The Predator-Prey model. It is a simple (really cool) ecological model to describe the predator-prey interactions between foxes and rabbits. You will often see variants of the Predator-Prey model used to study more complicated systems.\nThe basic equations that describe this model are the Lotka-Volterra equations.\n\\[\n\\begin{aligned}\n\\dfrac{dr}{dt} &= \\alpha r - \\beta rf \\\\\n\\dfrac{df}{dt} &= \\delta  fr - \\gamma f\n\\end{aligned}\n\\]\nI have chosen \\(r\\) to represent the rabbits (the prey) and \\(f\\) foxes (the predators). \\(\\alpha, \\beta, \\delta, \\gamma\\) are constants. For our simulation, we will use the values shown below.\n\n\n\n\n\\(\\alpha\\)\n2\n\n\n\\(\\beta\\)\n2\n\n\n\\(\\delta\\)\n3\n\n\n\\(\\gamma\\)\n3"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#example-code",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#example-code",
    "title": "Numerical Solutions (Good)",
    "section": "3.2 Example code",
    "text": "3.2 Example code\n\n\n\n\n\n\nmax_time = 10\ndt = 0.001\nrabbits0, foxes0 = 1, .1\ntime, rabbits, foxes = 0, rabbits0, foxes0\ndata = []\n\n\n# Lotka-Volterra equations\ndef drabbits_dt(rabbits, foxes):\n    a, b = 2, 2\n    return a*rabbits - b*rabbits*foxes\n\n\ndef dfoxes_dt(rabbits, foxes):\n    d, g = 3, 3\n    return d*foxes*rabbits - g*foxes\n\n\nwhile True:\n    data.append([time, rabbits, foxes])\n\n    # Don't update the original variables because we need\n    # the OLD values of rabbits to calculate foxes\n    rabbits_new = rabbits + drabbits_dt(rabbits, foxes)*dt\n\n    # Using the old value of rabbits\n    foxes += dfoxes_dt(rabbits, foxes)*dt\n\n    # No more need for two variables\n    rabbits = rabbits_new\n\n    time += dt\n\n    if time &gt; max_time:\n        break\n\n# Reorganising the data so I can easily access\n# them without having to mess with indices\ndata = np.array(data)\ndata = {\n    'time': data[:, 0],\n    'rabbits': data[:, 1],\n    'foxes': data[:, 2],\n}\n\nfig, ax = plt.subplots(nrows=1, ncols=2)\nax_with_time, ax_with_other = ax\n\n# Plotting the individual species\nax_with_time.plot(data['time'], data['rabbits'], label='Rabbits')\nax_with_time.plot(data['time'], data['foxes'], label='Foxes', alpha=.5)\nax_with_time.set_ylabel('Rabbits/Foxes')\nax_with_time.set_xlabel('Time')\nax_with_time.set_title(f'Rabbits/Foxes vs Time')\nax_with_time.legend()\n\n# Plotting one against the other\nax_with_other.plot(data['rabbits'], data['foxes'])\nax_with_other.set_xlabel('Rabbits')\nax_with_other.set_ylabel('Foxes')\nax_with_other.set_title(f'Foxes vs Rabbits')\n\nThis is a beautiful result. Notice that both the predator and prey show a cyclical trend over time. The rabbit population is the lowest when the foxes peak because of all the feasting. Past this, the foxes start going hungry, reducing their numbers and giving the rabbits a chance to make a comeback. And so the cycle goes on. The plot on the right (called a ‘phase plot’) is my favourite. It shows all the information I just stated. Do you see it? Can you figure out which direction (clockwise or counterclockwise) the flow of time represents?\n\nSome things to note about the code\nI want to highlight a few things about the above code:\n\nNotice how I encapsulated the derivatives in functions. This way of doing things allowed me to worry about what was happening in the loop without any distractions.\nI had to use a new variable rabbit_new to hold the new value of rabbits temporarily. This is because I still need the old value (contained in rabbits) to calculate the new value for foxes. This is a tad subtle; make sure you are comfortable with it!\nThis time, I first used a list data to collect the data and split them into a dictionary later. Some might consider this unnecessary. But it makes the code more readable"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#scipy-odeint",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#scipy-odeint",
    "title": "Numerical Solutions (Good)",
    "section": "4.1 SciPy odeint()",
    "text": "4.1 SciPy odeint()\nThe SciPy function I will use is called odeint(). You can import it as follows:\nfrom scipy.integrate import odeint\nYou get it working by giving it the initial values and functions to calculate the various derivatives. So, if your differential equation is of the form:\n\\[\n\\dfrac{dy}{dx} = f(y,x)\n\\]\nWe need to have a Python function that returns \\(f(y,x)\\) to give odeint(). I have intentionally written \\(y\\) before \\(x\\) here because odeint() expects the dependent variable first and the independent variable after. odeint() allows us to pass other optional variables too. I will now show you how all of these work.\nPlease note that I haven’t shown the code for the plotting because it is identical to that from the non-SciPy examples."
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#radioactivity",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#radioactivity",
    "title": "Numerical Solutions (Good)",
    "section": "4.2 Radioactivity",
    "text": "4.2 Radioactivity\n\n\n\n\n\n\nmax_time = 0.05\ndt = .001\ndecay_constant = 142       # For 85 Rb (per Myr)\nN0 = 1                     # Starting value of N (in billions of atoms)\n\n\ndef dNdt(N, time, decay_constant):\n    '''\n    Function for the derivative.\n    '''\n    return - decay_constant*N\n\n\nall_time = np.arange(0, max_time, dt)\n\nall_N = odeint(y0=[N0],                  # Initial values\n               func=dNdt,                # Function for the drivative\n               t=all_time,               # Time span\n               args=(decay_constant,)    # Any arguments to dNdt\n               )"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#logistic-equation",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#logistic-equation",
    "title": "Numerical Solutions (Good)",
    "section": "4.3 Logistic Equation",
    "text": "4.3 Logistic Equation\n\n\n\n\n\n\ndef dNdt(N, time, rate, carrying_capacity):\n    '''\n    Function for the derivative.\n    '''\n    return rate*N*(1-N/carrying_capacity)\n\n\nmax_time, dt = 3, .1\nN0, K, rate = 10, 100, 3\n\ndata = {}\ndata['time'] = np.arange(0, max_time, dt)\ndata['N'] = odeint(dNdt, N0, data['time'], (rate, K))"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#predator-prey",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#predator-prey",
    "title": "Numerical Solutions (Good)",
    "section": "4.4 Predator-Prey",
    "text": "4.4 Predator-Prey\n\n\n\n\n\n\nmax_time = 10\ndt = 0.001\nrabbits0, foxes0 = 1, .1\n\n# Lotka-Volterra equations\ndef dy_dt(y, t):\n    '''\n    Function for the derivative.\n    - y contains all the variables for the simulation \n    - t is the dependant variable\n    '''\n\n    rabbits, foxes = y\n\n    # Rabbits\n    a, b = 2, 2\n    drabbits_dt = a*rabbits - b*rabbits*foxes\n\n    # Foxes\n    d, g = 3, 3\n    dfoxes_dt = d*foxes*rabbits - g*foxes\n\n    return [drabbits_dt, dfoxes_dt]\n\n\ndata = {}\ndata['time'] = np.arange(0, max_time, dt)\n\n# Note the order I pass the rabbit and fox information\nresults = odeint(y0=[rabbits0, foxes0],          # Dependant variable\n                 func=dy_dt,                     # Derivatives\n                 t=data['time']                  # Independant variable\n                 )\n# Extract the individual results (Note, the order matters)\ndata['rabbits'] = results[:, 0]\ndata['foxes'] = results[:, 1]"
  },
  {
    "objectID": "docs/knowledge-lake/numerical/2_numerical_good.html#footnotes",
    "href": "docs/knowledge-lake/numerical/2_numerical_good.html#footnotes",
    "title": "Numerical Solutions (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI want to highlight that \\(\\dfrac{dN}{dt}\\) is a symbol and \\(\\dfrac{\\Delta N}{\\Delta t}\\) is a fraction. So you cannot dismantle a symbol!↩︎\nThis model is due to Verhulst and is often called the Logistic Model.↩︎\n‘Satisfying’ means substituting the solution leads to LHS = RHS↩︎\nIf you are a movie buff, the movie ‘Hidden Figures’ is about how Katherine Johnson plans NASA’s trip to the moon. She used the Euler method for this.↩︎"
  },
  {
    "objectID": "docs/problems/monte-carlo-ising.html",
    "href": "docs/problems/monte-carlo-ising.html",
    "title": "12| Monte Carlo Integration",
    "section": "",
    "text": "Introduction\nEvaluating integrals is necessary for most scientific modelling. So, many different integration methods have been developed. The Monte Carlo(MC) integration method is one of the most versatile. One of its charms is its ability to be scaled up to higher dimensions without much fuss. In this question, you will develop code to realise Monte Carlo integration.\n\n\nTasks\n\nTask 1Task 2Some theoryTask 3\n\n\n\nArea first\n\nThe image shows a plot of the function \\(f(x)=x^2\\sin^2(2x)\\). Let’s try to estimate the area of the region shaded in blue.\nHere is what you should do:\n\nGenerate \\((x,y)\\) coordinates for a large number (\\(n_\\text{all}\\)) of random points to evenly cover the area shaded in grey.\n\nAs you can see, this region is defined by \\(2 \\le x \\le 3\\) and \\(0 \\le y\\le 6\\).\nConsider using uniform() for this.\n\nAsk how many points you generated are below the curve (and therefore in the blue region). Let’s call this number \\(n_\\text{below}\\).\n\nNotice that all random points in the blue region satisfy \\(y_i \\leq f(x_i)\\)\n\nNow we can calculate the area of the blue region because: \\[\n  \\dfrac{\\text{Blue Area}}{\\text{Grey Area}} \\approx \\dfrac{n_\\text{below}}{n_\\text{all}}\\Rightarrow \\text{Blue Area}=\\dfrac{n_\\text{below}}{n_\\text{all}}\\times\\text{Grey Area}\n  \\]\n\n\n\n\n\nIntegration\nSince you now know the blue area, you also know the value of the following integral \\(\\displaystyle\\int_{x=2}^{x=3}f(x)dx\\)! So what you have done in this exercise is develop a numerical technique for evaluating integrals.\n\nCheck how good your estimate is by comparing it to the actual value of the integral, which is \\(4.0647\\). (I used Wolfram Alpha).\nCheck if your accuracy improves by increasing \\(n_\\text{all}\\).\n\n\n\n\n\nA Monte Carlo Estimator\n\\[\n\\newcommand\\ex[1]{\\left\\langle #1 \\right\\rangle}\n\\]\nThere is another way! Let’s play with some maths to see how.\nConsider a function \\(f(x)\\) that we want to integrate over \\([a,b]\\). If \\(\\ex{f(x)}\\) is the expectation value of \\(f(x)\\) over \\([a,b]\\), it follows that:\n\\[\n\\ex{f(x)}= \\dfrac{1}{b-a}\\int_a^bf(x)dx\n\\] But, \\[\n\\ex{f(x)}\\approx \\dfrac{1}{N}\\sum_{i=0}^{N-1}f(X_i)\n\\] Where \\(X_i\\) are \\(N\\) points in the interval \\([a,b]\\).\nWhence, for \\(X_i\\) drawn uniformly,\n\\[\n\\begin{equation}\n\\int_a^bf(x)dx \\approx (b-a)\\dfrac{1}{N}\\sum_{i=0}^{N-1}f(X_i)\n\\end{equation}\n\\]\nThe term on the right-hand side is called a Monte Carlo estimator. Notice that the Law of Large Numbers tells us that this approximation improves with large values of \\(N\\)\n\n\n\n\nUsing an estimator\nEvaluate the following integral using an MC estimator based on a Uniform probability distribution.\n\\[\n\\int_{x=2}^{x=3} x^2\\sin^2(2x)\\,dx\n\\]\n\nCompare your answer with your previous MC algorithm.\nCompare the speed of the two algorithms.\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/monte-carlo-electrons.html",
    "href": "docs/problems/monte-carlo-electrons.html",
    "title": "MC Electron Propagation",
    "section": "",
    "text": "The problem involves implementing a Monte Carlo simulation of electrons travling into matter using the recipe provided in Chapter 3: ‘The Single Scattering Model’ of the book ‘Monte Carlo modeling for electron microscopy and microanalysis’ by David C. Joy. You can find the chapter here.\nNote: I like to highlight that I am not infringing any copyright of the author by sharing this content as it is within the single chapter/10% allowance that is legally allowed.\nYou should present the simulation results for 10 and 100 keV electrons into carbon (C, density= 1.70 g/cm22) and PMMA (polymethyl methacrylate, C5O2H8C5O2H8, density= 1.18 g/cm22), including the spatial plots of electron trajectories.\n\n\n\\[\n\\begin{align}\nx_{n+1} &= x_{n} + step \\cos(\\alpha)\\\\\ny_{n+1} &= y_{n} + step \\cos\\left(\\frac{\\pi}{2}-A\\right)\n\\end{align}\n\\]\n\n\n\n\n\n\\[\n\\sigma_E = 5.21\\times10^{-21}\\dfrac{Z^2}{E^2}\\dfrac{4\\pi}{\\alpha(1+\\alpha)}\\left(\\dfrac{E+511}{E+1024}\\right)^2   \\qquad\\text{cm$^2$/atom}\n\\]\n\\[\n\\alpha = 3.4\\times10^{-3}\\dfrac{Z^{0.67}}{E}\n\\]\n\n\n\n\\[\n\\lambda = \\dfrac{A}{N_a\\rho\\,\\sigma_E}\\qquad{\\text{(cm)}}\n\\]\n\n\n\nSymbol\nMeaning\n\n\n\n\n\\(N_a\\)\nAvogardro number\n\n\n\\(\\rho\\)\nDensity (g/cm\\(^3\\))\n\n\n\\(A\\)\nAtomic weight in g/mole\n\n\n\n\n\n\\[\ns = -\\lambda\\ln(1-RND)\n\\]\n\n\n\n\n\\[\nE_{n+1} = E_n  -s\\cdot\\rho \\cdot \\frac{dE}{ds}\n\\] where,\n\n\n\nSymbol\nMeaning\n\n\n\n\n\\(L\\)\nFree flight length\n\n\n\\(E\\)\nEnergy of the particle,\n\n\n\\(\\Delta E\\)\nTotal energy lost in traversing L\n\n\n$ $\nRate of energy loss with path length,\n\n\n\n\\[\n\\dfrac{dE}{dS} = -78500 \\dfrac{Z}{AE}\\ln\\left[\\dfrac{1.166(E+0.85I)}{I}\\right]\n\\]\n\n\n\nSymbol\nMeaning\n\n\n\n\n\\(Z\\)\nAtomic number\n\n\n\\(A\\)\nAtomic Mass\n\n\n\\(I\\)\nMean ionisation energy\n\n\n\n\\[\nI = \\left[9.67Z + \\dfrac{58.5}{Z^{0.19}}\\right]\\times 10^{-3} \\qquad\\text{(keV)}\n\\]\n\n\n\n\\[\n\\begin{equation}\\label{for:ElasticScatteringAngleI}\n\\begin{array}{ccc}\n\\displaystyle R =  \\frac{\\displaystyle \\int_{0}^{\\theta}\\left (\\frac{d\\sigma}{d\\Omega}\\right) d\\theta}\n{\\displaystyle \\int_{0}^{\\pi}\\left (\\frac{d\\sigma}{d\\Omega}\\right) d\\theta}&  &\n\\end{array}\n\\end{equation}\n\\]\n\\[\n\\begin{equation}\\label{for:ElasticScatteringAngleII}\n\\begin{array}{ccc}\n\\displaystyle \\cos \\phi  = 1 - \\frac{2 \\alpha R}{1 + \\alpha - R}&  &\n\\end{array}\n\\end{equation}\n\\]\n\\[\n\\psi=2\\pi.RND\n\\]\n\n\n\n\n\n\\[\n\\begin{align*}\nR_{x} &= (R_{x0} \\cdot \\cos \\phi) + (V1 \\cdot V3) + (R_{y0}\\cdot\nV2 \\cdot V4) \\\\\n\\\\\nR_{y} &= (R_{y0} \\cdot \\cos \\phi) + [V4 \\cdot (R_{z0} \\cdot V1 - R_{x0} \\cdot V2) ] \\\\\n\\\\\nR_{z} &= (R_{z0} \\cdot \\cos \\phi) + (V2 \\cdot V3) - (R_{y0}\\cdot\nV1 \\cdot V4) \\\\\n\\end{align*}\n\\] where\n\\[\n\\begin{align*}\n    V1 &= AN \\cdot \\sin \\phi \\\\\n    \\\\\n    V2 &= AN \\cdot AM \\cdot \\sin \\phi \\\\\n    \\\\\n    V3 &= \\cos \\psi \\\\\n    \\\\\n    V4 &= \\sin \\psi\n\\end{align*}\n\\] \\[\n\\begin{align*}\n    \\\\\n    \\\\\n    AM &= - \\frac{R_{x0}}{R_{z0}}\n    \\\\\n    AN &= \\frac{1}{\\sqrt{1+ AM \\cdot AM}} \\\\\n    \\\\\n    \\\\\n\\end{align*}\n\\]\n\n\n\n\\[\n\\begin{align}\nx_{n+1} &= x_n + step\\cdot R_x\\\\\ny_{n+1} &= y_n + step\\cdot R_y\\\\\nz_{n+1} &= z_n + step\\cdot R_z\\\\\n\\end{align}\n\\]\n\n\n\n\nSimulate 1 particle in 2D (Brownian motion)\nSimulate 1 particle in 3D (Brownian motion)\n\nStarting direction cosines [0,0, 1] (vertically in)\n\nChange path length based just on a random number and \\(s = -\\lambda\\ln(1-RND)\\).\n\nLet \\(\\lambda\\) be 1\n\nIncorporate Energy loss (\\(\\dfrac{dE}{ds}\\))\nGet \\(\\lambda working\\)."
  },
  {
    "objectID": "docs/problems/monte-carlo-electrons.html#how-to-simulate-a-particle-in-2d",
    "href": "docs/problems/monte-carlo-electrons.html#how-to-simulate-a-particle-in-2d",
    "title": "MC Electron Propagation",
    "section": "",
    "text": "\\[\n\\begin{align}\nx_{n+1} &= x_{n} + step \\cos(\\alpha)\\\\\ny_{n+1} &= y_{n} + step \\cos\\left(\\frac{\\pi}{2}-A\\right)\n\\end{align}\n\\]"
  },
  {
    "objectID": "docs/problems/monte-carlo-electrons.html#how-to-simulate-a-particle-in-3d",
    "href": "docs/problems/monte-carlo-electrons.html#how-to-simulate-a-particle-in-3d",
    "title": "MC Electron Propagation",
    "section": "",
    "text": "\\[\n\\sigma_E = 5.21\\times10^{-21}\\dfrac{Z^2}{E^2}\\dfrac{4\\pi}{\\alpha(1+\\alpha)}\\left(\\dfrac{E+511}{E+1024}\\right)^2   \\qquad\\text{cm$^2$/atom}\n\\]\n\\[\n\\alpha = 3.4\\times10^{-3}\\dfrac{Z^{0.67}}{E}\n\\]\n\n\n\n\\[\n\\lambda = \\dfrac{A}{N_a\\rho\\,\\sigma_E}\\qquad{\\text{(cm)}}\n\\]\n\n\n\nSymbol\nMeaning\n\n\n\n\n\\(N_a\\)\nAvogardro number\n\n\n\\(\\rho\\)\nDensity (g/cm\\(^3\\))\n\n\n\\(A\\)\nAtomic weight in g/mole\n\n\n\n\n\n\\[\ns = -\\lambda\\ln(1-RND)\n\\]\n\n\n\n\n\\[\nE_{n+1} = E_n  -s\\cdot\\rho \\cdot \\frac{dE}{ds}\n\\] where,\n\n\n\nSymbol\nMeaning\n\n\n\n\n\\(L\\)\nFree flight length\n\n\n\\(E\\)\nEnergy of the particle,\n\n\n\\(\\Delta E\\)\nTotal energy lost in traversing L\n\n\n$ $\nRate of energy loss with path length,\n\n\n\n\\[\n\\dfrac{dE}{dS} = -78500 \\dfrac{Z}{AE}\\ln\\left[\\dfrac{1.166(E+0.85I)}{I}\\right]\n\\]\n\n\n\nSymbol\nMeaning\n\n\n\n\n\\(Z\\)\nAtomic number\n\n\n\\(A\\)\nAtomic Mass\n\n\n\\(I\\)\nMean ionisation energy\n\n\n\n\\[\nI = \\left[9.67Z + \\dfrac{58.5}{Z^{0.19}}\\right]\\times 10^{-3} \\qquad\\text{(keV)}\n\\]\n\n\n\n\\[\n\\begin{equation}\\label{for:ElasticScatteringAngleI}\n\\begin{array}{ccc}\n\\displaystyle R =  \\frac{\\displaystyle \\int_{0}^{\\theta}\\left (\\frac{d\\sigma}{d\\Omega}\\right) d\\theta}\n{\\displaystyle \\int_{0}^{\\pi}\\left (\\frac{d\\sigma}{d\\Omega}\\right) d\\theta}&  &\n\\end{array}\n\\end{equation}\n\\]\n\\[\n\\begin{equation}\\label{for:ElasticScatteringAngleII}\n\\begin{array}{ccc}\n\\displaystyle \\cos \\phi  = 1 - \\frac{2 \\alpha R}{1 + \\alpha - R}&  &\n\\end{array}\n\\end{equation}\n\\]\n\\[\n\\psi=2\\pi.RND\n\\]\n\n\n\n\n\n\\[\n\\begin{align*}\nR_{x} &= (R_{x0} \\cdot \\cos \\phi) + (V1 \\cdot V3) + (R_{y0}\\cdot\nV2 \\cdot V4) \\\\\n\\\\\nR_{y} &= (R_{y0} \\cdot \\cos \\phi) + [V4 \\cdot (R_{z0} \\cdot V1 - R_{x0} \\cdot V2) ] \\\\\n\\\\\nR_{z} &= (R_{z0} \\cdot \\cos \\phi) + (V2 \\cdot V3) - (R_{y0}\\cdot\nV1 \\cdot V4) \\\\\n\\end{align*}\n\\] where\n\\[\n\\begin{align*}\n    V1 &= AN \\cdot \\sin \\phi \\\\\n    \\\\\n    V2 &= AN \\cdot AM \\cdot \\sin \\phi \\\\\n    \\\\\n    V3 &= \\cos \\psi \\\\\n    \\\\\n    V4 &= \\sin \\psi\n\\end{align*}\n\\] \\[\n\\begin{align*}\n    \\\\\n    \\\\\n    AM &= - \\frac{R_{x0}}{R_{z0}}\n    \\\\\n    AN &= \\frac{1}{\\sqrt{1+ AM \\cdot AM}} \\\\\n    \\\\\n    \\\\\n\\end{align*}\n\\]\n\n\n\n\\[\n\\begin{align}\nx_{n+1} &= x_n + step\\cdot R_x\\\\\ny_{n+1} &= y_n + step\\cdot R_y\\\\\nz_{n+1} &= z_n + step\\cdot R_z\\\\\n\\end{align}\n\\]\n\n\n\n\nSimulate 1 particle in 2D (Brownian motion)\nSimulate 1 particle in 3D (Brownian motion)\n\nStarting direction cosines [0,0, 1] (vertically in)\n\nChange path length based just on a random number and \\(s = -\\lambda\\ln(1-RND)\\).\n\nLet \\(\\lambda\\) be 1\n\nIncorporate Energy loss (\\(\\dfrac{dE}{ds}\\))\nGet \\(\\lambda working\\)."
  },
  {
    "objectID": "docs/problems/monte-carlo-statistics.html",
    "href": "docs/problems/monte-carlo-statistics.html",
    "title": "MC Statistics",
    "section": "",
    "text": "Introduction\nIn this problem, we will use random numbers to create a simple simulation of radioactive decay. Let’s start with some basic observations:\n\nA given (unstable) nucleus has a fixed probability of decaying in a given time interval. This probability is different for nuclei of different elements. For example the probability of decaying (for a fixed time interval) for a U nucleus is (much) smaller than for a Th nucleus. This is characterized by the decay constant(\\(\\tau\\)) or half-life (\\(\\lambda\\)).\nSo the longer we have a sample, the greater the probability of its nuclei decaying. For example, the probability of decaying within 2s is greater than within 1s.\nThese probabilities do not scale linearly (i.e., the likelihood for 2s is not twice that for 1 s).\n\n\n\nTasks\n\nTask 1Task 2Task 3\n\n\nIt has been observed that the probability of nuclei decaying in a given time interval \\(\\Delta t\\) is \\(\\dfrac{1}{6}\\). This means after a time \\(\\Delta t\\)=1, about one-sixth of the nuclei would have disintegrated.\nSimulate and plot the change in the number of nuclei with time. Start with a 10000 nuclei. You should see a plot like the one below.\n\n\nRedo the previous task but this time adjust your parameteres so that you are simulation the decay of Th.\n\n\nThoroum decays into a daught nuclide X who is also unstable with a half-life of x. Simulate\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/roberts-gray-golgi_question.html",
    "href": "docs/problems/roberts-gray-golgi_question.html",
    "title": "09| A picture is worth thousands of data points",
    "section": "",
    "text": "Introduction\nA lot of data goes into creating an image. Or, put another way, we can extract many details by analysing an image. matplotlib allows you to do this quite easily. In this question, we will use matplotlib to quickly explore the topic of image analysis. For this, please download the zip file golgi-movie_robert_frames_gray.zip, which contains 17 fluorescence images collected by Dr Robert Lieu. The 17 images are a time series of the variation of a fluorescence marker protein.\nThe original images have been converted to grayscale (black & white) images to simplify this discussion.\n\n\nTasks\n\nTask 1Task 2Task 3\n\n\n\nLock and Load\n\nUse the following code to import and display one of the images. The cmap specifies the false-colour, colour scheme used to display the data.\nimg_data = plt.imread(file-name)\nplt.imshow(img_data, cmap='jet')\nplt.colorbar()\n\n\n\n\nHow is the data stored?\nHow is the image information stored by matplotlib? Let’s find out.\nDetermine the following:\n\nType of img_data.\nShape of img_data.\nValues of maximum, minimum and sum of img_data. What do these numbers represent?\nA histogram of all the values of img_data.\nThe total counts of the image.\n\nHints:\n\nflatten() might be useful.\n\n\n\n\n\nPlotting a trend\nWrite a snippet of Python code to produce the following plot that shows the variation of the total fluorescence intensity over time for the images provided.\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/researchers-frustration.html",
    "href": "docs/problems/researchers-frustration.html",
    "title": "05| A Researcher’s Frustration",
    "section": "",
    "text": "Introduction\nYou are the lead researcher in an international collaboration involving five countries (Singapore, US, UK, Australia New Zealand). The research project consists of measuring the height of an adult macaque species. The project is at its end, and you are collating all the data measured by your collaborators.\nUpon trying to combine the data files from your collaborators, you realise (in incredulous frustration) that each of your collaborators has made their measurements using a different unit! Here are the units that were used.\n\n\n\n\nCountry\nUnit\n\n\n\n\nSingapore\nmetres\n\n\nUK\ninches\n\n\nUS\nfeet\n\n\nAustralia\ncentimetres\n\n\nNew Zealand\nmillimeters\n\n\n\n\nYou can download the data here\n\n\nTasks\nWrite some Python code to:\n\nProduce a copy of the data that is ‘corrected’ to SI units.\n\nName these files with an ‘_si’ at the end.\n\nOrganise your data files in the following file structure\n\n\n\n\n\n\ngraph TB\nA(All Data)    --&gt;B(SIN) \n         A --&gt;C(AUS)\n         A --&gt;D(UK)\n         A --&gt;E(US)\n         A --&gt;F(NZ)\n         B --&gt;G(SI)\n         C --&gt;I(SI)\n         C --&gt;J(ORIGINAL)\n         D --&gt;K(SI)\n         D --&gt;L(ORIGINAL)\n         E --&gt;M(SI)\n         E --&gt;N(ORIGINAL)\n         F --&gt;O(SI)\n         F --&gt;P(ORIGINAL)\n\n\n\n\n\n\n\nPlot histograms of the data.\n\nPlot a histogram for each of the countries as a separate plot,\nPlot histograms of the countries as a grid of plots,\nPlot a histogram for the combined data. \n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/about-a-pendulum.html",
    "href": "docs/problems/about-a-pendulum.html",
    "title": "10| About a Pendulum",
    "section": "",
    "text": "Introduction\nIn this question, we will use our knowledge of segmentation analysis to develop tools for tracking motion. We will work with a simple video of a pendulum (pendulum.mp4) captured using my handphone. Once we track (i.e., extract its position-time information) the pendulum’s motion, we can plot and apply a more mathematical analysis to understand the motion better.\n\nOops: As you can see, the orientation of the video is wrong, sorry. Guess you will have to do something about that.\n\n\nTasks\n\nFigure out a way to extract the individual frames of the video.There are many ways (e.g., Python, ImageJ, ImageMagick, …) to do this so pick one that you like.Please indicate what you used.\nUsing either a ‘low-level’ approach using basic Numpy arrays or a ‘high-level’ approach using a package (e.g., scikit-image) extract the \\((t,x,y)\\) information of the pendulum bob and plot them.\nUse the SciPy functioncurve_fit() to fit a function of the form \\(A \\sin(2\\pi f t + \\alpha)\\) to your tracking data. The results should look like the red line of the plot shown below.\n\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/humpty-dumpty-ir-spectra_question.html",
    "href": "docs/problems/humpty-dumpty-ir-spectra_question.html",
    "title": "06| Humpty Dumpty IR Spectra",
    "section": "",
    "text": "Scenario\nYou are part of a large team of (idiosyncratic) scientists whose passion is to measure IR spectra of chemical compounds. They have just finished collecting the data for Toluene, 1-Octene and Ethanol. Unfortunately, in their abundant enthusiasm, many factions have used the same instrument to make multiple measurements. You can access a zip file of all the data collected at humpty-dumpty-ir-data.zip.\n\n\nTasks\n\nTask 1Task 2\n\n\n\nConsolidate the data\nYour role in the team is to consolidate all the data. Here are some things you need to be aware of:\n\nEach file name starts with a random number.\nDifferent files may have different delimiters.\nDifferent files for a given compound can contain overlapping data, so you must ensure that each data point is only included once.\nFor a given compound, measured values of transmittance for a given wavenumber are consistent across all files.\nFor some weird reason, the scientists thought it was neat to write the names of the compounds using a mixture of uppercase and lowercase letters!\n\nNote:\n\nYou can only use basic Python and the packages Numpy, glob, and os. You cannot use any other specialised packages or software.\nDo not modify the original files.\n\n\n\n\n\nTime to plot\nOnce you have consolidated your data, generate a plot similar to the following.\n\n\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/problems/vibrot-spectrum_question.html",
    "href": "docs/problems/vibrot-spectrum_question.html",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "We know from our basic chemistry lessons that atoms have energy levels. For example, the hydrogen atom’s ground state (\\(n=1\\)) has an energy of -13.6 eV, and the next excited state (\\(n=2\\)) has an energy of -3.4 eV. We also know that electrons can get excited to higher energy levels and spontaneously decay to a lower energy level. In this process, the electron will emit energy corresponding to the difference in energy levels. So, an electron making the transition \\(n=2 \\rightarrow 1\\) will emit a photon of energy 10.2 eV. This corresponds to a wavelength of 121.6 nm. These electronic transitions lead to what we refer to as atomic spectra.\nMolecules, too, have electronic energy levels. However, they also have rotational and vibrational energy levels. However, the energy levels corresponding to these types of motions are lower than electronic levels. Hence, the corresponding emissions are related to the infrared and microwave parts of the electromagnetic spectrum.\nYou can obtain the wavelength corresponding to a photon using the formula \\(E = \\dfrac{hc}{\\lambda}\\). \\(h\\) is Planck’s constant, \\(6.626 \\times 10^{-34}\\) Js and \\(c\\) is \\(2.998\\times 10^8\\) m/s, the speed of light in vacuum.\n\n\n\nThe rotational energy levels of a diatomic molecule (like HCl or CO) is given by:\n\\[\nE_\\text{ROT,$J$} = BJ(J+1)  \n\\tag{1}\\]\n\\(J = 0, 1, 2,3,\\ldots\\) is the quantum number associated with the rotational motion. \\(B\\) is called the Rotational constant and is given by:\n\\[\nB = \\dfrac{h^2}{8\\pi^2 I}   \n\\tag{2}\\]\nWhere \\(I\\) is the moment of inertia of the molecule about its centre-of-mass given by:\n\\[\nI = \\mu r^2_\\text{bond length}  \n\\tag{3}\\]\nWhere:\n\\[\n\\mu = \\dfrac{m_1 m_2}{m_1 + m_2}\n\\tag{4}\\]\nand \\(m_1\\) and \\(m_2\\) are the massess of the atoms and \\(r_\\text{bond length}\\) is the bond length.\nThe rules of quantum mechanics restrict the transitions between rotational energy levels in a molecule, which are specified by selection rules. The selection rule is a consequence of the conservation of angular momentum in the molecule. The selection rule for rotational transitions for a diatomic system is:\n\\[\n\\Delta J = \\pm 1\n\\tag{5}\\]\nThis means that the change in the rotational quantum number (\\(J\\)) between the initial and final states of the transition can only be plus or minus one.\n\n\n\nThere are multiple ways for a molecule to rotate. This is reflected in quantum mechanics by a concept called degeneracy, meaning that a given energy state can exist in multiple ways. The number of ways is called the degeneracy of the system.\nRotational states have a degeneracy given by:\n\\[\n\\text{Rotational degeneracy} = 2J +1\n\\]{#eq-x)\n\n\n\nA photon will be emitted whenever there is a transition between two allowed \\(J\\) values. The more transitions there are, the greater the number of photons emitted. Therefore, the intensity or brightness of the corresponding spectral line depends on how many transitions occur. Two factors determine this number of transitions.\nOne is how many molecules are in the initial and final energy (\\(J\\)) states. This is determined by the temperature of the system and is given by the famous Boltzmann distribution:\n\\[\n\\dfrac{N_m}{N_n} = e^{-\\left(\\dfrac{E_m - E_n}{k_b T}\\right)}   \n\\tag{6}\\]\nThe second is the degeneracy of the states.\n\n\n\nThe vibrational energy levels of a diatomic molecule (like HCl or CO) is given by:\n\\[\nE_\\text{VIB,$\\nu$} = \\left(\\nu+\\dfrac{1}{2}\\right) h\\omega_\\text{osc\n\\tag{7}\\]\n\\(\\nu = 0, 1, 2,3,\\ldots\\) is the quantum number associated with the rotational motion. \\(\\omega_\\text{osc}\\) is the natural angular frequency (radians/second) of the oscillations and is given by:\n\\[\n\\omega_\\text{osc}   = \\dfrac{1}{2\\pi}\\sqrt{\\dfrac{k}{\\mu}}  \n\\tag{8}\\]\n\\(k\\) represents the strength of the bond.\nThe selection rules for vibrational transitions are:\n\\[\n\\Delta \\nu = \\pm 1, \\pm 2, \\pm 3, \\ldots    \n\\tag{9}\\]\n\n\n\nIn reality, a molecule both rotates and vibrates. So, the energy levels of a molecule are more accurately described by:\n\\[\nE_\\text{VIB-ROT,$J, \\nu$} = BJ(J+1) + \\left(\\nu+\\dfrac{1}{2}\\right) h\\omega_\\text{osc}  \n\\tag{10}\\]\nThe energy transitions follow both transition rules:\n\\[\\begin{align}\n\\Delta J &= \\pm 1 \\\\\n\\Delta \\nu &= \\pm 1, \\pm 2, \\pm 3, \\ldots   \n\\end{align}\\]\n\n\n\n\n\n\nQuantity\nValue\n\n\n\n\nMass of \\(^{1}\\)H\n\\(1.673 \\times 10^{−27}\\) kg\n\n\nMass of \\(^{35}\\)Cl\n\\(58.06 \\times 10^{−27}\\) kg\n\n\nBond length (\\(r_\\text{bond length}\\))\n\\(0.127\\) nm\n\n\nBond strength (\\(k\\))\n\\(516\\) Nm\\(^{-1}\\)"
  },
  {
    "objectID": "docs/problems/vibrot-spectrum_question.html#energy-levels",
    "href": "docs/problems/vibrot-spectrum_question.html#energy-levels",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "We know from our basic chemistry lessons that atoms have energy levels. For example, the hydrogen atom’s ground state (\\(n=1\\)) has an energy of -13.6 eV, and the next excited state (\\(n=2\\)) has an energy of -3.4 eV. We also know that electrons can get excited to higher energy levels and spontaneously decay to a lower energy level. In this process, the electron will emit energy corresponding to the difference in energy levels. So, an electron making the transition \\(n=2 \\rightarrow 1\\) will emit a photon of energy 10.2 eV. This corresponds to a wavelength of 121.6 nm. These electronic transitions lead to what we refer to as atomic spectra.\nMolecules, too, have electronic energy levels. However, they also have rotational and vibrational energy levels. However, the energy levels corresponding to these types of motions are lower than electronic levels. Hence, the corresponding emissions are related to the infrared and microwave parts of the electromagnetic spectrum.\nYou can obtain the wavelength corresponding to a photon using the formula \\(E = \\dfrac{hc}{\\lambda}\\). \\(h\\) is Planck’s constant, \\(6.626 \\times 10^{-34}\\) Js and \\(c\\) is \\(2.998\\times 10^8\\) m/s, the speed of light in vacuum."
  },
  {
    "objectID": "docs/problems/vibrot-spectrum_question.html#rotational-energy-levels",
    "href": "docs/problems/vibrot-spectrum_question.html#rotational-energy-levels",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "The rotational energy levels of a diatomic molecule (like HCl or CO) is given by:\n\\[\nE_\\text{ROT,$J$} = BJ(J+1)  \n\\tag{1}\\]\n\\(J = 0, 1, 2,3,\\ldots\\) is the quantum number associated with the rotational motion. \\(B\\) is called the Rotational constant and is given by:\n\\[\nB = \\dfrac{h^2}{8\\pi^2 I}   \n\\tag{2}\\]\nWhere \\(I\\) is the moment of inertia of the molecule about its centre-of-mass given by:\n\\[\nI = \\mu r^2_\\text{bond length}  \n\\tag{3}\\]\nWhere:\n\\[\n\\mu = \\dfrac{m_1 m_2}{m_1 + m_2}\n\\tag{4}\\]\nand \\(m_1\\) and \\(m_2\\) are the massess of the atoms and \\(r_\\text{bond length}\\) is the bond length.\nThe rules of quantum mechanics restrict the transitions between rotational energy levels in a molecule, which are specified by selection rules. The selection rule is a consequence of the conservation of angular momentum in the molecule. The selection rule for rotational transitions for a diatomic system is:\n\\[\n\\Delta J = \\pm 1\n\\tag{5}\\]\nThis means that the change in the rotational quantum number (\\(J\\)) between the initial and final states of the transition can only be plus or minus one."
  },
  {
    "objectID": "docs/problems/vibrot-spectrum_question.html#degeneracy-of-states",
    "href": "docs/problems/vibrot-spectrum_question.html#degeneracy-of-states",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "There are multiple ways for a molecule to rotate. This is reflected in quantum mechanics by a concept called degeneracy, meaning that a given energy state can exist in multiple ways. The number of ways is called the degeneracy of the system.\nRotational states have a degeneracy given by:\n\\[\n\\text{Rotational degeneracy} = 2J +1\n\\]{#eq-x)"
  },
  {
    "objectID": "docs/problems/vibrot-spectrum_question.html#intensity-of-the-spectrums",
    "href": "docs/problems/vibrot-spectrum_question.html#intensity-of-the-spectrums",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "A photon will be emitted whenever there is a transition between two allowed \\(J\\) values. The more transitions there are, the greater the number of photons emitted. Therefore, the intensity or brightness of the corresponding spectral line depends on how many transitions occur. Two factors determine this number of transitions.\nOne is how many molecules are in the initial and final energy (\\(J\\)) states. This is determined by the temperature of the system and is given by the famous Boltzmann distribution:\n\\[\n\\dfrac{N_m}{N_n} = e^{-\\left(\\dfrac{E_m - E_n}{k_b T}\\right)}   \n\\tag{6}\\]\nThe second is the degeneracy of the states."
  },
  {
    "objectID": "docs/problems/vibrot-spectrum_question.html#vibrational-energy-levels",
    "href": "docs/problems/vibrot-spectrum_question.html#vibrational-energy-levels",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "The vibrational energy levels of a diatomic molecule (like HCl or CO) is given by:\n\\[\nE_\\text{VIB,$\\nu$} = \\left(\\nu+\\dfrac{1}{2}\\right) h\\omega_\\text{osc\n\\tag{7}\\]\n\\(\\nu = 0, 1, 2,3,\\ldots\\) is the quantum number associated with the rotational motion. \\(\\omega_\\text{osc}\\) is the natural angular frequency (radians/second) of the oscillations and is given by:\n\\[\n\\omega_\\text{osc}   = \\dfrac{1}{2\\pi}\\sqrt{\\dfrac{k}{\\mu}}  \n\\tag{8}\\]\n\\(k\\) represents the strength of the bond.\nThe selection rules for vibrational transitions are:\n\\[\n\\Delta \\nu = \\pm 1, \\pm 2, \\pm 3, \\ldots    \n\\tag{9}\\]"
  },
  {
    "objectID": "docs/problems/vibrot-spectrum_question.html#rotational-vibrational-energy-levels",
    "href": "docs/problems/vibrot-spectrum_question.html#rotational-vibrational-energy-levels",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "In reality, a molecule both rotates and vibrates. So, the energy levels of a molecule are more accurately described by:\n\\[\nE_\\text{VIB-ROT,$J, \\nu$} = BJ(J+1) + \\left(\\nu+\\dfrac{1}{2}\\right) h\\omega_\\text{osc}  \n\\tag{10}\\]\nThe energy transitions follow both transition rules:\n\\[\\begin{align}\n\\Delta J &= \\pm 1 \\\\\n\\Delta \\nu &= \\pm 1, \\pm 2, \\pm 3, \\ldots   \n\\end{align}\\]"
  },
  {
    "objectID": "docs/problems/vibrot-spectrum_question.html#data-for-hcl",
    "href": "docs/problems/vibrot-spectrum_question.html#data-for-hcl",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "Quantity\nValue\n\n\n\n\nMass of \\(^{1}\\)H\n\\(1.673 \\times 10^{−27}\\) kg\n\n\nMass of \\(^{35}\\)Cl\n\\(58.06 \\times 10^{−27}\\) kg\n\n\nBond length (\\(r_\\text{bond length}\\))\n\\(0.127\\) nm\n\n\nBond strength (\\(k\\))\n\\(516\\) Nm\\(^{-1}\\)"
  },
  {
    "objectID": "docs/problems/analysing-graduate-data.html",
    "href": "docs/problems/analysing-graduate-data.html",
    "title": "13| Graduate Data",
    "section": "",
    "text": "The Singapore government maintains and publicly shares various datasets at Data.gov.sg. In this question, we will analyse the median salaries of graduates from the different universities in Singapore.\n\n\nThis question heavily utilises the package called Pandas. Pandas is the de facto package for all things related to data analysis. You must familiarise yourself (see the Knowledge Lake) with how to use Pandas to work on this problem."
  },
  {
    "objectID": "docs/problems/analysing-graduate-data.html#you-need-pandas",
    "href": "docs/problems/analysing-graduate-data.html#you-need-pandas",
    "title": "13| Graduate Data",
    "section": "",
    "text": "This question heavily utilises the package called Pandas. Pandas is the de facto package for all things related to data analysis. You must familiarise yourself (see the Knowledge Lake) with how to use Pandas to work on this problem."
  },
  {
    "objectID": "docs/problems/monte-carlo-radioactivity.html",
    "href": "docs/problems/monte-carlo-radioactivity.html",
    "title": "MC Radioactivity",
    "section": "",
    "text": "Introduction\nIn this problem, we will use random numbers to create a simple simulation of radioactive decay. Let’s start with some basic observations:\n\nA given (unstable) nucleus has a fixed probability of decaying in a given time interval. This probability is different for nuclei of different elements. For example the probability of decaying (for a fixed time interval) for a U nucleus is (much) smaller than for a Th nucleus. This is characterized by the decay constant(\\(\\tau\\)) or half-life (\\(\\lambda\\)).\nSo the longer we have a sample, the greater the probability of its nuclei decaying. For example, the probability of decaying within 2s is greater than within 1s.\nThese probabilities do not scale linearly (i.e., the likelihood for 2s is not twice that for 1 s).\n\n\n\nTasks\n\nTask 1Task 2Task 3\n\n\nIt has been observed that the probability of nuclei decaying in a given time interval \\(\\Delta t\\) is \\(\\dfrac{1}{6}\\). This means after a time \\(\\Delta t\\)=1, about one-sixth of the nuclei would have disintegrated.\nSimulate and plot the change in the number of nuclei with time. Start with a 10000 nuclei. You should see a plot like the one below.\n\n\nRedo the previous task but this time adjust your parameteres so that you are simulation the decay of Th.\n\n\nThoroum decays into a daught nuclide X who is also unstable with a half-life of x. Simulate\n\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python-optimised/environments.html#why-use-virtual-environments",
    "href": "docs/python-optimised/environments.html#why-use-virtual-environments",
    "title": "Virtual Environments",
    "section": "0.1 Why Use Virtual Environments?",
    "text": "0.1 Why Use Virtual Environments?\n\nAvoid Clutter: When you install a package using conda (or pip), it will typically install it to your default (base) installation. Installing packages globally like this can lead to a cluttered and unwieldy environment, especially when tools like conda or pip attempt to resolve dependencies.\nSafe Testing: You might want to test a package safely without risking your base installation. Virtual environments allow experimentation without affecting the global Python setup.\nCollaboration: If you are working on a collaborative project, sharing your code and environment setup ensures consistency among team members.\nVersion Conflicts: Some packages may have compatibility issues with specific versions. Isolating each project’s dependencies prevents breaking changes when upgrading or downgrading packages.\nLegacy Code: There are instances when package upgrades will break your code due to code compatibility issues. Virtual environments allow you to maintain specific versions of packages to get around this problem."
  },
  {
    "objectID": "docs/python-optimised/environments.html#working-with-environments",
    "href": "docs/python-optimised/environments.html#working-with-environments",
    "title": "Virtual Environments",
    "section": "0.2 Working with Environments",
    "text": "0.2 Working with Environments\nThe following is a quick summary based on the instructions at the Conda wesbite. Please refer to that page for more details about optimizing the setup process.\nIf your installation is based on pip you must use venv. You can find more details about it here.\n\nCreateActivateDeactivateExport/Share\n\n\nThe following creates a virtual environment named my_virtual_env that uses Python version 3.10. It also installs specific versions of the SciPy and NumPy.\nconda create -name my_virtual_env python=3.10 scipy=0.17.3 numpy=1.24\n\n\nTo use an environment, you must activate it from the terminal. The following command activates the environment, switching to its specific Python and package setup.\nconda activate my_virtual_env\n\n\nUse this command to return to your base environment.\nconda deactivate\n\n\nExport the environment’s packages to a file for sharing:\nconda env export &gt; environment.yml\nOthers can replicate your environment by running:\nconda env create -f environment.yml"
  },
  {
    "objectID": "docs/about/schedule.html",
    "href": "docs/about/schedule.html",
    "title": "Schedule",
    "section": "",
    "text": "Welcome to SP2273: Working on Interdisciplinary Science, Pythonically. Thank you for joining 731. My name is Chammika Udalagama, and I am the course coordinator for this course. On this page, I will quickly run through many of the important features of the course. I have greatly elaborated on these in other chapters of this part."
  },
  {
    "objectID": "docs/about/schedule.html#footnotes",
    "href": "docs/about/schedule.html#footnotes",
    "title": "Schedule",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe usually refer to our SPS modules with just the last two digits.↩︎"
  },
  {
    "objectID": "docs/setting-up/setup_3_jupyter.html#download-install-miniconda",
    "href": "docs/setting-up/setup_3_jupyter.html#download-install-miniconda",
    "title": "Hello, Jupyter! (Need)",
    "section": "2.1 Download & install Miniconda",
    "text": "2.1 Download & install Miniconda\nFirst, we need to download the installer. Please follow the instructions below that are relevant to your operating system.\n\nWindows macOS \n\n\n\nDownload installer here\nInstall Miniconda.\n\nDouble-clicking the .exe file.\nFollow the instructions on the screen:\n\nWhen not sure, just use the installer’s default setting.\nYou must decide ‘Just Me’ or ‘All Users’. If you are installing for ‘All Users’, you must have Administrator privileges on your machine.\n\n\n\n\n\n\nDownload the installer\n\nVisit this page.\nChoose the bash package corresponding to your computer’s chip (i.e., M1, Intel)\nDownload to your Downloads folder (this is the default).\n\nInstall Miniconda.\n\nStart up the Terminal app either from the Applications folder or using the Launchpad.\n\nType the following and press ENTER\n\n\ncd ~/Downloads\nThis changes directory (folder) to ‘Downloads’.\n\n\nType the following, adjusting the file name according to step 1, and press ENTER\n\n\nbash Miniconda3-latest-MacOSX-x86_64.sh\nThis starts the installer.\n\n\nFollow the instructions on the screen:\n\nWhen not sure, just use the installer’s default setting.\nYou must decide ‘Just Me’ or ‘All Users’. If you are installing for ‘All Users’, you must have Administrator privileges on your machine."
  },
  {
    "objectID": "docs/setting-up/setup_3_jupyter.html#what-is-the-command-prompt",
    "href": "docs/setting-up/setup_3_jupyter.html#what-is-the-command-prompt",
    "title": "Hello, Jupyter! (Need)",
    "section": "3.1 What is the command prompt",
    "text": "3.1 What is the command prompt\nBefore proceeding further, allow me to introduce you to the command prompt. The command prompt is one of the most powerful features of your operating system. However, because it is not as friendly as the windows based graphical user interface (GUI), people shy away from using it. Unfortunately, we do not have a choice; we have to use the prompt to maintain (i. e., install, uninstall, upgrade) components and to start Jupyter Notebooks. So, let’s bite the bullet and learn how to use it."
  },
  {
    "objectID": "docs/setting-up/setup_3_jupyter.html#opening-the-prompt",
    "href": "docs/setting-up/setup_3_jupyter.html#opening-the-prompt",
    "title": "Hello, Jupyter! (Need)",
    "section": "3.2 Opening the prompt",
    "text": "3.2 Opening the prompt\n\nWindows macOS \n\n\nWindows users should use the Anaconda Prompt.You can open this from the Start menu.\n\n\nmacOS has a native prompt called the Terminal, which you can open from the Applications folder or the Launchpad."
  },
  {
    "objectID": "docs/setting-up/setup_3_jupyter.html#navigate-using-the-prompt",
    "href": "docs/setting-up/setup_3_jupyter.html#navigate-using-the-prompt",
    "title": "Hello, Jupyter! (Need)",
    "section": "3.3 Navigate using the prompt",
    "text": "3.3 Navigate using the prompt\nWe will often need to navigate to different folders using the prompt. The command to change the directory (or folder) is issued as follows.\ncd path-to-folder\nLet’s navigate into the folder you created previously. For this, we need the full path (e.g. C:\\\\Documents...) of that folder. Using the GUI (Windows File Explorer or Finder) is the easiest way to extract the path to the folder you want.\n\n\n\n\n\nGo to the folder using the file explore GUI,\nRight-click on the top address bar as shown below.\n\nPick Copy address as text\nNow just paste the result in the command line and press Enter:\n\ncd path-to-folder\n\n\n\nLocate the folder using the Finder,\nRight-click on the folder icon and choose Get Info.\nNow hold the Option button and pick Copy filename as Pathname.\nNow just paste the result in the command line and press Enter:\n\ncd path-to-folder"
  },
  {
    "objectID": "docs/setting-up/setup_3_jupyter.html#using-the-prompt-with-conda",
    "href": "docs/setting-up/setup_3_jupyter.html#using-the-prompt-with-conda",
    "title": "Hello, Jupyter! (Need)",
    "section": "3.4 Using the prompt with conda",
    "text": "3.4 Using the prompt with conda\nconda is the name of the main programme from Anaconda that controls everything in the installation. It is called the package manager. You will typically have to use conda to install, upgrade or remove packages. Here are two examples of how to use the prompt. Please try them both.\n\nTesting our installation.Updating Miniconda\n\n\nLet’s use the prompt to check if our previous installation of Miniconda went okay. For this, run (i.e., type and press ENTER) the following:\nconda list\nThis will give you a list of all the things that are installed under Miniconda.\n\n\nThe installer does not always install the most recent versions. So, let’s first update Miniconda itself. Here is the command to do this.\nconda update conda"
  },
  {
    "objectID": "docs/setting-up/setup_3_jupyter.html#jupyter-the-first-run",
    "href": "docs/setting-up/setup_3_jupyter.html#jupyter-the-first-run",
    "title": "Hello, Jupyter! (Need)",
    "section": "4.1 Jupyter… the first run",
    "text": "4.1 Jupyter… the first run\nFinally, it is time to run Jupyter for the first time. We need to start Jupyter using the prompt by invoking:\njupyter notebook\nIf you are on Windows, you can also type “Jupyter notebook” in the search bar and click on the Jupyter Notebook icon.\nWhen you do this, a webpage will open up and display the content of the folder you started Jupyter in. Since we are in the Learning Portfolio, you should see that content.\nWe are done with this chapter. I will show you how to use Jupyter in the next part. But, for now, press the button Logout."
  },
  {
    "objectID": "docs/setting-up/setup_3_jupyter.html#footnotes",
    "href": "docs/setting-up/setup_3_jupyter.html#footnotes",
    "title": "Hello, Jupyter! (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor instance: PyCharm, Spyder, Visual Studio, Colab, Kaggle↩︎\nwe will learn what a package does a bit later. For the moment, think of it as an essential ‘item’.↩︎\ni. e. only installs essential features↩︎"
  },
  {
    "objectID": "docs/setting-up/setup_1_hypothesis.html",
    "href": "docs/setting-up/setup_1_hypothesis.html",
    "title": "Hello, Hypothesis! (Good)",
    "section": "",
    "text": "Hypothesis is a free web tool that allows you to “annotate the web”. Specifically, it will enable you to highlight and make notes on web pages. It also has a chat feature that allows you to develop a discussion (with your instructors and peers) around the web page’s content. For 73, we will use Hypothesis to share comments and questions about the notes and inform me of any typos or mistakes."
  },
  {
    "objectID": "docs/setting-up/setup_1_hypothesis.html#footnotes",
    "href": "docs/setting-up/setup_1_hypothesis.html#footnotes",
    "title": "Hello, Hypothesis! (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHowever, by installing the Chrome extension, you can use Hypothesis with almost all other web pages. Please refer to this page if you want to do this.↩︎"
  }
]