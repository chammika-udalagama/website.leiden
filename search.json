[
  {
    "objectID": "docs/about_73/04_communicate.html",
    "href": "docs/about_73/04_communicate.html",
    "title": "Communication Channels",
    "section": "",
    "text": "Question BoxQuestion Box (Responses)Poll Everywhere\n\n\n\nLoading…\n\n\n\nAsk me a question first!\n\nWeek 3Week 1\n\n\n\n\n\n\n\n\nQuestion 1 Is there a way to enable email notifications for reviewer’s comments for every folder on ReviewNB?\n\n\nResponse Thank you for the question. Email notifications can only be enabled for individual notebooks by using the button in the notebook within ReviewNB (sample shown below).  I don’t think notifications can be enabled for folders because Git only works with individual files.\n\n\n\n\n\n\n\n\n\n\n\nQuestion 1 is jupyter notebook for us to take note and submit exercises?\n\n\nResponse\n\nYes, you can use Jupyter Notebooks for taking notes and documenting your learning. Additionally, we will be using it to interact with Python in an interactive manner, akin to a question-and-answer format.\nThis approach differs from the ‘traditional’ method of running Python scripts in a terminal. Jupyter Notebooks allow for a more dynamic and engaging way to run Python code and observe the results within the notebook.\n\n\n\n\n\n\n\n\n\n\nQuestion 2 what’s the diff between $\\frac{}{}$ and $\\dfrac{}{}$\n\n\nResponse The version with a d is bigger and suitable for a standalone equation blocks while the other (\\frac{}{}) is smaller and suitable for inline use. Or, we can just use it to see the difference: \\(\\frac{a}{b}\\) vs \\(\\dfrac{a}{b}\\)\n\n\n\n\n\n\n\n\n\nQuestion 3 I would like to check if the files that we worked on in Jupyter during the lecture will be what we should submit for grading? Additionally, when I was following along in class, I’ve sent commit messages saying I completed a notebook (Completed using jupyter (need) for example). Will that be taken as my work being ready for grading? If so, I wasn’t aware and still wish to refine my work further if possible.\n\n\nResponse Thank you for the questions.\n\nYes, you can submit those files we worked on during the lectures into your Learning Portfolio. As you have indicated, it is best to run through again and touch up things before submitting.\nPlease note that you should use READY FOR REVIEW for all future submissions of your Learning Portfolio.\n\n\n\n\n\n\n\n\n\n\nQuestion 4 I saw that the Using Jupyter (Need) page in the SP2273 website instructs us to create a new notebook called “using-jupyter_need,” but we worked on an existing file in the learning portfolio folder (using_jupyter_(need).ipynb) in class. I’m wondering which is the correct way to complete and submit my work? I also read the Assessment section which said that our task is to reproduce the content we learned about in our learning portfolio. For some of the sections in Using Jupyter (Need), there seem to be multiple sections like Lists and Equations with many different examples, as well as sections like 2.1 that do not seem to have reproducible examples. Are we supposed to reproduce the examples presented on the website or make our own unique examples (such as for links, images)? Is one example acceptable for the sections on the website that have multiple examples? Thank you!\n\n\nResponse Thank you for the excellent questions.\n\nYou must submit work for each unit using a Jupyter Notebook. Please use an unambiguous file name that clearly indicates the section you are working on.(The _need vs (need) is a typo, sorry).\nFor sections that do not contain reproducible examples, you are not obliged to recreate anything.\nThe primary purpose of the Learning Portfolio is for you to demonstrate/record your mastery of the various skills and knowledge we discuss. So, I do not mind if you develop your own examples as long as the use of the underlying concept is demonstrated.\nPlease note that you must work through all the examples if I provide more than one example.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJoin by Web using PollEv.com​/chammika\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/about_73/docs/acknowledgments_2023.html",
    "href": "docs/about_73/docs/acknowledgments_2023.html",
    "title": "SP2273 | Working on Interdisciplinary Science, Pythonically",
    "section": "",
    "text": "73 is based on an old SPS module called SP2171. Kelissa Goh, Darren Teo, Hillson Hung, Mingyi Chen (all from SPS batch 2019), and Yuan Zhe were heavily involved in re-inventing this old content into the first version of 73. The present version is also inspired by many ideas discussed in this process. So, I would like to take this opportunity to thank them.\nThe following individuals kindly helped proofread this version of the notes. I am thankful for their input.\nYuan Zhe, Bei Yi Yang, Darren Teo, Channe Chwa, Derek Ong, Hillson Hung, Genevieve Tang, Ang Siaw Wei, Bharath.\nGenevieve Tang and Linda Sellou were also instrumental in putting together some of the rubrics used for assessment, or which I am immensely grateful.\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/about_73/docs/schedule_table.html",
    "href": "docs/about_73/docs/schedule_table.html",
    "title": "SP2273 | Working on Interdisciplinary Science, Pythonically",
    "section": "",
    "text": "Week\n\n\nDate\n\n\nTopic\n\n\nDeadline?\n\n\n\n\nWeek 1\n\n\nWed, 17 Jan\n\n\nIntroduction & Setup\n\n\n\n\n\n\n\nFri, 19 Jan\n\n\nLearning Portfolio\n\n\n\n\n\n\nWeek 2\n\n\nWed, 24 Jan\n\n\n\n\n\n\n\n\nFri, 26 Jan\n\n\n\n\n\n\n\nWeek 3\n\n\nWed, 31 Jan\n\n\n\n\n\n\n\n\nFri, 02 Feb\n\n\n\n\n\n\n\nWeek 4\n\n\nWed, 07 Feb\n\n\n\n\n\n\n\n\nFri, 9 Feb\n\n\nNo session (Chinese New Year)\n\n\n\n\n\n\nWeek 5\n\n\nWed, 14 Feb\n\n\nLearning Portfolio\n\n\n\n\n\n\n\nFri, 16 Feb\n\n\n\nYes\n\n\n\n\nWeek 6\n\n\nWed, 21 Feb\n\n\n\n\n\n\n\n\nFri, 23 Feb\n\n\nPresentations by Instructors\n\n\nYes\n\n\n\n\nRecess\n\n\nWed, 28 Feb\n\n\nRest\n\n\n\n\n\n\n\nFri, 1 Mar\n\n\n\n\n\n\n\nWeek 7\n\n\nWed, 06 Mar\n\n\nApplications Challenge&Plan Mini Project\n\n\n\n\n\n\n\nFri, 8 Mar\n\n\n\n\n\n\n\nWeek 8\n\n\nWed, 13 Mar\n\n\n\n\n\n\n\n\nFri, 15 Mar\n\n\n\nYes\n\n\n\n\nWeek 9\n\n\nWed, 20 Mar\n\n\nImplement Mini Project\n\n\n\n\n\n\n\nFri, 22 Mar\n\n\n\nYes\n\n\n\n\nWeek 10\n\n\nWed, 27 Mar\n\n\n\n\n\n\n\n\nFri, 29 Mar\n\n\nNo session (Good Friday)\n\n\n\n\n\n\nWeek 11\n\n\nWed, 3 Apr\n\n\nGroup Presentations\n\n\n\n\n\n\n\nFri, 5 Apr\n\n\n\nYes\n\n\n\n\nWeek 12\n\n\nWed, 10 Apr\n\n\nNo session (Hari Raya Puasa)\n\n\n\n\n\n\n\nFri, 12 Apr\n\n\nIndividual Viva\n\n\n\n\n\n\nWeek 13\n\n\nWed, 17 Apr\n\n\n\n\n\n\n\n\nFri, 19 Apr\n\n\n\n\n\n\n\nReading\n\n\nMon, 22 Apr\n\n\n\n\nYes\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/about_73/03_schedule.html",
    "href": "docs/about_73/03_schedule.html",
    "title": "Schedule, Deadlines & Workflow",
    "section": "",
    "text": "Python Clinic By SPS Mentors\n\n\n\n\n\n\n\nScheduleDeadlinesWorkflow\n\n\n\n\n\nWeek\n\n\nDate\n\n\nTopic\n\n\nDeadline?\n\n\n\n\nWeek 1\n\n\nWed, 17 Jan\n\n\nIntroduction & Setup\n\n\n\n\n\n\n\nFri, 19 Jan\n\n\nLearning Portfolio\n\n\n\n\n\n\nWeek 2\n\n\nWed, 24 Jan\n\n\n\n\n\n\n\n\nFri, 26 Jan\n\n\n\n\n\n\n\nWeek 3\n\n\nWed, 31 Jan\n\n\n\n\n\n\n\n\nFri, 02 Feb\n\n\n\n\n\n\n\nWeek 4\n\n\nWed, 07 Feb\n\n\n\n\n\n\n\n\nFri, 9 Feb\n\n\nNo session (Chinese New Year)\n\n\n\n\n\n\nWeek 5\n\n\nWed, 14 Feb\n\n\nLearning Portfolio\n\n\n\n\n\n\n\nFri, 16 Feb\n\n\n\nYes\n\n\n\n\nWeek 6\n\n\nWed, 21 Feb\n\n\n\n\n\n\n\n\nFri, 23 Feb\n\n\nPresentations by Instructors\n\n\nYes\n\n\n\n\nRecess\n\n\nWed, 28 Feb\n\n\nRest\n\n\n\n\n\n\n\nFri, 1 Mar\n\n\n\n\n\n\n\nWeek 7\n\n\nWed, 06 Mar\n\n\nApplications Challenge&Plan Mini Project\n\n\n\n\n\n\n\nFri, 8 Mar\n\n\n\n\n\n\n\nWeek 8\n\n\nWed, 13 Mar\n\n\n\n\n\n\n\n\nFri, 15 Mar\n\n\n\nYes\n\n\n\n\nWeek 9\n\n\nWed, 20 Mar\n\n\nImplement Mini Project\n\n\n\n\n\n\n\nFri, 22 Mar\n\n\n\nYes\n\n\n\n\nWeek 10\n\n\nWed, 27 Mar\n\n\n\n\n\n\n\n\nFri, 29 Mar\n\n\nNo session (Good Friday)\n\n\n\n\n\n\nWeek 11\n\n\nWed, 3 Apr\n\n\nGroup Presentations\n\n\n\n\n\n\n\nFri, 5 Apr\n\n\n\nYes\n\n\n\n\nWeek 12\n\n\nWed, 10 Apr\n\n\nNo session (Hari Raya Puasa)\n\n\n\n\n\n\n\nFri, 12 Apr\n\n\nIndividual Viva\n\n\n\n\n\n\nWeek 13\n\n\nWed, 17 Apr\n\n\n\n\n\n\n\n\nFri, 19 Apr\n\n\n\n\n\n\n\nReading\n\n\nMon, 22 Apr\n\n\n\n\nYes\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n#\nComponent\nType\nAction\nDeadline\nWeek\nWhere\n\n\n\n\n1\nMini Project\nGroup\nDeclare group members.\n6 PM Fri, 16 Feb\nWeek 5\nUse this Google Sheet.\n\n\n2\nLearning Potfolio\nIndividual\nComplete Learning Portfolio\n6 PM Fri, 23 Feb\nWeek 6\nGitHub (Individual Repository)\n\n\n3\nApplications Challenge\nIndividual\nSubmit Jupyter notebook\n6 PM Fri, 15 Mar\nWeek 8\nGitHub (Group Repository)\n\n\n4\nGroup Presentation\nGroup\nReserve a time slot\n6 PM Fri, 22 Mar\nWeek 9\nUse this Google Sheet.\n\n\n5\nIndividual Viva\nIndividual\nReserve a time slot\n6 PM Fri, 22 Mar\nWeek 9\nUse this Google Sheet.\n\n\n6\nGroup Presentation\nGroup\nSubmit Jupyter notebook\n6 PM Mon, 1 Apr\nWeek 11\nGitHub (Group Repository)\n\n\n7\nGroup Presentation\nGroup\nSubmit Presentation Slides\n6 PM Mon, 1 Apr\nWeek 11\nUse this Google Sheet.\n\n\n8\nTEAMMATES\nIndividual\nSubmit feedback your teammates\n6 PM Mon, 22 Apr\nReading\nTEAMMATES\n\n\n\nSome things to note:\n\nThere are ‘many moving parts’ in 73. To ensure smooth coordination, adherence to deadlines is vital. Therefore, late submissions will incur a 10% penalty per task, increasing to 50% beyond 12 hours.\nDeadlines fall on Fridays, except for Weeks 10 and 13. I have also set the time at 6 pm because I do not want you to work into the wee hours of the night on account of 73; sleep and rest are essential.\n\n\n\n\n\n\nWhen\n\n\nWhat to Do\n\n\nType\n\n\nNote\n\n\nMore Info\n\n\n\n\nWeek1\n\n\nSet up software.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek1 - 6\n\n\nWork on the individual Learning Portfolio.\n\n\nIndividual\n\n\nMust submit for feedback and address any concerns the reviewer raises.\n\n\nLink\n\n\n\n\nWork on end-of-lesson exercises during tutorials.\n\n\nIndividual\n\n\nMust submit for feedback and address any concerns the reviewer raises.\n\n\nLink\n\n\n\n\nLook out for potential group members.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek5\n\n\nDeclare group members.\n\n\nGroup\n\n\nUse this form.\n\n\nLink\n\n\n\n\nWeek6, Friday\n\n\nAttend lecture to see examples of presentations.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek7, 8\n\n\nWork on Application Problem.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nStart planning your mini-project.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nImplement your mini-project.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nWeek11\n\n\nPresentations.\n\n\nGroup\n\n\nUse this form to pick a slot.\n\n\nLink\n\n\n\n\nWeek12, 13\n\n\nIndividual Viva.\n\n\nIndividual\n\n\nUse this form to pick a slot.\n\n\nLink\n\n\n\n\nSubmit TEAMMATES.\n\n\nIndividual\n\n\nEmail will be sent to you.\n\n\nLink\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Schedule, Deadlines & Workflow"
    ]
  },
  {
    "objectID": "docs/about_73/some_results/05_some-results.html",
    "href": "docs/about_73/some_results/05_some-results.html",
    "title": "Some Results",
    "section": "",
    "text": "What to expect on this page\nThis semester, you participated in several surveys (Beginning of Semester in Week 1, Mid-Semester in Week 6), a non-grade bearing Readiness Test, and many assessments. Allow me to share some results and statistics related to these so that you can appreciate how diverse our class is and how you have progressed. Of the assessments, I only have the scores for the Learning Portfolio and Applications Challenge ready, so we will have to do with those.\n\n\n1 Beginning of Semester Questionnaire (Week 1)\n\nComputational CompetencyMajorPronounSPS?\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n2 Mid Semester Questionnaire (Week 6)\n\nComputational Competency\n\n\nI am pleased to see that everyone seems to be progressing (upwards) in their perceived level of computational competency.\n\n\n\n\n\n\n3 Readiness Test (Week 7)\nFor the following, I used the Computational Competencies declared at the beginning of the semester to categorise the scores.\nInterestingly, notice how there is a spread of abilities amongst the ‘novices’, which I would have expected from the ‘beginners’.\n\n\n\n4 Assessments Distributions\n\nLearning PortfolioApplication Challenge\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Some Results"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_viva.html",
    "href": "docs/about_73/assessment/assessment_viva.html",
    "title": "Viva (35%)",
    "section": "",
    "text": "Quick Summary\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nWeight\nWhen\nDeliverable\n\n\n\n\nIndividaul\n35%\nWeeks 12 & 13\n• 30 min interview with the examnination panel.• Pick a viva slot.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Viva (35%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_viva.html#what-is-a-viva-voce-examination",
    "href": "docs/about_73/assessment/assessment_viva.html#what-is-a-viva-voce-examination",
    "title": "Viva (35%)",
    "section": "1.1 What is a Viva-Voce examination?",
    "text": "1.1 What is a Viva-Voce examination?\nThe Viva-Voce, or viva, replaces a traditional final exam. A Viva-voce (Latin for ‘with the living voice’) is a more interactive, engaging form of assessment. Vivas are often reserved for higher levels of study and are more demanding in terms of academic manpower. However, vivas are an essential feature of assessments in SPS.\nViva-voce examinations present a different approach to assessing student learning than written examinations, as examiners can directly interact with students and clarify and evaluate students’ understanding and skills at a much deeper level. Beyond conceptual understanding, these examinations can also assess soft skills such as problem-solving and scientific communication, where students can be prompted to elaborate on or defend their ideas(Sayre 2014; Markulis and Strang 2008). In that sense, viva examinations have the potential to serve as both an assessment for and an assessment of learning(Iannone and Simpson 2015).",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Viva (35%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_viva.html#objectives-of-the-73-viva-voce",
    "href": "docs/about_73/assessment/assessment_viva.html#objectives-of-the-73-viva-voce",
    "title": "Viva (35%)",
    "section": "1.2 Objectives of the 73 Viva-Voce",
    "text": "1.2 Objectives of the 73 Viva-Voce\nBy the end of the semester, you will have acquired and practiced many skills. These include technical skills (e.g., Python, Git, Jupyter), science and problem-solving skills (e.g., computational thinking, Applications Challenge, Mini Project), and communication skills (e.g., presentations).\nThe 73 Individual Viva-Voce assesses your mastery of the course content, focusing on the Group Mini Project and the Applications Challenge. It evaluates your ability to apply your acquired knowledge and skills to problem-solving. The assessment goes beyond simple knowledge recall, requiring you to demonstrate deeper comprehension by adapting and expanding your code and justifying your choices based on the material learned in the first half of the semester.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Viva (35%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_viva.html#what-will-you-gain-from-the-viva",
    "href": "docs/about_73/assessment/assessment_viva.html#what-will-you-gain-from-the-viva",
    "title": "Viva (35%)",
    "section": "1.3 What will you gain from the Viva",
    "text": "1.3 What will you gain from the Viva\n\nTwo-way Assessment Platform: The viva, being a discussion between the student and the examination panel, offers numerous opportunities for real-time clarification and immediate feedback. You can explain, defend, and justify your strategies more clearly than in other examination methods.\nMimics Interview Scenarios: The viva is excellent practice for job interviews, providing an interactive examination environment with face-to-face communication. This experience will enhance your critical thinking and also develop communication skills. It will prompt you to craft thoughtful and coherent responses.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Viva (35%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_viva.html#what-to-expect",
    "href": "docs/about_73/assessment/assessment_viva.html#what-to-expect",
    "title": "Viva (35%)",
    "section": "1.4 What to expect",
    "text": "1.4 What to expect\nHere are some of the types of questions that may be asked:\n\nWhat is the significance of line 10 of your code?\nWhy did you use a for loop instead of a while loop?\nCan you change your function so that one of the arguments is optional?\nCan you use your strategy to solve a similar equation like…?\nWhat is the scientific rationale for that line of code?",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Viva (35%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_viva.html#other-matters",
    "href": "docs/about_73/assessment/assessment_viva.html#other-matters",
    "title": "Viva (35%)",
    "section": "1.5 Other matters",
    "text": "1.5 Other matters\n\nAll the viva sessions will be recorded for grading purposes.\nYou can use any reasonable resource you like during the viva. However, you cannot message your friends or use a service like ChatGPT (because your friends or chatGPT are not being examined, dah!).\nYou can bring anything (books, notes, laptop…) you like.\nYou do not have to bring a copy of your Jupyter Notebook; we will have your submitted one ready.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Viva (35%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_viva.html#designing-this-assessment",
    "href": "docs/about_73/assessment/assessment_viva.html#designing-this-assessment",
    "title": "Viva (35%)",
    "section": "1.6 Designing this assessment",
    "text": "1.6 Designing this assessment\nWith a mark allocation of 35%, the Individual Viva is the weightiest assessment component in 73. Due to this importance, I asked the help of the dynamic duo of Kellie Wong and Kelissa Goh, under the supervision of Linda Sellou, to conduct a study on Viva-voce assessments. The main intention of this study was to gather information to create an environment that is friendly, inclusive, fair, and conducive to your learning. In addition to a thorough literature survey, Kellie and Kelissa conducted focus group discussions with SPS mentors to hear their thoughts and experiences taking and grading viva assessments. The findings of this study have informed the instructions (to you and the examiners), the workflow, and the rubric you see below.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Viva (35%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_overview.html",
    "href": "docs/about_73/assessment/assessment_overview.html",
    "title": "Assessments Overview",
    "section": "",
    "text": "73 offers a balanced mix of individual (60%) and group (40%) assessment components designed to cultivate a broad range of skills that go beyond just Python proficiency. These components encourage the development of computational thinking, the application of technical knowledge to scientific problem-solving, and technical abilities in Python, Git, and Jupyter. They also focus on fostering collaborative, presentation, and communication skills essential in your future journey.\nHere is a quick summary of the various components. You can find more details(e.g., what to do, benefits, rubrics) of each component on their dedicated pages.\n\n\n\n\nType\nWeight(%)\n\n\n\n\nIndividual\n60%\n\n\nGroup\n40%\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nComponent\nRecipient\nWeight\nWhen\nDue\n\n\n\n\nLearning Portfolio\nIndividual\n20%\nWeeks 1 - 6\nWeek 6\n\n\nApplication Challenge\nGroup\n15%\nWeeks 7, 8\nWeek 8\n\n\nMini Project\nGroup\n25%\nWeeks 7 - 10\nWeek 11\n\n\nViva-voce (30 minutes)\nIndividual\n35%\n\nWeek 12, 13\n\n\nGroup Peer Feedback\nIndividual\n5%\n\nMonday Reading Week\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Assessments Overview"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/main-grading-first.html",
    "href": "docs/about_73/assessment/main-grading-first.html",
    "title": "SP2273 | Working on Interdisciplinary Science, Pythonically",
    "section": "",
    "text": "Graders… before proceeding\n\n\n\nIf you have not done so, please refer to the general grading instructions first.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/about_73/assessment/assessment_mini-project.html",
    "href": "docs/about_73/assessment/assessment_mini-project.html",
    "title": "Mini Project (25%)",
    "section": "",
    "text": "Quick Summary\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nWeight\nWhen\nDeliverable\n\n\n\n\nGroup\n25%\nPlanning: Weeks 7,8Implementation: Weeks 9, 10\n• 20 min group presentation in Week 11 (Slides must be submitted).• An Jupyter notebook containing the accompanying Python code.• Submit both to CANVAS.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Mini Project (25%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_mini-project.html#what-is-the-group-mini-project-about",
    "href": "docs/about_73/assessment/assessment_mini-project.html#what-is-the-group-mini-project-about",
    "title": "Mini Project (25%)",
    "section": "1.1 What is the Group Mini Project about?",
    "text": "1.1 What is the Group Mini Project about?\nIn the real world, computational tools are integral for learning, understanding, and applying scientific principles. The Group Mini Project aims to demonstrate how computers, specifically Python, can be utilised for these purposes. Your task is to select a scientific topic that interests you and your group members. You must then create a presentation to communicate this topic to your classmates. However, the presentation must incorporate computational tools (such as plotting, modelling, simulations, animations, etc.) developed using Python. The presentation will contribute 15% to your overall grade, while the Python code will account for 10%. Please note that the Python code should be prepared and submitted separately in a Jupyter Notebook format.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Mini Project (25%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_mini-project.html#objective-of-the-group-mini-project",
    "href": "docs/about_73/assessment/assessment_mini-project.html#objective-of-the-group-mini-project",
    "title": "Mini Project (25%)",
    "section": "1.2 Objective of the Group Mini Project",
    "text": "1.2 Objective of the Group Mini Project\nTo clarify, the objectives are as follows:\n\nShare the science with a 20 minute presentation (15%) Your presentation should be designed to educate your classmates, who may not be specialists, about the basics of your chosen topic. Explaining the fundamental scientific concepts related to the topic and articulating why it is significant and worth learning is crucial. Additionally, you should highlight how and when Python was utilised in your presentation without sharing the actual code.\nShare the code in a Jupyter Notebook (10%) The content of your presentations must be developed in your shared GitHub repository using Python in a separate Jupyter Notebook. Your code must be well-documented and accessible to your classmates in terms of understanding. It would help if you also emphasised how programming, specifically Python, enhances the appreciation and understanding of the topic.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Mini Project (25%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_mini-project.html#why-is-the-group-mini-project-good-for-you",
    "href": "docs/about_73/assessment/assessment_mini-project.html#why-is-the-group-mini-project-good-for-you",
    "title": "Mini Project (25%)",
    "section": "1.3 Why is the Group Mini Project good for you",
    "text": "1.3 Why is the Group Mini Project good for you\nThe Group Mini Project is authentic in that it mirrors how computational tools are used in real life. By choosing a topic that interests you, you are deepening your understanding of the subject and honing your skills in gathering, analysing, and synthesising information. This project will also enhance your critical thinking skills by identifying and solving problems related to your chosen topic. Additionally, your freedom in this project allows for innovative uses of Python, such as simulations, animations, and data visualisation. These activities will encourage a deeper level of analytical thinking as you develop and explain your code.\nIn presenting these ideas to an audience, you will develop public speaking skills and the ability to convey technical information clearly and accessibly. This skill is essential in the scientific community, as effective communication is key to making your work valuable and accessible. It will also help you make a name for yourself.\nFinally, working and collaborating in a team setting will foster effective communication, task delegation, and collective goal achievement. These are crucial skills in any teamwork environment, further preparing you for the adventures beyond the University.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Mini Project (25%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_mini-project.html#important-considerations",
    "href": "docs/about_73/assessment/assessment_mini-project.html#important-considerations",
    "title": "Mini Project (25%)",
    "section": "1.4 Important considerations",
    "text": "1.4 Important considerations\n\nManage Expectations: You will have approximately two weeks to plan the mini project, followed by another two weeks for implementation. This timeframe is relatively short, so it is crucial to set realistic goals. Try not to overextend yourselves by taking on too much. Focus on achievable objectives that allow you to effectively demonstrate your understanding and skills within the given period. Please use the rubrics often to make sure you are on track.\nRemember that the Group Mini Project will also impact the Individual viva (see below).\nRemember the viva: The final Individual Viva will focus on the content of the Group Mini Project. Ensure everyone in the group is up to speed with the science and the coding presented in the Mini Project. Put another way, don’t make your project so complicated that one or more of you will struggle to the extent that you will not know enough to participate in the viva.\nExample Presentations: To give you a clearer idea of the type of projects and presentations expected, the instructors will deliver three sample presentations at the end of week 6. These presentations will serve as references for your project’s scope, depth, and presentation style. Please ensure you attend this session.\nSeeking Assistance: Don’t hesitate to ask for help. If you encounter challenges, whether they’re related to Python, the scientific content, or the presentation aspect, the instructors and teaching assistants are here to support you.\nCollaboration and Communication: Collaboration is key in this project. Regular communication within your group is essential. Plan your roles, set deadlines, and update each other on your progress. Effective teamwork can significantly enhance the quality of your project.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Mini Project (25%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/transparency.html",
    "href": "docs/about_73/assessment/transparency.html",
    "title": "SP2273 | Working on Interdisciplinary Science, Pythonically",
    "section": "",
    "text": "In the name of transparency\n\n\n\nIn the interest of complete transparency, I have made the grading instructions available to everyone. I hope this information about the behind-the-scenes workings will help to provide a clear understanding of our assessment process.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good_exercises.html",
    "href": "docs/python_basics/05_functions/2_functions_good_exercises.html",
    "title": "Functions (Good) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (Celsius to Fahrenheit or Kelvin) ☻\n\nDevelop a function named convert_celsius() to convert temperatures from Celsius to either Fahrenheit or Kelvin.\nThe function should take two arguments:\n\ntemperature_celsius: The temperature in Celsius.\ntarget_scale (string): The target scale for conversion, with the default value set to 'Fahrenheit'.\n\nThe function should return the temperature in Kelvin if target_scale is 'Kelvin'; otherwise, it should return the temperature in Fahrenheit.\n\n\n\nExercise 2 (Fahrenheit to Celsius or Kelvin) ☻\n\nDevelop a function called convert_fahrenheit() for converting temperatures from Fahrenheit to either Celsius or Kelvin.\nThe function should take two arguments:\n\ntemperature_fahrenheit: The temperature in Fahrenheit.\ntarget_scale (string): The target scale for conversion, defaulting to 'Celsius'.\n\nThe function should return the temperature in Kelvin if target_scale is 'Kelvin'; otherwise, return it in Celsius.\n\n\n\nExercise 3 (General Temperature Conversion) ☻\n\nImplement a function named convert_temperature() to perform general temperature conversions.\nThe function should take three arguments:\n\ntemperature: The temperature to be converted.\nsource_scale (string): The scale of the input temperature (either 'Celsius', 'Fahrenheit', or 'Kelvin').\ntarget_scale (string): The desired scale for the output temperature.\n\nRemember to reuse your previous functions!\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/1_functions_need.html",
    "href": "docs/python_basics/05_functions/1_functions_need.html",
    "title": "Functions (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/1_functions_need.html#named-functions",
    "href": "docs/python_basics/05_functions/1_functions_need.html#named-functions",
    "title": "Functions (Need)",
    "section": "1.1 Named Functions",
    "text": "1.1 Named Functions\n\nNamed functions that return\nWe define the function by using the keyword def as follows:\n\ndef greeting(name):\n    if name == 'Batman':\n        return 'Hello Batman! So, nice to meet you!'\n    else:\n        return f'Hello {name}!'\n\nThe function’s name is greeting and it accepts a single argument called name. We can then use the function as:\ngreeting(\"Super Man\")\nor\ngreeting(name=\"Super Man\")\nAs with all structures in Python, notice the keyword def, the colon (:) and the indentation that demarcates the function’s code block. Notice also that I have used the keyword return to get an output from the function. When Python sees a return keyword it jumps out of the function with the return value. You can pick up the returned value by assigning it to a variable or even use it directly like:\ngreet=greeting(name='Super Man')\nprint(greet)\nor this works too:\nprint(greeting(name='Super Man'))\nIncidentally, you can use return only within a function.\nI also like to point out that you can return almost anything! Here is an example of a function that accepts a list and returns the maximum, minimum and mean.\n\ndef basic_stats(numbers):\n    np_numbers = np.array(numbers)\n    my_min = np_numbers.min()\n    my_max = np_numbers.max()\n    my_mean = np_numbers.mean()\n    return my_max, my_min, my_mean\n\nHere is how you can use it:\nlist_min, list_max, list_mean = basic_stats([1, 2, 3, 4, 5])\n\n\nNamed functions that don’t return\nA function does not have to return anything. A good example is print(), which does something but does not return a value. You will often also need functions like these, for instance, to save data to a file. I will show you a few of such functions in later chapters.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/1_functions_need.html#anonymous-functions",
    "href": "docs/python_basics/05_functions/1_functions_need.html#anonymous-functions",
    "title": "Functions (Need)",
    "section": "1.2 Anonymous functions",
    "text": "1.2 Anonymous functions\nAnonymous or lambda functions are suitable for short one-liners. Let me show you two examples.\n\n\n\nThis function accepts a single argument called name.\nmy_short_function = lambda name: f\"Hello {name}!\"\nWe can use it like\nmy_short_function(name=\"Super Man\")\nA lambda function always returns the value of the last statement.\n\n\nThe above example is not a very good ‘anonymous’ one because I have used a name! So let me show you another one where things are really anonymous.\nLet’s say I want to sort the following 2D list.\n\nnumbers=[[9, 0, -10],\n         [8, 1, -11],\n         [7, 2, -12],\n         [6, 3, -13],\n         [5, 4, -14],\n         [4, 5, -15],\n         [3, 6, -16],\n         [2, 7, -17],\n         [1, 8, -18],\n         [0, 9, -19]]\n\nI can use the sorted() function for this. Here are three ways I can use it.\n\n\n\n\n\n\n# Sort by comparing the default key\n# (i.e., the 1st element)\nsorted(numbers)\n\n\n[[0, 9, -19]\n [1, 8, -18]\n [2, 7, -17]\n [3, 6, -16]\n [4, 5, -15]\n [5, 4, -14]\n [6, 3, -13]\n [7, 2, -12]\n [8, 1, -11]\n [9, 0, -10]]\n\n\nNotice that this sorting is based on comparing the first elements of the sub-lists.\n\n\n# Sort by comparing a custom key\n# that uses the 2nd element (index=1)\nsorted(numbers, key=lambda x: x[1])\n\n\n[[9, 0, -10]\n [8, 1, -11]\n [7, 2, -12]\n [6, 3, -13]\n [5, 4, -14]\n [4, 5, -15]\n [3, 6, -16]\n [2, 7, -17]\n [1, 8, -18]\n [0, 9, -19]]\n\n\nIf I want to use some other criteria, then I need to specify a key that sorted() can be used for comparison. As you can see, I have used a lambda function for this.\n\n\n# Sort by comparing a custom key\n# that uses the sum of the elements.\nsorted(numbers, key=lambda x: sum(x))   \n\n\n[[0, 9, -19]\n [1, 8, -18]\n [2, 7, -17]\n [3, 6, -16]\n [4, 5, -15]\n [5, 4, -14]\n [6, 3, -13]\n [7, 2, -12]\n [8, 1, -11]\n [9, 0, -10]]\n\n\nThis is really powerful as I can specify almost any criterion I like. For example, I can sort according to the sum of the elements of the sub-lists.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/1_functions_need.html#optional-arguments",
    "href": "docs/python_basics/05_functions/1_functions_need.html#optional-arguments",
    "title": "Functions (Need)",
    "section": "1.3 Optional arguments",
    "text": "1.3 Optional arguments\nPython allows us to make arguments to our function optional. To do this, we need to give the argument a default value so that it always has something to work with.\n\ndef greeting(name='no one'):\n    if name == 'Batman':\n        return 'Hello Batman! So, nice to meet you!'\n    else:\n        return f'Hello {name}!'\n\nNow we can run this function without an argument, and it will still work without throwing an error.\n\ngreeting()\n\n'Hello no one!'\n\n\nFor another example, let’s look at the documentation for print().\n?print\n    Docstring:\n    print(value, ..., sep=' ', end='\\n', file=sys.stdout, flush=False)\n\n    Prints the values to a stream, or to sys.stdout by default.\n    Optional keyword arguments:\n    file:  a file-like object (stream); defaults to the current sys.stdout.\n    sep:   string inserted between values, default a space.\n    end:   string appended after the last value, default a newline.\n    flush: whether to forcibly flush the stream.\n    Type:      builtin_function_or_method\nYou see that print() can accept other arguments that are optional with default values. However, we can specify them if we like; here goes.\n# Using default values\nprint('I', 'am', 'Batman!')\n# Specifying an optional argument\nprint('I', 'am', 'Batman!', sep='---')  \n\n\n\n\nI am Batman!\n\n\n\n\nI---am---Batman!\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember:\n\nyou can define your own functions,\nfunctions can have optional arguments,\nfunctions don’t always have to return anything.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/1_functions_need.html#the-importance-of-functions",
    "href": "docs/python_basics/05_functions/1_functions_need.html#the-importance-of-functions",
    "title": "Functions (Need)",
    "section": "1.4 The importance of functions?",
    "text": "1.4 The importance of functions?\n\nAn argument for functions\nNow that you know a bit about creating functions, let me highlight why functions are a good idea.\nAbstraction of details The most important benefit of functions goes beyond programming and relates to your ability to strategize. If you break up a complicated solution into modular chunks (i.e., functions), it becomes easier to think about it because you are not dealing with all the details all at once. As a result, it is easier to focus on your overall solution because you are not distracted by unnecessary information. This hiding of ‘stuff’ is called abstraction in computer science lingo. The concept of abstraction can be tricky to grasp. So, let me share an analogy related to driving.\nA vehicle has many ‘abstracted’ systems, amongst which the engine is a good example. You do not need to know the engine’s details (e.g. electric, petrol, diesel, guineapig) to use it. You can use the engine of almost any car because you are not required to know what happens inside. This frees up your resources because you are not distracted by unnecessary details. Of course, there will be times when you want to know how an engine works to pick the best engine.\nReusability of code If you encapsulate a chunk of code in a function, it becomes straightforward to reuse it instead of copying and pasting at different places. This means your code will be shorter and more compact.\nMaintainability of code With functions, your code is easier to change and maintain because you need only make changes in one place, at the function definition.\n\n\nA word of caution\nI have seen many instances where functions are abused; for example, by trying to do too many things or having too many arguments. They can also be overused. Having too many functions can make it difficult to read your code and also increase computational overheads. You will get a better feel for when to use functions with experience, but please bear in mind that functions can be misused.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/3_functions_nice.html",
    "href": "docs/python_basics/05_functions/3_functions_nice.html",
    "title": "Functions (Nice)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/3_functions_nice.html#args-kwarg",
    "href": "docs/python_basics/05_functions/3_functions_nice.html#args-kwarg",
    "title": "Functions (Nice)",
    "section": "2.1 *args & **kwarg",
    "text": "2.1 *args & **kwarg\nYou will often see the syntax *args and **kwarg. These stand for arguments and keyword arguments, respectively. They allow us flexible ways of using unpacking and dictionaries to pass information to functions. Let’s see how to do this.\n\n*args\n\n\n\ndef multiply(x, y):\n    return x * y\n\nnumbers = [1, 2]\nmultiply(*numbers)\n\n\n\nWe can use unpacking to make passing arguments to functions a breeze!\nThe * is essential! Without this, Python will assign x=numbers and complain that y is missing.\n\n\n\n2\n\n\n\n\n\n\ndef multiply(*args):\n    result = 1\n    for number in args:\n        result *= number\n\n    return result\n\nnumbers = [1, 2, 3]\nmultiply(*numbers)\nmultiply(1, 2, 3, 4, 5)\n\n\n\nWhat if we want our function to multiply more than two numbers?\n\n\n\n\n6\n\n\nThis will work, too!\n\n\n120\n\n\n\n\n\n\n\n\n\n\n**kwargs\n\n\n\ndef multiply(x, y, z):\n    return x * y * z\n\n# Let's use the function\nnumbers = {'x': 1, 'y': 2, 'z': 3}\nmultiply(**numbers)\n\n\n\nWe can also pass keyword arguments using a dictionary:\nThe ** is essential!\n\n\n\n6\n\n\n\n\n\n\ndef multiply(x, y, z):\n    return x * y * z\n\n# Let's use the function\nnumbers = {'y': 2, 'z': 3}\nmultiply(1, **numbers)\n\n\n\nWe can mix positional arguments and a dictionary!\n\n\n\n6\n\n\n\n\n\n\ndef add_powers(numbers, power):\n    result = 0\n    for number in numbers:\n        result += number**power\n\n    return result\n\n# Let's use the function\nkwargs = {'numbers': [1, 2, 3], 'power': 2}\nadd_powers(**kwargs)\n\n\n\n\n\n\n\n14\n\n\n\n\n\n\ndef add_powers(**kwargs):\n    numbers = kwargs['numbers']\n    power = kwargs['power']\n\n    result = 0\n    for number in numbers:\n        result += number**power\n\n    return result\n\n\n# Let's use the function\nadd_powers(numbers=[1, 2, 3], power=2)\nkwargs = {'numbers': [1, 2, 3], 'power': 2}\nadd_powers(**kwargs)\n\n\n\nWe can also set up our function to accept any keyword arguments!\n\n\n\n\n14\n\n\nThis works too!\n\n\n14",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/3_functions_nice.html#the-problem",
    "href": "docs/python_basics/05_functions/3_functions_nice.html#the-problem",
    "title": "Functions (Nice)",
    "section": "3.1 The Problem",
    "text": "3.1 The Problem\nUsing functions to modularise your code (and your thinking) is good. However, you need to be careful with the type of variables that you pass as arguments. To see what I am talking about, try running the following code. Can you see what is happening?\n\ndef do_something(inside_number, inside_array, inside_list):\n    print('Doing something!')\n    inside_number *= 2\n    inside_array *= 2\n    inside_list *= 2\n\n    print(f\"INSIDE|\\tNumber: {inside_number}(id: {id(inside_number)}), Array: {inside_array}(id: {id(inside_array)}), List: {inside_list}(id: {id(inside_list)})\")\n\noutside_number = 10\noutside_array = np.array([10])\noutside_list = [10]\n\nprint(f\"BEFORE|\\tNumber: {outside_number}(id: {id(outside_number)}), Array: {outside_array}(id: {id(outside_array)}), List: {outside_list}(id: {id(outside_list)})\")\ndo_something(outside_number, outside_array, outside_list)\nprint(f\"AFTER|\\tNumber: {outside_number}(id: {id(outside_number)}), Array: {outside_array}(id: {id(outside_array)}), List: {outside_list}(id: {id(outside_list)})\")\n\n\n\nBEFORE| Number: 10(id: 139949048705000), Array: [10](id: 139947793568688), List: [10](id: 139947793716800)\n\n\nDoing something!\nINSIDE| Number: 20(id: 139949048705320), Array: [20](id: 139947793568688), List: [10, 10](id: 139947793716800)\n\n\nAFTER|  Number: 10(id: 139949048705000), Array: [20](id: 139947793568688), List: [10, 10](id: 139947793716800)\n\n\nSo, the function has changed the values of some variable outside the function! But, not all variables are affected.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/3_functions_nice.html#an-explanation",
    "href": "docs/python_basics/05_functions/3_functions_nice.html#an-explanation",
    "title": "Functions (Nice)",
    "section": "3.2 An Explanation",
    "text": "3.2 An Explanation\nFor ‘immutable’ variables, what happens inside the function does not change the variable outside. In other languages, this behaviour is called passing by value.\nFor ‘mutable’ variables, what happens inside the function does change the variable outside. In other languages, this behaviour is called passing by reference.\nSo, in Python, you must be very careful about the mutability of the variable you are passing. Otherwise, you will spend a long time trying to understand why your code is acting weird.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/3_functions_nice.html#a-list-of-exceptions",
    "href": "docs/python_basics/05_functions/3_functions_nice.html#a-list-of-exceptions",
    "title": "Functions (Nice)",
    "section": "4.1 A list of exceptions",
    "text": "4.1 A list of exceptions\nHere is an incomplete list of exceptions2. You can find more details at the Python documentation pages.\n\n\n\n\n\n\n\n\nException\nDescription\n\n\n\n\nAssertionError\nRaised when the assert statement fails.\n\n\nAttributeError\nRaised on the attribute assignment or reference fails.\n\n\nEOFError\nRaised when the input() function hits the end-of-file condition.\n\n\nFloatingPointError\nRaised when a floating point operation fails.\n\n\nImportError\nRaised when the imported module is not found.\n\n\nIndexError\nRaised when the index of a sequence is out of range.\n\n\nKeyError\nRaised when a key is not found in a dictionary.\n\n\nNameError\nRaised when a variable is not found in the local or global scope.\n\n\nOSError\nRaised when a system operation causes a system-related error.\n\n\nOverflowError\nRaised when the result of an arithmetic operation is too large to be represented.\n\n\nRuntimeError\nRaised when an error does not fall under any other category.\n\n\nSyntaxError\nRaised by the parser when a syntax error is encountered.\n\n\nIndentationError\nRaised when there is an incorrect indentation.\n\n\nSystemError\nRaised when the interpreter detects internal error.\n\n\nSystemExit\nRaised by the sys.exit() function.\n\n\nTypeError\nRaised when a function or operation is applied to an object of an incorrect type.\n\n\nUnboundLocalError\nRaised when a reference is made to a local variable in a function or method, but no value has been bound to that variable.\n\n\nValueError\nRaised when a function gets an argument of correct type but improper value.\n\n\nZeroDivisionError\nRaised when the second operand of a division or module operation is zero.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/3_functions_nice.html#handling-specific-exceptions",
    "href": "docs/python_basics/05_functions/3_functions_nice.html#handling-specific-exceptions",
    "title": "Functions (Nice)",
    "section": "4.2 Handling specific exceptions",
    "text": "4.2 Handling specific exceptions\nI was sloppy in my try-exept example in the last chapter. I could have been more specific about the type of exception. A better version of the code is:\ntry:\n    number=input(\"Give me a number and I will calculate its square.\")\n    square=int(number)**2\n    print(f'The square of {number} is {square}!')\nexcept ValueError:\n    print(f\"Oh oh! I cannot square {number}!\")",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/3_functions_nice.html#try-also-has-an-else",
    "href": "docs/python_basics/05_functions/3_functions_nice.html#try-also-has-an-else",
    "title": "Functions (Nice)",
    "section": "4.3 try also has an else",
    "text": "4.3 try also has an else\nThe try-except statement also has an optional else block that is run only if everything works smoothly. Here is an example:\ntry:\n    number=input(\"Give me a number and I will calculate its square.\")\n    square=int(number)**2\n    print(f'The square of {number} is {square}!')\nexcept ValueError:\n    print(f\"Oh oh! I cannot square {number}!\")\nelse:\n    print('Yeah! Things ran without a problem!')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/3_functions_nice.html#footnotes",
    "href": "docs/python_basics/05_functions/3_functions_nice.html#footnotes",
    "title": "Functions (Nice)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nand classes↩︎\nborrowed from here↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good_exercises.html",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good_exercises.html",
    "title": "Storing Data (Good) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (Total recall) ☻\nPurely from memory, write short descriptions of the following terms:\n\n\n\n\nTerm\nBrief description\n\n\n\n\nSubsetting\n\n\n\nIndexing\n\n\n\nSlicing\n\n\n\nMasking\n\n\n\n\n\nIf you cannot recall the answers, please refer to the notes and put this information you could not recall in italics.\n\n\nExercise 2 (Show me the ‘odd’ letters) ☻\nnp_array_2d = np.array([[1, \"A\"], [3, \"C\"], [2, \"B\"], [4, \"D\"],\n                        [5, \"E\"], [7, \"G\"], [6, \"F\"], [8, \"H\"],\n                        [10, \"J\"], [9, \"I\"]])\nUse masking to subset the letters that correspond to the odd numbers. I.e., get the result [A, C, E, G, I].\nThis is a slightly tricky problem because arrays are fussy about type. So, let me give you a recipe to solve this problem.\n\nSubset all the first elements.\n\nYou should get array(['1', '3', '2', ..., '10', '9'])\n\nConvert this to integers using astype(int)\n\nYou must look up how astype() works.\n\nUse % to get the remainder for division by 2.\n\nYou should get array([1, 1, 0, ..., 0, 1]).\n\nUse the previous result to create a mask that checks if the remainder is zero or not\n\nYou should get array([True, True, False, ..., False, True]).\nNow you have identified the locations of the odd numbers.\n\nUse the mask and extract the corresponding second elements.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need_exercises.html",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need_exercises.html",
    "title": "Storing Data (Need) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (Total recall?) ☻\nPurely from memory, jot down:\n\nTwo similarities between lists and arrays.\nTwo differences between lists and arrays.\nWhat is a dictionary?\n\nIf you cannot recall the answers, please refer to the course notes and put this information you could not recall in italics.\n\n\nExercise 2 (Indexing) ☻\nModify the following code to print out all elements with an odd number. I have done the one corresponding to i9 for you.\n\npy_list = [\"a1\", \"b2\", \"c3\", \"d4\", \"e5\", \"f6\", \"g7\", \"h8\", \"i9\", \"j10\"]\n                    # Prints 'a1'\n                    # Prints 'c3'\n                    # Prints 'e5'\n                    # Prints 'g7'\nprint(py_list[8])   # Prints 'i9'\n\ni9\n\n\n\n\nExercise 3 (Index again) ☻\nGiven the following list in Python:\nelements = ['Hydrogen',\n            'Helium', 'Lithium',\n            'Beryllium', 'Boron', 'Carbon',\n            'Nitrogen', 'Oxygen',\n            'Fluorine',\n            'Neon']\n\nAccess and print the element at index 4 using forward indexing.\nAccess and print the element at index 4 from the end of the list using reverse indexing.\n\n\n\nExercise 4 (How many ones) ☻\nUse the concepts you learned in this chapter to determine the number of 1’s in the following list of numbers.\nnumbers=[45, 60, 1, 30, 96, 1, 96, 57, 16, 1,\n        99, 62, 86, 43, 42, 60, 59, 1, 1, 35,\n        83, 47, 34, 28, 68, 23, 22, 92, 1, 79,\n        1, 29, 94, 72, 46, 47, 1, 74, 32, 20,\n        8, 37, 35, 1, 89, 29, 86, 19, 43, 61]                  \nHere are some hints:\n\nUse a NumPy array.\nAsk a question.\nFalse is considered 0, and True is considered 1 by sum().\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html",
    "title": "Files, Folders & OS (Need)",
    "section": "",
    "text": "From xkcd",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#path",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#path",
    "title": "Files, Folders & OS (Need)",
    "section": "1.1 Path",
    "text": "1.1 Path\nWhen dealing with computers, you will often encounter the term ‘path’. The path is simply a way to specify a location on your computer. It is like an address, and if you follow the path, it will take you to your file or folder.\nLike specifying location, you can specify your path absolutely or relatively. So, for example, I can specify that SPS is located on level 3 of block S16. However, if I am already on Level 5 of S16, I can say, go two floors down. The former is an absolute path, and the latter is relative. I have always found it easier to use relative paths, especially if I later want to move my folders about.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that the path tells us how to find a file or folder and that you can specify it absolutely or relatively.\n\n\nFor example, here is an absolute path to a file on the Desktop on a Windows machine.\nC:\\\\Users\\Chammika\\Desktop\\data-01.txt",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#more-about-relative-paths",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#more-about-relative-paths",
    "title": "Files, Folders & OS (Need)",
    "section": "1.2 More about relative paths",
    "text": "1.2 More about relative paths\nWhen dealing with relative paths, you will find it helpful to know . and .. notation.\n\n\n\n\nNotation\nMeaning\n\n\n\n\n.\n‘this folder’\n\n\n..\n‘one folder above’\n\n\n\n\nSo,\n\n.\\data-files\\data-01.txt means the file data-01.txt in the folder data-files in the current folder.\n..\\data-files\\data-01.txt means the file data-01.txt in the folder data-files located in the folder above.\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember . means current folder, and .. means one folder up.\n\n\n\n\nmacOS or Linux\nmacOS and Linux allow you to use ~ to refer to your home directory. So, for example, you can access the Desktop in these systems ‘relatively’ with ~/Desktop. So, I can look for a file in my Desktop using:\n~\\Desktop\\data-01.txt",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#path-separator",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#path-separator",
    "title": "Files, Folders & OS (Need)",
    "section": "1.3 Path separator",
    "text": "1.3 Path separator\nToday’s major OSs (Windows, macOS, Linux) offer similar graphical environments. However, one of the most striking differences between Windows and macOS (or Linux) is the path separator.\nWindows uses \\ as the path separator while macOS (or Linux) uses /. So, the absolute path to a file on the Desktop on each of these systems will look like this:\n\n\n\nWindows\nC:\\\\Users\\chammika\\Desktop\\data-01.txt\n\n\nmacOS (or Linux)\n/Users/chammika/Desktop/data-01.txt\n\n\n\nIf you want to share your code and want it to work on both systems, you must not hardcode either path separator. Later, I will show you how to use the Python os package to fix this problem.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#text-files-vs.-binary-files",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#text-files-vs.-binary-files",
    "title": "Files, Folders & OS (Need)",
    "section": "1.4 Text files vs. Binary files",
    "text": "1.4 Text files vs. Binary files\nYou can think of all files on your computer as being either text files or binary files. Text files are simple and can be opened, and their contents examined by almost any software (e.g., Notepad, TextEdit, Jupiter,…). Examples of text file formats are .txt, .md or .csv.\nBinary files, in contrast, require some processing to make sense of what they contain. For example, if you look at the raw data in a .png file, you will see gibberish. In addition, some binary files will only run on specific OSs. For example, the Excel.app on a Mac will not run on Windows, nor will the Excel.exe file run on macOS (or Linux). Some reasons for having binary files are speed and size; text files, though simple, can get bulky.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#extensions",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#extensions",
    "title": "Files, Folders & OS (Need)",
    "section": "1.5 Extensions",
    "text": "1.5 Extensions\nFiles are usually named to end with an extension separated from the name by a . like name.extension. This extension lets the OS know what software or app to use to extract the details in a file. For example, a .xlsx means use Excel or .pptx means use PowerPoint. Be careful about changing the extension of a file, as it will make your OS cough and throw a fit. If you don’t believe me, try changing a .xlsx to .txt and double-click.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#reading-data",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#reading-data",
    "title": "Files, Folders & OS (Need)",
    "section": "2.1 Reading data",
    "text": "2.1 Reading data\nHere is what you would typically do to read a text file.\nwith open('spectrum-01.txt', 'r') as file:\n    file_content = file.read()\n\nprint(file_content)\nThe open() function ‘opens’ your file. The 'r' specifies that I only want to read from the file. Using with frees you from worrying about closing the file after you are done.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#writing-data",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#writing-data",
    "title": "Files, Folders & OS (Need)",
    "section": "2.2 Writing data",
    "text": "2.2 Writing data\nNow, let’s write the following into a file.\n\ntext = 'Far out in the uncharted backwaters of the unfashionable end of the western spiral arm of the Galaxy lies a small unregarded yellow sun.\\nOrbiting this at a distance of roughly ninety-two million miles is an utterly insignificant little blue green planet whose ape-descended life forms are so amazingly primitive that they still think digital watches are a pretty neat idea.'\n\nI will use two writing methods just so that I can show you how they work.\n\nWriting to a file in one go\nFirst, let’s write everything in one go.\nwith open('my-text-once.txt', 'w') as file:\n    file.write(text)\nYou should now have a file my-text-once.txt in your directory. You should open it to take a look. By the way, the 'w' indicates that I am opening the file for writing.\n\n\nWriting to a file, line by line\nLet me show you how to write a line at a time. This is useful when dealing with data generated on the fly. Since I don’t have such data now, I will split the lines of the previous text [The contents in both files will be slightly different. However, this is not a time to worry about that.].\nwith open('my-text-lines.txt', 'w') as file:\n    for line in text.splitlines():\n        file.writelines(line)\nI must add that writing to a file is a very slow operation. So, it will slow things down if you do it in a loop.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#creating-folders",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#creating-folders",
    "title": "Files, Folders & OS (Need)",
    "section": "5.1 Creating folders",
    "text": "5.1 Creating folders\nYou can create a folder programmatically using os.mkdir(). This is very useful because you can write a tiny bit of code to quickly organise your data. For example, let’s say we need to store information about the people ‘John’, ‘Paul’ and ‘Ringo’. I can quickly create some folders for this by:\n\nos.mkdir('people')\n\nfor person in ['John', 'Paul', 'Ringo']:\n    path = os.path.join('people', person)\n    print(f'Creating {path}')\n    os.mkdir(path)\n\nCreating people/John\nCreating people/Paul\nCreating people/Ringo\n\n\nYou don’t need the print() statement. I have included it so I have some feedback on what is (or is not) happening.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#checking-for-existence",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#checking-for-existence",
    "title": "Files, Folders & OS (Need)",
    "section": "5.2 Checking for existence",
    "text": "5.2 Checking for existence\nPython will complain if you try to run this code twice, saying that the file (yes, Python refers to folders as files) already exists. So, when you create resources, it is a good idea to check if they already exist. There are two ways to do this: use try-except with the FileExistsError or use os.path.exists().\n\nUsing try-except\nfor person in ['John', 'Paul', 'Ringo']:\n    path = os.path.join('people', person)\n    try:\n        os.mkdir(path)\n        print(f'Creating {path}')\n    except FileExistsError:\n        print(f'{path} already exists; skipping creation.')\n\n\nUsing os.path.exists()\nfor person in ['John', 'Paul', 'Ringo']:\n    path = os.path.join('people', person)\n    if os.path.exists(path):\n        print(f'{path} already exists; skipping creation.')\n    else:\n        os.mkdir(path)\n        print(f'Creating {path}')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need.html#copying-files",
    "href": "docs/python_basics/06_this-n-that/1_os_need.html#copying-files",
    "title": "Files, Folders & OS (Need)",
    "section": "5.3 Copying files",
    "text": "5.3 Copying files\nLet me show you how to copy files programmatically.\nFirst, there should be a copy of the 73 logo (sp2273_logo.png) in the current folder. Then, I will copy this into the folders I created for ‘John’, ‘Paul,’ and ‘Ringo’.\n\nfor person in ['John', 'Paul', 'Ringo']:\n    path_to_destination = os.path.join('people', person)\n    shutil.copy('sp2273_logo.png', path_to_destination)\n    print(f'Copied file to {path_to_destination}')\n\n'people/John/sp2273_logo.png'\nCopied file to people/John\n'people/Paul/sp2273_logo.png'\nCopied file to people/Paul\n'people/Ringo/sp2273_logo.png'\nCopied file to people/Ringo\n\n\nLet’s say I want all the images in a sub-folder called imgs in each person’s directory. I can do this by first creating the folders imgs and then moving the logo file into that folder.\n\nfor person in ['John', 'Paul', 'Ringo']:\n    # Create folder 'imgs'\n    path_to_imgs = os.path.join('people', person, 'imgs')\n    if not os.path.exists(path_to_imgs):\n        os.mkdir(path_to_imgs)\n\n    # Move logo file\n    current_path_of_logo = os.path.join('people', person, 'sp2273_logo.png')\n    new_path_of_logo = os.path.join('people', person, 'imgs', 'sp2273_logo.png')\n\n    shutil.move(current_path_of_logo, new_path_of_logo)\n    print(f'Moved logo to {new_path_of_logo}')\n\n'people/John/imgs/sp2273_logo.png'\nMoved logo to people/John/imgs/sp2273_logo.png\n'people/Paul/imgs/sp2273_logo.png'\nMoved logo to people/Paul/imgs/sp2273_logo.png\n'people/Ringo/imgs/sp2273_logo.png'\nMoved logo to people/Ringo/imgs/sp2273_logo.png\n\n\n\n\n\n\n\n\nFYI\n\n\n\nYou can do all these extremely fast using only the terminal and its loops structure. Just letting you know if you want to explore on your own.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "Files, Folders & OS (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need.html",
    "href": "docs/python_basics/07_plotting/1_plotting_need.html",
    "title": "Plotting (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\nMatplotlib unleashed! (Image from Python Data Visualization with Matplotlib — Part 1)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need.html#lets-look-at-some-code.",
    "href": "docs/python_basics/07_plotting/1_plotting_need.html#lets-look-at-some-code.",
    "title": "Plotting (Need)",
    "section": "1.1 Let’s look at some code.",
    "text": "1.1 Let’s look at some code.\nShown below is some code and the resulting plot.\n# Some data for plotting\nx = [0, 1, 2, 3, 4, 5, 6]\ny_1 = [0, 2, 4, 6, 8, 10, 12]\ny_2 = [0, 3, 6, 9, 12, 15, 18]\n\n# Let's start plotting\nplt.plot(x, y_1, label='Y values',\n         color='red', linestyle='dashed')\nplt.xlabel('x-values')\nplt.ylabel('y-values')\nplt.title('X vs Y')\nplt.grid(alpha=.25)\nplt.legend(loc='upper left')\n\n\n\n\n\n\n\n\n\n\nCopy, paste, and run this code snippet to generate the plot. Then, spend a few minutes perusing the code to figure out what each line achieves in the plot. A simple way to do this is by commenting out some lines to turn off their contributions or changing some parameters (e.g., loc to bottom left) and numbers (e.g., alpha to .8). It will help you learn faster if you try to predict what will happen before running the code.\n\nThings to note\n\nYou can use the following abbreviations if you like:\n\n\n\n\n\nLong form\nAbbreviation\n\n\n\n\ncolor\nc\n\n\nlinestyle\nls\n\n\nlinewidth\nlw\n\n\n\n\nso, both the following lines produce the same result.\nplt.plot(x, y, color='red', linestyle='dashed', linewidth=2)\nplt.plot(x, y, c='red', ls='dashed', lw=2)\n\nJupyter is an interactive environment, so you will see an output even if you omit plt.show(). However, it is good practice to include this line anyway so your code will also work in non-interactive environments (for instance, when the script is run directly from the command line).\n\n\n\n\n\n\n\n\nThe plotting functions usually have default values for the styling parameters. So, if you wish, you can keep it simple and plot just using:\nplt.plot(x, y_1, y_2)\nThe resulting plot is shown alongside.\nYou can split the arguments into separate lines to improve readability.So, both of the following forms are acceptable.\n\n\n\n\n\n\n\n\nplt.plot(x, y, color='red', linestyle='dashed', linewidth=2)\nplt.plot(x, y_1, label='Y values',\n           color='red', linestyle='dashed')\n\nThe order of how you specify the keyword arguments (color, linewidth, …) does not matter.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need.html#adding-another-plot",
    "href": "docs/python_basics/07_plotting/1_plotting_need.html#adding-another-plot",
    "title": "Plotting (Need)",
    "section": "1.2 Adding another plot",
    "text": "1.2 Adding another plot\n\n\n\n\n\n\nYou can add another plot command to the graph to plot the data of y_2 in blue by adding the following line.\nplt.plot(x, y_2,\n         label='Y2 values', color='blue')\nOnce you do this, the code will look like this:\n\n\n\n\n\n\n\n# Some data for plotting\nx = [0, 1, 2, 3, 4, 5, 6]\ny_1 = [0, 2, 4, 6, 8, 10, 12]\ny_2 = [0, 3, 6, 9, 12, 15, 18]\n\n# Lets start plotting\nplt.plot(x, y_1, label='Y1 values', color='red', linestyle='dashed')\nplt.plot(x, y_2, label='Y2 values', color='blue')\nplt.xlabel('x-values')\nplt.ylabel('y-values')\nplt.title('X vs Y')\nplt.grid(alpha=.25)\nplt.legend(loc='upper left')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need.html#yet-another-plot-but-with-error-bars",
    "href": "docs/python_basics/07_plotting/1_plotting_need.html#yet-another-plot-but-with-error-bars",
    "title": "Plotting (Need)",
    "section": "1.3 Yet another plot but with error bars",
    "text": "1.3 Yet another plot but with error bars\n\n\n\n\n\n\nLet me add another plot, but this time I will also include \\(x\\) and \\(y\\) error bars for the points. The plotting command I need to use for this is called errorbar().\nplt.errorbar(x, y_3,\n             xerr=x_error, yerr=y_error,\n             label=\"Y3 with errors\",\n             color=\"green\")\nOnce you do this, the code will look like this:\n\n\n\n\n\n\n\n# Some data for plotting\nx = [0, 1, 2, 3, 4, 5, 6]\ny_1 = [0, 2, 4, 6, 8, 10, 12]\ny_2 = [0, 3, 6, 9, 12, 15, 18]\ny_3 = [0, 4, 8, 12, 16, 20, 24]\nx_error, y_error = .1, 0.75\n\n# Lets start plotting\nplt.plot(x, y_1, label='Y1 values', color='red', linestyle='dashed',)\nplt.plot(x, y_2, label='Y2 values', color='blue', )\nplt.errorbar(x, y_3, xerr=x_error, yerr=y_error,\n             label='Y3 with errors', color='green')\nplt.xlabel('x-values')\nplt.ylabel('y-values')\nplt.title('X vs Y')\nplt.grid(alpha=.25)\nplt.legend(loc='upper left')\n\nIn this example, I have provided constant errors for all the points. However, you can also provide a list of errors so that each will have a different length.\n\n\n\n\n\n\n\nPlease note\n\n\n\nFrom here onwards, I will show a minimum of code related to styling to reduce clutter. You should, however, still retain them to get nice-looking plots.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need.html#adding-mathematical-functions",
    "href": "docs/python_basics/07_plotting/1_plotting_need.html#adding-mathematical-functions",
    "title": "Plotting (Need)",
    "section": "2.1 Adding mathematical functions",
    "text": "2.1 Adding mathematical functions\nOne of the advantages of NumPy arrays is that they allow us to generate data-related mathematical functions easily. Let’s reuse our previous code to plot \\(x^2\\) and \\(\\sin(x)\\)\nx = np.array([0, 1, 2, 3, 4, 5, 6])\n\nx2 = x**2                  # The math stuff\nsin_x = np.sin(x)\n\nplt.plot(x, x2, label='x^2',\n         color='red', linestyle='dashed', )\nplt.plot(x, sin_x, label='sin(x)',\n         color='blue')\nplt.legend()                                 \n\n\n\n\n\n\n\n\n\n\nAlas, our plot does not look good because \\(\\sin(x)\\) lies between \\(\\pm 1\\), but \\(x^2\\) has no such bounds. One way to fix this is to add another y-axis that shares the same x-axis.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need.html#plotting-twinx",
    "href": "docs/python_basics/07_plotting/1_plotting_need.html#plotting-twinx",
    "title": "Plotting (Need)",
    "section": "We need another axis!",
    "text": "We need another axis!\nMatplotlib offers a variety of ways to have multiple axes. The simplest way is to have another y-axis that shares the same x-axis. We can use the command twinx() for this.\n\n\n\n\n\n\n\n\n\n\n\n\nFigure 1: Two y-axes and fewer points.\n\n\n\n\n\n\n\n\n\n\n\nFigure 2: Using np.linspace().\n\n\n\n\n\n\n\nx = np.array([0, 1, 2, 3, 4, 5, 6])\nx2 = x**2\nsin_x = np.sin(x)\n\nplt.plot(x, x2, label='x^2',color='red', linestyle='dashed')\nplt.legend(loc='lower left')                                  # For y-axis 1\n\nplt.twinx()                                                   # This creates a new y-axis \n                                                              # for the plots that comes after\nplt.plot(x, sin_x, label='sin(x)',color='blue', )\nplt.legend(loc='lower right')                                 # For y-axis 2\n\n\nThings to note\n\nWe now have two legend() calls, one for each axis.\nour plot still does not look good because we have only a few points. Let’s use np.linspace to fix this with:\nx = np.linspace(0, 6, 100)\nThe improvement is seen in the plot on the right.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need.html#plotting-data-from-files",
    "href": "docs/python_basics/07_plotting/1_plotting_need.html#plotting-data-from-files",
    "title": "Plotting (Need)",
    "section": "4.1 Plotting data from files",
    "text": "4.1 Plotting data from files\nPlotting data stored in a file (e.g., spreadsheet, text file, database) is a routine task for a scientist. In fact, the first thing you should do with any data is to look at it with a simple plot.\nFor the rest of this section, I will use the Earth’s land temperature data from the Berkeley Earth website. Please visit the site (Global Warming \\(\\rightarrow\\) Data Overview) and download the average temperature data for Daily Land. The original name of the file should be Complete_TAVG_daily.txt\n\n\n\n\n\n\ndata = np.loadtxt('Complete_TAVG_daily.txt',\n                   skiprows=24)\ndate = data[:, 0]\nanomaly = data[:, -1]\n\nplt.plot(date, anomaly, alpha=.5)\nplt.ylim([-8, 8])\nI have used a small alpha value to soften the colour of the plot and made the plot range symmetrical in the \\(y\\) direction.\n\n\n\n\n\n\nLet’s add a horizontal line at the zero value to highlight the trend shown by the data.The hlines() function needs a \\(y\\)-value and starting and ending values for \\(x\\).\nplt.hlines(0, date[0], date[-1], linestyle='--', colors='grey')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need.html#styles",
    "href": "docs/python_basics/07_plotting/1_plotting_need.html#styles",
    "title": "Plotting (Need)",
    "section": "4.2 Styles",
    "text": "4.2 Styles\nUnlike myself, most people (very sensibly) might just want a decent-looking plot without spending time customising it. To facilitate this Matplotlib offers some standard style templates (see here). I am going to use the one called fivethirtyeight.\nplt.style.use('fivethirtyeight')\nThis line must be included right at the top!\nEt voila! Do you see global warming?!\n\nHere is the complete code for the final product.\n\nplt.style.use('fivethirtyeight')\n\ndata = np.loadtxt('Complete_TAVG_daily.txt', skiprows=24)\n\ndate = data[:, 0]\nanomaly = data[:, -1]\n\nplt.plot(date, anomaly, alpha=.5)\nplt.hlines(0, date[0], date[-1], linestyle='--', colors='grey')\nplt.ylim([-8, 8])\n\nplt.xlabel('Date')\nplt.ylabel('Temperature Anomaly')\nplt.title('Temperature anomaly\\n(Relative to  average from Jan 1951 - Dec 1980.)')\n\n\nxkcd!\nOkay, since we are talking about styles, I must tell you that the developers of Matplotlib have a healthy sense of humour and have included the option of making your plots in the xkcd style. To enable this, just run plt.xkcd() instead of setting a style. Here is what the previous plot looks like using the xkcd style. Cool!\n\n\n\nResetting styles\nIf you want to reset things and jump out of this style, you need to set the default style using:\nplt.style.use('default')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/1_plotting_need_exercises.html",
    "href": "docs/python_basics/07_plotting/1_plotting_need_exercises.html",
    "title": "Plotting (Need) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (Fill in the blanks) Fill in the blanks(indicated with a ?), so the code below will produce the plot shown.\n\n\n\n\n\n\n# Some data for plotting\nx = [0, 1, 2, 3, 4, 5]\ny = [0, 4, 8, 12, 16, 20]\ny_err = [0.0, 0.5, 1.0, 1.5, 2.0, 2.5]\nx_err = .25\n\nplt.errorbar(x, y, \n             xerr=?, yerr=?,\n             color=?, linestyle=?,\n             marker=?, markerfacecolor=?,\n             ecolor=?,capsize=5,\n             label=?)\nplt.xlabel('x-values')\nplt.ylabel('y-values')\nplt.title('X vs Y')\nplt.grid(alpha=.25)\nplt.legend(?)\nplt.show()\n\n\n\n\n\n\n\n\nExercise 2 (A simple mathematical plot)  \n\n\n\n\n\n\n\nUse NumPy to generate \\(x\\) and \\(y\\) data suitable for plotting the graph of the function: \\[ y = e^{-x/10}\\sin(x)\\]\nfor values of \\(x\\) in the range \\(0\\) to \\(50\\).\nCustomise your plot so that:\n\nThe x and y axes have labels of fontsize of 15\nThe x and y axes labels are in the color, darkorange.\nThere is a grid with an opacity of 25%.\nIndicate the equation of the function in the title with a font size of 20.Hint: Look at Writing mathematical expressions in Matplotlib.\nChange the \\(y\\) limit (using ylim) to \\([-1,1]\\)\n\n\nIn the end, your plot should look like the one shown alongside.\n\n\n\n\n\n\n\nContributed by Darren Teo\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/2_basics_good_exercises.html",
    "href": "docs/python_basics/02_basics/2_basics_good_exercises.html",
    "title": "Fundamentals (Good) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (What is your grade?)  \n\nStep 1Task\n\n\nPython allows you to solicit information from the user.\nOne way to do this is using the input() function. Here is an example of how to use it.\nuser_input = input('Give me a number?')\nprint('You entered', user_input)\nRun this code and explore.\n\n\nWrite a Python program that takes a numerical grade (0-100) as input and outputs the corresponding letter grade based on the following criteria:\n\n\n\n\nGrade\nScore Range\n\n\n\n\nA\n70 - 100\n\n\nB\n50 - 69\n\n\nC\n35 - 49\n\n\nFail\n0 - 34\n\n\n\n\nNote:\n\nHere is an example of the type of exchange expected.\nEnter the student's score: 85\nThe student's letter grade is: A\nEnsure your program handles unexpected inputs gracefully and displays a relevant error message.\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercises (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/1_basics_need_exercises.html",
    "href": "docs/python_basics/02_basics/1_basics_need_exercises.html",
    "title": "Fundamentals (Need) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (Total recall?) ☻\n\nPurely from memory, list as many of the basic Python features I mentioned in my notes as you remember.\nUse a Markdown cell for this list.\nNow, visit the notes and complete the list with the ones you missed.\nIndicate those you missed by putting them in italics.\n\n\n\nExercise 2 (Debug me) ☻\nFix (debug) the following code to create a Pythagorean triple 3, 4, 5 (because \\(3^2+4^2=5^2\\)).\nx, y = 3, 4\n        z = sqrt(x*2 + y**2)\n    Print(x, y, z)\n\n\nExercise 3 (In your own words) ☻\nUsing your own words, write a single sentence to describe what each of the following means or the role they serve in Python.\nPlease use a Markdown table for this.\n\n\n\n\n\n\n#\nTerm\nDescription\n\n\n\n\n1\nFunction\n\n\n\n2\nArguments\n\n\n\n3\nComments\n\n\n\n4\nIndentations\n\n\n\n5\nPackages\n\n\n\n6\n.\n\n\n\n7\n:\n\n\n\n8\n[]\n\n\n\n9\n[[[]]]\n\n\n\n10\n{}\n\n\n\n\n\n\n\n\n\nExercise 4 (More than one way to divide) ☻\nProgramming languages usually offer multiple options for dividing one number by another. Shown below are three such options. Either by observation (i.e., trial and error), Googling or discussing with a friend, figure out what each one does.\nI recommended the trial and error approach first so that you get a feel for how to use Python.\nIndicate your answer by writing a comment.\n5/2           # What do I do?\n5//2          # What do I do?\n5%2           # What do I do?\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercises (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/2_loops_good.html",
    "href": "docs/python_basics/04_loops/2_loops_good.html",
    "title": "Loops (Good)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/2_loops_good.html#basic-syntax",
    "href": "docs/python_basics/04_loops/2_loops_good.html#basic-syntax",
    "title": "Loops (Good)",
    "section": "2.1 Basic syntax",
    "text": "2.1 Basic syntax\n[number for number in range(5)]\n\n\n\nThe adjoining creates a simple list with numbers from 0 to 4.The syntax is very similar to that of a for loop. You just need to put the thing you want as an output at the front.\n\n\n\n[0, 1, 2, 3, 4]\n\n\n\n\n[number**2 for number in range(5)]\n\n\n\nIf you want to create a list of squares, we just have to:\n\n\n\n[0, 1, 4, 9, 16]",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/2_loops_good.html#list-comprehension-with-conditions",
    "href": "docs/python_basics/04_loops/2_loops_good.html#list-comprehension-with-conditions",
    "title": "Loops (Good)",
    "section": "2.2 List comprehension with conditions",
    "text": "2.2 List comprehension with conditions\n[number for number in range(10) if number % 2 ==0]\n\n\n\nList comprehension has several useful features. One such allows us to specify a condition. Here is an example:\n\n\n\n[0, 2, 4, 6, 8]",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/2_loops_good.html#for-with-unpacking",
    "href": "docs/python_basics/04_loops/2_loops_good.html#for-with-unpacking",
    "title": "Loops (Good)",
    "section": "3.1 for with unpacking",
    "text": "3.1 for with unpacking\nPython allows a neat trick called unpacking, which works like this:\n\nx, y, z=[1, 2, 3]\nprint(f'x = {x}, y = {y}, z = {z}')\n\nx = 1, y = 2, z = 3\n\n\nUnpacking can be put to good use (for example) when we are dealing with 2D list. We can combine unpacking with a for loop to extract elements as follows:\n\npy_superhero_info = [['Natasha Romanoff', 'Black Widow'],\n                     ['Tony Stark', 'Iron Man'],\n                     ['Stephen Strange', 'Doctor Strange']]\n\nfor real_name, super_name in py_superhero_info:\n    print(f\"{real_name} is Marvel's {super_name}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/2_loops_good.html#for-with-zip",
    "href": "docs/python_basics/04_loops/2_loops_good.html#for-with-zip",
    "title": "Loops (Good)",
    "section": "3.2 for with zip()",
    "text": "3.2 for with zip()\nLet’s revisit the example from the previous chapter that had two lists of real and superhero names that we used to print. There is yet another way to solve this task using a function called zip(). zip() is a neat function that can do some cool things. For the moment let me show you how to use zip() to combine two lists.\n\nsuper_names = [\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\nreal_names = [\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\nfor real_name, super_name in zip(real_names,super_names):\n    print(f\"{real_name} is Marvel's {super_name}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!\n\n\nThis is by far the most elegant solution we have for using multiple lists with a for loop.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/2_loops_good.html#for-with-dictionaries",
    "href": "docs/python_basics/04_loops/2_loops_good.html#for-with-dictionaries",
    "title": "Loops (Good)",
    "section": "3.3 for with dictionaries",
    "text": "3.3 for with dictionaries\nYou will invariably need to loop through dictionaries in your programming career. Here is how you can do it with a for loop.\n\nsuperhero_info={\"Natasha Romanoff\": \"Black Widow\",\n                \"Tony Stark\": \"Iron Man\",\n                \"Stephen Strange\": \"Doctor Strange\"}\n\nfor key, value in superhero_info.items():\n    print(f\"{key} is Marvel's {value}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!\n\n\nThe ‘hidden’ function items() spits out both the key and the corresponding value.\nIf you like, you can directly access the keys as follows:\n\nfor key in superhero_info.keys():\n    value=superhero_info[key]\n    print(f\"{key} is Marvel's {value}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!\n\n\nBy the way, I have used the variable names key and value to highlight their roles in the dictionary. You can use whatever you like. In fact, using real_name and super_name is preferred.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/2_loops_good.html#footnotes",
    "href": "docs/python_basics/04_loops/2_loops_good.html#footnotes",
    "title": "Loops (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nor the end of the Universe↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/1_loops_need_exercises.html",
    "href": "docs/python_basics/04_loops/1_loops_need_exercises.html",
    "title": "Loops (Need) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (Celcius to Farenheit) ☻\nYou are provided with the following list of temperatures in Celsius. Write a quick Python snippet that converts each temperature to Fahrenheit and prints both temperatures.\ntemperatures_celsius = [\n    0, 5, 10, 15, 20, 25,\n    30, 35, 40, 45, 50\n]\n\n\n\nExercise 2 (Multiplication table) ☻\n\nExampleTask\n\n\nYou can put a loop within a loop to do doubly loopy stuff. Here is an example:\n\nfor letter in ['A', 'B', 'C']:\n    for number in [1, 2, 3]:\n        print(f'{letter}{number}', end='\\t')\n    print('\\n')\n\nA1  A2  A3  \n\nB1  B2  B3  \n\nC1  C2  C3  \n\n\nTry this out and explore.\n\n\nWrite a Python snippet that prints a multiplication table (up to 5) for numbers 1 through 5 using nested for loops. The output should be formatted as shown below:\n\n\n1 : 1   2   3   4   5   \n2 : 2   4   6   8   10  \n3 : 3   6   9   12  15  \n4 : 4   8   12  16  20  \n5 : 5   10  15  20  25  \n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/3_loops_nice.html",
    "href": "docs/python_basics/04_loops/3_loops_nice.html",
    "title": "Loops (Nice)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe material in this ‘Nice’ chapter is optional. The discussion typically deals with content beyond what a novice should know. So, please finish all the ‘Need’ and ‘Good’ portions before you go through this chapter.\n\n\n\n1 There is more to list comprehension\n\n\n\n\n\n\n\n\n\nYou can have more than one loop in a list comprehension.\n\n\n[[a,b] for a in range(5) for b in ['A', 'B', 'C']]\n\n\n[[0, 'A']\n [0, 'B']\n [0, 'C']\n [1, 'A']\n [1, 'B']\n [1, 'C']\n [2, 'A']\n [2, 'B']\n [2, 'C']\n [3, 'A']\n [3, 'B']\n [3, 'C']\n [4, 'A']\n [4, 'B']\n [4, 'C']]\n\n\n\n\n\n\n\n\n\n\n\n\n\nYou can even incorporate a condition!\n\n\n[[a,b] for a in range(5) for b in ['A', 'B', 'C'] if a % 2 != 0]\n\n\n[[1, 'A']\n [1, 'B']\n [1, 'C']\n [3, 'A']\n [3, 'B']\n [3, 'C']]\n\n\n\n\n\n\n\nnested_list=[[1, 2, 3], [4, 5, 6, 7]]\n[y for x in nested_list for y in x]\nnested_list=[[1, 2, 3], [4, 5, 6, 7]]\n\noutput =[]\nfor x in nested_list:\n    for y in x:\n        output.append(y)\n\n\n\nHere is a slightly more complicated use of list comprehension to flatten a list.\n\n\n\n\n[1, 2, 3, 4, 5, 6, 7]\n\n\nThis does the same as:\n\n\n\n\n\n\n\n\n2 Zipping a dictionary\nzip() offers one of the easiest ways to combine two lists into a dictionary:\n\nsuper_names=[\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\nreal_names=[\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\ndict(zip(real_names, super_names))\n\n{'Natasha Romanoff': 'Black Widow', 'Tony Stark': 'Iron Man', 'Stephen Strange': 'Doctor Strange'}\n\n\nIn the above dict() is used to recast zip()’s output into a dictionary.\n\n\n3 for and while has an else\nnumbers=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n\nfor i in numbers:\n    if i &lt; 0: break\nelse:\n    print('No negative numbers in the list')\n\n\n\nThe for and while loops in Python come with an optional else statement! The code in the else block is executed only if the loops are completed. The else code-block will not run if you exit the loop prematurely (e.g. by using break).\nShown alongside is a trivial example. You should add a negative number to the list, and re-run the snippet. There will be no message this time.\nSo, the else statement can be used to distinguish between the loops completing as planned or if there was a break (or return or an exception).\n\n\n\n\nNo negative numbers in the list\n\n\n\n\n\n\n\nExercises\n\nExercise 1 (Changing a list)  \n\nProblemA solution\n\n\nWe want a snippet of code based on a for loop to remove fruits starting with the letter ‘p’ from the following list.\nfruits = [\"apple\", \"banana\", \"jackfruit\",\n          \"pineapple\", \"papaya\", \"watermelons\",\n          \"peaches\", \"durian\",  \"mangoes\",\n          \"strawberries\", \"passionfruit\"\n          ]\nThe following has been suggested as a solution. However, it does not work!\nfor fruit in fruits:\n    if fruit[0] == \"p\":\n        fruits.remove(fruit)\nIdentify, understand and fix the error.\n\n\nfor fruit in fruits:\n    if fruit[0] == \"p\":\n        fruits.remove(fruit)\nAlthough the above code is elegant it has a serious flaw which you can see by using pythontutor.com to visualise the flow of the script.\nA safer solution is the following:\n\nfruits = [\"apple\", \"banana\", \"jackfruit\",\n          \"pineapple\", \"papaya\", \"watermelons\",\n          \"peaches\", \"durian\",  \"mangoes\",\n          \"strawberries\", \"passionfruit\"\n          ]\n\ncopy_of_fruits = fruits.copy()\n\n# Not that we are looping(iterating) over the copy\nfor fruit in copy_of_fruits:\n    if fruit[0] == \"p\":\n        fruits.remove(fruit)\nAn even better, clean and elegant solutions is:\nfruits = [\"apple\", \"banana\", \"jackfruit\",\n          \"pineapple\", \"papaya\", \"watermelons\",\n          \"peaches\", \"durian\",  \"mangoes\",\n          \"strawberries\", \"passionfruit\"\n          ]\n\n[fruit for fruit in fruits if fruit[0] != \"p\"]\n\n\n\n\n\n\n# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 2 (A list of powers)  \n\nProblemA Solution\n\n\nThe following code is an attempt to create a list \\([n, n^2,n^3]\\) for several values of \\(n\\). We can specify the maximum value of \\(n\\) by changing maximum_n.\nmaximum_n = 5\nresult = [[]] * maximum_n\n\nfor n in range(1, maximum_n + 1):\n    result[n - 1].append(n)\n    result[n - 1].append(n**2)\n    result[n - 1].append(n**3)\nFor maximum_n = 5 the content of result should be as shown below.\n[[1, 1, 1],\n [2, 4, 8],\n [3, 9, 27],\n [4, 16, 64],\n [5, 25, 125]]\nHowever, the code does not produce this expected result!Identify, understand, explain and fix the bug.\n\n\n\nAn explantion\nThe problem arises because [[]] * 5 creates 5 references to the same empty list []. Running a list comprehension will create 5 different empty lists [].\nLet’s check if what I have said is true.\nmaximum_n = 5\n\nresult = [[]] * maximum_n\n\nfor count, element in enumerate(result):\n    print(count, id(element))\nmaximum_n = 5\n\nresult = [[] for _ in range(maximum_n)]\n\nfor count, element in enumerate(result):\n    print(count, id(element))\n\n\n\n\n0 140013001824896\n1 140013001824896\n2 140013001824896\n3 140013001824896\n4 140013001824896\n\n\n\n\n0 140013001865856\n1 140013001866880\n2 140013001902400\n3 140013001900160\n4 140013001867072\n\n\n\n\n\n\nA solution\n\nmaximum_n = 5\n# result = [[]] * maximum_n\nresult = [[] for _ in range(maximum_n)]\n\nfor n in range(1, maximum_n + 1):\n    result[n - 1].append(n)\n    result[n - 1].append(n**2)\n    result[n - 1].append(n**3)\n\n\n\n[[1, 1, 1]\n [2, 4, 8]\n [3, 9, 27]\n [4, 16, 64]\n [5, 25, 125]]\n\n\n\n\n\n\n\n\nExercise 3 (Time profiling)  \n\nProblem\n\n\nUse %%timeit to compare the execution speeds of the following:\n\n\n\n\n\n\n\n\n\n\n#\nOption 1\nOption 2\nResult\n\n\n\n\n1\nCreating a list of squares with for loop\nCreating a list of squares with while loop\n\n\n\n2\nCreating a list of squares with a for loop.\nCreating a list of squares with a list comprehension loop.\n\n\n\n3\nCreating a list of squares using list append()\nCreating a list of squares using list +=\n\n\n\n4\nCreating a list of squares using list append()\nCreating a list of squares using append()of Numpy\n\n\n\n5\nCreating a list of squares using Numpy\nCreating a list of squares using List comprehension loop.\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html",
    "href": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html",
    "title": "Using Jupyter (Good)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html#keyboard-shortcuts",
    "href": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html#keyboard-shortcuts",
    "title": "Using Jupyter (Good)",
    "section": "1.1 Keyboard Shortcuts",
    "text": "1.1 Keyboard Shortcuts\nUsing keyboard shortcuts will make your workflow smooth and efficient. Here are some essential shortcuts. It will help you to practice using all these keyboard shortcuts.\n\n\n\n\n\n\n\n\nAction\nShortcut\n\n\n\n\nRun cell\nCTRL + ENTER or CMD + ENTER\n\n\nRun cell and move to the next\nSHIFT + ENTER\n\n\nConvert cell to code cell\nESC + Y\n\n\nConvert cell to Markdown cell\nESC + M\n\n\nCreate new cell\nESC + A (above)ESC + B (below)\n\n\nCopy cell(s)\nESC + C\n\n\nPaste cell(s)\nESC + V\n\n\nMerge cells\nSHIFT + M\n\n\nDelete cell\nESC + D + D\n\n\nShow shortcuts\nESC + H\n\n\n\n\nYou will notice that many shortcut commands use the escape button (ESC). This is because typing ESC puts Jupyter into command mode, ready for a command, not code or text.\n\nThings to note\n\nYou can select one or more cells using SHIFT and the up and down arrow keys.\nBe careful with the delete shortcut; it can be ruthless.\nYou can view (and set) shortcuts for Jupyter Notebooks by typing ESC + H.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html#shell-commands",
    "href": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html#shell-commands",
    "title": "Using Jupyter (Good)",
    "section": "1.2 Shell commands",
    "text": "1.2 Shell commands\nYou can run ‘terminal’ commands (called shell commands) from Jupyter without switching to the terminal. The only thing you need to do is to add a ! in front of the command.\nTo test out this feature, run the following:\n\nWindows macOS \n\n\n\nThis will print the current working directory.\n!cd\nThis will show you a list of all the files in your folder.\n!dir\n\n\n\n\nThis will print the current working directory.\n!pwd\nThis will show you a list of all the files in your folder.\n!ls\n\n\n\n\n\n\n\n\n\n\nSkip ‘Jupyter Extensions’\n\n\n\nJupyter Notebooks are transitioning to Notebook version 7. As a consequence, it seems that Jupyter Extensions no longer work properly. Therefore, I have decided to skip the following step (Jupyter Extensions) in your setup.\nNote that this will only cause minor differences in your coding experience.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html#installing-the-extensions",
    "href": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html#installing-the-extensions",
    "title": "Using Jupyter (Good)",
    "section": "Installing the extensions",
    "text": "Installing the extensions\nYou can add several useful features (e.g., code formatting, TOC, equation numbers) to your Jupyter notebooks by installing jupyter_contrib_nbextensions (documentation).\nYou can do this in the terminal by invoking the following.\nconda install -c conda-forge jupyter_contrib_nbextensions\njupyter contrib nbextension install --user\nOnce you have finished installing, log out and restart Jupyter. You will then see a new tab, as shown in the image below.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html#enabling-the-extensions",
    "href": "docs/python_basics/01_using_jupyter/2_using-jupyter_good.html#enabling-the-extensions",
    "title": "Using Jupyter (Good)",
    "section": "Enabling the extensions",
    "text": "Enabling the extensions\nYou will also see details of what each extension does by clicking on the name in the list. Finally, you can enable them simply by checking the box on the list. Here are some of the extensions I recommend.\n\nEquation Auto Numbering\nTable of Contents (2)\nVariable Inspector\nCode folding\nAutopep8 You must install the package autopep8 using conda for this to work.\n\nDiscover what features these have added by creating a new Jupyter Notebook. You will see several new buttons in the toolbar corresponding to some extensions. For instance, if you run x=10 in a code cell the Variable Inspector will show the details of the variable.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/2_using-jupyter_good_exercises.html",
    "href": "docs/python_basics/01_using_jupyter/2_using-jupyter_good_exercises.html",
    "title": "Using Jupyter (Good), Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercises (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/2_using-jupyter_good_exercises.html#footnotes",
    "href": "docs/python_basics/01_using_jupyter/2_using-jupyter_good_exercises.html#footnotes",
    "title": "Using Jupyter (Good), Exercises",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nOkay, okay it was me, but you pressed the button.↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercises (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_1_hypothesis.html",
    "href": "docs/python_basics/00_setting_up/setup_1_hypothesis.html",
    "title": "Hello, Hypothesis! (Good)",
    "section": "",
    "text": "Hypothesis is a free web tool that allows you to “annotate the web”. Specifically, it will enable you to highlight and make notes on web pages. It also has a chat feature that allows you to develop a discussion (with your instructors and peers) around the web page’s content. For 73, we will use Hypothesis to share comments and questions about the notes and inform me of any typos or mistakes.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Hypothesis! (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_1_hypothesis.html#footnotes",
    "href": "docs/python_basics/00_setting_up/setup_1_hypothesis.html#footnotes",
    "title": "Hello, Hypothesis! (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nHowever, by installing the Chrome extension, you can use Hypothesis with almost all other web pages. Please refer to this page if you want to do this.↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Hypothesis! (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_3_jupyter.html",
    "href": "docs/python_basics/00_setting_up/setup_3_jupyter.html",
    "title": "Hello, Jupyter! (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Jupyter! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_3_jupyter.html#download-install-miniconda",
    "href": "docs/python_basics/00_setting_up/setup_3_jupyter.html#download-install-miniconda",
    "title": "Hello, Jupyter! (Need)",
    "section": "2.1 Download & install Miniconda",
    "text": "2.1 Download & install Miniconda\nFirst, we need to download the installer. Please follow the instructions below that are relevant to your operating system.\n\nWindows macOS \n\n\n\nDownload installer here\nInstall Miniconda.\n\nDouble-clicking the .exe file.\nFollow the instructions on the screen:\n\nWhen not sure, just use the installer’s default setting.\nYou must decide ‘Just Me’ or ‘All Users’. If you are installing for ‘All Users’, you must have Administrator privileges on your machine.\n\n\n\n\n\n\nDownload the installer\n\nVisit this page.\nChoose the bash package corresponding to your computer’s chip (i.e., M1, Intel)\nDownload to your Downloads folder (this is the default).\n\nInstall Miniconda.\n\nStart up the Terminal app either from the Applications folder or using the Launchpad.\n\nType the following and press ENTER\n\n\ncd ~/Downloads\nThis changes directory (folder) to ‘Downloads’.\n\n\nType the following, adjusting the file name according to step 1, and press ENTER\n\n\nbash Miniconda3-latest-MacOSX-x86_64.sh\nThis starts the installer.\n\n\nFollow the instructions on the screen:\n\nWhen not sure, just use the installer’s default setting.\nYou must decide ‘Just Me’ or ‘All Users’. If you are installing for ‘All Users’, you must have Administrator privileges on your machine.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Jupyter! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_3_jupyter.html#what-is-the-command-prompt",
    "href": "docs/python_basics/00_setting_up/setup_3_jupyter.html#what-is-the-command-prompt",
    "title": "Hello, Jupyter! (Need)",
    "section": "3.1 What is the command prompt",
    "text": "3.1 What is the command prompt\nBefore proceeding further, allow me to introduce you to the command prompt. The command prompt is one of the most powerful features of your operating system. However, because it is not as friendly as the windows based graphical user interface (GUI), people shy away from using it. Unfortunately, we do not have a choice; we have to use the prompt to maintain (i. e., install, uninstall, upgrade) components and to start Jupyter Notebooks. So, let’s bite the bullet and learn how to use it.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Jupyter! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_3_jupyter.html#opening-the-prompt",
    "href": "docs/python_basics/00_setting_up/setup_3_jupyter.html#opening-the-prompt",
    "title": "Hello, Jupyter! (Need)",
    "section": "3.2 Opening the prompt",
    "text": "3.2 Opening the prompt\n\nWindows macOS \n\n\nWindows users should use the Anaconda Prompt.You can open this from the Start menu.\n\n\nmacOS has a native prompt called the Terminal, which you can open from the Applications folder or the Launchpad.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Jupyter! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_3_jupyter.html#navigate-using-the-prompt",
    "href": "docs/python_basics/00_setting_up/setup_3_jupyter.html#navigate-using-the-prompt",
    "title": "Hello, Jupyter! (Need)",
    "section": "3.3 Navigate using the prompt",
    "text": "3.3 Navigate using the prompt\nWe will often need to navigate to different folders using the prompt. The command to change the directory (or folder) is issued as follows.\ncd path-to-folder\nLet’s navigate into the folder you created previously. For this, we need the full path (e.g. C:\\\\Documents...) of that folder. Using the GUI (Windows File Explorer or Finder) is the easiest way to extract the path to the folder you want.\n\n\n\n\n\nGo to the folder using the file explore GUI,\nRight-click on the top address bar as shown below.\n\nPick Copy address as text\nNow just paste the result in the command line and press Enter:\n\ncd path-to-folder\n\n\n\nLocate the folder using the Finder,\nRight-click on the folder icon and choose Get Info.\nNow hold the Option button and pick Copy filename as Pathname.\nNow just paste the result in the command line and press Enter:\n\ncd path-to-folder",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Jupyter! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_3_jupyter.html#using-the-prompt-with-conda",
    "href": "docs/python_basics/00_setting_up/setup_3_jupyter.html#using-the-prompt-with-conda",
    "title": "Hello, Jupyter! (Need)",
    "section": "3.4 Using the prompt with conda",
    "text": "3.4 Using the prompt with conda\nconda is the name of the main programme from Anaconda that controls everything in the installation. It is called the package manager. You will typically have to use conda to install, upgrade or remove packages. Here are two examples of how to use the prompt. Please try them both.\n\nTesting our installation.Updating Miniconda\n\n\nLet’s use the prompt to check if our previous installation of Miniconda went okay. For this, run (i.e., type and press ENTER) the following:\nconda list\nThis will give you a list of all the things that are installed under Miniconda.\n\n\nThe installer does not always install the most recent versions. So, let’s first update Miniconda itself. Here is the command to do this.\nconda update conda",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Jupyter! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_3_jupyter.html#jupyter-the-first-run",
    "href": "docs/python_basics/00_setting_up/setup_3_jupyter.html#jupyter-the-first-run",
    "title": "Hello, Jupyter! (Need)",
    "section": "4.1 Jupyter… the first run",
    "text": "4.1 Jupyter… the first run\nFinally, it is time to run Jupyter for the first time. We need to start Jupyter using the prompt by invoking:\njupyter notebook\nIf you are on Windows, you can also type “Jupyter notebook” in the search bar and click on the Jupyter Notebook icon.\nWhen you do this, a webpage will open up and display the content of the folder you started Jupyter in. Since we are in the Learning Portfolio, you should see that content.\nWe are done with this chapter. I will show you how to use Jupyter in the next part. But, for now, press the button Logout.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Jupyter! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_3_jupyter.html#footnotes",
    "href": "docs/python_basics/00_setting_up/setup_3_jupyter.html#footnotes",
    "title": "Hello, Jupyter! (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor instance: PyCharm, Spyder, Visual Studio, Colab, Kaggle↩︎\nwe will learn what a package does a bit later. For the moment, think of it as an essential ‘item’.↩︎\ni. e. only installs essential features↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, Jupyter! (Need)"
    ]
  },
  {
    "objectID": "docs/applications_challenge/01_applications-challenge-overview.html",
    "href": "docs/applications_challenge/01_applications-challenge-overview.html",
    "title": "Overview",
    "section": "",
    "text": "Your 73 journey so far has been heavily scaffolded with much hand-holding. You now need to gradually practice applying the knowledge gained so far to solve problems independently. The second half of 73 will facilitate this in two steps. The first (Application Challenge) will get you to work on a given problem. The next step (Mini Project) will allow you more freedom to pick a problem of your choice. Since this can still be overwhelming to handle individually, you will work in groups to help each other whenever possible.\n\n\nThere are many benefits to be reaped from the second half of the course. The ones I am focussed on are:\n\nAppreciate the breadth of possibilities that computational techniques can unlock.\nEngage in collaborative work to effectively utilise each group member’s strengths, thereby collectively accomplishing the assigned tasks.\nGradually gain the confidence necessary to write your own code independently.\nDevelop your ability to utilise resources from both within the course and external sources to support your learning and problem-solving.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Overview"
    ]
  },
  {
    "objectID": "docs/applications_challenge/01_applications-challenge-overview.html#learning-objectives",
    "href": "docs/applications_challenge/01_applications-challenge-overview.html#learning-objectives",
    "title": "Overview",
    "section": "",
    "text": "There are many benefits to be reaped from the second half of the course. The ones I am focussed on are:\n\nAppreciate the breadth of possibilities that computational techniques can unlock.\nEngage in collaborative work to effectively utilise each group member’s strengths, thereby collectively accomplishing the assigned tasks.\nGradually gain the confidence necessary to write your own code independently.\nDevelop your ability to utilise resources from both within the course and external sources to support your learning and problem-solving.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Overview"
    ]
  },
  {
    "objectID": "docs/applications_challenge/01_applications-challenge-overview.html#a-new-tool-colab",
    "href": "docs/applications_challenge/01_applications-challenge-overview.html#a-new-tool-colab",
    "title": "Overview",
    "section": "A new tool: Colab",
    "text": "A new tool: Colab\nNow that we focus on working as a group, we need an avenue to work collaboratively. For this, we will use a new online tool from Google called Colab. You only need a Google account to access it. More details of how what to do appears in another chapter.\nYou might wonder why we are not using GitHub and ReviewNB for this. While Git and GitHub are top-class tools, I am concerned that learning the mechanics of using them (pushing, pulling, resolving conflicts, and merging) might distract you from Python and science, given you have only about four weeks for the Application Challenge and Mini Project.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Overview"
    ]
  },
  {
    "objectID": "docs/applications_challenge/01_applications-challenge-overview.html#the-knowledge-base",
    "href": "docs/applications_challenge/01_applications-challenge-overview.html#the-knowledge-base",
    "title": "Overview",
    "section": "The Knowledge Base",
    "text": "The Knowledge Base\nThe Knowledge Base is a collection of examples where programming (in the guise of Python) is used for scientific purposes. These should give you a flavor of what computing can do for science. The material in the Knowledge Base is more or less self-contained.\nYou are not meant to consume all of the Knowledge Base. Instead, pick and choose items that interest you and are relevant to the Application Challenge your group has selected. You might have to learn a thing or two from one part to make sense of another. How deeply you want to do this is up to you.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Overview"
    ]
  },
  {
    "objectID": "docs/applications_challenge/01_applications-challenge-overview.html#the-importance-of-working-in-a-group",
    "href": "docs/applications_challenge/01_applications-challenge-overview.html#the-importance-of-working-in-a-group",
    "title": "Overview",
    "section": "The importance of working in a group",
    "text": "The importance of working in a group\nParticipating in group work offers a chance to develop and hone vital communication and strategic skills that will be invaluable for future endeavours. Working together on a problem is a great learning experience. It lets you see how others think, learn from their ideas, and improve your own by defending your thoughts. Plus, you’ll spend time helping each other, ensuring everyone contributes – and that’s a good thing for learning.\nFor those of you who might be tempted to dismiss all this as a cliché, I would like to share how, even recently, I have (unfortunately) observed how academic collaborations break up and how graduate students quit due to challenges due to poor interpersonal skills. So, you should always welcome any opportunity to cultivate self-awareness and gain insights into your behaviour and interactions within a group. I am not suggesting that this group experience is a panacea, but it will definitely help.\nFinally, I like to distinguish between working as a group and working as a team. The former is a temporary, lukewarm marriage of convenience, while the latter is the coming together of like minds in a conducive environment of tolerance and support to achieve a goal. If you are lucky, you will also enjoy being in a team.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Overview"
    ]
  },
  {
    "objectID": "docs/applications_challenge/01_applications-challenge-overview.html#always-remember-the-individual-viva",
    "href": "docs/applications_challenge/01_applications-challenge-overview.html#always-remember-the-individual-viva",
    "title": "Overview",
    "section": "Always remember the individual viva",
    "text": "Always remember the individual viva\nPlease bear in mind that the content of the second half will be central to the individual viva. So, as a group member, you should be nurturing and mindful that all your group mates keep up and understand what is happening. As an individual, you should ensure that you are abreast of everything done or submitted by the group. Come the viva(which is 35% of your grade), you will have to defend this content on your own.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Overview"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/analysing-graduate-data.html",
    "href": "docs/applications_challenge/questions/analysing-graduate-data.html",
    "title": "13| Graduate Data",
    "section": "",
    "text": "The Singapore government maintains and publicly shares various datasets at Data.gov.sg. In this question, we will analyse the median salaries of graduates from the different universities in Singapore.\n\n\nThis question heavily utilises the package called Pandas. Pandas is the de facto package for all things related to data analysis. You must familiarise yourself (see the Knowledge Lake) with how to use Pandas to work on this problem.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "13| Graduate Data"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/analysing-graduate-data.html#you-need-pandas",
    "href": "docs/applications_challenge/questions/analysing-graduate-data.html#you-need-pandas",
    "title": "13| Graduate Data",
    "section": "",
    "text": "This question heavily utilises the package called Pandas. Pandas is the de facto package for all things related to data analysis. You must familiarise yourself (see the Knowledge Lake) with how to use Pandas to work on this problem.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "13| Graduate Data"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/vibrot-spectrum_question.html",
    "href": "docs/applications_challenge/questions/vibrot-spectrum_question.html",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "We know from our basic chemistry lessons that atoms have energy levels. For example, the hydrogen atom’s ground state (\\(n=1\\)) has an energy of -13.6 eV, and the next excited state (\\(n=2\\)) has an energy of -3.4 eV. We also know that electrons can get excited to higher energy levels and spontaneously decay to a lower energy level. In this process, the electron will emit energy corresponding to the difference in energy levels. So, an electron making the transition \\(n=2 \\rightarrow 1\\) will emit a photon of energy 10.2 eV. This corresponds to a wavelength of 121.6 nm. These electronic transitions lead to what we refer to as atomic spectra.\nMolecules, too, have electronic energy levels. However, they also have rotational and vibrational energy levels. However, the energy levels corresponding to these types of motions are lower than electronic levels. Hence, the corresponding emissions are related to the infrared and microwave parts of the electromagnetic spectrum.\nYou can obtain the wavelength corresponding to a photon using the formula \\(E = \\dfrac{hc}{\\lambda}\\). \\(h\\) is Planck’s constant, \\(6.626 \\times 10^{-34}\\) Js and \\(c\\) is \\(2.998\\times 10^8\\) m/s, the speed of light in vacuum.\n\n\n\nThe rotational energy levels of a diatomic molecule (like HCl or CO) is given by:\n\\[\nE_\\text{ROT,$J$} = BJ(J+1)  \n\\tag{1}\\]\n\\(J = 0, 1, 2,3,\\ldots\\) is the quantum number associated with the rotational motion. \\(B\\) is called the Rotational constant and is given by:\n\\[\nB = \\dfrac{h^2}{8\\pi^2 I}   \n\\tag{2}\\]\nWhere \\(I\\) is the moment of inertia of the molecule about its centre-of-mass given by:\n\\[\nI = \\mu r^2_\\text{bond length}  \n\\tag{3}\\]\nWhere:\n\\[\n\\mu = \\dfrac{m_1 m_2}{m_1 + m_2}\n\\tag{4}\\]\nand \\(m_1\\) and \\(m_2\\) are the massess of the atoms and \\(r_\\text{bond length}\\) is the bond length.\nThe rules of quantum mechanics restrict the transitions between rotational energy levels in a molecule, which are specified by selection rules. The selection rule is a consequence of the conservation of angular momentum in the molecule. The selection rule for rotational transitions for a diatomic system is:\n\\[\n\\Delta J = \\pm 1\n\\tag{5}\\]\nThis means that the change in the rotational quantum number (\\(J\\)) between the initial and final states of the transition can only be plus or minus one.\n\n\n\nThere are multiple ways for a molecule to rotate. This is reflected in quantum mechanics by a concept called degeneracy, meaning that a given energy state can exist in multiple ways. The number of ways is called the degeneracy of the system.\nRotational states have a degeneracy given by:\n\\[\n\\text{Rotational degeneracy} = 2J +1\n\\]{#eq-x)\n\n\n\nA photon will be emitted whenever there is a transition between two allowed \\(J\\) values. The more transitions there are, the greater the number of photons emitted. Therefore, the intensity or brightness of the corresponding spectral line depends on how many transitions occur. Two factors determine this number of transitions.\nOne is how many molecules are in the initial and final energy (\\(J\\)) states. This is determined by the temperature of the system and is given by the famous Boltzmann distribution:\n\\[\n\\dfrac{N_m}{N_n} = e^{-\\left(\\dfrac{E_m - E_n}{k_b T}\\right)}   \n\\tag{6}\\]\nThe second is the degeneracy of the states.\n\n\n\nThe vibrational energy levels of a diatomic molecule (like HCl or CO) is given by:\n\\[\nE_\\text{VIB,$\\nu$} = \\left(\\nu+\\dfrac{1}{2}\\right) h\\omega_\\text{osc\n\\tag{7}\\]\n\\(\\nu = 0, 1, 2,3,\\ldots\\) is the quantum number associated with the rotational motion. \\(\\omega_\\text{osc}\\) is the natural angular frequency (radians/second) of the oscillations and is given by:\n\\[\n\\omega_\\text{osc}   = \\dfrac{1}{2\\pi}\\sqrt{\\dfrac{k}{\\mu}}  \n\\tag{8}\\]\n\\(k\\) represents the strength of the bond.\nThe selection rules for vibrational transitions are:\n\\[\n\\Delta \\nu = \\pm 1, \\pm 2, \\pm 3, \\ldots    \n\\tag{9}\\]\n\n\n\nIn reality, a molecule both rotates and vibrates. So, the energy levels of a molecule are more accurately described by:\n\\[\nE_\\text{VIB-ROT,$J, \\nu$} = BJ(J+1) + \\left(\\nu+\\dfrac{1}{2}\\right) h\\omega_\\text{osc}  \n\\tag{10}\\]\nThe energy transitions follow both transition rules:\n\\[\\begin{align}\n\\Delta J &= \\pm 1 \\\\\n\\Delta \\nu &= \\pm 1, \\pm 2, \\pm 3, \\ldots   \n\\end{align}\\]\n\n\n\n\n\n\nQuantity\nValue\n\n\n\n\nMass of \\(^{1}\\)H\n\\(1.673 \\times 10^{−27}\\) kg\n\n\nMass of \\(^{35}\\)Cl\n\\(58.06 \\times 10^{−27}\\) kg\n\n\nBond length (\\(r_\\text{bond length}\\))\n\\(0.127\\) nm\n\n\nBond strength (\\(k\\))\n\\(516\\) Nm\\(^{-1}\\)",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "14| Vibrational Rotational Spectrum of HCl"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/vibrot-spectrum_question.html#energy-levels",
    "href": "docs/applications_challenge/questions/vibrot-spectrum_question.html#energy-levels",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "We know from our basic chemistry lessons that atoms have energy levels. For example, the hydrogen atom’s ground state (\\(n=1\\)) has an energy of -13.6 eV, and the next excited state (\\(n=2\\)) has an energy of -3.4 eV. We also know that electrons can get excited to higher energy levels and spontaneously decay to a lower energy level. In this process, the electron will emit energy corresponding to the difference in energy levels. So, an electron making the transition \\(n=2 \\rightarrow 1\\) will emit a photon of energy 10.2 eV. This corresponds to a wavelength of 121.6 nm. These electronic transitions lead to what we refer to as atomic spectra.\nMolecules, too, have electronic energy levels. However, they also have rotational and vibrational energy levels. However, the energy levels corresponding to these types of motions are lower than electronic levels. Hence, the corresponding emissions are related to the infrared and microwave parts of the electromagnetic spectrum.\nYou can obtain the wavelength corresponding to a photon using the formula \\(E = \\dfrac{hc}{\\lambda}\\). \\(h\\) is Planck’s constant, \\(6.626 \\times 10^{-34}\\) Js and \\(c\\) is \\(2.998\\times 10^8\\) m/s, the speed of light in vacuum.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "14| Vibrational Rotational Spectrum of HCl"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/vibrot-spectrum_question.html#rotational-energy-levels",
    "href": "docs/applications_challenge/questions/vibrot-spectrum_question.html#rotational-energy-levels",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "The rotational energy levels of a diatomic molecule (like HCl or CO) is given by:\n\\[\nE_\\text{ROT,$J$} = BJ(J+1)  \n\\tag{1}\\]\n\\(J = 0, 1, 2,3,\\ldots\\) is the quantum number associated with the rotational motion. \\(B\\) is called the Rotational constant and is given by:\n\\[\nB = \\dfrac{h^2}{8\\pi^2 I}   \n\\tag{2}\\]\nWhere \\(I\\) is the moment of inertia of the molecule about its centre-of-mass given by:\n\\[\nI = \\mu r^2_\\text{bond length}  \n\\tag{3}\\]\nWhere:\n\\[\n\\mu = \\dfrac{m_1 m_2}{m_1 + m_2}\n\\tag{4}\\]\nand \\(m_1\\) and \\(m_2\\) are the massess of the atoms and \\(r_\\text{bond length}\\) is the bond length.\nThe rules of quantum mechanics restrict the transitions between rotational energy levels in a molecule, which are specified by selection rules. The selection rule is a consequence of the conservation of angular momentum in the molecule. The selection rule for rotational transitions for a diatomic system is:\n\\[\n\\Delta J = \\pm 1\n\\tag{5}\\]\nThis means that the change in the rotational quantum number (\\(J\\)) between the initial and final states of the transition can only be plus or minus one.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "14| Vibrational Rotational Spectrum of HCl"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/vibrot-spectrum_question.html#degeneracy-of-states",
    "href": "docs/applications_challenge/questions/vibrot-spectrum_question.html#degeneracy-of-states",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "There are multiple ways for a molecule to rotate. This is reflected in quantum mechanics by a concept called degeneracy, meaning that a given energy state can exist in multiple ways. The number of ways is called the degeneracy of the system.\nRotational states have a degeneracy given by:\n\\[\n\\text{Rotational degeneracy} = 2J +1\n\\]{#eq-x)",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "14| Vibrational Rotational Spectrum of HCl"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/vibrot-spectrum_question.html#intensity-of-the-spectrums",
    "href": "docs/applications_challenge/questions/vibrot-spectrum_question.html#intensity-of-the-spectrums",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "A photon will be emitted whenever there is a transition between two allowed \\(J\\) values. The more transitions there are, the greater the number of photons emitted. Therefore, the intensity or brightness of the corresponding spectral line depends on how many transitions occur. Two factors determine this number of transitions.\nOne is how many molecules are in the initial and final energy (\\(J\\)) states. This is determined by the temperature of the system and is given by the famous Boltzmann distribution:\n\\[\n\\dfrac{N_m}{N_n} = e^{-\\left(\\dfrac{E_m - E_n}{k_b T}\\right)}   \n\\tag{6}\\]\nThe second is the degeneracy of the states.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "14| Vibrational Rotational Spectrum of HCl"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/vibrot-spectrum_question.html#vibrational-energy-levels",
    "href": "docs/applications_challenge/questions/vibrot-spectrum_question.html#vibrational-energy-levels",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "The vibrational energy levels of a diatomic molecule (like HCl or CO) is given by:\n\\[\nE_\\text{VIB,$\\nu$} = \\left(\\nu+\\dfrac{1}{2}\\right) h\\omega_\\text{osc\n\\tag{7}\\]\n\\(\\nu = 0, 1, 2,3,\\ldots\\) is the quantum number associated with the rotational motion. \\(\\omega_\\text{osc}\\) is the natural angular frequency (radians/second) of the oscillations and is given by:\n\\[\n\\omega_\\text{osc}   = \\dfrac{1}{2\\pi}\\sqrt{\\dfrac{k}{\\mu}}  \n\\tag{8}\\]\n\\(k\\) represents the strength of the bond.\nThe selection rules for vibrational transitions are:\n\\[\n\\Delta \\nu = \\pm 1, \\pm 2, \\pm 3, \\ldots    \n\\tag{9}\\]",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "14| Vibrational Rotational Spectrum of HCl"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/vibrot-spectrum_question.html#rotational-vibrational-energy-levels",
    "href": "docs/applications_challenge/questions/vibrot-spectrum_question.html#rotational-vibrational-energy-levels",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "In reality, a molecule both rotates and vibrates. So, the energy levels of a molecule are more accurately described by:\n\\[\nE_\\text{VIB-ROT,$J, \\nu$} = BJ(J+1) + \\left(\\nu+\\dfrac{1}{2}\\right) h\\omega_\\text{osc}  \n\\tag{10}\\]\nThe energy transitions follow both transition rules:\n\\[\\begin{align}\n\\Delta J &= \\pm 1 \\\\\n\\Delta \\nu &= \\pm 1, \\pm 2, \\pm 3, \\ldots   \n\\end{align}\\]",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "14| Vibrational Rotational Spectrum of HCl"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/vibrot-spectrum_question.html#data-for-hcl",
    "href": "docs/applications_challenge/questions/vibrot-spectrum_question.html#data-for-hcl",
    "title": "14| Vibrational Rotational Spectrum of HCl",
    "section": "",
    "text": "Quantity\nValue\n\n\n\n\nMass of \\(^{1}\\)H\n\\(1.673 \\times 10^{−27}\\) kg\n\n\nMass of \\(^{35}\\)Cl\n\\(58.06 \\times 10^{−27}\\) kg\n\n\nBond length (\\(r_\\text{bond length}\\))\n\\(0.127\\) nm\n\n\nBond strength (\\(k\\))\n\\(516\\) Nm\\(^{-1}\\)",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "14| Vibrational Rotational Spectrum of HCl"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/humpty-dumpty-ir-spectra_question.html",
    "href": "docs/applications_challenge/questions/humpty-dumpty-ir-spectra_question.html",
    "title": "06| Humpty Dumpty IR Spectra",
    "section": "",
    "text": "Scenario\nYou are part of a large team of (idiosyncratic) scientists whose passion is to measure IR spectra of chemical compounds. They have just finished collecting the data for Toluene, 1-Octene and Ethanol. Unfortunately, in their abundant enthusiasm, many factions have used the same instrument to make multiple measurements. You can access a zip file of all the data collected at humpty-dumpty-ir-data.zip.\n\n\nTasks\n\nTask 1Task 2\n\n\n\nConsolidate the data\nYour role in the team is to consolidate all the data. Here are some things you need to be aware of:\n\nEach file name starts with a random number.\nDifferent files may have different delimiters.\nDifferent files for a given compound can contain overlapping data, so you must ensure that each data point is only included once.\nFor a given compound, measured values of transmittance for a given wavenumber are consistent across all files.\nFor some weird reason, the scientists thought it was neat to write the names of the compounds using a mixture of uppercase and lowercase letters!\n\nNote:\n\nYou can only use basic Python and the packages Numpy, glob, and os. You cannot use any other specialised packages or software.\nDo not modify the original files.\n\n\n\n\n\nTime to plot\nOnce you have consolidated your data, generate a plot similar to the following.\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "06| Humpty Dumpty IR Spectra"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/about-a-pendulum.html",
    "href": "docs/applications_challenge/questions/about-a-pendulum.html",
    "title": "10| About a Pendulum",
    "section": "",
    "text": "Introduction\nIn this question, we will use our knowledge of segmentation analysis to develop tools for tracking motion. We will work with a simple video of a pendulum (pendulum.mp4) captured using my handphone. Once we track (i.e., extract its position-time information) the pendulum’s motion, we can plot and apply a more mathematical analysis to understand the motion better.\n\nOops: As you can see, the orientation of the video is wrong, sorry. Guess you will have to do something about that.\n\n\nTasks\n\nFigure out a way to extract the individual frames of the video.There are many ways (e.g., Python, ImageJ, ImageMagick, …) to do this so pick one that you like.Please indicate what you used.\nUsing either a ‘low-level’ approach using basic Numpy arrays or a ‘high-level’ approach using a package (e.g., scikit-image) extract the \\((t,x,y)\\) information of the pendulum bob and plot them.\nUse the SciPy functioncurve_fit() to fit a function of the form \\(A \\sin(2\\pi f t + \\alpha)\\) to your tracking data. The results should look like the red line of the plot shown below.\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "10| About a Pendulum"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/researchers-frustration.html",
    "href": "docs/applications_challenge/questions/researchers-frustration.html",
    "title": "05| A Researcher’s Frustration",
    "section": "",
    "text": "Introduction\nYou are the lead researcher in an international collaboration involving five countries (Singapore, US, UK, Australia New Zealand). The research project consists of measuring the height of an adult macaque species. The project is at its end, and you are collating all the data measured by your collaborators.\nUpon trying to combine the data files from your collaborators, you realise (in incredulous frustration) that each of your collaborators has made their measurements using a different unit! Here are the units that were used.\n\n\n\n\nCountry\nUnit\n\n\n\n\nSingapore\nmetres\n\n\nUK\ninches\n\n\nUS\nfeet\n\n\nAustralia\ncentimetres\n\n\nNew Zealand\nmillimeters\n\n\n\n\nYou can download the data here\n\n\nTasks\nWrite some Python code to:\n\nProduce a copy of the data that is ‘corrected’ to SI units.\n\nName these files with an ‘_si’ at the end.\n\nOrganise your data files in the following file structure\n\n\n\n\n\n\ngraph TB\nA(All Data)    --&gt;B(SIN) \n         A --&gt;C(AUS)\n         A --&gt;D(UK)\n         A --&gt;E(US)\n         A --&gt;F(NZ)\n         B --&gt;G(SI)\n         C --&gt;I(SI)\n         C --&gt;J(ORIGINAL)\n         D --&gt;K(SI)\n         D --&gt;L(ORIGINAL)\n         E --&gt;M(SI)\n         E --&gt;N(ORIGINAL)\n         F --&gt;O(SI)\n         F --&gt;P(ORIGINAL)\n\n\n\n\n\n\n\nPlot histograms of the data.\n\nPlot a histogram for each of the countries as a separate plot,\nPlot histograms of the countries as a grid of plots,\nPlot a histogram for the combined data. \n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "05| A Researcher’s Frustration"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/about-plotting.html",
    "href": "docs/applications_challenge/questions/about-plotting.html",
    "title": "01| About Plotting",
    "section": "",
    "text": "This challenge involves two mini-challenges related to plotting. Enjoy",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "01| About Plotting"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/about-plotting.html#introduction-1",
    "href": "docs/applications_challenge/questions/about-plotting.html#introduction-1",
    "title": "01| About Plotting",
    "section": "Introduction",
    "text": "Introduction\nA simple model for the interaction potential between two atoms as a function of their distance, \\(r\\), is the Lennard-Jones potential given by:\n\\[\nU(r) = \\dfrac{B}{ r^{12}} − \\dfrac{A}{r^{6}}\n\\tag{1}\\]\nWhere \\(A\\) and \\(B\\) are positive constants.\nThis was popular in the early days of computing because \\(r^{−12}\\) is easy to compute as the square of \\(r^{−6}\\). So, it was also sometimes called the 6-12 potential.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "01| About Plotting"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/about-plotting.html#tasks",
    "href": "docs/applications_challenge/questions/about-plotting.html#tasks",
    "title": "01| About Plotting",
    "section": "Tasks",
    "text": "Tasks\n\nPlot \\(U(r)\\) for Argon atoms where \\(A = 1.024 \\times 10^{−23}\\) J nm\\(^6\\) and \\(B = 1.582 \\times 10^{−26}\\) J nm\\(^{12}\\).\n\nYour plot should show the ‘interesting’ part of this curve, which tends rapidly to infinity for small values of \\(r\\) and zero for large \\(r\\).\nConsider swapping units by dividing \\(A\\) and \\(B\\) by the Boltzmann’s constant to measure \\(U(r)\\) in units of K.\n\nWhat is the depth, \\(\\epsilon\\), and location, \\(r_0\\), of the potential minimum for this system? Remember to think like a scientist, not a programmer! Indicate these values by drawing horizontal and vertical lines at these locations.\nOn the same figure show the interatomic force given by: \\[\nF(r) = −\\dfrac{dU}{dr} = \\dfrac{12 B}{ r^{13}} − \\dfrac{6 A}{r^{7}}\n  \\tag{2}\\]\nFor small displacements from the equilibrium interatomic separation (where \\(F = 0\\)), the potential may be approximated to the harmonic oscillator function,\n\\[\nV(r) = \\dfrac{1}{2}k(r-r_0)^2+ \\epsilon\n  \\tag{3}\\]\nwhere\n\\[\nk = \\left|\\dfrac{d^2U}{dr^2}\\right|_{r_0}= \\dfrac{156 B}{ {r_0}^{14}} − \\dfrac{42 A}{{r_0}^{8}}\n  \\tag{4}\\]\nPlot \\(U(r)\\) and \\(V(r)\\) on the same figure but as a separate subplot.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "01| About Plotting"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/jcamp-jdx_question.html",
    "href": "docs/applications_challenge/questions/jcamp-jdx_question.html",
    "title": "07| Parsing JCAMP-JDX files",
    "section": "",
    "text": "Introduction\nIn this problem, we will focus on how to use JCAMP-DX files. JCAMP-DX is a file format for storing and exchanging data from spectroscopic measurements, such as infrared and Raman spectra. JCAMP stands for Joint Committee on Atomic and Molecular Physical Data (jcamp-dx.org), a committee responsible for developing and maintaining standards for the exchange of spectroscopic data.\nThe JCAMP-DX format is a text-based format that includes both data and metadata. It supports a wide range of spectroscopic techniques and allows storing many different data types, including spectra, chromatograms, and mass spectrometry. The format is widely used in the scientific community and is considered a standard for exchanging spectroscopic data. In particular, NIST uses the JCAMP-DX to share data in the NIST Chemistry WebBook.\nJCAMP-DX files typically have a .jdx file extension. Many software applications, such as Notepad or TextEdit, can open them. However, to be useful, the file needs to be parsed, i.e., its content analysed and any essential data extracted.\n\n\nTasks\n\nTask 1Task 2Task 3\n\n\n\nGet data\nVisit the NIST Chemistry WebBook and download the data in JCAMP-DX format for the IR spectra of:\n1. Carbon-dioxide\n2. Water\n3. Methane \n\n\n\n\nWrite your own parsing code\nWrite a Python script to extract the IR spectral data from your downloaded files.\nNote: \n\nUse only basic Python and Numpy. You cannot use any specialised packages or software.\nDo not modify the original file from NIST.\n\n\n\n\n\nTime to plot\nUse your previous code snippet to extract the relevant data and generate a plot similar to the following:\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "07| Parsing JCAMP-JDX files"
    ]
  },
  {
    "objectID": "docs/applications_challenge/03_the-questions.html",
    "href": "docs/applications_challenge/03_the-questions.html",
    "title": "02| Bisection Method",
    "section": "",
    "text": "Instructions\n\n\n1 Introduction\nThe values of \\(x\\) that satisfy \\(f(x) = 0\\) are called the roots of \\(f(x)\\). Finding the roots of equations is important in science and engineering, but some equations, such as \\(\\cos x - x = 0\\) (called transcendental equations), cannot be solved analytically. In such cases, numerical methods are needed. One such method is the Bisection method.\nTo understand how the Bisection method works, notice that the function has opposite signs on either side of the root. The Bisection method uses this fact to ‘box in’ the root. Here’s how it works:\n\nPick two values of \\(x\\) (let’s call them \\(x_\\text{left}\\) and \\(x_\\text{right}\\)) that we know lie on opposite sides of the root.\nDetermine the midpoint \\(x_\\text{mid}\\) of \\(x_\\text{left}\\) and \\(x_\\text{right}\\), and evaluate the function at this point.\nIf the sign of \\(f(x_\\text{mid})\\) is the same as the sign \\(f(x_\\text{left})\\), then replace \\(x_\\text{left}\\) with \\(x_\\text{mid}\\). Else, replace \\(x_\\text{right}\\) with the midpoint.\nNow you have narrowed the range of the root to \\((x_\\text{left}, x_\\text{mid})\\) or \\((x_\\text{mid}, x_\\text{right})\\). Continue steps 2-4 until you have achieved the desired accuracy for the root.\n\nThe Bisection method is a simple but effective root-finding algorithm that can be implemented using only basic Python programming.\n\n\n2 Tasks\n\nPlot for an estimate\nGet an estimate for the root of \\(\\cos x - x =0\\) by plotting the functions \\(\\cos x\\) and \\(x\\).\nUse bisection\nUse the bisection method to determine the root of \\(\\cos x - x =0\\) to 10 decimal places.\n(Answer = 0.739_085_133_2)\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/classes/classes_01.html",
    "href": "docs/classes/classes_01.html",
    "title": "Classes 1 (Nice)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Classes 1 (Nice)"
    ]
  },
  {
    "objectID": "docs/classes/classes_01.html#setting-up-a-simple-class",
    "href": "docs/classes/classes_01.html#setting-up-a-simple-class",
    "title": "Classes 1 (Nice)",
    "section": "2.1 Setting up a simple class",
    "text": "2.1 Setting up a simple class\nLet’s create a class to represent a particle. We will use this later to simulate it bouncing off a wall. To keep things simple, I will start with a 1D geometry. A particle typically has a mass, a radius (assuming it’s spherical) and a velocity. So, I can do the following.\n\nclass CParticle1D:\n    mass=None\n    position=None\n    radius=None",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Classes 1 (Nice)"
    ]
  },
  {
    "objectID": "docs/classes/classes_01.html#using-the-class",
    "href": "docs/classes/classes_01.html#using-the-class",
    "title": "Classes 1 (Nice)",
    "section": "2.2 Using the class",
    "text": "2.2 Using the class\nNow, let me use this class to create two particles.\n\nparticle_0=CParticle1D()        # Create a new particle\nparticle_0.mass=10             # Set mass for particle 0 \nparticle_0.position=.5         # Set position of particle 0\nparticle_0.radius=.01          # Set the radius of particle 0\n\nparticle_1=CParticle1D()        # Create another particle\nparticle_1.mass=20             # Set mass for particle 1 \nparticle_1.position=.1         # Set position of particle 1\nparticle_1.radius=.01          # Set the radius of particle 1\n\nIn the above snippet, particle_0 and particle_1 are instances of the class CParticle1D. particle_0 and particle_1 are also called objects of the type CParticle1D. This is similar to 1 being an object of the class int.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that objects are instances of a class.\n\n\nOnce you have created your objects, you can use them in your other code. A trivial example is:\n\nprint(f'Particle 0 has mass {particle_0.mass} and is at position {particle_0.position}.')\n\nParticle 0 has mass 10 and is at position 0.5.\n\nprint(f'Particle 1 has mass {particle_1.mass} and is at position {particle_1.position}.')\n\nParticle 1 has mass 20 and is at position 0.1.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Classes 1 (Nice)"
    ]
  },
  {
    "objectID": "docs/classes/classes_01.html#class-vs-object-variables",
    "href": "docs/classes/classes_01.html#class-vs-object-variables",
    "title": "Classes 1 (Nice)",
    "section": "2.3 Class vs Object variables",
    "text": "2.3 Class vs Object variables\nLet’s say we want all the particles we create to be identical (i.e., same mass and size). Classes allow us to quickly implement this by adjusting the variable at the class level. These adjustments will then be visible to all the objects that are created.\nLet’s see this in action.\n\nCParticle1D.mass = 99           # Set the class variable mass\nCParticle1D.radius = .01        # Set the class variable radius\n\nparticle_0=CParticle1D()        # Create a new particle\nparticle_0.position=.5         # Set position of particle 0\n                               # This is the position variable\n                               # of object 0\n\nparticle_1=CParticle1D()        # Create another particle\nparticle_1.position=.1         # Set position of particle 1\n                               # This is the position variable\n                               # of object 1\n\nNow, let’s redo our trivial usage:\n\nprint(f'Particle 0 has mass {particle_0.mass} and is at position {particle_0.position}.')\n\nParticle 0 has mass 99 and is at position 0.5.\n\nprint(f'Particle 1 has mass {particle_1.mass} and is at position {particle_1.position}.')\n\nParticle 1 has mass 99 and is at position 0.1.\n\n\nNotice the distinction between class variables and object variables. When you want to access the class variable, you use the . with the class name. Instead, if you wish to use the object variable, use the . with the object. What you do with the object does not affect the class or other objects (particles, in our case). However, there are subtleties to this that I don’t want to go into now. Let’s discover them later.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Classes 1 (Nice)"
    ]
  },
  {
    "objectID": "docs/classes/classes_01.html#making-it-more-scalable",
    "href": "docs/classes/classes_01.html#making-it-more-scalable",
    "title": "Classes 1 (Nice)",
    "section": "2.4 Making it more scalable",
    "text": "2.4 Making it more scalable\nTypically we want to be able to expand a simulation to a more significant number of particles. Unfortunately, the previous way of creating particles is not very scalable. Here is a slightly better way.\n\n# Make all the particles identical\nCParticle1D.mass=99\nCParticle1D.radius=.01\n\n# Create a list of particles\nall_particles=[CParticle1D()]\nall_particles+=[CParticle1D()]\nall_particles+=[CParticle1D()]\n\n# Initialise with a random position\ni = 0\nall_particles[i].position=np.random.rand()\n\ni += 1\nall_particles[i].position=np.random.rand()\n\ni += 1\nall_particles[i].position=np.random.rand()\n\nHere, I have used NumPy to create a random position.\nLet’s see if it worked:\n\ni = 0\nprint(f'Particle {i}: mass={all_particles[i].mass}, position= {all_particles[i].position:.3f}.')\n\nParticle 0: mass=99, position= 0.715.\n\ni += 1\nprint(f'Particle {i}: mass={all_particles[i].mass}, position= {all_particles[i].position:.3f}.')\n\nParticle 1: mass=99, position= 0.885.\n\ni += 1\nprint(f'Particle {i}: mass={all_particles[i].mass}, position= {all_particles[i].position:.3f}.')\n\nParticle 2: mass=99, position= 0.469.\n\n\nThis is still grossly inefficient for a lazy person like me because it requires lots of typing. It can be made a lot simpler and less error-prone by using loops. I will show this to you later.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Classes 1 (Nice)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#what-do-we-mean-by-changes",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#what-do-we-mean-by-changes",
    "title": "Numerical Solutions (Good)",
    "section": "1.1 What do we mean by changes?",
    "text": "1.1 What do we mean by changes?\nI have often mentioned that differential equations allow us to model systems that change. They also help us capture some of these systems’ essential dynamical features. However, these changes do not necessarily need to be in time. Here are some examples of what we mean by ‘change’:\n\nchange in elevation as you walk along mountainous terrain,\nchange in the nutrients in the soil as you walk along a field,\nchange in nutrients as we dive into the ocean,\nchange in the concentration of a medicine in our blood as the day progresses,\nchange in the brightness of sunlight as the day progresses,\nchange in the population as time passes.\nchanges in how fast a chemical reaction occurs as the reagents’ concentration is depleted.\n\nThe first three examples relate to change in space while the latter three to changes in time. The last is a change in concentration. So, a system can change in almost any parameter that is available!",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#calculus-meaning-and-notation",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#calculus-meaning-and-notation",
    "title": "Numerical Solutions (Good)",
    "section": "1.2 Calculus: Meaning and Notation",
    "text": "1.2 Calculus: Meaning and Notation\nTo get the most out of differential equations, you must speak the language of calculus. This is because calculus allows us to describe changes mathematically. I will use a concrete example of a changing population to see how this works. Incidentally, this is a problem people thought about and solved about 200 years ago!\nSo, where to start? What is a simple model for the change of a population? We can start by assuming that the change in a population will depend on the current size of the population. The justification for this is that fewer people now will mean fewer people later, or more people now will mean even more people later. We can express this idea succinctly as:\n\\[\n\\dfrac{dN(t)}{dt} = r N(t)\\qquad\\qquad\\qquad\\qquad\\text{(1)}\n\\tag{1}\\]\nHere \\(N(t)\\) is the number of people at time \\(t\\) where \\(t\\) is time measured in a convenient unit, say years. \\(\\frac{dN(t)}{dt}\\) tells us how much the \\(N(t)\\) is changing. \\(r\\) is a constant (i.e. a simple number) representing the rate of growth. \\(r\\) is useful to distinguish between different types of populations (e.g. opulent ones with large \\(r\\) vs. less fortunate ones with lower values of \\(r\\)). To make it easier to read, we will write \\(N\\) instead of \\(N(t)\\), but keeping in mind that time \\(t\\) lurks in the background.\nThe symbol \\(\\frac{dN}{dt}\\) on the LHS is read as rate of change of \\(N\\) with respect to \\(t\\). The rate (i.e. \\(\\frac{dN}{dt}\\)) tells us how much \\(N\\) will change if we increase \\(t\\) by a unit (i.e. 1).",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#calculus-getting-a-feel-for-dfracdndt",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#calculus-getting-a-feel-for-dfracdndt",
    "title": "Numerical Solutions (Good)",
    "section": "1.3 Calculus: Getting a feel for \\(\\dfrac{dN}{dt}\\)",
    "text": "1.3 Calculus: Getting a feel for \\(\\dfrac{dN}{dt}\\)\nIf you like, you can get a feel for what this equation is saying by approximating the symbol as a fraction1.\n\\[\n\\dfrac{dN}{dt} \\approx \\dfrac{\\Delta N}{\\Delta t} \\Rightarrow \\Delta N = r N\\;\\Delta t\\qquad\\qquad\\qquad\\qquad\\text{(2)}\n\\tag{2}\\]\nPlease note the approximate sign(\\(\\approx\\)). Our approximation gets better the smaller we make \\(\\Delta t\\). Remember, you already saw this in action in the bucket example. We can use this approximation to build up how \\(N\\) will change as follows:\n\n\n\n\n\n\n\n\n\nTime\nPopulation\nChange for next step\n\n\n\n\n\\[t= 0\\]\n\\[N_0\\]\n\\[\\Delta N = rN_0 \\times \\Delta t\\]\n\n\n\\[t= \\Delta t\\]\n\\[N_1 = N_0 + \\Delta N\\]\n\\[\\Delta N = rN_1 \\times \\Delta t\\]\n\n\n\\[t= 2\\, \\Delta t\\]\n\\[N_2 = N_1 + \\Delta N\\]\n\\[\\Delta N = rN_2 \\times \\Delta t\\]\n\n\n\\[t= 3\\, \\Delta t\\]\n\\[N_3 = N_2 + \\Delta N\\]\n\\[\\Delta N = rN_3 \\times \\Delta t\\]\n\n\n\\[\\ldots\\]\n\\[\\ldots\\]\n\\[\\ldots\\]\n\n\n\n\nNote that \\(N_0\\) is the starting population at \\(t=0\\). So what we want to know is how the population will evolve from there.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that \\(\\dfrac{dy}{dx}\\) tells us how much \\(y\\) changes if you change \\(x\\) by a unit. You can make sense of \\(\\dfrac{dy}{dx}\\) by thinking of the approximation \\(\\dfrac{\\Delta y}{\\Delta x}\\).This approximation gets better the smaller the step.\n\n\n\nStopping a population explosion\nYou will notice that our ‘model’ says the population will keep growing faster and faster. But, this is unrealistic as other factors (such as resources) should come into play. So, an improved model for a population is2:\n\\[\n\\dfrac{dN}{dt} = r N \\left(1- \\dfrac{N}{K}\\right)\\qquad\\qquad\\qquad\\qquad\\text{(3)}\n\\tag{3}\\]\nHere \\(K\\) (called the carrying capacity) represents the maximum population that the system can hold sustainably. You should note how the equation (elegantly) leads to a reduction in population when the population exceeds the carrying capacity(i.e. \\(N &gt; K\\)). When \\(N &gt; K\\) the R.H.S. becomes negative, and the population starts to decrease!",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#the-euler-method",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#the-euler-method",
    "title": "Numerical Solutions (Good)",
    "section": "2.1 The Euler Method",
    "text": "2.1 The Euler Method\nThe Euler Method4 created by the prolific Leonhard Euler is based on equation (2). Here is the recipe that Euler proposed\\(\\ldots\\). I recommend you recall and draw parallels to how we solved our previous bucket problem. This is the one and the same method!\nLet’s say we want to solve the differential equation\n\\[\n\\dfrac{dy}{dt} = f(y,t)\n\\]\nWe approximate it with a fraction:\n\\[\n\\dfrac{dy}{dt} \\approx \\dfrac{\\Delta y}{\\Delta t} = f(y,t)\\Rightarrow \\boxed{\\Delta y= f(y,t)\\Delta t}\n\\tag{4}\\]\nWe can then start with an initial value (condition) \\(y(t=0) = y_a\\) and take small steps away like:\n\n\\[\\begin{array}{c|rcl|rcl}\n\\text{Initial condition} & y_0  &=& y_a & t_0 \\\\\n\\text{Step 1}& y_{1} &=& y_{0} + f(t_0,y_0) \\Delta t & t_1 &=& t_0 + \\Delta t\\\\\n\\text{Step 2}& y_{2} &=& y_{1} + f(t_1,y_1) \\Delta t & t_2 &=& t_1 + \\Delta t\\\\\n\\text{Step 3}& y_{3} &=& y_{2} + f(t_2,y_2) \\Delta t & t_3 &=& t_2 + \\Delta t\\\\\n& \\ldots &=& \\ldots  & \\ldots &=& \\ldots  \\\\\n\\text{Step $n+1$}& y_{n+1} &=& y_{n} + f(t_n,y_n) \\Delta t & t_{n+1} &=& t_{n} + \\Delta t\\\\\n\\end{array}\\]\n\nWhen we follow this recipe, we can get the numerical values of the solution. The more steps we have, the more accurate our values are. This is shown in the figure below. Again, you saw this in action with the bucket example.\n\n\n\n\n\nFinally, I would like to point out that irrespective of how complicated the system or problem is, the strategy you will adopt is the same simple one: Euler!",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#using-euler-for-the-logistic-equation",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#using-euler-for-the-logistic-equation",
    "title": "Numerical Solutions (Good)",
    "section": "2.2 Using Euler for the logistic equation",
    "text": "2.2 Using Euler for the logistic equation\nLet’s solve equation (3) using Euler to see how things work. Luckily for us, this equation can also be solved analytically. So, we can compare how Euler fairs with the ‘real’ solution. Here is the analytical solution:\n\\[\nN(t) = \\dfrac{K}{1+\\left(\\dfrac{K}{N_0}-1\\right)e^{-rt}}\n\\tag{5}\\]\n\ndef logistic(time, N0, carrying_capacity, rate):\n    '''\n    This outputs the exact solution to \n    the logistic differential equation.\n    '''\n    C = 1/N0-1/carrying_capacity\n    output = (1+C*carrying_capacity*np.exp(-rate*time))\n    output = carrying_capacity/output\n    return output\n\n\nN_stop_difference = 1E-2                # Stop running if the change in population\n                                        # between consecutive runs is less than this value\ndt = .1\nN0, K, rate = 10, 100, 3\ndata = {'time': [], 'N': []}\ntime, N = 0, N0\n\nwhile True:\n    data['time'].append(time)\n    data['N'].append(N)\n\n    dN = rate*N*(1-N/K)*dt\n    N += dN\n    time += dt\n\n    # Should we stop the loop?\n    try:\n        # The lists start empty so the following will raise an\n        # error the first two rounds. I am using try to get around it.\n        if np.abs(data['N'][-1]-data['N'][-2]) &lt;= N_stop_difference:\n            break\n    except IndexError:\n        # I am being paranoid and checking if there is an error even\n        # when the list has more than two elements\n        if len(data['N']) &lt; 2:\n            pass\n        else:\n            print('Trouble')\n            quit()\n\nexact_data = logistic(time=np.array(data['time']),\n                      N0=N0,\n                      carrying_capacity=K,\n                      rate=rate)\n\nplt.plot(data['time'], data['N'], '.', label='Numerical')\nplt.plot(data['time'], exact_data,\n         label='Exact', zorder=1)  # zorder pushes the plot back\nplt.legend(loc='lower right')\nplt.ylabel('Population($N$)')\nplt.xlabel('Time')\nplt.hlines(K, 0, data['time'][-1],\n           colors='grey', ls='dashed', zorder=1)\n\n\n\n\n\n\n\nSome things to note about the code\nI like to draw your attention to some programmatically features in the above code that you may not have seen before:\n\nI have used a dictionary to hold the time and population data. Isn’t it more elegant?\nI use a True condition with the while loop. So, it will run until the end of The Universe until I break out on my own.\nTo break out, I check if the population has changed significantly?\n\nThe threshold I am using is \\(0.01\\). To check this, I do not compare the two numbers (Never ever compare two floats!). Instead, I check if the difference between the two is as small as I want.\nI use np.abs() to not worry if the difference is negative.\n\nSince I need to compare two numbers, I will have to wait for at least two rounds for the condition to work. I use try-except to step around the hissy-fit that Python would otherwise throw.\n\nI know what error (IndexError) to use because when I didn’t, Python screamed it at me!",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#the-equations",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#the-equations",
    "title": "Numerical Solutions (Good)",
    "section": "3.1 The equations",
    "text": "3.1 The equations\nIn this section, I will show you how to solve coupled differential equations. The one I have picked is called The Predator-Prey model. It is a simple (really cool) ecological model to describe the predator-prey interactions between foxes and rabbits. You will often see variants of the Predator-Prey model used to study more complicated systems.\nThe basic equations that describe this model are the Lotka-Volterra equations.\n\\[\n\\begin{aligned}\n\\dfrac{dr}{dt} &= \\alpha r - \\beta rf \\\\\n\\dfrac{df}{dt} &= \\delta  fr - \\gamma f\n\\end{aligned}\n\\]\nI have chosen \\(r\\) to represent the rabbits (the prey) and \\(f\\) foxes (the predators). \\(\\alpha, \\beta, \\delta, \\gamma\\) are constants. For our simulation, we will use the values shown below.\n\n\n\n\n\\(\\alpha\\)\n2\n\n\n\\(\\beta\\)\n2\n\n\n\\(\\delta\\)\n3\n\n\n\\(\\gamma\\)\n3",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#example-code",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#example-code",
    "title": "Numerical Solutions (Good)",
    "section": "3.2 Example code",
    "text": "3.2 Example code\n\n\n\n\n\n\nmax_time = 10\ndt = 0.001\nrabbits0, foxes0 = 1, .1\ntime, rabbits, foxes = 0, rabbits0, foxes0\ndata = []\n\n\n# Lotka-Volterra equations\ndef drabbits_dt(rabbits, foxes):\n    a, b = 2, 2\n    return a*rabbits - b*rabbits*foxes\n\n\ndef dfoxes_dt(rabbits, foxes):\n    d, g = 3, 3\n    return d*foxes*rabbits - g*foxes\n\n\nwhile True:\n    data.append([time, rabbits, foxes])\n\n    # Don't update the original variables because we need\n    # the OLD values of rabbits to calculate foxes\n    rabbits_new = rabbits + drabbits_dt(rabbits, foxes)*dt\n\n    # Using the old value of rabbits\n    foxes += dfoxes_dt(rabbits, foxes)*dt\n\n    # No more need for two variables\n    rabbits = rabbits_new\n\n    time += dt\n\n    if time &gt; max_time:\n        break\n\n# Reorganising the data so I can easily access\n# them without having to mess with indices\ndata = np.array(data)\ndata = {\n    'time': data[:, 0],\n    'rabbits': data[:, 1],\n    'foxes': data[:, 2],\n}\n\nfig, ax = plt.subplots(nrows=1, ncols=2)\nax_with_time, ax_with_other = ax\n\n# Plotting the individual species\nax_with_time.plot(data['time'], data['rabbits'], label='Rabbits')\nax_with_time.plot(data['time'], data['foxes'], label='Foxes', alpha=.5)\nax_with_time.set_ylabel('Rabbits/Foxes')\nax_with_time.set_xlabel('Time')\nax_with_time.set_title(f'Rabbits/Foxes vs Time')\nax_with_time.legend()\n\n# Plotting one against the other\nax_with_other.plot(data['rabbits'], data['foxes'])\nax_with_other.set_xlabel('Rabbits')\nax_with_other.set_ylabel('Foxes')\nax_with_other.set_title(f'Foxes vs Rabbits')\n\nThis is a beautiful result. Notice that both the predator and prey show a cyclical trend over time. The rabbit population is the lowest when the foxes peak because of all the feasting. Past this, the foxes start going hungry, reducing their numbers and giving the rabbits a chance to make a comeback. And so the cycle goes on. The plot on the right (called a ‘phase plot’) is my favourite. It shows all the information I just stated. Do you see it? Can you figure out which direction (clockwise or counterclockwise) the flow of time represents?\n\nSome things to note about the code\nI want to highlight a few things about the above code:\n\nNotice how I encapsulated the derivatives in functions. This way of doing things allowed me to worry about what was happening in the loop without any distractions.\nI had to use a new variable rabbit_new to hold the new value of rabbits temporarily. This is because I still need the old value (contained in rabbits) to calculate the new value for foxes. This is a tad subtle; make sure you are comfortable with it!\nThis time, I first used a list data to collect the data and split them into a dictionary later. Some might consider this unnecessary. But it makes the code more readable",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#scipy-odeint",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#scipy-odeint",
    "title": "Numerical Solutions (Good)",
    "section": "4.1 SciPy odeint()",
    "text": "4.1 SciPy odeint()\nThe SciPy function I will use is called odeint(). You can import it as follows:\nfrom scipy.integrate import odeint\nYou get it working by giving it the initial values and functions to calculate the various derivatives. So, if your differential equation is of the form:\n\\[\n\\dfrac{dy}{dx} = f(y,x)\n\\]\nWe need to have a Python function that returns \\(f(y,x)\\) to give odeint(). I have intentionally written \\(y\\) before \\(x\\) here because odeint() expects the dependent variable first and the independent variable after. odeint() allows us to pass other optional variables too. I will now show you how all of these work.\nPlease note that I haven’t shown the code for the plotting because it is identical to that from the non-SciPy examples.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#radioactivity",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#radioactivity",
    "title": "Numerical Solutions (Good)",
    "section": "4.2 Radioactivity",
    "text": "4.2 Radioactivity\n\n\n\n\n\n\nmax_time = 0.05\ndt = .001\ndecay_constant = 142       # For 85 Rb (per Myr)\nN0 = 1                     # Starting value of N (in billions of atoms)\n\n\ndef dNdt(N, time, decay_constant):\n    '''\n    Function for the derivative.\n    '''\n    return - decay_constant*N\n\n\nall_time = np.arange(0, max_time, dt)\n\nall_N = odeint(y0=[N0],                  # Initial values\n               func=dNdt,                # Function for the drivative\n               t=all_time,               # Time span\n               args=(decay_constant,)    # Any arguments to dNdt\n               )",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#logistic-equation",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#logistic-equation",
    "title": "Numerical Solutions (Good)",
    "section": "4.3 Logistic Equation",
    "text": "4.3 Logistic Equation\n\n\n\n\n\n\ndef dNdt(N, time, rate, carrying_capacity):\n    '''\n    Function for the derivative.\n    '''\n    return rate*N*(1-N/carrying_capacity)\n\n\nmax_time, dt = 3, .1\nN0, K, rate = 10, 100, 3\n\ndata = {}\ndata['time'] = np.arange(0, max_time, dt)\ndata['N'] = odeint(dNdt, N0, data['time'], (rate, K))",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#predator-prey",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#predator-prey",
    "title": "Numerical Solutions (Good)",
    "section": "4.4 Predator-Prey",
    "text": "4.4 Predator-Prey\n\n\n\n\n\n\nmax_time = 10\ndt = 0.001\nrabbits0, foxes0 = 1, .1\n\n# Lotka-Volterra equations\ndef dy_dt(y, t):\n    '''\n    Function for the derivative.\n    - y contains all the variables for the simulation \n    - t is the dependant variable\n    '''\n\n    rabbits, foxes = y\n\n    # Rabbits\n    a, b = 2, 2\n    drabbits_dt = a*rabbits - b*rabbits*foxes\n\n    # Foxes\n    d, g = 3, 3\n    dfoxes_dt = d*foxes*rabbits - g*foxes\n\n    return [drabbits_dt, dfoxes_dt]\n\n\ndata = {}\ndata['time'] = np.arange(0, max_time, dt)\n\n# Note the order I pass the rabbit and fox information\nresults = odeint(y0=[rabbits0, foxes0],          # Dependant variable\n                 func=dy_dt,                     # Derivatives\n                 t=data['time']                  # Independant variable\n                 )\n# Extract the individual results (Note, the order matters)\ndata['rabbits'] = results[:, 0]\ndata['foxes'] = results[:, 1]",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/2_numerical_good.html#footnotes",
    "href": "docs/knowledge_lake/numerical/2_numerical_good.html#footnotes",
    "title": "Numerical Solutions (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI want to highlight that \\(\\dfrac{dN}{dt}\\) is a symbol and \\(\\dfrac{\\Delta N}{\\Delta t}\\) is a fraction. So you cannot dismantle a symbol!↩︎\nThis model is due to Verhulst and is often called the Logistic Model.↩︎\n‘Satisfying’ means substituting the solution leads to LHS = RHS↩︎\nIf you are a movie buff, the movie ‘Hidden Figures’ is about how Katherine Johnson plans NASA’s trip to the moon. She used the Euler method for this.↩︎",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html",
    "title": "Random Numbers (Good)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#random-numbers-from-the-normal-distribution",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#random-numbers-from-the-normal-distribution",
    "title": "Random Numbers (Good)",
    "section": "2.1 Random numbers from the Normal distribution",
    "text": "2.1 Random numbers from the Normal distribution\n\n\n\n\n\nBefore we draw random numbers from a Normal distribution (also known as a Gaussian distribution), let’s remind ourselves what the Normal distribution is. With the characteristic shape shown in the plots above (that I borrowed from Wikipedia), the Normal distribution is defined by two parameters. The mean \\(\\mu\\) and the standard deviation \\(\\sigma\\). The mean decides the centre’s location and the standard deviation decides the chubbiness. A feature of the Normal distribution (as indicated in the image above) is that 68% of the points lie between \\(\\mu\\pm\\sigma\\). The mathematical form of this distribution is:\n\\[\nf(x)=\\dfrac{1}{\\sigma \\sqrt{2\\pi}}{\\large e}^{-\\dfrac{1}{2}\\left(\\dfrac{x-\\mu}{\\sigma}\\right)^2}\n\\]\nThe function we need to draw normal random samples is np.random.normal(loc=, scale=, size=). loc is used to specify the mean and scale the standard deviation. For example:\n\nnp.random.normal(loc=5, scale=2, size=10)\n\narray([6.23467679, 5.69110152, 6.2548526 , 4.91412283, 5.26087859,\n       6.01631475, 3.54998986, 3.3420698 , 7.65130615, 6.00569723])",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#visualising-the-random-numbers",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#visualising-the-random-numbers",
    "title": "Random Numbers (Good)",
    "section": "2.2 Visualising the random numbers",
    "text": "2.2 Visualising the random numbers\nIt isn’t easy to see that the above numbers are from a Normal distribution. However, it is easier if we plot the data, as we did before.\n\n\n\n\n\n\nn = 1_000_0\nrandom_numbers = np.random.normal(loc=5, scale=2, size=n)\n\nfig, ax = plt.subplots(nrows=1, ncols=2)\n\naxis = ax[0]\naxis.hist(random_numbers, bins=100, alpha=.25)\naxis.set_xlabel(\"Value of random number\")\naxis.set_ylabel(\"Frequency\")\n\naxis = ax[1]\naxis.scatter(range(n), random_numbers, alpha=.25)\naxis.set_xlabel(\"Position in the random number list\")\naxis.set_ylabel(\"Value of random number\")\n\nI hope this visualisation will help you understand what I meant by drawing a number from a Normal distribution.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#section",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#section",
    "title": "Random Numbers (Good)",
    "section": "2.3 68%?",
    "text": "2.3 68%?\nLet’s check if the Normal random numbers given to us satisfy the 68% condition?\n\nn = 10_000\nmean, sd = 5, 2\nrandom_numbers = np.random.normal(loc=mean, scale=sd, size=n)\n\nmask = (random_numbers &gt;= mean - sd) & (random_numbers &lt;= mean + sd)\n\nprint(f'% of points between 1 std.dev. from the mean: {np.sum(mask)/n*100:.2f}%')\n\n% of points between 1 std.dev. from the mean: 68.43%",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#the-scenario",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#the-scenario",
    "title": "Random Numbers (Good)",
    "section": "3.1 The scenario",
    "text": "3.1 The scenario\nLet’s simulate a simple random walk1 in 1D. The scenario is such that a particle is restricted to moving in 1D (i.e. only along a line). It moves in steps, either one unit to the left or one to the right. The choice of left or right is selected randomly. Let’s take the probability of going right as \\(p\\), and going left is \\(q\\) (\\(=1-p\\)).",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#the-simulation",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#the-simulation",
    "title": "Random Numbers (Good)",
    "section": "3.2 The simulation",
    "text": "3.2 The simulation\nI can encapsulate the above information as a function as follows:\ndef brown_1d(prob_right=.5, no_of_steps=10000):\n    ''' \n        This function returns the final position of the particle \n        after the number of steps.\n        prob_right is the probability of going right.\n    '''\n\n    step_size = 1    \n    x = 0                               # starting x position\n\n    for _ in range(no_of_steps):\n        if rnd.random() &lt; prob_right:   # Go right?\n            x += step_size\n        else:\n            x -= step_size\n\n    return x\nBefore going ahead, I am tired of having to type np.random.! Time to get lazy by:\n\nimport numpy.random as rnd\n\nNow I can just use rnd! So, back to the main story…\nEach time I run this function, I will get a different value. However, I like to see if there is a pattern. Let me repeat an experiment of 1000 steps 10,000 times to see what I get.\nno_of_steps, p = 1_000, .5\nrepeats = 10_000\nresults = [brown_1d(prob_right=p, no_of_steps=no_of_steps)\n           for _ in range(repeats)]\n\nplt.hist(results, bins=25, density=True)\nplt.xlabel(f'Distance from the origin after {no_of_steps} steps')\nplt.title(f'Probability distribution for 1D Random walk with p={p}')\nNote that I have put density=True to ask Matplotlib to normalise the area under the curve to 1.\n\n\n\n\n\nInteresting; the distribution looks familiar since \\(p=.5\\) is symmetrical about the starting position. I am curious to see what happens if I increase the probability \\(p\\) to 0.6. Then, the curve should shift to the right. Let’s see if this happens. I will not show the code because it is the same as above.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#what-does-theory-say",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#what-does-theory-say",
    "title": "Random Numbers (Good)",
    "section": "3.3 What does theory say?",
    "text": "3.3 What does theory say?\nA theoretical analysis of 1D random walks predicts that the distribution of positions should have a mean of \\(N(p - q)\\) and a standard deviation of \\(\\sqrt{4N pq}\\) (where \\(N\\) is the total number of steps). The distribution is actually Binomial, but since we have a large number of steps, it approximates a Gaussian. So, let’s overlay a Normal distribution over our previous plots to see how well our simulation agrees with the theory.\nHere is the function I used for the Normal distribution, which is the equation I showed you earlier.\ndef normal(x, m=0, s=1):\n    '''\n    Probability density function for the\n    Gaussian distribution.\n    '''\n    s2 = s**2\n    output = np.exp(-(x-m)**2/(2*s2))\n    output /= np.sqrt(2*np.pi*s2)\n    return output\nI can use the following code to overlay this on my histogram:\nprob_left = 1 - prob_right                       # q = 1 -p\nmean = no_of_steps * (prob_right - prob_left)    # mean = N(p - q)\nsd = np.sqrt(4*no_of_steps*prob_right*prob_left) # sd = sqrt(4 N p q)\nx = np.unique(results)                           # Numbers that form \n                                                 # the x-axis\nplt.plot(x, normal(x, mean, sd), label='Theoretical')\nHere is what I got.\n \nNeat!\nBy the way, techniques such as the above that involve random numbers are called Monte Carlo methods. This is because random numbers are associated with gambling, and the city of Monte Carlo is famous for the latter.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#the-method",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#the-method",
    "title": "Random Numbers (Good)",
    "section": "4.1 The method",
    "text": "4.1 The method\n\nConsider a circle inscribed on a square surface, as shown above. Let’s take the radius of the circle to be 1. Then, if we throw a large number (\\(N_{total}\\)) of grains of sand randomly onto this surface, the number of grains landing on the green, the circular area will be related to the number on the total area by:\n\\[\n\\begin{align*}\\frac{N_{green}}{N_{total}}\\approx \\frac{\\text{Area of green region}}{\\text{Area of square}}\n\\end{align*}\n\\]\nBut we know the formulae for the areas! So,\n\\[\n\\begin{align*}\n\\frac{\\text{Area of green region}}{\\text{Area of square}}&= \\frac{\\pi (1)^2}{2\\times 2}=\\frac{1}{4}\\pi \\quad\\Rightarrow \\quad\\pi  = 4\\left(\\frac{\\text{Area of green region}}{\\text{Area of square}}\\right)\n\\end{align*}\n\\]\n\\[\n\\text{i.e.}\\qquad\\pi  \\approx 4\\left(\\frac{N_{green}}{N_{total}}\\right)\n\\]\nWe can simulate this experiment by randomly ‘creating’ points (to represent where a grain of sand will land) by using NumPy’s PRNG. We can then decide if this grain of sand is inside or outside to get \\(N_{green}\\) and then go on to get an estimate for \\(\\pi\\)!",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#a-poor-but-intuitive-solution",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#a-poor-but-intuitive-solution",
    "title": "Random Numbers (Good)",
    "section": "4.2 A poor but intuitive solution",
    "text": "4.2 A poor but intuitive solution\nLet me start with a (poor) but intuitive solution by throwing one grain at a time.\n\nN_total = 100_000                             # Yes, Python allows the _\nN_green = 0\n\nfor _ in range(N_total):\n    x = rnd.uniform(low=-1, high=1, size=1)     \n    y = rnd.uniform(low=-1, high=1, size=1)\n    r = np.sqrt(x**2 + y**2)                   # Distance from the origin\n\n    if r &lt;= 1:\n        N_green += 1                           # In or out of the circle\n\n4 * N_green / N_total                          # Estimate for pi\n\n3.13552\n\n\nThis solution is slow because of the way we are drawing out the random number, one at a time",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#a-better-solution",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#a-better-solution",
    "title": "Random Numbers (Good)",
    "section": "4.3 A better solution",
    "text": "4.3 A better solution\nHere is a better solution that generates multiple random numbers at once.\n\nN_total=1_000_000\nx=rnd.uniform(low=-1, high=1, size=N_total)\ny=rnd.uniform(low=-1, high=1, size=N_total)\nN_green= np.sum((x**2+y**2) &lt;= 1)                # Oh! the ease of NumPy!\n\n4 * (N_green / N_total)\n\n3.145332",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#a-smarter-solution",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#a-smarter-solution",
    "title": "Random Numbers (Good)",
    "section": "4.4 A smarter solution",
    "text": "4.4 A smarter solution\nThere is room to improve our algorithm. Notice that if we limit our experiment to only the first quadrant of the circle and the related square, our equation remains the same!\n\\[\\begin{align*}\n\\frac{\\text{Area of green region}}{\\text{Area of square}}&= \\frac{\\pi (1)^2\\color{darkorange}{/4}}{2\\times 2\\color{darkorange}{/4}}=\\frac{1}{4}\\pi \\quad\\Rightarrow \\quad\\pi  = 4\\left(\\frac{\\text{Area of green region}}{\\text{Area of square}}\\right)\n\\end{align*}\\]\nHowever, the range for \\(x\\) and \\(y\\) becomes \\([0,1)\\). So, our statistics have improved drastically! We can now use the faster, simpler rand().\n\nN_total=1_000_000\nx=rnd.rand(N_total)\ny=rnd.rand(N_total)\nN_green=np.sum((x**2+y**2) &lt;= 1)\n\n4 * (N_green / N_total)\n\n3.140268",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/good/2_random_good.html#footnotes",
    "href": "docs/knowledge_lake/random_numbers/good/2_random_good.html#footnotes",
    "title": "Random Numbers (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nRandom walks are important in many branches of science. For example, see here.↩︎",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image/1_images_need.html#what-is-an-image",
    "href": "docs/knowledge_lake/image/1_images_need.html#what-is-an-image",
    "title": "Image Analysis (Need)",
    "section": "1.1 What is an image?",
    "text": "1.1 What is an image?\nConsider the following example where I read the image four-circles.jpg and plot it using Matplotlib.\n\n\n\n\n\n\nimg = plt.imread('four-circles.jpg')\nplt.imshow(img)                       \nplt.axis('off')                       \nplt.show()\n\n\n\n\n\n\nWhat I am really interested in right now is how this image is stored in the variable img\n\nprint(f'{type(img)=}', f'{img.shape=}')\n\ntype(img)=&lt;class 'numpy.ndarray'&gt; img.shape=(1000, 1000, 3)\n\n\nSo Matplotlib stores this image information as a \\(1000 \\times 1000 \\times 3\\), (multi-dimensional) NumPy array! I.e., the image comprises \\(3\\) stacked \\(1000 \\times 1000\\) NumPy arrays. These stacks contain information about the RGB (red, green, blue) channels that make up the image.\nWe can check this by visualizing the ‘layers’ or ‘channels’ separately. I will do this in a bit. But first, we need to check one more thing."
  },
  {
    "objectID": "docs/knowledge_lake/image/1_images_need.html#data-type",
    "href": "docs/knowledge_lake/image/1_images_need.html#data-type",
    "title": "Image Analysis (Need)",
    "section": "1.2 Data type",
    "text": "1.2 Data type\nLet’s see what data type has been used to store this image information. For this, I will look at the type of a single element (say the first one):\n\nprint(f'{type(img[0,0,0])=}')\n\ntype(img[0,0,0])=&lt;class 'numpy.uint8'&gt;\n\n\nSo, the values are stored as the uint8 type. I.e., as a 8-bit, unsigned integer. This means that uint8 can only accommodate unsigned (positive only) numbers from \\(0\\) to \\(2^8-1 = 255\\). So, this can be used to describe 256 distinct levels."
  },
  {
    "objectID": "docs/knowledge_lake/image/1_images_need.html#image-layers-or-channels",
    "href": "docs/knowledge_lake/image/1_images_need.html#image-layers-or-channels",
    "title": "Image Analysis (Need)",
    "section": "1.3 Image Layers (or Channels)",
    "text": "1.3 Image Layers (or Channels)\nI will plot the RBG layers (channels) separately to better understand how the image information is stored.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n\nax_original, ax_red, ax_green, ax_blue = ax\n\nax_original.imshow(img)\nax_original.set_title('Original (RGB)')\n\n# ALL row & ALL columns of layer 0\nax_red.imshow(img[:, :, 0], cmap='gray')\nax_red.set_title('Red Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 1\nax_green.imshow(img[:, :, 1], cmap='gray')\nax_green.set_title('Green Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 2\nax_blue.imshow(img[:, :, 2], cmap='gray')\nax_blue.set_title('Blue Channel(in Grayscale)')\n\n\n\n\nNotice:\n\nFor the red channel, we cannot see the green and blue circles. But we can still see the yellow; you need some red (and green) to make yellow.\nFor the green channel, we cannot see the red and blue circles. But we can still see the yellow; you need some green (and red) to make yellow.\nFor the blue channel, we cannot see the red and green circles. The yellow circle is also not visible. You don’t need blue to make yellow."
  },
  {
    "objectID": "docs/knowledge_lake/image/1_images_need.html#histograms",
    "href": "docs/knowledge_lake/image/1_images_need.html#histograms",
    "title": "Image Analysis (Need)",
    "section": "1.4 Histograms",
    "text": "1.4 Histograms\nQuantitative work with images is based on the understanding that the amount and intensity of a colour has can be related to something real like the amount of a protein. One good way to understand this idea is to create a histogram of the three channels. This is straightforward; we just need to convert the 2D array of numbers into a 1D array by using np.flatten(). Let me demonstrate on four-circles.jpg.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.style.use('bmh')\n\n# Convert the 2D array to a long 1D list using 'flatten'\nr_data = img[:, :, 0].flatten()\ng_data = img[:, :, 1].flatten()\nb_data = img[:, :, 2].flatten()\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_red, ax_green, ax_blue = ax\n\nax_red.hist(r_data, color='red', bins=50, density=True)\nax_red.set_title('Red values')\n\nax_green.hist(g_data, color='green', bins=50, density=True)\nax_green.set_title('Green values')\n\nax_blue.hist(b_data, color='blue', bins=50, density=True)\nax_blue.set_title('Blue values')\n\n\n\n\nNotice\n\nAll three channels have a lot of pixels close to zero intensity. This makes sense because most of the image is empty.\nFor all three channels, the (respective) rightmost peak represents the circles with the pure RGB colour. These have a high intensity (almost maximum, 255) of the colour.\nThe middle peak in the green channel represents the low-intensity green required to make the yellow circle!"
  },
  {
    "objectID": "docs/knowledge_lake/image/1_images_need.html#histograms-1",
    "href": "docs/knowledge_lake/image/1_images_need.html#histograms-1",
    "title": "Image Analysis (Need)",
    "section": "3.1 Histograms",
    "text": "3.1 Histograms\nIn images like this, colour has a quantitative meaning. They directly relate to the protein that has been stained. More colour (say green) means there is more of that protein. One good way to ‘see’ this is to create a histogram of the three channels.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.style.use('bmh')\nimg = plt.imread('golgi.jpg')\n\nr_data = img[:, :, 0].flatten()\ng_data = img[:, :, 1].flatten()\nb_data = img[:, :, 2].flatten()\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_red, ax_green, ax_blue = ax\n\nax_red.hist(r_data, color='red', bins=100, density=True)\nax_red.set_title('Red values')\n\nax_green.hist(g_data, color='green', bins=100, density=True)\nax_green.set_title('Green values')\n\nax_blue.hist(b_data, color='blue', bins=100, density=True)\nax_blue.set_title('Blue values')\n\n\n\n\nNotice\n\nThe intensities of all three channels are low, with blue being almost non-existent(it actually is).\nThere are a lot of pixels with almost no (close to zero) intensity. Again, this makes sense; the image is mostly black."
  },
  {
    "objectID": "docs/knowledge_lake/image/1_images_need.html#noise",
    "href": "docs/knowledge_lake/image/1_images_need.html#noise",
    "title": "Image Analysis (Need)",
    "section": "3.2 Noise",
    "text": "3.2 Noise\n\n\n\n\n\nTake a look at the above image (background.tif). Although it looks black, is it really full of zeros? Let’s take a look at the image data.\n\nimg = plt.imread('background.tif')\nprint(f'{img.shape=}',\n      f'{img.min()=}',\n      f'{img.max()=}',\n      f'{img.mean()=}',\n      f'{img.sum()=}',\n      sep='\\n')\n\nimg.shape=(512, 512, 3)\nimg.min()=0\nimg.max()=28\nimg.mean()=4.996832529703776\nimg.sum()=3929669\n\n\nSo, there are non-zero yet small values. These small values are called noise and are randomly generated due to camera thermal processes. In image processing, it is good to remove/correct noise before doing any quantitative work. This is especially relevant when your signal is weak. I.e., when your signal-to-noise ratio is poor.\nTo correct for noise, you need to decide on a threshold value; signals below this will be considered as noise. There are algorithms to calculate this threshold, but trial and error also works. We have to be careful not to delete too much, or else our signal also gets deleted. This is the reason why measurements should have a good signal-to-noise ratio.\n\nRemoving noise\nI am going to pick a threshold of 25 to ‘remove noise’\n\nthreshold = 20\nimg_no_noise = img.copy()\nimg_no_noise[img_no_noise &lt; threshold] = 0\nprint(f'{img_no_noise.shape=}',\n      f'{img_no_noise.min()=}',\n      f'{img_no_noise.max()=}',\n      f'{img_no_noise.mean()=}',\n      f'{img_no_noise.sum()=}',\n      sep='\\n')\n\nimg_no_noise.shape=(512, 512, 3)\nimg_no_noise.min()=0\nimg_no_noise.max()=28\nimg_no_noise.mean()=0.027776082356770832\nimg_no_noise.sum()=21844\n\n\nNotice how the mean and sum are now much smaller."
  },
  {
    "objectID": "docs/knowledge_lake/image/1_images_need.html#removing-noise-from-golgi.jpg",
    "href": "docs/knowledge_lake/image/1_images_need.html#removing-noise-from-golgi.jpg",
    "title": "Image Analysis (Need)",
    "section": "3.3 Removing noise from golgi.jpg",
    "text": "3.3 Removing noise from golgi.jpg\nNow let me remove noise from golgi.jpg. Since the zeros are not very useful information, in this round, I will remove them before producing the histogram.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# | echo: true\n# | eval: false\n# | file: __cleaned_scripts/golgi_single-frame_matplotlib_remove-noise.py"
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/1_images_need.html#what-is-an-image",
    "href": "docs/knowledge_lake/image_analysis/1_images_need.html#what-is-an-image",
    "title": "Image Analysis (Need)",
    "section": "1.1 What is an image?",
    "text": "1.1 What is an image?\nConsider the following example where I read the image four-circles.jpg and plot it using Matplotlib.\n\n\n\n\n\n\nimg = plt.imread('four-circles.jpg')\nplt.imshow(img)                       \nplt.axis('off')                       \nplt.show()\n\n\n\n\n\n\nWhat I am really interested in right now is how this image is stored in the variable img\n\nprint(f'{type(img)=}', f'{img.shape=}')\n\ntype(img)=&lt;class 'numpy.ndarray'&gt; img.shape=(1000, 1000, 3)\n\n\nSo Matplotlib stores this image information as a \\(1000 \\times 1000 \\times 3\\), (multi-dimensional) NumPy array! I.e., the image comprises \\(3\\) stacked \\(1000 \\times 1000\\) NumPy arrays. These stacks contain information about the RGB (red, green, blue) channels that make up the image.\nWe can check this by visualizing the ‘layers’ or ‘channels’ separately. I will do this in a bit. But first, we need to check one more thing.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/1_images_need.html#data-type",
    "href": "docs/knowledge_lake/image_analysis/1_images_need.html#data-type",
    "title": "Image Analysis (Need)",
    "section": "1.2 Data type",
    "text": "1.2 Data type\nLet’s see what data type has been used to store this image information. For this, I will look at the type of a single element (say the first one):\n\nprint(f'{type(img[0,0,0])=}')\n\ntype(img[0,0,0])=&lt;class 'numpy.uint8'&gt;\n\n\nSo, the values are stored as the uint8 type. I.e., as a 8-bit, unsigned integer. This means that uint8 can only accommodate unsigned (positive only) numbers from \\(0\\) to \\(2^8-1 = 255\\). So, this can be used to describe 256 distinct levels.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/1_images_need.html#image-layers-or-channels",
    "href": "docs/knowledge_lake/image_analysis/1_images_need.html#image-layers-or-channels",
    "title": "Image Analysis (Need)",
    "section": "1.3 Image Layers (or Channels)",
    "text": "1.3 Image Layers (or Channels)\nI will plot the RBG layers (channels) separately to better understand how the image information is stored.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\nfig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n\nax_original, ax_red, ax_green, ax_blue = ax\n\nax_original.imshow(img)\nax_original.set_title('Original (RGB)')\n\n# ALL row & ALL columns of layer 0\nax_red.imshow(img[:, :, 0], cmap='gray')\nax_red.set_title('Red Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 1\nax_green.imshow(img[:, :, 1], cmap='gray')\nax_green.set_title('Green Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 2\nax_blue.imshow(img[:, :, 2], cmap='gray')\nax_blue.set_title('Blue Channel(in Grayscale)')\n\n\n\n\nNotice:\n\nFor the red channel, we cannot see the green and blue circles. But we can still see the yellow; you need some red (and green) to make yellow.\nFor the green channel, we cannot see the red and blue circles. But we can still see the yellow; you need some green (and red) to make yellow.\nFor the blue channel, we cannot see the red and green circles. The yellow circle is also not visible. You don’t need blue to make yellow.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/1_images_need.html#histograms",
    "href": "docs/knowledge_lake/image_analysis/1_images_need.html#histograms",
    "title": "Image Analysis (Need)",
    "section": "1.4 Histograms",
    "text": "1.4 Histograms\nQuantitative work with images is based on the understanding that the amount and intensity of a colour has can be related to something real like the amount of a protein. One good way to understand this idea is to create a histogram of the three channels. This is straightforward; we just need to convert the 2D array of numbers into a 1D array by using np.flatten(). Let me demonstrate on four-circles.jpg.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.style.use('bmh')\n\n# Convert the 2D array to a long 1D list using 'flatten'\nr_data = img[:, :, 0].flatten()\ng_data = img[:, :, 1].flatten()\nb_data = img[:, :, 2].flatten()\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_red, ax_green, ax_blue = ax\n\nax_red.hist(r_data, color='red', bins=50, density=True)\nax_red.set_title('Red values')\n\nax_green.hist(g_data, color='green', bins=50, density=True)\nax_green.set_title('Green values')\n\nax_blue.hist(b_data, color='blue', bins=50, density=True)\nax_blue.set_title('Blue values')\n\n\n\n\nNotice\n\nAll three channels have a lot of pixels close to zero intensity. This makes sense because most of the image is empty.\nFor all three channels, the (respective) rightmost peak represents the circles with the pure RGB colour. These have a high intensity (almost maximum, 255) of the colour.\nThe middle peak in the green channel represents the low-intensity green required to make the yellow circle!",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/1_images_need.html#histograms-1",
    "href": "docs/knowledge_lake/image_analysis/1_images_need.html#histograms-1",
    "title": "Image Analysis (Need)",
    "section": "3.1 Histograms",
    "text": "3.1 Histograms\nIn images like this, colour has a quantitative meaning. They directly relate to the protein that has been stained. More colour (say green) means there is more of that protein. One good way to ‘see’ this is to create a histogram of the three channels.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nplt.style.use('bmh')\nimg = plt.imread('golgi.jpg')\n\nr_data = img[:, :, 0].flatten()\ng_data = img[:, :, 1].flatten()\nb_data = img[:, :, 2].flatten()\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_red, ax_green, ax_blue = ax\n\nax_red.hist(r_data, color='red', bins=100, density=True)\nax_red.set_title('Red values')\n\nax_green.hist(g_data, color='green', bins=100, density=True)\nax_green.set_title('Green values')\n\nax_blue.hist(b_data, color='blue', bins=100, density=True)\nax_blue.set_title('Blue values')\n\n\n\n\nNotice\n\nThe intensities of all three channels are low, with blue being almost non-existent(it actually is).\nThere are a lot of pixels with almost no (close to zero) intensity. Again, this makes sense; the image is mostly black.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/1_images_need.html#noise",
    "href": "docs/knowledge_lake/image_analysis/1_images_need.html#noise",
    "title": "Image Analysis (Need)",
    "section": "3.2 Noise",
    "text": "3.2 Noise\n\n\n\n\n\nTake a look at the above image (background.tif). Although it looks black, is it really full of zeros? Let’s take a look at the image data.\n\nimg = plt.imread('background.tif')\nprint(f'{img.shape=}',\n      f'{img.min()=}',\n      f'{img.max()=}',\n      f'{img.mean()=}',\n      f'{img.sum()=}',\n      sep='\\n')\n\nimg.shape=(512, 512, 3)\nimg.min()=0\nimg.max()=28\nimg.mean()=4.996832529703776\nimg.sum()=3929669\n\n\nSo, there are non-zero yet small values. These small values are called noise and are randomly generated due to camera thermal processes. In image processing, it is good to remove/correct noise before doing any quantitative work. This is especially relevant when your signal is weak. I.e., when your signal-to-noise ratio is poor.\nTo correct for noise, you need to decide on a threshold value; signals below this will be considered as noise. There are algorithms to calculate this threshold, but trial and error also works. We have to be careful not to delete too much, or else our signal also gets deleted. This is the reason why measurements should have a good signal-to-noise ratio.\n\nRemoving noise\nI am going to pick a threshold of 25 to ‘remove noise’\n\nthreshold = 20\nimg_no_noise = img.copy()\nimg_no_noise[img_no_noise &lt; threshold] = 0\nprint(f'{img_no_noise.shape=}',\n      f'{img_no_noise.min()=}',\n      f'{img_no_noise.max()=}',\n      f'{img_no_noise.mean()=}',\n      f'{img_no_noise.sum()=}',\n      sep='\\n')\n\nimg_no_noise.shape=(512, 512, 3)\nimg_no_noise.min()=0\nimg_no_noise.max()=28\nimg_no_noise.mean()=0.027776082356770832\nimg_no_noise.sum()=21844\n\n\nNotice how the mean and sum are now much smaller.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/1_images_need.html#removing-noise-from-golgi.jpg",
    "href": "docs/knowledge_lake/image_analysis/1_images_need.html#removing-noise-from-golgi.jpg",
    "title": "Image Analysis (Need)",
    "section": "3.3 Removing noise from golgi.jpg",
    "text": "3.3 Removing noise from golgi.jpg\nNow let me remove noise from golgi.jpg. Since the zeros are not very useful information, in this round, I will remove them before producing the histogram.\n\nResultCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n# | echo: true\n# | eval: false\n# | file: __cleaned_scripts/golgi_single-frame_matplotlib_remove-noise.py",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/3_pandas_nice.html#setting-the-context",
    "href": "docs/knowledge_lake/pandas/3_pandas_nice.html#setting-the-context",
    "title": "Pandas (Nice)",
    "section": "1.1 Setting the context",
    "text": "1.1 Setting the context\nSeaborn can help tweak our plots based on where we want to use them. This is done with set_context(). The options we have are paper, talk and poster. You can also set a theme (i.e. plotting style).\n\nsns.set_context(\"paper\")\nsns.set_style(\"darkgrid\")",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Nice)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/3_pandas_nice.html#some-examples",
    "href": "docs/knowledge_lake/pandas/3_pandas_nice.html#some-examples",
    "title": "Pandas (Nice)",
    "section": "1.2 Some Examples",
    "text": "1.2 Some Examples\n\n\n\nWe use catplot() is used for categorical data. Show me a bar chart for (the numbers in) column Total based on the categorical variables in column Major. Split the plots into columns according to the categories in Gender.\n\nsns.catplot(data=df, x=\"Major\", y=\"Total\", col=\"Gender\", kind=\"bar\")\n\n\n\n\n\n\n\nplt.show()\n\n\n\n\n\n\n\n\nTry the following:\n\nSwap x and y\nUse row instead of col\nUse hue instead of col\n\n\n\n\nsns.catplot(data=df, x=\"Major\", y=\"Total\", col=\"Gender\", kind=\"box\")\n\n\n\n\n\n\n\n\nTry the following:\n\nSwap x and y.\nUse row instead of col.\nUse hue instead of col.\n\n\n\nUse displot() for plotting distributions. Show me the histogram for the scores in Total separated out based on the Major. Dodge the bars so that they do not overlap.\n\nsns.displot(data=df, x='Total', hue='Major', multiple=\"dodge\")\n\n\n\n\n\n\n\n\nTry the following:\n\nUse row or col instead of hue.\nUse stack instead of dodge.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Nice)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/3_pandas_nice.html#merging-dataframes",
    "href": "docs/knowledge_lake/pandas/3_pandas_nice.html#merging-dataframes",
    "title": "Pandas (Nice)",
    "section": "2.1 Merging dataframes",
    "text": "2.1 Merging dataframes\nIn the last chapter, I used pd.concat() to join two dataframes. pd.concat() is nice because you can give it a list of dataframes to join in one go. However, I now would like to take you through another way of combining the two dummy class dataframes with less hassle using pd.merge(). I have shown the full code below. However, here is the part that deals with pd.merge().\n\nUnderstanding pd.merge()\ndf_combined = pd.merge(\n    left=df_class_1,           # dataframe 1\n    right=df_class_2,          # dataframe 2\n    how='outer',               # Join without losing any data\n    left_on='Student No',      # Use to align dataframe 1\n    right_on='Student No'      # Use to align dataframe 2\n)\nIn the last chapter, we set the dataframe index to the MATRIC_NO in both dataframes so that we could use it to align the various rows during pd.concat(). However, if you use pd.merge(), we can specify two dataframes (using left= and right=) and two columns in these dataframes that can be used for alignment. This is what left_on= and right_on= do.\npd.merge() also has a parameter how= that decides how these two data sets are combined. You must be careful with this one. Here are the\n\n\n\n\n\n\n\nOption\nEffect\n\n\n\n\nleft\nKeep all rows of the left dataframe. If the right has missing on values, fill the right part with NaN\n\n\nright\nKeep all rows of the right dataframe. If the left has missing on values, fill the left part with NaN\n\n\ninner\n(default) Keep only those rows with common left and right data.\n\n\nouter\nKeep all rows of both dataframes. Fill any missing values with NaN\n\n\n\nConvince yourself of how how= works by trying the various options. Here are the results you should get for df_combined.shape.\n\n\n\n\nOption\nEffect\n\n\n\n\nleft\n(35,8)\n\n\nright\n(31,8)\n\n\ninner\n(31,8)\n\n\nouter\n(35,8)\n\n\n\n\n\n\nThe full recipe\n\nfrom matplotlib import pyplot as plt\n\ndf_class_1 = pd.read_excel('dummy-class-1-of-2.xlsx', skiprows=1)\ndf_class_2 = pd.read_excel('dummy-class-2-of-2.xlsx')\n\n# Combine the two datasets\ndf_combined = pd.merge(\n    left=df_class_1,       # dataframe 1\n    right=df_class_2,      # dataframe 2\n    how='outer',           # Join without losing any data\n    left_on='Student No',  # Use to align dataframe 1\n    right_on='Student No'  # Use to align dataframe 2\n)\n\n# Rename columns\ndf_combined.rename(\n    columns={'Student No': 'MATRIC_NO',\n             'Test 1 (30%)': 'Test 1',\n             'Test 2 (20%)': 'Test 2',\n             'Test 3 (50%)': 'Test 3'},\n    inplace=True\n)\n\n# Reorgnise/drop columns\ndf_combined = df_combined[['MATRIC_NO',\n                           'Name', 'Major', 'Gender',\n                           'Test 1', 'Test 2', 'Test 3']\n                          ]\n\n# Replace text with long forms\ndf_combined.replace(\n    to_replace={\n        'PHY': 'Physics',\n        'CHM': 'Chemistry',\n        'LS': 'Life Sciences',\n        'CBIO': 'Comp. Biology',\n        'F': 'Female',\n        'M': 'Male',\n        'NB': 'Non-binary'\n    }, inplace=True\n)\n\n# Remove the ' from Test 2\n\n\ndef clean(text):\n    '''\n    Function to remove ' ' from column 'Test 2'.\n    To be applied using apply()\n    '''\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\n\ndf_combined['Test 2'] = df_combined['Test 2'].apply(clean)\n\n# Update column types\ndf_combined = df_combined.astype({\n    'Gender': 'category',\n    'Major': 'category',\n    'Test 2': 'float'\n}\n)\n\n# df_combined.fillna(0, inplace=True)                      # Fix missing scores\ndf_combined[\"Total\"] = df_combined[['Test 1', 'Test 2', 'Test 3']].sum(axis=1)\ndf_combined = df_combined.round(2)\ndf_combined.to_excel('finalised_scores.xlsx', index=False)\ndf_combined.head()\n\ndf_combined.boxplot(by='Major',\n                    column=['Test 1', 'Test 2', 'Test 3', 'Total'],\n                    vert=False, figsize=(8, 6))\nplt.show()",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Nice)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/3_pandas_nice.html#isin",
    "href": "docs/knowledge_lake/pandas/3_pandas_nice.html#isin",
    "title": "Pandas (Nice)",
    "section": "2.2 isin()",
    "text": "2.2 isin()\n\n\n\ndf_class = pd.read_excel('dummy-class-1-of-2.xlsx', skiprows=1)\n\n#------------------ Drop and reorganise columns  -----------------#\ncolumns_to_keep = ['Student No', 'Name', 'Major', 'Gender',\n                   'Test 1 (30%)', 'Test 2 (20%)']\n\ndf_class = df_class[columns_to_keep]\n\n#------------------------- Rename columns ------------------------#\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 1 (30%)': 'Test 1',\n                   'Test 2 (20%)': 'Test 2'}\n\ndf_class.rename(columns=new_column_info, inplace=True)\n\n#--------------------- Set index to MATRIC_NO --------------------#\ndf_class.set_index('MATRIC_NO', drop=False, inplace=True)\n\n#-------------------------- Rename stuff -------------------------#\nreplace_info = {\n    'PHY': 'Physics',\n    'CHM': 'Chemistry',\n    'LS': 'Life Sciences',\n    'CBIO': 'Comp. Biology',\n    'F': 'Female',\n    'M': 'Male',\n    'NB': 'Non-binary'\n}\n\ndf_class.replace(to_replace=replace_info, inplace=True)\n\n#---------------- Remove the ' ' from column Test 2 --------------#\n\n\ndef clean(text):\n    '''\n    Function to remove ' ' from column 'Test 2'.\n    To be applied using apply()\n    '''\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\n\ndf_class['Test 2'] = df_class['Test 2'].apply(clean)\n\n#--------------- Convert column Test 2 to type float -------------#\nnew_type_info = {'Major': 'category',\n                 'Gender': 'category',\n                 'Test 2': 'float'}\n\ndf_class = df_class.astype(new_type_info)\n\n#------------------------ Add a new column -----------------------#\ndf_class[\"Total\"] = df_class[\"Test 1\"] + df_class[\"Test 2\"]\n\n#------------------------- Export the file -----------------------#\ndf_class.to_excel('finalised_scores.xlsx', index=False)\n\ndf_class.head()\n\nLet’s say we want to find out if ‘Ronin Christian’ and ‘Maryjane Sandoval’ are in the class and how they are doing. Let me show you another way to generate a mask using the method isin(), which queries the whole dataframe.\n\nmask = df_class.isin(['Maryjane Sandoval', 'Ronin Christian'])\ndf_class[mask]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1282849W\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA5408925A\n\n\nNaN\n\n\nRonin Christian\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6973859L\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA5410124H\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9568373Q\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6824244G\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9194090U\n\n\nNaN\n\n\nMaryjane Sandoval\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA4828364M\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA4607700C\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7067766E\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA5569996J\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3202548I\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6131593U\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7653832E\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9462811I\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1218599T\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7210476B\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1512479K\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7986368Y\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA2727061A\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA2999472W\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7116486E\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6931452S\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9649096H\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1643380L\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6787293E\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA5975988J\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3699958T\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1956366U\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1468689D\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3217320C\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA6867791C\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA4080490P\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7667457P\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nSince this output is overwhelming, we should use any() as any() will pick out the non-NaN locations. The axis option will allow us to specify if to apply it to rows or columns(I can never remember which is which, so I just try 0 or 1).\n\n\ndf_class[mask].any(axis=1)\n\nMATRIC_NO\nA3028967J    False\nA1282849W    False\nA5408925A     True\nA6973859L    False\nA5410124H    False\nA9568373Q    False\nA6824244G    False\nA9194090U     True\nA4828364M    False\nA4607700C    False\nA7067766E    False\nA5569996J    False\nA3202548I    False\nA6131593U    False\nA7653832E    False\nA9462811I    False\nA1218599T    False\nA7210476B    False\nA1512479K    False\nA7986368Y    False\nA2727061A    False\nA2999472W    False\nA7116486E    False\nA6931452S    False\nA9649096H    False\nA1643380L    False\nA6787293E    False\nA5975988J    False\nA3699958T    False\nA1956366U    False\nA1468689D    False\nA3217320C    False\nA6867791C    False\nA4080490P    False\nA7667457P    False\ndtype: bool\n\n\nWe can reuse the above as a mask.\ndf_class[df_class[mask].any(axis=1)]\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPhysics\n\n\nMale\n\n\n18.366\n\n\n15.56\n\n\n33.926\n\n\n\n\nA9194090U\n\n\nA9194090U\n\n\nMaryjane Sandoval\n\n\nLife Sciences\n\n\nFemale\n\n\n18.981\n\n\n16.40\n\n\n35.381\n\n\n\n\nA shorter way is to use any() to probe the mask directly.\ndf_class[mask.any(axis=1)]",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Nice)"
    ]
  },
  {
    "objectID": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html",
    "href": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html",
    "title": "AY23/24 SP2273 Application Challenge / Mini Project",
    "section": "",
    "text": "Disclaimer: Sincere apologies. For some strange reasons, the markdown is not rendering properly for the raw cells.\nDisclaimer: If they are errors or discrepancies with the text, the google doc has the original version as backup.\n\n\nChapters covered: 1. Storing Data 2. Loops 3. Plotting 4. Random Numbers 5. Numerical Solutions\n\n\nMuch of the Science we know revolves around the use of the reductionist approach, where a system of interest is broken down into individual components and studied one at a time. While this has most certainly helped deepen our understanding of the underlying biological processes, there lies a growing interest now in piecing them back together and examining it as a whole. This is a relatively new field known as Systems Biology. Although it might be enticing to think that a system is no more than a sum of its parts, this is not always the case.\nTo help us in this endeavour, we would require the right mathematical and computation tools. One of which is modelling, where we attempt to create a simplified representation of a system of interest. This allows us to explore our understanding, to perform imaginative experiments, and ideally to make predictions. However, it inherently requires some sort of simplification and is not an exact replica of the system. That is perfectly alright because the purpose of modelling is to help us gain new insights into our system of interest.\nThere exists a plethora of approaches to modelling such as logic, deterministic, and stochastic. Stochastic models have the benefit of accounting for stochasticity, or chance, that is present in all biological systems. This has greater importance in shaping outcomes especially when the system of interest is small with low population counts. Importantly, one must consider if the system of interest fits these underlying assumptions that comes with stochastic models: 1. The components exist homogeneously 2. The components move randomly\nWe shall focus on a discrete stochastic method known as the stochastic simulation algorithm (SSA) that was published by Daniel T. Gillespie back in 1977. I chose this method because it is relatively simple and easy to understand for the purpose of this course. It is also an excellent entry into exploring stochastic modelling. At present, this method is widely applied to model biological systems, chemical reactions, ecological systems, cellular signalling, and epidemiology.\n\n\n\n\nSet reaction rate parameters, initial counts of each component, and time to 0.\nDetermine the next event.\n\nCalculate the propensities of each event with the formula: Propensity = rate constant x dependent component counts.\nRandomly sample from a uniform distribution based on the weighted probabilities as determined by the reaction propensities.\nConcept: Greater the event propensity, greater the probability of selecting the event.\n\nDetermine the time to the next event.\n\nRandomly sample from an exponential distribution using a scale parameter of 1/total propensity.\nReason for doing so is because time between events follows an exponential distribution.\nConcept: Greater the number of potential events, shorter the time to the next event.\n\nUpdate the counts of each component along with time.\nRepeat steps 2-4 until maximum simulation time is reached.\n\nIn essence, the beauty of SSA lies in the fact that at any point in time, we only need to answer what is the next event and when is the next event. The flipside of it is that it pays with computational power and time as each iteration requires drawing two random numbers as well as calculating the propensities.\nNote: Be careful not to set the maximum simulation time too high.\n\n\n\n\nCreate an event-propensity table for the system of interest\nFollow the brief outline of SSA and code in Python3) Simulate and plot graph\nManipulate parameters and have fun\n\n\n\n\nAt the end of this section, students should be able to: 1. Perform modelling using SSA in Python 2. Understand how Python can be applied in Science 3. Develop ideas on how Python can be used in their home field\n\n\n\nGillespie, D. T. (1977). Exact stochastic simulation of coupled chemical reactions. The journal of physical chemistry, 81(25), 2340-2361.\nLancaster, A., & Webster, G. (2019). Python for the Life Sciences: A Gentle Introduction to Python for Life Scientists. Apress.\nSzékely, T., Jr, & Burrage, K. (2014). Stochastic simulation in systems biology. Computational and structural biotechnology journal, 12(20-21), 14–25. https://doi.org/10.1016/j.csbj.2014.10.003\nWilkinson D. J. (2009). Stochastic modelling for quantitative description of heterogeneous biological systems. Nature reviews. Genetics, 10(2), 122–133. https://doi.org/10.1038/nrg2509\n\n\n\n\nI chose these systems with the intent of covering the three main specialisations in Life Sciences although now it has been reduced to two due to the merger of Biomedical Sciences and Molecular Cell Biology. Nonetheless, the Schlogl reaction relates to Biochemistry, the Lotka-Volterra predator-prey model relates to Ecology, and the Lac operon relates to Molecular Biology.\n\n\nThe Schlogl reaction system is made up of four reactions that can exhibit bistability under certain conditions. It is an intriguing example that is similar to that of a toggle switch model. Importantly, the bistability nature cannot be captured by deterministic models as the spontaneous transition between the two states is attributed to stochasticity, or more specifically intrinsic heterogeneity. The four reactions are as follows.\nReaction 1: A + 2X → 3X\nReaction 2: 3X → A + 2X\nReaction 3: B → X\nReaction 4: X → B\nX, A and B represent three different molecular species. We are interested in how the number of X change with time. In contrast, A and B are considered as buffer species where their numbers are assumed to be constant. The propensity for Reaction 1 can be derived by calculating \\(k1*A*X*(X-1)/2\\) where k1 denotes the rate constant while A and X denote their respective counts. Similarly, the propensity for Reaction 2 can be derived by calculating \\(k2*X*(X-1)*(X-2)/6\\).\nYour task is to come up with the code to simulate how the number of X change with time by implementing the stochastic simulation algorithm (SSA). Keep in mind that time (t) is nondimensional. Set these parameters accordingly A=105, B=2x105, k1=3x10-7, k2=10-4, k3=10-3, and k4=3.5. Simulate for initial number of X at 100, 250 and 400 up till t=10.\nHere are some things to get your group started. 1. Using a markdown cell, generate an event-propensity table for the Schlogl reaction. Ideally, there should be three columns for events, propensities, rate constants. 1. Follow the brief outline of SSA and come up with code. 1. Simulate and plot graph. You may wish to repeat the simulations to deduce at which initial number of X will result in bistability. 1. Use a loop to capture the data for all initial numbers of X and plot onto a single graph. 1. Use a markdown cell to elaborate on your analysis and interpretation of the graph.\nAdapted from Székely & Burrage (2014) and Ilie, Enright & Jackson (2009).\n\n\nSzékely, T., Jr, & Burrage, K. (2014). Stochastic simulation in systems biology. Computational and structural biotechnology journal, 12(20-21), 14–25. https://doi.org/10.1016/j.csbj.2014.10.003\nIlie, S., Enright, W. H., & Jackson, K. R. (2009). Numerical solution of stochastic models of biochemical kinetics. Canadian Applied Mathematics Quarterly, 17(3), 523-554.\n\n\n\n\nThe Lotka-Volterra (LV) predator-prey model allows examining how the populations of prey and predator change with time in an ecosystem. Recently, it has become more apparent that the population of wild chickens in NUS is rising and has even invaded the football fields or around S16 in search of food. Suddenly, a wild thought appears in your mind wondering what would happen if foxes were introduced into this ecosystem. The events for this model are as follows.\nReaction 1: C → 2C\nReaction 2: C + F → 2F\nReaction 3: F → \\(\\emptyset\\)\nC and F represent chickens and foxes respectively. We are interested in how the populations of chickens and foxes change with time.\nYour task is to come up with the code to simulate how the populations of chickens and foxes change with time by implementing the stochastic simulation algorithm (SSA). Keep in mind that time (t) is nondimensional. Set these parameters accordingly k1=1, k2=0.005, and k3=0.6. Simulate for initial numbers of chickens at 50 and foxes at 50 up till t=100.\nHere are some things to get your group started. 1. Using a markdown cell, generate an event-propensity table for the LV model. Ideally, there should be three columns for events, propensities, rate constants. 1. Follow the brief outline of SSA and come up with code. 1. Simulate and plot graph. You may wish to repeat the simulations and notice if there are any differences compared to a deterministic model. 1. Use a markdown cell to elaborate on your analysis and interpretation of the graph.\nAdapted from University of Pennsylvania and University of Glasgow.\n\n\nhttps://www.seas.upenn.edu/~ese3030/homework/week_10/week_10_ctmc_lac_operon.pdf\nhttps://www.dcs.gla.ac.uk/~srogers/teaching/mscbioinfo/SysBio2.pdf\n\n\n\n\nThe lac operon is a group of genes under a single promoter that enables lactose utilisation upon expression and is a classic example of a genetic regulatory system in bacteria. Just like us, bacteria are lazy individuals. They prefer to consume the simpler glucose but can still reduce the complex lactose when push comes to shove. To break down lactose into glucose, they employ the enzyme \\(\\beta\\)-galactosidase. These events can then be simplified as follows.\nReaction 1: L + \\(\\beta\\)-gal → G + \\(\\beta\\)-gal (k1=1)\nReaction 2: G → \\(\\emptyset\\) (k2=0.1)\nNote: L: lactose, \\(\\beta\\)-gal: \\(\\beta\\)-galactosidase, G: glucose, k: rate constants\nBut before the bacteria can wield β-galactosidase, it needs to make it first. The gene responsible for this enzyme lies in the lac operon. Since lactose is not widely available, it makes sense that the gene is turned OFF by default. This is achieved by constitutively expressing a lac repressor protein (LRP) that binds to part of the operon to prevent transcription of this gene. You can imagine that the flipside of this is the activation of the operon to turn ON transcription of this gene. There can also be a case where it is neither turned ON or OFF. These events can then be simplified as follows.\nReaction 3: O → O + mRNA (k3=0.01)\nReaction 4: AO → AO + mRNA (k4=0.1)\nReaction 5: RO → RO + mRNA (k5=0.001)\nNote: O: operon, AO: activated operon, RO: repressed operon; k: rate constants. Reaction 5 exists due to leaky expression.\nLet’s focus on how the gene is turned OFF by default. We know that the LRP is always expressed and binds to part of the operon to prevent transcription of \\(\\beta\\)-galactosidase.When lactose is present, it will bind to LRP to prevent interfering with transcription. If they can bind, then they can also dissociate. These events can then be simplified as follows.\nReaction 6: LRP + O → RO (k6=1)\nReaction 7: RO → LRP + RO (k7=1)\nReaction 8: LRP + L → LRP-L (k8=10)\nReaction 9: LRP-L → LRP + L (k9=1)\nNote: LRP: lac repressor protein, O: operon, RO: repressed operon, L: lactose, LRP-L: lac repressor protein bound with lactose, k: rate constants.\nLet’s now focus on how the gene is turned ON when glucose is absent. Another protein called the catabolite activator protein (CAP) can bind to the operon and activate transcription of \\(\\beta\\)-galactosidase. When glucose is present, it will bind to CAP to prevent interfering with transcription. If they can bind, then they can also dissociate. These events can then be simplified as follows.\nReaction 10: CAP + O → AO (k10=1)\nReaction 11: AO → CAP + O (k11=1)\nReaction 12: CAP + G → CAP-G (k12=10)\nReaction 13: CAP-G → CAP + G (k13=1)\nNote: CAP: catabolite activator protein, O: operon, AO: activated operon, G: glucose, CAP-G: catabolite activator protein bound with glucose, k: rate constants.\nAs with all protein production, the last step is to translate the mRNA into the enzyme \\(\\beta\\)-galactosidase. These events can then be simplified as follows.\nReaction 14: mRNA → mRNA + \\(\\beta\\)-gal (k14=1)\nReaction 15: mRNA → \\(\\emptyset\\) (k15=1)\nReaction 16: \\(\\beta\\)-gal → \\(\\emptyset\\) (k16=0.1)\nNote: \\(\\beta\\)-gal: \\(\\beta\\)-galactosidase, k: rate constants.\nYour task is to come up with the code to simulate how the numbers of lactose and glucose change with time by implementing the stochastic simulation algorithm (SSA). Keep in mind that time (t) is nondimensional. Simulate for initial numbers of lactose at 50, glucose at 50, operon at 1, LRP at 10, and CAP at 10 up till t=120. The initial numbers of the remaining components are at 0.\nHere are some things to get your group started. 1. Using a markdown cell, generate an event-propensity table for the lac operon system. Ideally, there should be three columns for events, propensities, rate constants. 1. Follow the brief outline of SSA and come up with code. 1. Simulate and plot graph. Set the width of the graph wider to get a clearer view of the graph. 1. Use a markdown cell to elaborate on your analysis and interpretation of the graph.\nAdapted from University of Pennsylvania and University of Rochester.\n\n\nhttps://www.seas.upenn.edu/~ese3030/homework/week_10/week_10_ctmc_lac_operon.pdf\nhttps://www.hajim.rochester.edu/ece/sites/gmateos/ECE440/Slides/block_4_continuous_time_markov_chains_part_e.pdf\n\n\n\n\n\nDisclaimer: The codes work but they have not been optimized yet due to time constraints. The plotted graphs are correct and students attempting these should get same/similar graphs.\n\n\nThe Schlogl reaction system is made up of four reactions that can exhibit bistability under certain parameter settings, similar to that of a toggle switch model. The table below shows the event-propensity table for the Schlogl reaction system. | No. | Events | Propensities | Rate constants | |:——-:|:—————-:|:——————–:|:————————–:| | 1 | A + 2X → 3X | \\(k_{1}AX(X-1)/2\\) | \\(k_{1} = 3 \\times 10^{-7}\\) | | 2 | 3X → A + 2X | \\(k_{2}X(X-1)(X-2)/6\\) | \\(k_{2} = 10^{-4}\\) | | 3 | B → X | \\(k_{3}B\\) | \\(k_{3} = 10^{-3}\\) | | 4 | X → B | \\(k_{4}X\\) | \\(k_{4} = 3.5\\) |\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n# initial A, B counts\na = 10**5\nb = 2 * 10**5\n\n# reaction rate constants\nk1 = 3 * 10**-7\nk2 = 10**-4\nk3 = 10**-3\nk4 = 3.5\n\n# dictionary to update counts for each reaction\nd = {'r1': np.array([1, 0, 0]),\n     'r2': np.array([-1, 0, 0]),\n     'r3': np.array([1, 0, 0]),\n     'r4': np.array([-1, 0, 0])\n    }\n\n# list to store simulation history\nsim_hx = []\n\n# varying initial X count\nfor xstart in [100, 250, 250, 400]:\n    \n    # initial counts\n    x = xstart\n    x0 = np.array([x, a, b])\n    xt = [x0]\n\n    # time parameters\n    t = 0\n    tpoints = [t]\n    tmax = 10\n    \n    # simulation loop\n    while t &lt; tmax:\n        \n        # get current counts\n        curr_x = xt[-1][0]\n        curr_a = xt[-1][1]\n        curr_b = xt[-1][2]\n        \n        # calculate propensities\n        p1 = k1 * curr_a * curr_x * (curr_x-1) / 2\n        p2 = k2 * curr_x * (curr_x-1) * (curr_x-2) / 6\n        p3 = k3 * curr_b\n        p4 = k4 * curr_x\n        \n        # put them in array\n        array_p = np.array([p1, p2, p3, p4])\n        \n        # calculate total propensity\n        total_p = array_p.sum()\n        \n        # randomly sample from uniform distribution\n        sample_p = np.random.uniform(0, total_p)\n        \n        # determine next event\n        array_pcs = np.cumsum(array_p)\n        mask = array_pcs &gt; sample_p\n        index = mask.nonzero()[0][0]\n        \n        # update counts\n        xnew = xt[-1] + d[f'r{index+1}']\n        xt.append(xnew)\n        \n        # determine time to next event\n        scale_para = 1 / total_p\n        dt = np.random.exponential(scale_para)\n    \n        # update time\n        t += dt\n        tpoints.append(t)\n    \n    # convert counts history to array\n    xt = np.array(xt)\n    sim_hx.append([xt, tpoints])\n\n\nplt.xlim([0, 10])\nplt.ylim([0, 800])\nplt.xlabel('time')\nplt.ylabel('X')\nplt.plot(sim_hx[0][1], sim_hx[0][0], c='deeppink')\nplt.plot(sim_hx[1][1], sim_hx[1][0], c='forestgreen')\nplt.plot(sim_hx[2][1], sim_hx[2][0], c='royalblue')\nplt.plot(sim_hx[3][1], sim_hx[3][0], c='darkorange')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe Lotka-Volterra predator-prey model looks at how the populations of prey and predator changes with time in an ecology system. The table below shows the event-propensity table for the Lotka-Volterra predator-prey model. | No. | Events | Propensities | Rate constants | |:——-:|:——————–:|:—————-:|:——————:| | 1 | X → 2X | \\(k_{1}X\\) | \\(k_{1} = 1\\) | | 2 | X + Y → 2Y | \\(k_{2}XY\\) | \\(k_{2} = 0.005\\) | | 3 | Y → \\(\\emptyset\\) | \\(k_{3}Y\\) | \\(k_{3} = 0.6\\) |\nNote: Deterministic model will oscillate continuously; Stochastic model, by chance, will stop oscillating after some time and go extinct.\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n# initial X, Y counts\nx = 50\ny = 50\nstart = np.array([x, y])\ncounts = [start]\n\n# reaction rate constants\nk1 = 1\nk2 = 0.005\nk3 = 0.6\n\n# time parameters\nt = 0\ntpoints = [t]\ntmax = 100\n\n# dictionary to update counts for each reaction\nd = {'r1': np.array([1, 0]),\n     'r2': np.array([-1, 1]),\n     'r3': np.array([0, -1])\n    }\n\n# simulation loop\nwhile t &lt; tmax:\n\n    # get current counts\n    curr_x = counts[-1][0]\n    curr_y = counts[-1][1]\n\n    # oscillations will stop eventually\n    if curr_x == 0 and curr_y == 0:\n        old_count = counts[-1]\n        counts.append(old_count)\n        t += 0.5\n        tpoints.append(t)\n        continue\n    \n    # calculate propensities\n    p1 = k1 * curr_x\n    p2 = k2 * curr_x * curr_y\n    p3 = k3 * curr_y\n\n    # calculate total propensity\n    array_p = np.array([p1, p2, p3])\n    total_p = array_p.sum()\n\n    # randomly sample from uniform distribution\n    sample_p = np.random.uniform(0, total_p)\n\n    # determine next event\n    array_pcs = np.cumsum(array_p)\n    mask = array_pcs &gt; sample_p\n    index = mask.nonzero()[0][0]\n    \n    # update counts\n    new_count = counts[-1] + d[f'r{index+1}']\n    counts.append(new_count)\n\n    # determine time to next event\n    scale_para = 1 / total_p\n    dt = np.random.exponential(scale_para)\n\n    # update time\n    t += dt\n    tpoints.append(t)\n\n# convert counts history to array\ncounts = np.array(counts)\n\n\nplt.xlim([0, tmax])\nplt.ylim([0, 1200])\nplt.xlabel('time')\nplt.ylabel('counts')\nplt.plot(tpoints, counts[:,0], c='deeppink', label='X - prey')\nplt.plot(tpoints, counts[:,1], c='royalblue', label='Y - predator')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe lac operon is a group of genes under a single promoter that enables lactose utilization upon expression and is a classic example of a genetic regulatory system in bacteria. The table below shows the event-propensity table for the lac operon system.\n\n\n\n\n\n\n\n\n\nNo.\nEvents\nPropensities\nRate constants\n\n\n\n\n1\nL + \\(\\beta-gal\\) → G + \\(\\beta-gal\\)\n\\(k_{1}.L.\\beta-gal\\)\n\\(k_{1} = 1\\)\n\n\n2\nG → \\(\\emptyset\\)\n\\(k_{2}.G\\)\n\\(k_{2} = 0.1\\)\n\n\n3\n\\(O_{p}\\) → \\(O_{p}\\) + mRNA\n\\(k_{3}.O_{p}\\)\n\\(k_{3} = 0.01\\)\n\n\n4\n\\(AO_{p}\\) → \\(AO_{p}\\) + mRNA\n\\(k_{4}.AO_{p}\\)\n\\(k_{4} = 0.1\\)\n\n\n5\n\\(RO_{p}\\) → \\(RO_{p}\\) + mRNA\n\\(k_{5}.RO_{p}\\)\n\\(k_{5} = 0.001\\)\n\n\n6\nLRP + \\(O_{p}\\) → \\(RO_{p}\\)\n\\(k_{6}.LRP.O_{p}\\)\n\\(k_{6} = 1\\)\n\n\n7\n\\(RO_{p}\\) → LRP + \\(O_{p}\\)\n\\(k_{7}.RO_{p}\\)\n\\(k_{7} = 1\\)\n\n\n8\nLRP + L → LRP-L\n\\(k_{8}.LRP.L\\)\n\\(k_{8} = 10\\)\n\n\n9\nLRP-L → LRP + L\n\\(k_{9}.LRP-L\\)\n\\(k_{9} = 1\\)\n\n\n10\nCAP + \\(O_{p}\\) → \\(AO_{p}\\)\n\\(k_{10}.CAP.O_{p}\\)\n\\(k_{10} = 1\\)\n\n\n11\n\\(AO_{p}\\) → CAP + \\(O_{p}\\)\n\\(k_{11}.AO_{p}\\)\n\\(k_{11} = 1\\)\n\n\n12\nCAP + G → CAP-G\n\\(k_{12}.CAP.G\\)\n\\(k_{12} = 10\\)\n\n\n13\nCAP-G → CAP + G\n\\(k_{13}.CAP-G\\)\n\\(k_{13} = 1\\)\n\n\n14\nmRNA → mRNA + \\(\\beta-gal\\)\n\\(k_{14}.mRNA\\)\n\\(k_{14} = 1\\)\n\n\n15\nmRNA → \\(\\emptyset\\)\n\\(k_{15}.mRNA\\)\n\\(k_{15} = 1\\)\n\n\n16\n\\(\\beta-gal\\) → \\(\\emptyset\\)\n\\(k_{16}.\\beta-gal\\)\n\\(k_{16} = 0.1\\)\n\n\n\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n# initial counts\nl = 50\nb_gal = 0\ng = 50\nop = 1\naop = 0\nrop = 0\nmrna = 0\nlrp = 10\nlrp_l = 0\ncap = 10\ncap_g = 0\nx0 = np.array([l, b_gal, g, op, aop, rop,\n               mrna, lrp, lrp_l, cap, cap_g])\nxt = [x0]\n\n# reaction rate constants\nk1 = 1\nk2 = 0.1\nk3 = 0.01\nk4 = 0.1\nk5 = 0.001\nk6 = 1\nk7 = 1\nk8 = 10\nk9 = 1\nk10 = 1\nk11 = 1\nk12 = 10\nk13 = 1\nk14 = 1\nk15 = 1\nk16 = 0.1\n\n# time parameters\nt = 0\ntpoints = [t]\ntmax = 120\n\n# dictionary to update counts for each reaction\nd = {'r1': np.array([-1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n     'r2': np.array([0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0]),\n     'r3': np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n     'r4': np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n     'r5': np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n     'r6': np.array([0, 0, 0, -1, 0, 1, 0, -1, 0, 0, 0]),\n     'r7': np.array([0, 0, 0, 1, 0, -1, 0, 1, 0, 0, 0]),\n     'r8': np.array([-1, 0, 0, 0, 0, 0, 0, -1, 1, 0, 0]),\n     'r9': np.array([1, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0]),\n     'r10': np.array([0, 0, 0, -1, 1, 0, 0, 0, 0, -1, 0]),\n     'r11': np.array([0, 0, 0, 1, -1, 0, 0, 0, 0, 1, 0]),\n     'r12': np.array([0, 0, -1, 0, 0, 0, 0, 0, 0, -1, 1]),\n     'r13': np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, -1]),\n     'r14': np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n     'r15': np.array([0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]),\n     'r16': np.array([0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n    }\n\n# simulation loop\nwhile t &lt; tmax:\n\n    # get current counts\n    curr_l = xt[-1][0]\n    curr_b_gal = xt[-1][1]\n    curr_g = xt[-1][2]\n    curr_op = xt[-1][3]\n    curr_aop = xt[-1][4]\n    curr_rop = xt[-1][5]\n    curr_mrna = xt[-1][6]\n    curr_lrp = xt[-1][7]\n    curr_lrp_l = xt[-1][8]\n    curr_cap = xt[-1][9]\n    curr_cap_g = xt[-1][10]\n\n    # calculate propensities\n    p1 = k1 * curr_l * curr_b_gal\n    p2 = k2 * curr_g\n    p3 = k3 * curr_op\n    p4 = k4 * curr_aop\n    p5 = k5 * curr_rop\n    p6 = k6 * curr_lrp * curr_op\n    p7 = k7 * curr_rop\n    p8 = k8 * curr_lrp * curr_l\n    p9 = k9 * curr_lrp_l\n    p10 = k10 * curr_cap * curr_op\n    p11 = k11 * curr_aop\n    p12 = k12 * curr_cap * curr_g\n    p13 = k13 * curr_cap_g\n    p14 = k14 * curr_mrna\n    p15 = k15 * curr_mrna\n    p16 = k16 * curr_b_gal\n\n    # calculate total propensity\n    array_p = np.array([p1, p2, p3, p4, p5, p6, p7, p8,\n                       p9, p10, p11, p12, p13, p14, p15, p16])\n    total_p = array_p.sum()\n\n    # randomly sample from uniform distribution\n    sample_p = np.random.uniform(0, total_p)\n\n    # determine next event\n    array_pcs = np.cumsum(array_p)\n    mask = array_pcs &gt; sample_p\n    index = mask.nonzero()[0][0]\n\n    # update counts\n    xnew = xt[-1] + d[f'r{index+1}']\n    xt.append(xnew)\n\n    # determine time to next event\n    scale_para = 1 / total_p\n    dt = np.random.exponential(scale_para)\n\n    # update time\n    t += dt\n    tpoints.append(t)\n\n# convert counts history to array\nxt = np.array(xt)\n\n\nplt.figure().set_figwidth(10)\nplt.xlim([0, tmax])\n#plt.ylim([0, 100])\nplt.xlabel('time')\nplt.ylabel('counts')\nplt.plot(tpoints, xt[:,0], c='darkorange', label='lactose')\nplt.plot(tpoints, xt[:,2], c='gold', label='glucose')\nplt.legend(loc='upper right')\n\n#plt.twinx()\n\n#plt.plot(tpoints, xt[:,1], c='royalblue', label='beta-gal')\n#plt.plot(tpoints, xt[:,3], c='black', label='regular')\n#plt.plot(tpoints, xt[:,4], c='forestgreen', label='activated')\n#plt.plot(tpoints, xt[:,5], c='red', label='repressed')\n#plt.plot(tpoints, xt[:,6], c='blueviolet', label='mRNA')\n\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\n\nThe titles proposed here are part of Assignment 2 for SP2274 where students had to use logic models based on Boolean logic gates to model these systems. Many students raised the need to consider stochasticity especially in the context of a single cell organism which fits in comfortably with the topic that will empower students with more control over the system of interest. If they are included in the Mini Project basket, we are hoping to collect some sort of feedback regarding the students’ perception on this project if possible.\n\n\nCopper homeostasis in E. coli that is published in a review paper by Rademacher and Masepohl (2012).\nRademacher, C., & Masepohl, B. (2012). Copper-responsive gene regulation in bacteria. Microbiology (Reading, England), 158(Pt 10), 2451–2464. https://doi.org/10.1099/mic.0.058487-0\n\n\n\nLysogeny maintenance circuit of bacteriophage lambda that is published in a primary paper by Bednarz et al. (2014).\nBednarz, M., Halliday, J. A., Herman, C., & Golding, I. (2014). Revisiting bistability in the lysis/lysogeny circuit of bacteriophage lambda. PloS one, 9(6), e100876. https://doi.org/10.1371/journal.pone.0100876"
  },
  {
    "objectID": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html#topic-stochastic-modelling",
    "href": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html#topic-stochastic-modelling",
    "title": "AY23/24 SP2273 Application Challenge / Mini Project",
    "section": "",
    "text": "Chapters covered: 1. Storing Data 2. Loops 3. Plotting 4. Random Numbers 5. Numerical Solutions\n\n\nMuch of the Science we know revolves around the use of the reductionist approach, where a system of interest is broken down into individual components and studied one at a time. While this has most certainly helped deepen our understanding of the underlying biological processes, there lies a growing interest now in piecing them back together and examining it as a whole. This is a relatively new field known as Systems Biology. Although it might be enticing to think that a system is no more than a sum of its parts, this is not always the case.\nTo help us in this endeavour, we would require the right mathematical and computation tools. One of which is modelling, where we attempt to create a simplified representation of a system of interest. This allows us to explore our understanding, to perform imaginative experiments, and ideally to make predictions. However, it inherently requires some sort of simplification and is not an exact replica of the system. That is perfectly alright because the purpose of modelling is to help us gain new insights into our system of interest.\nThere exists a plethora of approaches to modelling such as logic, deterministic, and stochastic. Stochastic models have the benefit of accounting for stochasticity, or chance, that is present in all biological systems. This has greater importance in shaping outcomes especially when the system of interest is small with low population counts. Importantly, one must consider if the system of interest fits these underlying assumptions that comes with stochastic models: 1. The components exist homogeneously 2. The components move randomly\nWe shall focus on a discrete stochastic method known as the stochastic simulation algorithm (SSA) that was published by Daniel T. Gillespie back in 1977. I chose this method because it is relatively simple and easy to understand for the purpose of this course. It is also an excellent entry into exploring stochastic modelling. At present, this method is widely applied to model biological systems, chemical reactions, ecological systems, cellular signalling, and epidemiology.\n\n\n\n\nSet reaction rate parameters, initial counts of each component, and time to 0.\nDetermine the next event.\n\nCalculate the propensities of each event with the formula: Propensity = rate constant x dependent component counts.\nRandomly sample from a uniform distribution based on the weighted probabilities as determined by the reaction propensities.\nConcept: Greater the event propensity, greater the probability of selecting the event.\n\nDetermine the time to the next event.\n\nRandomly sample from an exponential distribution using a scale parameter of 1/total propensity.\nReason for doing so is because time between events follows an exponential distribution.\nConcept: Greater the number of potential events, shorter the time to the next event.\n\nUpdate the counts of each component along with time.\nRepeat steps 2-4 until maximum simulation time is reached.\n\nIn essence, the beauty of SSA lies in the fact that at any point in time, we only need to answer what is the next event and when is the next event. The flipside of it is that it pays with computational power and time as each iteration requires drawing two random numbers as well as calculating the propensities.\nNote: Be careful not to set the maximum simulation time too high.\n\n\n\n\nCreate an event-propensity table for the system of interest\nFollow the brief outline of SSA and code in Python3) Simulate and plot graph\nManipulate parameters and have fun\n\n\n\n\nAt the end of this section, students should be able to: 1. Perform modelling using SSA in Python 2. Understand how Python can be applied in Science 3. Develop ideas on how Python can be used in their home field\n\n\n\nGillespie, D. T. (1977). Exact stochastic simulation of coupled chemical reactions. The journal of physical chemistry, 81(25), 2340-2361.\nLancaster, A., & Webster, G. (2019). Python for the Life Sciences: A Gentle Introduction to Python for Life Scientists. Apress.\nSzékely, T., Jr, & Burrage, K. (2014). Stochastic simulation in systems biology. Computational and structural biotechnology journal, 12(20-21), 14–25. https://doi.org/10.1016/j.csbj.2014.10.003\nWilkinson D. J. (2009). Stochastic modelling for quantitative description of heterogeneous biological systems. Nature reviews. Genetics, 10(2), 122–133. https://doi.org/10.1038/nrg2509"
  },
  {
    "objectID": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html#application-challenge",
    "href": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html#application-challenge",
    "title": "AY23/24 SP2273 Application Challenge / Mini Project",
    "section": "",
    "text": "I chose these systems with the intent of covering the three main specialisations in Life Sciences although now it has been reduced to two due to the merger of Biomedical Sciences and Molecular Cell Biology. Nonetheless, the Schlogl reaction relates to Biochemistry, the Lotka-Volterra predator-prey model relates to Ecology, and the Lac operon relates to Molecular Biology.\n\n\nThe Schlogl reaction system is made up of four reactions that can exhibit bistability under certain conditions. It is an intriguing example that is similar to that of a toggle switch model. Importantly, the bistability nature cannot be captured by deterministic models as the spontaneous transition between the two states is attributed to stochasticity, or more specifically intrinsic heterogeneity. The four reactions are as follows.\nReaction 1: A + 2X → 3X\nReaction 2: 3X → A + 2X\nReaction 3: B → X\nReaction 4: X → B\nX, A and B represent three different molecular species. We are interested in how the number of X change with time. In contrast, A and B are considered as buffer species where their numbers are assumed to be constant. The propensity for Reaction 1 can be derived by calculating \\(k1*A*X*(X-1)/2\\) where k1 denotes the rate constant while A and X denote their respective counts. Similarly, the propensity for Reaction 2 can be derived by calculating \\(k2*X*(X-1)*(X-2)/6\\).\nYour task is to come up with the code to simulate how the number of X change with time by implementing the stochastic simulation algorithm (SSA). Keep in mind that time (t) is nondimensional. Set these parameters accordingly A=105, B=2x105, k1=3x10-7, k2=10-4, k3=10-3, and k4=3.5. Simulate for initial number of X at 100, 250 and 400 up till t=10.\nHere are some things to get your group started. 1. Using a markdown cell, generate an event-propensity table for the Schlogl reaction. Ideally, there should be three columns for events, propensities, rate constants. 1. Follow the brief outline of SSA and come up with code. 1. Simulate and plot graph. You may wish to repeat the simulations to deduce at which initial number of X will result in bistability. 1. Use a loop to capture the data for all initial numbers of X and plot onto a single graph. 1. Use a markdown cell to elaborate on your analysis and interpretation of the graph.\nAdapted from Székely & Burrage (2014) and Ilie, Enright & Jackson (2009).\n\n\nSzékely, T., Jr, & Burrage, K. (2014). Stochastic simulation in systems biology. Computational and structural biotechnology journal, 12(20-21), 14–25. https://doi.org/10.1016/j.csbj.2014.10.003\nIlie, S., Enright, W. H., & Jackson, K. R. (2009). Numerical solution of stochastic models of biochemical kinetics. Canadian Applied Mathematics Quarterly, 17(3), 523-554.\n\n\n\n\nThe Lotka-Volterra (LV) predator-prey model allows examining how the populations of prey and predator change with time in an ecosystem. Recently, it has become more apparent that the population of wild chickens in NUS is rising and has even invaded the football fields or around S16 in search of food. Suddenly, a wild thought appears in your mind wondering what would happen if foxes were introduced into this ecosystem. The events for this model are as follows.\nReaction 1: C → 2C\nReaction 2: C + F → 2F\nReaction 3: F → \\(\\emptyset\\)\nC and F represent chickens and foxes respectively. We are interested in how the populations of chickens and foxes change with time.\nYour task is to come up with the code to simulate how the populations of chickens and foxes change with time by implementing the stochastic simulation algorithm (SSA). Keep in mind that time (t) is nondimensional. Set these parameters accordingly k1=1, k2=0.005, and k3=0.6. Simulate for initial numbers of chickens at 50 and foxes at 50 up till t=100.\nHere are some things to get your group started. 1. Using a markdown cell, generate an event-propensity table for the LV model. Ideally, there should be three columns for events, propensities, rate constants. 1. Follow the brief outline of SSA and come up with code. 1. Simulate and plot graph. You may wish to repeat the simulations and notice if there are any differences compared to a deterministic model. 1. Use a markdown cell to elaborate on your analysis and interpretation of the graph.\nAdapted from University of Pennsylvania and University of Glasgow.\n\n\nhttps://www.seas.upenn.edu/~ese3030/homework/week_10/week_10_ctmc_lac_operon.pdf\nhttps://www.dcs.gla.ac.uk/~srogers/teaching/mscbioinfo/SysBio2.pdf\n\n\n\n\nThe lac operon is a group of genes under a single promoter that enables lactose utilisation upon expression and is a classic example of a genetic regulatory system in bacteria. Just like us, bacteria are lazy individuals. They prefer to consume the simpler glucose but can still reduce the complex lactose when push comes to shove. To break down lactose into glucose, they employ the enzyme \\(\\beta\\)-galactosidase. These events can then be simplified as follows.\nReaction 1: L + \\(\\beta\\)-gal → G + \\(\\beta\\)-gal (k1=1)\nReaction 2: G → \\(\\emptyset\\) (k2=0.1)\nNote: L: lactose, \\(\\beta\\)-gal: \\(\\beta\\)-galactosidase, G: glucose, k: rate constants\nBut before the bacteria can wield β-galactosidase, it needs to make it first. The gene responsible for this enzyme lies in the lac operon. Since lactose is not widely available, it makes sense that the gene is turned OFF by default. This is achieved by constitutively expressing a lac repressor protein (LRP) that binds to part of the operon to prevent transcription of this gene. You can imagine that the flipside of this is the activation of the operon to turn ON transcription of this gene. There can also be a case where it is neither turned ON or OFF. These events can then be simplified as follows.\nReaction 3: O → O + mRNA (k3=0.01)\nReaction 4: AO → AO + mRNA (k4=0.1)\nReaction 5: RO → RO + mRNA (k5=0.001)\nNote: O: operon, AO: activated operon, RO: repressed operon; k: rate constants. Reaction 5 exists due to leaky expression.\nLet’s focus on how the gene is turned OFF by default. We know that the LRP is always expressed and binds to part of the operon to prevent transcription of \\(\\beta\\)-galactosidase.When lactose is present, it will bind to LRP to prevent interfering with transcription. If they can bind, then they can also dissociate. These events can then be simplified as follows.\nReaction 6: LRP + O → RO (k6=1)\nReaction 7: RO → LRP + RO (k7=1)\nReaction 8: LRP + L → LRP-L (k8=10)\nReaction 9: LRP-L → LRP + L (k9=1)\nNote: LRP: lac repressor protein, O: operon, RO: repressed operon, L: lactose, LRP-L: lac repressor protein bound with lactose, k: rate constants.\nLet’s now focus on how the gene is turned ON when glucose is absent. Another protein called the catabolite activator protein (CAP) can bind to the operon and activate transcription of \\(\\beta\\)-galactosidase. When glucose is present, it will bind to CAP to prevent interfering with transcription. If they can bind, then they can also dissociate. These events can then be simplified as follows.\nReaction 10: CAP + O → AO (k10=1)\nReaction 11: AO → CAP + O (k11=1)\nReaction 12: CAP + G → CAP-G (k12=10)\nReaction 13: CAP-G → CAP + G (k13=1)\nNote: CAP: catabolite activator protein, O: operon, AO: activated operon, G: glucose, CAP-G: catabolite activator protein bound with glucose, k: rate constants.\nAs with all protein production, the last step is to translate the mRNA into the enzyme \\(\\beta\\)-galactosidase. These events can then be simplified as follows.\nReaction 14: mRNA → mRNA + \\(\\beta\\)-gal (k14=1)\nReaction 15: mRNA → \\(\\emptyset\\) (k15=1)\nReaction 16: \\(\\beta\\)-gal → \\(\\emptyset\\) (k16=0.1)\nNote: \\(\\beta\\)-gal: \\(\\beta\\)-galactosidase, k: rate constants.\nYour task is to come up with the code to simulate how the numbers of lactose and glucose change with time by implementing the stochastic simulation algorithm (SSA). Keep in mind that time (t) is nondimensional. Simulate for initial numbers of lactose at 50, glucose at 50, operon at 1, LRP at 10, and CAP at 10 up till t=120. The initial numbers of the remaining components are at 0.\nHere are some things to get your group started. 1. Using a markdown cell, generate an event-propensity table for the lac operon system. Ideally, there should be three columns for events, propensities, rate constants. 1. Follow the brief outline of SSA and come up with code. 1. Simulate and plot graph. Set the width of the graph wider to get a clearer view of the graph. 1. Use a markdown cell to elaborate on your analysis and interpretation of the graph.\nAdapted from University of Pennsylvania and University of Rochester.\n\n\nhttps://www.seas.upenn.edu/~ese3030/homework/week_10/week_10_ctmc_lac_operon.pdf\nhttps://www.hajim.rochester.edu/ece/sites/gmateos/ECE440/Slides/block_4_continuous_time_markov_chains_part_e.pdf"
  },
  {
    "objectID": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html#suggested-answers",
    "href": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html#suggested-answers",
    "title": "AY23/24 SP2273 Application Challenge / Mini Project",
    "section": "",
    "text": "Disclaimer: The codes work but they have not been optimized yet due to time constraints. The plotted graphs are correct and students attempting these should get same/similar graphs.\n\n\nThe Schlogl reaction system is made up of four reactions that can exhibit bistability under certain parameter settings, similar to that of a toggle switch model. The table below shows the event-propensity table for the Schlogl reaction system. | No. | Events | Propensities | Rate constants | |:——-:|:—————-:|:——————–:|:————————–:| | 1 | A + 2X → 3X | \\(k_{1}AX(X-1)/2\\) | \\(k_{1} = 3 \\times 10^{-7}\\) | | 2 | 3X → A + 2X | \\(k_{2}X(X-1)(X-2)/6\\) | \\(k_{2} = 10^{-4}\\) | | 3 | B → X | \\(k_{3}B\\) | \\(k_{3} = 10^{-3}\\) | | 4 | X → B | \\(k_{4}X\\) | \\(k_{4} = 3.5\\) |\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n# initial A, B counts\na = 10**5\nb = 2 * 10**5\n\n# reaction rate constants\nk1 = 3 * 10**-7\nk2 = 10**-4\nk3 = 10**-3\nk4 = 3.5\n\n# dictionary to update counts for each reaction\nd = {'r1': np.array([1, 0, 0]),\n     'r2': np.array([-1, 0, 0]),\n     'r3': np.array([1, 0, 0]),\n     'r4': np.array([-1, 0, 0])\n    }\n\n# list to store simulation history\nsim_hx = []\n\n# varying initial X count\nfor xstart in [100, 250, 250, 400]:\n    \n    # initial counts\n    x = xstart\n    x0 = np.array([x, a, b])\n    xt = [x0]\n\n    # time parameters\n    t = 0\n    tpoints = [t]\n    tmax = 10\n    \n    # simulation loop\n    while t &lt; tmax:\n        \n        # get current counts\n        curr_x = xt[-1][0]\n        curr_a = xt[-1][1]\n        curr_b = xt[-1][2]\n        \n        # calculate propensities\n        p1 = k1 * curr_a * curr_x * (curr_x-1) / 2\n        p2 = k2 * curr_x * (curr_x-1) * (curr_x-2) / 6\n        p3 = k3 * curr_b\n        p4 = k4 * curr_x\n        \n        # put them in array\n        array_p = np.array([p1, p2, p3, p4])\n        \n        # calculate total propensity\n        total_p = array_p.sum()\n        \n        # randomly sample from uniform distribution\n        sample_p = np.random.uniform(0, total_p)\n        \n        # determine next event\n        array_pcs = np.cumsum(array_p)\n        mask = array_pcs &gt; sample_p\n        index = mask.nonzero()[0][0]\n        \n        # update counts\n        xnew = xt[-1] + d[f'r{index+1}']\n        xt.append(xnew)\n        \n        # determine time to next event\n        scale_para = 1 / total_p\n        dt = np.random.exponential(scale_para)\n    \n        # update time\n        t += dt\n        tpoints.append(t)\n    \n    # convert counts history to array\n    xt = np.array(xt)\n    sim_hx.append([xt, tpoints])\n\n\nplt.xlim([0, 10])\nplt.ylim([0, 800])\nplt.xlabel('time')\nplt.ylabel('X')\nplt.plot(sim_hx[0][1], sim_hx[0][0], c='deeppink')\nplt.plot(sim_hx[1][1], sim_hx[1][0], c='forestgreen')\nplt.plot(sim_hx[2][1], sim_hx[2][0], c='royalblue')\nplt.plot(sim_hx[3][1], sim_hx[3][0], c='darkorange')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe Lotka-Volterra predator-prey model looks at how the populations of prey and predator changes with time in an ecology system. The table below shows the event-propensity table for the Lotka-Volterra predator-prey model. | No. | Events | Propensities | Rate constants | |:——-:|:——————–:|:—————-:|:——————:| | 1 | X → 2X | \\(k_{1}X\\) | \\(k_{1} = 1\\) | | 2 | X + Y → 2Y | \\(k_{2}XY\\) | \\(k_{2} = 0.005\\) | | 3 | Y → \\(\\emptyset\\) | \\(k_{3}Y\\) | \\(k_{3} = 0.6\\) |\nNote: Deterministic model will oscillate continuously; Stochastic model, by chance, will stop oscillating after some time and go extinct.\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n# initial X, Y counts\nx = 50\ny = 50\nstart = np.array([x, y])\ncounts = [start]\n\n# reaction rate constants\nk1 = 1\nk2 = 0.005\nk3 = 0.6\n\n# time parameters\nt = 0\ntpoints = [t]\ntmax = 100\n\n# dictionary to update counts for each reaction\nd = {'r1': np.array([1, 0]),\n     'r2': np.array([-1, 1]),\n     'r3': np.array([0, -1])\n    }\n\n# simulation loop\nwhile t &lt; tmax:\n\n    # get current counts\n    curr_x = counts[-1][0]\n    curr_y = counts[-1][1]\n\n    # oscillations will stop eventually\n    if curr_x == 0 and curr_y == 0:\n        old_count = counts[-1]\n        counts.append(old_count)\n        t += 0.5\n        tpoints.append(t)\n        continue\n    \n    # calculate propensities\n    p1 = k1 * curr_x\n    p2 = k2 * curr_x * curr_y\n    p3 = k3 * curr_y\n\n    # calculate total propensity\n    array_p = np.array([p1, p2, p3])\n    total_p = array_p.sum()\n\n    # randomly sample from uniform distribution\n    sample_p = np.random.uniform(0, total_p)\n\n    # determine next event\n    array_pcs = np.cumsum(array_p)\n    mask = array_pcs &gt; sample_p\n    index = mask.nonzero()[0][0]\n    \n    # update counts\n    new_count = counts[-1] + d[f'r{index+1}']\n    counts.append(new_count)\n\n    # determine time to next event\n    scale_para = 1 / total_p\n    dt = np.random.exponential(scale_para)\n\n    # update time\n    t += dt\n    tpoints.append(t)\n\n# convert counts history to array\ncounts = np.array(counts)\n\n\nplt.xlim([0, tmax])\nplt.ylim([0, 1200])\nplt.xlabel('time')\nplt.ylabel('counts')\nplt.plot(tpoints, counts[:,0], c='deeppink', label='X - prey')\nplt.plot(tpoints, counts[:,1], c='royalblue', label='Y - predator')\nplt.legend(loc='upper right')\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThe lac operon is a group of genes under a single promoter that enables lactose utilization upon expression and is a classic example of a genetic regulatory system in bacteria. The table below shows the event-propensity table for the lac operon system.\n\n\n\n\n\n\n\n\n\nNo.\nEvents\nPropensities\nRate constants\n\n\n\n\n1\nL + \\(\\beta-gal\\) → G + \\(\\beta-gal\\)\n\\(k_{1}.L.\\beta-gal\\)\n\\(k_{1} = 1\\)\n\n\n2\nG → \\(\\emptyset\\)\n\\(k_{2}.G\\)\n\\(k_{2} = 0.1\\)\n\n\n3\n\\(O_{p}\\) → \\(O_{p}\\) + mRNA\n\\(k_{3}.O_{p}\\)\n\\(k_{3} = 0.01\\)\n\n\n4\n\\(AO_{p}\\) → \\(AO_{p}\\) + mRNA\n\\(k_{4}.AO_{p}\\)\n\\(k_{4} = 0.1\\)\n\n\n5\n\\(RO_{p}\\) → \\(RO_{p}\\) + mRNA\n\\(k_{5}.RO_{p}\\)\n\\(k_{5} = 0.001\\)\n\n\n6\nLRP + \\(O_{p}\\) → \\(RO_{p}\\)\n\\(k_{6}.LRP.O_{p}\\)\n\\(k_{6} = 1\\)\n\n\n7\n\\(RO_{p}\\) → LRP + \\(O_{p}\\)\n\\(k_{7}.RO_{p}\\)\n\\(k_{7} = 1\\)\n\n\n8\nLRP + L → LRP-L\n\\(k_{8}.LRP.L\\)\n\\(k_{8} = 10\\)\n\n\n9\nLRP-L → LRP + L\n\\(k_{9}.LRP-L\\)\n\\(k_{9} = 1\\)\n\n\n10\nCAP + \\(O_{p}\\) → \\(AO_{p}\\)\n\\(k_{10}.CAP.O_{p}\\)\n\\(k_{10} = 1\\)\n\n\n11\n\\(AO_{p}\\) → CAP + \\(O_{p}\\)\n\\(k_{11}.AO_{p}\\)\n\\(k_{11} = 1\\)\n\n\n12\nCAP + G → CAP-G\n\\(k_{12}.CAP.G\\)\n\\(k_{12} = 10\\)\n\n\n13\nCAP-G → CAP + G\n\\(k_{13}.CAP-G\\)\n\\(k_{13} = 1\\)\n\n\n14\nmRNA → mRNA + \\(\\beta-gal\\)\n\\(k_{14}.mRNA\\)\n\\(k_{14} = 1\\)\n\n\n15\nmRNA → \\(\\emptyset\\)\n\\(k_{15}.mRNA\\)\n\\(k_{15} = 1\\)\n\n\n16\n\\(\\beta-gal\\) → \\(\\emptyset\\)\n\\(k_{16}.\\beta-gal\\)\n\\(k_{16} = 0.1\\)\n\n\n\n\nimport numpy as np\nfrom matplotlib import pyplot as plt\n\n\n# initial counts\nl = 50\nb_gal = 0\ng = 50\nop = 1\naop = 0\nrop = 0\nmrna = 0\nlrp = 10\nlrp_l = 0\ncap = 10\ncap_g = 0\nx0 = np.array([l, b_gal, g, op, aop, rop,\n               mrna, lrp, lrp_l, cap, cap_g])\nxt = [x0]\n\n# reaction rate constants\nk1 = 1\nk2 = 0.1\nk3 = 0.01\nk4 = 0.1\nk5 = 0.001\nk6 = 1\nk7 = 1\nk8 = 10\nk9 = 1\nk10 = 1\nk11 = 1\nk12 = 10\nk13 = 1\nk14 = 1\nk15 = 1\nk16 = 0.1\n\n# time parameters\nt = 0\ntpoints = [t]\ntmax = 120\n\n# dictionary to update counts for each reaction\nd = {'r1': np.array([-1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n     'r2': np.array([0, 0, -1, 0, 0, 0, 0, 0, 0, 0, 0]),\n     'r3': np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n     'r4': np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n     'r5': np.array([0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0]),\n     'r6': np.array([0, 0, 0, -1, 0, 1, 0, -1, 0, 0, 0]),\n     'r7': np.array([0, 0, 0, 1, 0, -1, 0, 1, 0, 0, 0]),\n     'r8': np.array([-1, 0, 0, 0, 0, 0, 0, -1, 1, 0, 0]),\n     'r9': np.array([1, 0, 0, 0, 0, 0, 0, 1, -1, 0, 0]),\n     'r10': np.array([0, 0, 0, -1, 1, 0, 0, 0, 0, -1, 0]),\n     'r11': np.array([0, 0, 0, 1, -1, 0, 0, 0, 0, 1, 0]),\n     'r12': np.array([0, 0, -1, 0, 0, 0, 0, 0, 0, -1, 1]),\n     'r13': np.array([0, 0, 1, 0, 0, 0, 0, 0, 0, 1, -1]),\n     'r14': np.array([0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0]),\n     'r15': np.array([0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]),\n     'r16': np.array([0, -1, 0, 0, 0, 0, 0, 0, 0, 0, 0])\n    }\n\n# simulation loop\nwhile t &lt; tmax:\n\n    # get current counts\n    curr_l = xt[-1][0]\n    curr_b_gal = xt[-1][1]\n    curr_g = xt[-1][2]\n    curr_op = xt[-1][3]\n    curr_aop = xt[-1][4]\n    curr_rop = xt[-1][5]\n    curr_mrna = xt[-1][6]\n    curr_lrp = xt[-1][7]\n    curr_lrp_l = xt[-1][8]\n    curr_cap = xt[-1][9]\n    curr_cap_g = xt[-1][10]\n\n    # calculate propensities\n    p1 = k1 * curr_l * curr_b_gal\n    p2 = k2 * curr_g\n    p3 = k3 * curr_op\n    p4 = k4 * curr_aop\n    p5 = k5 * curr_rop\n    p6 = k6 * curr_lrp * curr_op\n    p7 = k7 * curr_rop\n    p8 = k8 * curr_lrp * curr_l\n    p9 = k9 * curr_lrp_l\n    p10 = k10 * curr_cap * curr_op\n    p11 = k11 * curr_aop\n    p12 = k12 * curr_cap * curr_g\n    p13 = k13 * curr_cap_g\n    p14 = k14 * curr_mrna\n    p15 = k15 * curr_mrna\n    p16 = k16 * curr_b_gal\n\n    # calculate total propensity\n    array_p = np.array([p1, p2, p3, p4, p5, p6, p7, p8,\n                       p9, p10, p11, p12, p13, p14, p15, p16])\n    total_p = array_p.sum()\n\n    # randomly sample from uniform distribution\n    sample_p = np.random.uniform(0, total_p)\n\n    # determine next event\n    array_pcs = np.cumsum(array_p)\n    mask = array_pcs &gt; sample_p\n    index = mask.nonzero()[0][0]\n\n    # update counts\n    xnew = xt[-1] + d[f'r{index+1}']\n    xt.append(xnew)\n\n    # determine time to next event\n    scale_para = 1 / total_p\n    dt = np.random.exponential(scale_para)\n\n    # update time\n    t += dt\n    tpoints.append(t)\n\n# convert counts history to array\nxt = np.array(xt)\n\n\nplt.figure().set_figwidth(10)\nplt.xlim([0, tmax])\n#plt.ylim([0, 100])\nplt.xlabel('time')\nplt.ylabel('counts')\nplt.plot(tpoints, xt[:,0], c='darkorange', label='lactose')\nplt.plot(tpoints, xt[:,2], c='gold', label='glucose')\nplt.legend(loc='upper right')\n\n#plt.twinx()\n\n#plt.plot(tpoints, xt[:,1], c='royalblue', label='beta-gal')\n#plt.plot(tpoints, xt[:,3], c='black', label='regular')\n#plt.plot(tpoints, xt[:,4], c='forestgreen', label='activated')\n#plt.plot(tpoints, xt[:,5], c='red', label='repressed')\n#plt.plot(tpoints, xt[:,6], c='blueviolet', label='mRNA')\n\nplt.tight_layout()\nplt.show()"
  },
  {
    "objectID": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html#mini-project",
    "href": "contributions/chee-onn/AY2324 Application Challenge Mini Project.html#mini-project",
    "title": "AY23/24 SP2273 Application Challenge / Mini Project",
    "section": "",
    "text": "The titles proposed here are part of Assignment 2 for SP2274 where students had to use logic models based on Boolean logic gates to model these systems. Many students raised the need to consider stochasticity especially in the context of a single cell organism which fits in comfortably with the topic that will empower students with more control over the system of interest. If they are included in the Mini Project basket, we are hoping to collect some sort of feedback regarding the students’ perception on this project if possible.\n\n\nCopper homeostasis in E. coli that is published in a review paper by Rademacher and Masepohl (2012).\nRademacher, C., & Masepohl, B. (2012). Copper-responsive gene regulation in bacteria. Microbiology (Reading, England), 158(Pt 10), 2451–2464. https://doi.org/10.1099/mic.0.058487-0\n\n\n\nLysogeny maintenance circuit of bacteriophage lambda that is published in a primary paper by Bednarz et al. (2014).\nBednarz, M., Halliday, J. A., Herman, C., & Golding, I. (2014). Revisiting bistability in the lysis/lysogeny circuit of bacteriophage lambda. PloS one, 9(6), e100876. https://doi.org/10.1371/journal.pone.0100876"
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#all-missing-data",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#all-missing-data",
    "title": "Pandas (Good)",
    "section": "1.1 All missing data",
    "text": "1.1 All missing data\nFirst, let’s see if we can get the exact locations of the missing data. Let’s start with the method isna().\ndf_class.isna()\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1282849W\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA5408925A\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6973859L\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA5410124H\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nTrue\n\n\nTrue\n\n\n\n\nA9568373Q\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6824244G\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA9194090U\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA4828364M\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA4607700C\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7067766E\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA5569996J\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA3202548I\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6131593U\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7653832E\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nTrue\n\n\nFalse\n\n\nTrue\n\n\n\n\nA9462811I\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1218599T\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7210476B\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1512479K\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7986368Y\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA2727061A\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nTrue\n\n\nTrue\n\n\n\n\nA2999472W\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7116486E\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6931452S\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA9649096H\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1643380L\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6787293E\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA5975988J\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA3699958T\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nTrue\n\n\nTrue\n\n\nTrue\n\n\n\n\nA1956366U\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA1468689D\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA3217320C\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA6867791C\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA4080490P\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nA7667457P\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\nFalse\n\n\n\n\nThe missing data is where you see True. I hope that you will agree that this information is overwhelming and utterly useless. So, we need to have a way to get more refined information.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#columns-and-rows-of-the-missing-data",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#columns-and-rows-of-the-missing-data",
    "title": "Pandas (Good)",
    "section": "1.2 Columns and rows of the missing data",
    "text": "1.2 Columns and rows of the missing data\nWe can exercise more finesse by combining isna() with any(). any() in this case just asks if there are any True values. The axis option will allow us to pick the rows or columns (Honestly, I can never remember which is which, so I just try 0 or 1 and see what I get).\n\ndf_class.isna().any(axis=0)      # Are there any True in the columns?\n\nMATRIC_NO    False\nName         False\nMajor        False\nGender       False\nTest 1        True\nTest 2        True\nTotal         True\ndtype: bool\n\n\n\ndf_class.isna().any(axis=1)      # Are there any True in the rows?\n\nMATRIC_NO\nA3028967J    False\nA1282849W    False\nA5408925A    False\nA6973859L    False\nA5410124H     True\nA9568373Q    False\nA6824244G    False\nA9194090U    False\nA4828364M    False\nA4607700C    False\nA7067766E    False\nA5569996J    False\nA3202548I    False\nA6131593U    False\nA7653832E     True\nA9462811I    False\nA1218599T    False\nA7210476B    False\nA1512479K    False\nA7986368Y    False\nA2727061A     True\nA2999472W    False\nA7116486E    False\nA6931452S    False\nA9649096H    False\nA1643380L    False\nA6787293E    False\nA5975988J    False\nA3699958T     True\nA1956366U    False\nA1468689D    False\nA3217320C    False\nA6867791C    False\nA4080490P    False\nA7667457P    False\ndtype: bool",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#more-details-of-the-missing-numbers",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#more-details-of-the-missing-numbers",
    "title": "Pandas (Good)",
    "section": "1.3 More details of the missing numbers",
    "text": "1.3 More details of the missing numbers\nDo you see that we can use the last output as a mask to locate the rows that have missing numbers? Let me show you the following:\n\nmask_for_nan = df_class.isna().any(axis=1)\ndf_class[mask_for_nan]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.72\n\n\nNaN\n\n\n\n\nA2727061A\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#dealing-with-missing-numbers",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#dealing-with-missing-numbers",
    "title": "Pandas (Good)",
    "section": "1.4 Dealing with missing numbers?",
    "text": "1.4 Dealing with missing numbers?\nHow you handle missing numbers must depend on what type of data you are dealing with.\nHere are a few things you can do:\n\nReplacing the missing data with a constant value\nFor our dummy class, the numbers are missing because the students were missing from the tests. So, it is easy; we give them zero (the fourth option). The easiest way to do this is using fillna(). I will use a crazy value first so that you can see what is going on.\n\ndf_class.loc[:, ['Test 1', 'Test 2', 'Total']].fillna(99999, inplace=True)\ndf_class[mask_for_nan]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.72\n\n\nNaN\n\n\n\n\nA2727061A\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nDo you see it? Yes, it’s that easy.\nLet me first replace the crazy number with 0 before I forget.\n\ndf_class.replace(99999, 0, inplace = True)\ndf_class[mask_for_nan]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.72\n\n\nNaN\n\n\n\n\nA2727061A\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\nNaN\n\n\nNaN\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nYes, there is a problem with the ‘Total’ column, but we can deal with that later since we have to modify it anyway.\n\n\nExpunging all columns that have missing data (Drastic!)\nI am not going to do this right now, but here is one way you can:\nmask_for_nan_columns = df_class.isna().any(axis=0)\ncolumns_to_keep = df_class.columns[~mask_for_nan_columns].values\ndf_class = df_class[columns_to_keep]\nI inverted (using ~) the mask to pick those columns that are NaN free. Then I just updated df_class with only those columns.\nThis works too:\ndf_class.dropna(axis = 0, inplace=True)\n\n\nExpunging all rows that have missing data (Drastic!)\nAgain, I am not going to do this right now, but here is one way you can:\ndf_class = df_class[~mask_for_nan]\nAgain, I just inverted my mask. And, yet again, the following works too:\ndf_class.dropna(axis = 1, inplace=True)\n\n\nReplace missing data with a representative value (like an average)\nYet, again, I am not going to do this right now, but here is one way you can:\ntest_mean = df_class.loc['Test 1'].mean()\ndf.loc['Test 1'].fillna(test_mean)",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#itterating-over-a-dataframe",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#itterating-over-a-dataframe",
    "title": "Pandas (Good)",
    "section": "1.5 Itterating over a dataframe",
    "text": "1.5 Itterating over a dataframe\nI was looking for a way to introduce iterating (looping) over a dataframe. Now is an excellent opportunity because we can use it to replace the missing data. But this is certainly not the best way because there are highly optimised weapons in the Panda’s arsenal like apply(), fillna() and so on. However, I (lazily) often find myself using loops because they are plain and simple to get started and understand.\nYou can loop through your dataframe using the method itterrows() as follows. It spits out the index and the row for every iteration.\nfor index, row in df_class.iterrows():\n    name = row['Name']\n\n    for column in ['Test 1', 'Test 2']:\n        if np.isnan(row[column]):\n            print(f'{index}: {name:&lt;15}  missing data for {column}')\n            df_class.loc[index, column] = 0\nIf you run this, you should end up with the following:\n    A5410124H: Kyla Young       missing data for Test 2\n    A7653832E: Quentin Kemp     missing data for Test 1\n    A2727061A: Malik Becker     missing data for Test 2\n    A3699958T: Norah Miles      missing data for Test 1\n    A3699958T: Norah Miles      missing data for Test 2\nYou can extract the various columns from the row variable just as you do with a dataframe (loc and iloc works too). I have used isnan() from NumPy to check for NaN because you cannot use ==. I am also using the index to update the original value of the dataframe. There are cautionary tales (e.g. see Nice of Loops) about changing something while iterating over it. However, it is safe in this case.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#the-complete-recipe",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#the-complete-recipe",
    "title": "Pandas (Good)",
    "section": "2.1 The complete recipe",
    "text": "2.1 The complete recipe\nLet me show you the complete recipe for everything we have done in this part. I have reordered some actions (e.g. creation of the ‘Total’ column) and modified a few things (e.g. df_class_1 instead of df_class). I have also removed the excessive comments from the previous version. Everything should flow nicely and make sense to you.\n\n\n# -----------------------------------------------------------------#\n#                           First file                            #\n# -----------------------------------------------------------------#\ndf_class_1 = pd.read_excel('dummy-class-1-of-2.xlsx', skiprows=1)\n\ncolumns_to_keep = ['Student No', 'Name', 'Major', 'Gender',\n                   'Test 1 (30%)', 'Test 2 (20%)']\ndf_class_1 = df_class_1[columns_to_keep]\n\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 1 (30%)': 'Test 1',\n                   'Test 2 (20%)': 'Test 2'}\ndf_class_1.rename(columns=new_column_info, inplace=True)\n\ndf_class_1.set_index('MATRIC_NO', drop=False, inplace=True)\n\nreplace_info = {\n    'PHY': 'Physics',\n    'CHM': 'Chemistry',\n    'LS': 'Life Sciences',\n    'CBIO': 'Comp. Biology',\n    'F': 'Female',\n    'M': 'Male',\n    'NB': 'Non-binary'\n}\ndf_class_1.replace(to_replace=replace_info, inplace=True)\n\n\ndef clean(text):\n    '''\n    Function to remove ' ' from column 'Test 2'.\n    To be applied using apply()\n    '''\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\n\ndf_class_1['Test 2'] = df_class_1['Test 2'].apply(clean)\n\nnew_type_info = {'Major': 'category',\n                 'Gender': 'category',\n                 'Test 2': 'float'}\ndf_class_1 = df_class_1.astype(new_type_info)\n\n# -----------------------------------------------------------------#\n#                           Second file                           #\n# -----------------------------------------------------------------#\ndf_class_2 = pd.read_excel('dummy-class-2-of-2.xlsx')\n\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 3 (50%)': 'Test 3'}\ndf_class_2.rename(columns=new_column_info, inplace=True)\n\ndf_class_2.set_index('MATRIC_NO', inplace=True)\n\n# ---------- Concatenate the two dataframes along columns ---------#\ndf_combined = pd.concat([df_class_1, df_class_2], axis=1)\n\n# -----------------------------------------------------------------#\ndf_combined.loc[:, [\"Test 1\", \"Test 2\", \"Test 3\"]].fillna(0, inplace=True)\ndf_combined[\"Total\"] = df_combined[[\"Test 1\", \"Test 2\", \"Test 3\"]].sum(axis=1)\ndf_combined.sort_values(by='Total', inplace=True)\ndf_combined = df_combined.round(2)\ndf_combined.to_excel('finalised_scores.xlsx', index=False)\ndf_combined.head()\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTest 3\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n0.00\n\n\n\n\nA6867791C\n\n\nA6867791C\n\n\nKatie Ayers\n\n\nComp. Biology\n\n\nFemale\n\n\n16.53\n\n\n10.28\n\n\nNaN\n\n\n26.81\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.31\n\n\nNaN\n\n\n17.5\n\n\n32.81\n\n\n\n\nA7210476B\n\n\nA7210476B\n\n\nSidney Wiggins\n\n\nPhysics\n\n\nNon-binary\n\n\n19.59\n\n\n14.68\n\n\nNaN\n\n\n34.27\n\n\n\n\nA7667457P\n\n\nA7667457P\n\n\nCarter Crane\n\n\nLife Sciences\n\n\nMale\n\n\n20.82\n\n\n13.82\n\n\nNaN\n\n\n34.63",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#barcharts",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#barcharts",
    "title": "Pandas (Good)",
    "section": "3.1 Barcharts",
    "text": "3.1 Barcharts\n\n\n\n\ngrp = df_combined.groupby(['Gender'])[\"Total\"]\ngrp.mean().plot(kind='barh');\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ngrp = df_combined.groupby(['Major'])[[\"Test 1\", \"Test 2\", \"Test 3\"]]\ngrp.mean().plot(kind='barh')\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#histograms",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#histograms",
    "title": "Pandas (Good)",
    "section": "3.2 Histograms",
    "text": "3.2 Histograms\n\n\n\nIf we like, we can create the axes that Pandas will use. Then, you can pass the axis using the ax option. Let me show you.\n\nfix, ax = plt.subplots(nrows=2, ncols=2, sharey=True, figsize=(10,8))\ndf_combined['Total'].plot.hist(ax=ax[0, 0])\ndf_combined['Test 1'].plot.hist(ax=ax[0, 1])\ndf_combined['Test 2'].plot.hist(ax=ax[1, 0])\ndf_combined['Test 3'].plot.hist(ax=ax[1, 1])\nplt.tight_layout()\nplt.show()",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#pie",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#pie",
    "title": "Pandas (Good)",
    "section": "3.3 Pie",
    "text": "3.3 Pie\n\n\n\n\ndf_combined.groupby('Major').size().plot.pie(autopct=\"%d\")\n\n\n\n\n\n\n\n\nautopct specifies the format in which the percentages are displayed.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#boxplots",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#boxplots",
    "title": "Pandas (Good)",
    "section": "3.4 Boxplots",
    "text": "3.4 Boxplots\nBoxplots are amazing at conveying a lot of statistical information efficiently. You will not go wrong if you get into the habit of using them often.\n\n\n\nThis plots all the numerical columns as boxplots.\n\ndf_combined.boxplot()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndf_combined.boxplot(by='Major', column=['Total'], vert=False);\nplt.tight_layout()\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\ndf_combined.boxplot(by='Major',\n                    column=['Test 1', 'Test 2', 'Test 3', 'Total'],\n                    vert=False, figsize=(8, 6));\nplt.show()\n\n\n\n\n\n\n\n\n\n\n\nThere is more that you can do; you can find more details about plotting with Pandas at visualisation page of the Pandas documentation.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/2_pandas_good.html#footnotes",
    "href": "docs/knowledge_lake/pandas/2_pandas_good.html#footnotes",
    "title": "Pandas (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nI dare you that the same using two spreadsheets is going to be inefficient, error-prone, and a headache.↩︎\nActually, Seaborn is a wonderful package that add on to Matplotlib.↩︎",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html",
    "title": "Pandas (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#reading-data-from-csv-or-excel-files.",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#reading-data-from-csv-or-excel-files.",
    "title": "Pandas (Need)",
    "section": "1.1 Reading data from csv or excel files.",
    "text": "1.1 Reading data from csv or excel files.\nOne of the most common file formats used to hold data that you will encounter are Excel files (.xls or .xlsx), csv(comma-separated-values) files or text files (.txt or .dat). Pandas offer ways to read all these files and (many) more. Let’s read in the data in dummy-class.xlsx.\n\ndf_class = pd.read_excel(\"dummy-class-1-of-2.xlsx\", skiprows = 1)\n\nI have used the option skiprows=1 because the first row of the Excel file contains a description that is not data. skiprows is one of many options we can specify.\nI have used the variable df_class to hold the dataframe. With Jupyter you can see the dataframe in a nicely formatted output by simply running:\n\nCodeOutput\n\n\ndf_class\n\n\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n0\n\n\n0\n\n\nBraiden Henson\n\n\nA3028967J\n\n\nPHY\n\n\nM\n\n\n‘18.96’\n\n\n20.205\n\n\n\n\n1\n\n\n1\n\n\nGustavo Vang\n\n\nA1282849W\n\n\nCHM\n\n\nF\n\n\n‘17.44’\n\n\n13.470\n\n\n\n\n2\n\n\n2\n\n\nRonin Christian\n\n\nA5408925A\n\n\nPHY\n\n\nM\n\n\n‘15.56’\n\n\n18.366\n\n\n\n\n3\n\n\n3\n\n\nOwen Anderson\n\n\nA6973859L\n\n\nLS\n\n\nF\n\n\n‘16.36’\n\n\n18.366\n\n\n\n\n4\n\n\n4\n\n\nKyla Young\n\n\nA5410124H\n\n\nPHY\n\n\nM\n\n\nNaN\n\n\n15.306\n\n\n\n\n5\n\n\n5\n\n\nWyatt Oliver\n\n\nA9568373Q\n\n\nPHY\n\n\nM\n\n\n‘14.088’\n\n\n12.246\n\n\n\n\n6\n\n\n6\n\n\nEssence Bauer\n\n\nA6824244G\n\n\nLS\n\n\nM\n\n\n‘16.72’\n\n\n16.530\n\n\n\n\n7\n\n\n7\n\n\nMaryjane Sandoval\n\n\nA9194090U\n\n\nLS\n\n\nF\n\n\n‘16.4’\n\n\n18.981\n\n\n\n\n8\n\n\n8\n\n\nCarl Trujillo\n\n\nA4828364M\n\n\nLS\n\n\nNB\n\n\n‘13.68’\n\n\n15.306\n\n\n\n\n9\n\n\n9\n\n\nHalle Fritz\n\n\nA4607700C\n\n\nLS\n\n\nF\n\n\n‘9.04’\n\n\n17.754\n\n\n\n\n10\n\n\n10\n\n\nMarie Hoffman\n\n\nA7067766E\n\n\nLS\n\n\nF\n\n\n‘16.88’\n\n\n19.593\n\n\n\n\n11\n\n\n11\n\n\nLilianna Kaufman\n\n\nA5569996J\n\n\nLS\n\n\nM\n\n\n‘17.0’\n\n\n26.328\n\n\n\n\n12\n\n\n12\n\n\nJaxon Chung\n\n\nA3202548I\n\n\nPHY\n\n\nM\n\n\n‘16.68’\n\n\n14.082\n\n\n\n\n13\n\n\n13\n\n\nZoey Oconnell\n\n\nA6131593U\n\n\nLS\n\n\nF\n\n\n‘14.128’\n\n\n22.041\n\n\n\n\n14\n\n\n14\n\n\nQuentin Kemp\n\n\nA7653832E\n\n\nCHM\n\n\nF\n\n\n‘15.72’\n\n\nNaN\n\n\n\n\n15\n\n\n15\n\n\nLeo Mayo\n\n\nA9462811I\n\n\nPHY\n\n\nF\n\n\n‘14.68’\n\n\n20.817\n\n\n\n\n16\n\n\n16\n\n\nCamden Williams\n\n\nA1218599T\n\n\nCHM\n\n\nF\n\n\n‘17.648’\n\n\n22.653\n\n\n\n\n17\n\n\n17\n\n\nSidney Wiggins\n\n\nA7210476B\n\n\nPHY\n\n\nNB\n\n\n‘14.68’\n\n\n19.593\n\n\n\n\n18\n\n\n18\n\n\nSolomon Fletcher\n\n\nA1512479K\n\n\nCHM\n\n\nF\n\n\n‘15.0’\n\n\n18.981\n\n\n\n\n19\n\n\n19\n\n\nRiley Christensen\n\n\nA7986368Y\n\n\nCHM\n\n\nF\n\n\n‘16.016’\n\n\n15.306\n\n\n\n\n20\n\n\n20\n\n\nMalik Becker\n\n\nA2727061A\n\n\nPHY\n\n\nM\n\n\nNaN\n\n\n12.858\n\n\n\n\n21\n\n\n21\n\n\nSkylar Hensley\n\n\nA2999472W\n\n\nCHM\n\n\nM\n\n\n‘17.648’\n\n\n23.877\n\n\n\n\n22\n\n\n22\n\n\nBraydon Duran\n\n\nA7116486E\n\n\nLS\n\n\nF\n\n\n‘14.36’\n\n\n15.918\n\n\n\n\n23\n\n\n23\n\n\nJalen Harmon\n\n\nA6931452S\n\n\nLS\n\n\nF\n\n\n‘16.88’\n\n\n22.041\n\n\n\n\n24\n\n\n24\n\n\nEan Haas\n\n\nA9649096H\n\n\nLS\n\n\nF\n\n\n‘14.36’\n\n\n19.593\n\n\n\n\n25\n\n\n25\n\n\nCarolina Mcmahon\n\n\nA1643380L\n\n\nPHY\n\n\nM\n\n\n‘18.08’\n\n\n12.858\n\n\n\n\n26\n\n\n26\n\n\nElian Potter\n\n\nA6787293E\n\n\nPHY\n\n\nM\n\n\n‘14.36’\n\n\n23.265\n\n\n\n\n27\n\n\n27\n\n\nLitzy White\n\n\nA5975988J\n\n\nPHY\n\n\nNB\n\n\n‘15.92’\n\n\n20.817\n\n\n\n\n28\n\n\n28\n\n\nNorah Miles\n\n\nA3699958T\n\n\nCHM\n\n\nM\n\n\nNaN\n\n\nNaN\n\n\n\n\n29\n\n\n29\n\n\nMariela Sheppard\n\n\nA1956366U\n\n\nLS\n\n\nNB\n\n\n‘11.0’\n\n\n18.366\n\n\n\n\n30\n\n\n30\n\n\nIsabela Stokes\n\n\nA1468689D\n\n\nCHM\n\n\nM\n\n\n‘16.8’\n\n\n18.366\n\n\n\n\n31\n\n\n31\n\n\nKathleen Rodriguez\n\n\nA3217320C\n\n\nPHY\n\n\nM\n\n\n‘17.76’\n\n\n22.653\n\n\n\n\n32\n\n\n32\n\n\nKatie Ayers\n\n\nA6867791C\n\n\nCBIO\n\n\nF\n\n\n‘10.28’\n\n\n16.530\n\n\n\n\n33\n\n\n33\n\n\nTucker Sloan\n\n\nA4080490P\n\n\nLS\n\n\nM\n\n\n‘15.04’\n\n\n17.754\n\n\n\n\n34\n\n\n34\n\n\nCarter Crane\n\n\nA7667457P\n\n\nLS\n\n\nM\n\n\n‘13.816’\n\n\n20.817",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#characteristics-to-notice",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#characteristics-to-notice",
    "title": "Pandas (Need)",
    "section": "1.2 Characteristics to notice",
    "text": "1.2 Characteristics to notice\nOkay, now you are bound to think that the above dataframe is no different from a typical spreadsheet. First, however, let me draw your attention to three different characteristics.\n\nThe first is the use of an index (leftmost column in bold) for each row (0 1 2 3...). This simple fact simplifies doing things with your data. I will show you some examples later.\nThe second is that a column (called a Pandas Series) can only have a single type of data. So, for example, you can have numbers or text; but not both.\nThe third is the presence of NaN (‘Not-a-Number’) when data is missing. Missing data is a common bane of real data; Pandas offers powerful ways to deal with such missing numbers transparently. I will show more later in this chapter.\n\nFor the moment,\n\n\n\n\n\n\nRemember\n\n\n\nRemember that a dataframe is like a spreadsheet but has an additional unique index for each row. This index plays an important role.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#head-and-tail",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#head-and-tail",
    "title": "Pandas (Need)",
    "section": "2.1 Head and Tail",
    "text": "2.1 Head and Tail\nReal data sets are bound to have more rows than the dummy class toy data set. You can take a quick peek at the top or bottom of the dataframe by using the head() and tail() methods, respectively.\ndf_class.head(3)\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n0\n\n\n0\n\n\nBraiden Henson\n\n\nA3028967J\n\n\nPHY\n\n\nM\n\n\n‘18.96’\n\n\n20.205\n\n\n\n\n1\n\n\n1\n\n\nGustavo Vang\n\n\nA1282849W\n\n\nCHM\n\n\nF\n\n\n‘17.44’\n\n\n13.470\n\n\n\n\n2\n\n\n2\n\n\nRonin Christian\n\n\nA5408925A\n\n\nPHY\n\n\nM\n\n\n‘15.56’\n\n\n18.366\n\n\n\n\ndf_class.tail(3)\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n32\n\n\n32\n\n\nKatie Ayers\n\n\nA6867791C\n\n\nCBIO\n\n\nF\n\n\n‘10.28’\n\n\n16.530\n\n\n\n\n33\n\n\n33\n\n\nTucker Sloan\n\n\nA4080490P\n\n\nLS\n\n\nM\n\n\n‘15.04’\n\n\n17.754\n\n\n\n\n34\n\n\n34\n\n\nCarter Crane\n\n\nA7667457P\n\n\nLS\n\n\nM\n\n\n‘13.816’\n\n\n20.817\n\n\n\n\nIf you do not specify the number of rows, it defaults to five.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#size-and-shape",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#size-and-shape",
    "title": "Pandas (Need)",
    "section": "2.2 Size and Shape",
    "text": "2.2 Size and Shape\nWe can get the size and shape of the dataframe by using shape, len() and columns.\n\ndf_class.shape\n\n(35, 7)\n\n\n\nlen(df_class)\n\n35\n\n\n\ndf_class.columns\n\nIndex(['Unnamed: 0', 'Name', 'Student No', 'Major', 'Gender', 'Test 2 (20%)',\n       'Test 1 (30%)'],\n      dtype='object')",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#summaries-i",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#summaries-i",
    "title": "Pandas (Need)",
    "section": "2.3 Summaries (I)",
    "text": "2.3 Summaries (I)\nPandas offer more powerful ways to get more valuable summaries of your dataset with the methods info() and describe().\n\ndf_class.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 35 entries, 0 to 34\nData columns (total 7 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Unnamed: 0    35 non-null     int64  \n 1   Name          35 non-null     object \n 2   Student No    35 non-null     object \n 3   Major         35 non-null     object \n 4   Gender        35 non-null     object \n 5   Test 2 (20%)  32 non-null     object \n 6   Test 1 (30%)  33 non-null     float64\ndtypes: float64(1), int64(1), object(5)\nmemory usage: 2.0+ KB\n\n\nThis information is very useful. You can quickly see the various columns, what type of data they contain and how many data points are present. This is a good place to spot missing data like in ‘Test 1’ and ‘Test 2’. The type object means str or English-like data. float64 is floating point data (i.e. decimal numbers). We also note that ‘Test 2’ is not a numerical type despite their data having numerical significance. So, one of the first things we should do is convert these to numerical types. I will focus on type conversion a bit later. However, let me ‘parachute’ some code here to continue our discussion.\n\nA quick digression\n\nThe problemCodeAfter the conversion\n\n\nPandas do not see ‘Test 2’ data as numbers because its data has additional' '.\n\ndf_class['Test 2 (20%)'].head(3)\n\n0    '18.96'\n1    '17.44'\n2    '15.56'\nName: Test 2 (20%), dtype: object\n\n\n\n\nHere, I first replace the ' with nothing and then convert the data using pd.to_numeric()\n\ndf_class['Test 2 (20%)'] = df_class['Test 2 (20%)'].str.replace(\"'\", \"\")\ndf_class['Test 2 (20%)'] = pd.to_numeric(df_class['Test 2 (20%)'])\n\n\n\n\ndf_class.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nRangeIndex: 35 entries, 0 to 34\nData columns (total 7 columns):\n #   Column        Non-Null Count  Dtype  \n---  ------        --------------  -----  \n 0   Unnamed: 0    35 non-null     int64  \n 1   Name          35 non-null     object \n 2   Student No    35 non-null     object \n 3   Major         35 non-null     object \n 4   Gender        35 non-null     object \n 5   Test 2 (20%)  32 non-null     float64\n 6   Test 1 (30%)  33 non-null     float64\ndtypes: float64(2), int64(1), object(4)\nmemory usage: 2.0+ KB\n\n\n\n\n\n\n\nBack to the original discussion\nOkay, let’s continue discussing ways to peek into the file.\n\ndf_class.describe()\n\n       Unnamed: 0  Test 2 (20%)  Test 1 (30%)\ncount   35.000000     32.000000     33.000000\nmean    17.000000     15.405750     18.534455\nstd     10.246951      2.229394      3.487934\nmin      0.000000      9.040000     12.246000\n25%      8.500000     14.360000     15.918000\n50%     17.000000     15.820000     18.366000\n75%     25.500000     16.880000     20.817000\nmax     34.000000     18.960000     26.328000\n\n\ndescribe() gives us some summary statistics. By default, it only shows information relevant to the numerical columns. But let’s ask for more!\n\ndf_class.describe(include=\"all\")\n\n        Unnamed: 0            Name  ... Test 2 (20%) Test 1 (30%)\ncount    35.000000              35  ...    32.000000    33.000000\nunique         NaN              35  ...          NaN          NaN\ntop            NaN  Braiden Henson  ...          NaN          NaN\nfreq           NaN               1  ...          NaN          NaN\nmean     17.000000             NaN  ...    15.405750    18.534455\nstd      10.246951             NaN  ...     2.229394     3.487934\nmin       0.000000             NaN  ...     9.040000    12.246000\n25%       8.500000             NaN  ...    14.360000    15.918000\n50%      17.000000             NaN  ...    15.820000    18.366000\n75%      25.500000             NaN  ...    16.880000    20.817000\nmax      34.000000             NaN  ...    18.960000    26.328000\n\n[11 rows x 7 columns]\n\n\nunique tells us how many unique entries are present. It also shows information about the top one with the highest frequency. For example, there are four ‘Majors’ and LS appears 14 times. Gender has three unique values, with M appearing 16 times.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#summaries-ii",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#summaries-ii",
    "title": "Pandas (Need)",
    "section": "2.4 Summaries (II)",
    "text": "2.4 Summaries (II)\nI can also do the following to get quick summaries.\n\n\n\nData for a single column.\n\ndf_class['Test 1 (30%)'].mean()\n\n18.534454545454548\n\n\n\n\nData for multiple columns.\n\ndf_class[['Test 1 (30%)', 'Test 2 (20%)']].mean()\n\nTest 1 (30%)    18.534455\nTest 2 (20%)    15.405750\ndtype: float64\n\n\n\n\nShow me all the values\n\ndf_class['Major'].values\n\narray(['PHY', 'CHM', 'PHY', 'LS', 'PHY', 'PHY', 'LS', 'LS', 'LS', 'LS',\n       'LS', 'LS', 'PHY', 'LS', 'CHM', 'PHY', 'CHM', 'PHY', 'CHM', 'CHM',\n       'PHY', 'CHM', 'LS', 'LS', 'LS', 'PHY', 'PHY', 'PHY', 'CHM', 'LS',\n       'CHM', 'PHY', 'CBIO', 'LS', 'LS'], dtype=object)\n\n\n\n\n\ndf_class['Major'].unique()\n\narray(['PHY', 'CHM', 'LS', 'CBIO'], dtype=object)\n\n\n\n\n\ndf_class['Major'].value_counts()\n\nMajor\nLS      14\nPHY     12\nCHM      8\nCBIO     1\nName: count, dtype: int64\n\n\nWe can typecast these outputs to more familiar lists or dictionaries by:\n\ndf_class['Major'].value_counts().to_dict()\n\n{'LS': 14, 'PHY': 12, 'CHM': 8, 'CBIO': 1}\n\n\n\ndf_class['Major'].value_counts().to_list()\n\n[14, 12, 8, 1]\n\n\nThe following is useful too:\n\ndf_class['Major'].value_counts().index.to_list()\n\n['LS', 'PHY', 'CHM', 'CBIO']",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#dropping-unnecessary-columns",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#dropping-unnecessary-columns",
    "title": "Pandas (Need)",
    "section": "3.1 Dropping unnecessary columns",
    "text": "3.1 Dropping unnecessary columns\nLet me start by dropping the unnecessary column Unnamed: 0.\n\ndf_class.drop(columns=['Unnamed: 0'])\n\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n0\n\n\n0\n\n\nBraiden Henson\n\n\nA3028967J\n\n\nPHY\n\n\nM\n\n\n18.96\n\n\n20.205\n\n\n\n\n1\n\n\n1\n\n\nGustavo Vang\n\n\nA1282849W\n\n\nCHM\n\n\nF\n\n\n17.44\n\n\n13.470\n\n\n\n\n2\n\n\n2\n\n\nRonin Christian\n\n\nA5408925A\n\n\nPHY\n\n\nM\n\n\n15.56\n\n\n18.366\n\n\n\n\n3\n\n\n3\n\n\nOwen Anderson\n\n\nA6973859L\n\n\nLS\n\n\nF\n\n\n16.36\n\n\n18.366\n\n\n\n\n4\n\n\n4\n\n\nKyla Young\n\n\nA5410124H\n\n\nPHY\n\n\nM\n\n\nNaN\n\n\n15.306\n\n\n\n\nOkay, it seems to have worked but, if you look at df_class, you will see nothing has changed!\ndf_class.head()\n\n\n\n\n\n\nUnnamed: 0\n\n\nName\n\n\nStudent No\n\n\nMajor\n\n\nGender\n\n\nTest 2 (20%)\n\n\nTest 1 (30%)\n\n\n\n\n\n\n0\n\n\n0\n\n\nBraiden Henson\n\n\nA3028967J\n\n\nPHY\n\n\nM\n\n\n18.96\n\n\n20.205\n\n\n\n\n1\n\n\n1\n\n\nGustavo Vang\n\n\nA1282849W\n\n\nCHM\n\n\nF\n\n\n17.44\n\n\n13.470\n\n\n\n\n2\n\n\n2\n\n\nRonin Christian\n\n\nA5408925A\n\n\nPHY\n\n\nM\n\n\n15.56\n\n\n18.366\n\n\n\n\n3\n\n\n3\n\n\nOwen Anderson\n\n\nA6973859L\n\n\nLS\n\n\nF\n\n\n16.36\n\n\n18.366\n\n\n\n\n4\n\n\n4\n\n\nKyla Young\n\n\nA5410124H\n\n\nPHY\n\n\nM\n\n\nNaN\n\n\n15.306\n\n\n\n\nWhat is happening is that the drop() command drops, but gives us a new dataframe without changing the original. There are two ways to change our original dataframe.\nOne is simply to update the variable.\ndf_class = df_class.drop(columns=['Unnamed: 0'])\nAnother is to set the option inplace=True so that drop() makes the modifications to the original dataframe, inplace.\n\ndf_class.drop(columns=['Unnamed: 0'], inplace=True)\n\nIf you do this, there will be no output displayed. Note also that not all methods offer the option inplace.\n\n\n\n\n\n\nRemember\n\n\n\nRemember to update the original dataframe if you make changes by either updating the variable or using inplace\n\n\nI find this behaviour of not modifying the original dataframe until we explicitly say so very useful. I can mess with the dataframe as I like and only update when I know I am ready.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#reorganising-columns",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#reorganising-columns",
    "title": "Pandas (Need)",
    "section": "3.2 Reorganising columns",
    "text": "3.2 Reorganising columns\nI like to reorganise my columns so that the student number is the first column. I can do it like this:\n\ncolumns_to_keep = ['Student No', 'Name', 'Major', 'Gender',\n                   'Test 1 (30%)', 'Test 2 (20%)']\n\ndf_class = df_class[columns_to_keep]\n\nIncidentally, I could have done the reorganisation and dropping with this single step. However, this can get tedious if you have a lot of columns.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#renaming-columns",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#renaming-columns",
    "title": "Pandas (Need)",
    "section": "3.3 Renaming columns",
    "text": "3.3 Renaming columns\nLet’s now rename some of the columns. This is very easy; we just have to supply a dictionary with the columns we want to update. The changes I want are:\n\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 1 (30%)': 'Test 1',\n                   'Test 2 (20%)': 'Test 2'}\n\ndf_class.rename(columns=new_column_info, inplace=True)\n\ndf_class.head()\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\n\n\n\n\n0\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPHY\n\n\nM\n\n\n20.205\n\n\n18.96\n\n\n\n\n1\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nCHM\n\n\nF\n\n\n13.470\n\n\n17.44\n\n\n\n\n2\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPHY\n\n\nM\n\n\n18.366\n\n\n15.56\n\n\n\n\n3\n\n\nA6973859L\n\n\nOwen Anderson\n\n\nLS\n\n\nF\n\n\n18.366\n\n\n16.36\n\n\n\n\n4\n\n\nA5410124H\n\n\nKyla Young\n\n\nPHY\n\n\nM\n\n\n15.306\n\n\nNaN",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#setting-the-index",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#setting-the-index",
    "title": "Pandas (Need)",
    "section": "3.4 Setting the index",
    "text": "3.4 Setting the index\nAt the moment, the indices are just numbers from 0 to 34. You can check this with\n\ndf_class.index\n\nRangeIndex(start=0, stop=35, step=1)\n\n\nHowever, I want to change it so I can refer to my rows using the MATRIC_NO (I will show you why this is useful later).\n\ndf_class.set_index('MATRIC_NO', drop=False, inplace=True)\n\nI am asking Pandas to use the values of the column ‘MATRIC_NO’ as indices for the rows. I put drop=False to prevent Pandas from dropping the column because I still like to keep it.\ndf_class.head()\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPHY\n\n\nM\n\n\n20.205\n\n\n18.96\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nCHM\n\n\nF\n\n\n13.470\n\n\n17.44\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPHY\n\n\nM\n\n\n18.366\n\n\n15.56\n\n\n\n\nA6973859L\n\n\nA6973859L\n\n\nOwen Anderson\n\n\nLS\n\n\nF\n\n\n18.366\n\n\n16.36\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPHY\n\n\nM\n\n\n15.306\n\n\nNaN",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#applying-changes",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#applying-changes",
    "title": "Pandas (Need)",
    "section": "3.5 Applying changes",
    "text": "3.5 Applying changes\nThere are a few things I like to change with the data.\n\nReplacing the abbreviation for the majors with full names,\nReplacing the abbreviation for the ‘M’, ‘F’, ‘NB’ with their full forms.\n\nThe Test 2 column has all its numbers between inverted commas (e.g. ‘16.36’ ). I like to remove these inverted commas.\n\nThe first two are very simple. But before we do anything, let’s get a list of all the unique items in the columns Majors and Gender.\n\ndf_class['Major'].unique()\n\narray(['PHY', 'CHM', 'LS', 'CBIO'], dtype=object)\n\ndf_class['Gender'].unique()\n\narray(['M', 'F', 'NB'], dtype=object)\n\n\nNow that we know the unique values, let’s make the changes.\n\nreplace_info = {\n    'PHY': 'Physics',\n    'CHM': 'Chemistry',\n    'LS': 'Life Sciences',\n    'CBIO': 'Comp. Biology',\n    'F': 'Female',\n    'M': 'Male',\n    'NB': 'Non-binary'\n}\n\ndf_class.replace(to_replace=replace_info, inplace=True)\n\nThere are a few ways to do the third. Let me show you the method that is the most versatile and uses the apply() method.\n\ndef clean(text):\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\ndf_class['Test 2'] = df_class['Test 2'].apply(clean)\n\nHere we use the apply() method to apply my function clean to the column ‘Test 2’. The missing numbers in this column are a bit annoying because they are replaced with NaN, which is a float, while everything else is a string (i.e. English). So, I have included a try-except statement to get around this. Again, I know the exact error because Python screamed it at me when I did not account for the error. The apply() method is super useful and can be used to do more complicated things. This is good enough for now.\nLet’s see what our handiwork looks like:\ndf_class.head()\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPhysics\n\n\nMale\n\n\n20.205\n\n\n18.96\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n13.470\n\n\n17.44\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPhysics\n\n\nMale\n\n\n18.366\n\n\n15.56\n\n\n\n\nA6973859L\n\n\nA6973859L\n\n\nOwen Anderson\n\n\nLife Sciences\n\n\nFemale\n\n\n18.366\n\n\n16.36\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#changing-column-type",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#changing-column-type",
    "title": "Pandas (Need)",
    "section": "3.6 Changing Column Type",
    "text": "3.6 Changing Column Type\nLet’s now change the column type for some of our columns so that they are more representative of the data they carry. First, remember that we have a problem with column ‘Test 2’ in that it is in English and not in number format viz.\n\ndf_class.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 35 entries, A3028967J to A7667457P\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype  \n---  ------     --------------  -----  \n 0   MATRIC_NO  35 non-null     object \n 1   Name       35 non-null     object \n 2   Major      35 non-null     object \n 3   Gender     35 non-null     object \n 4   Test 1     33 non-null     float64\n 5   Test 2     32 non-null     float64\ndtypes: float64(2), object(4)\nmemory usage: 1.9+ KB\n\n\nChanging type is done with a dictionary and is just as easy. I will also change the type of Major and Gender as they hold categorical data (i.e. data that are limited to a fixed number of options).\n\nnew_type_info = {'Major': 'category',\n                 'Gender': 'category',\n                 'Test 2': 'float'}\n\n# atype does NOT have an inplace option\ndf_class = df_class.astype(new_type_info)      \n\nLet’s check if this worked.\n\ndf_class.info()\n\n&lt;class 'pandas.core.frame.DataFrame'&gt;\nIndex: 35 entries, A3028967J to A7667457P\nData columns (total 6 columns):\n #   Column     Non-Null Count  Dtype   \n---  ------     --------------  -----   \n 0   MATRIC_NO  35 non-null     object  \n 1   Name       35 non-null     object  \n 2   Major      35 non-null     category\n 3   Gender     35 non-null     category\n 4   Test 1     33 non-null     float64 \n 5   Test 2     32 non-null     float64 \ndtypes: category(2), float64(2), object(2)\nmemory usage: 1.8+ KB\n\n\nYup, looks good.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#adding-a-new-column",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#adding-a-new-column",
    "title": "Pandas (Need)",
    "section": "3.7 Adding a new column",
    "text": "3.7 Adding a new column\nWe should create a new column called Total to hold the total score. This is laughably simple.\n\ndf_class[\"Total\"] = df_class[\"Test 1\"] + df_class[\"Test 2\"]\n\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPhysics\n\n\nMale\n\n\n20.205\n\n\n18.96\n\n\n39.165\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n13.470\n\n\n17.44\n\n\n30.910\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPhysics\n\n\nMale\n\n\n18.366\n\n\n15.56\n\n\n33.926\n\n\n\n\nA6973859L\n\n\nA6973859L\n\n\nOwen Anderson\n\n\nLife Sciences\n\n\nFemale\n\n\n18.366\n\n\n16.36\n\n\n34.726\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#saving-to-file",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#saving-to-file",
    "title": "Pandas (Need)",
    "section": "3.8 Saving to file",
    "text": "3.8 Saving to file\nLet’s export our dataframe as an Excel file (many other options are possible!).\ndf_class.to_excel('finalised_scores.xlsx', index=False)\nI have used the index=False to tell Pandas not to write the index column.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#the-recipe-so-far",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#the-recipe-so-far",
    "title": "Pandas (Need)",
    "section": "3.9 The recipe so far",
    "text": "3.9 The recipe so far\nIdeally, what should follow now is fixing any missing data. However, I will postpone that discussion to the next chapter and move on to another important thing to do with dataframes. Before that, however, let me show you the full recipe we have so far been building.\n\ndf_class = pd.read_excel('dummy-class-1-of-2.xlsx', skiprows=1)\n\n#------------------ Drop and reorganise columns  -----------------#\ncolumns_to_keep = ['Student No', 'Name', 'Major', 'Gender',\n                   'Test 1 (30%)', 'Test 2 (20%)']\n\ndf_class = df_class[columns_to_keep]\n\n#------------------------- Rename columns ------------------------#\nnew_column_info = {'Student No': 'MATRIC_NO',\n                   'Test 1 (30%)': 'Test 1',\n                   'Test 2 (20%)': 'Test 2'}\n\ndf_class.rename(columns=new_column_info, inplace=True)\n\n#--------------------- Set index to MATRIC_NO --------------------#\ndf_class.set_index('MATRIC_NO', drop=False, inplace=True)\n\n#-------------------------- Rename stuff -------------------------#\nreplace_info = {\n    'PHY': 'Physics',\n    'CHM': 'Chemistry',\n    'LS': 'Life Sciences',\n    'CBIO': 'Comp. Biology',\n    'F': 'Female',\n    'M': 'Male',\n    'NB': 'Non-binary'\n}\n\ndf_class.replace(to_replace=replace_info, inplace=True)\n\n#---------------- Remove the ' ' from column Test 2 --------------#\n\n\ndef clean(text):\n    '''\n    Function to remove ' ' from column 'Test 2'.\n    To be applied using apply()\n    '''\n    try:\n        return text.replace(\"'\", \"\")\n    except AttributeError:\n        # This will handle the NaN of the missing data\n        return text\n\n\ndf_class['Test 2'] = df_class['Test 2'].apply(clean)\n\n#--------------- Convert column Test 2 to type float -------------#\nnew_type_info = {'Major': 'category',\n                 'Gender': 'category',\n                 'Test 2': 'float'}\n\ndf_class = df_class.astype(new_type_info)\n\n#------------------------ Add a new column -----------------------#\ndf_class[\"Total\"] = df_class[\"Test 1\"] + df_class[\"Test 2\"]\n\n#------------------------- Export the file -----------------------#\ndf_class.to_excel('finalised_scores.xlsx', index=False)\n\ndf_class.head()",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#locating-data",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#locating-data",
    "title": "Pandas (Need)",
    "section": "4.1 Locating data",
    "text": "4.1 Locating data\nPandas offer us two ways (loc and iloc) to access and locate the data in our dataframe.\n\nUsing iloc\nWe use iloc by specifying an index (like with a NumPy array). So, the following will show the contents from rows 11, 12, and 13 of columns 3 and 4 (Remember that Python is zero-indexed!).\ndf_class.iloc[10:13, 2:4]\n\n\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\nA7067766E\n\n\nLife Sciences\n\n\nFemale\n\n\n\n\nA5569996J\n\n\nLife Sciences\n\n\nMale\n\n\n\n\nA3202548I\n\n\nPhysics\n\n\nMale\n\n\n\n\n\n\nUsing loc\nWe use loc by specifying a names of rows (i.e. the indexes) or a mask. I will explain the mask part in a bit; for the moment, here is how to get the same output as above. Please note that the ‘numbers’ corresponding to rows from 11 to 14, in this case, are ‘names’.\ndf_class.loc[[\"A7067766E\", \"A5569996J\", \"A3202548I\"], [\"Major\", \"Gender\"]]\n\n\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\nA7067766E\n\n\nLife Sciences\n\n\nFemale\n\n\n\n\nA5569996J\n\n\nLife Sciences\n\n\nMale\n\n\n\n\nA3202548I\n\n\nPhysics\n\n\nMale",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#asking-questions-with-masks",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#asking-questions-with-masks",
    "title": "Pandas (Need)",
    "section": "4.2 Asking questions with masks",
    "text": "4.2 Asking questions with masks\nloc is most powerful with a mask (like NumPy) array. You can create a mask of (True and False) by asking a simple question. Here are some examples. \n\n\n\n\ndf_class[\"Major\"] == \"Chemistry\"\n\nMATRIC_NO\nA3028967J    False\nA1282849W     True\nA5408925A    False\nA6973859L    False\nA5410124H    False\nA9568373Q    False\nA6824244G    False\nA9194090U    False\nA4828364M    False\nA4607700C    False\nA7067766E    False\nA5569996J    False\nA3202548I    False\nA6131593U    False\nA7653832E     True\nA9462811I    False\nA1218599T     True\nA7210476B    False\nA1512479K     True\nA7986368Y     True\nA2727061A    False\nA2999472W     True\nA7116486E    False\nA6931452S    False\nA9649096H    False\nA1643380L    False\nA6787293E    False\nA5975988J    False\nA3699958T     True\nA1956366U    False\nA1468689D     True\nA3217320C    False\nA6867791C    False\nA4080490P    False\nA7667457P    False\nName: Major, dtype: bool\n\n\nas you can see, the ‘answer’ is a bunch of True and False values for the whole dataframe. You can then apply these True and False values to mask the values that are False like this:\ndf_class.loc[df_class[\"Major\"] == \"Chemistry\"]\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n13.470\n\n\n17.440\n\n\n30.910\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.720\n\n\nNaN\n\n\n\n\nA1218599T\n\n\nA1218599T\n\n\nCamden Williams\n\n\nChemistry\n\n\nFemale\n\n\n22.653\n\n\n17.648\n\n\n40.301\n\n\n\n\nA1512479K\n\n\nA1512479K\n\n\nSolomon Fletcher\n\n\nChemistry\n\n\nFemale\n\n\n18.981\n\n\n15.000\n\n\n33.981\n\n\n\n\nA7986368Y\n\n\nA7986368Y\n\n\nRiley Christensen\n\n\nChemistry\n\n\nFemale\n\n\n15.306\n\n\n16.016\n\n\n31.322\n\n\n\n\nA2999472W\n\n\nA2999472W\n\n\nSkylar Hensley\n\n\nChemistry\n\n\nMale\n\n\n23.877\n\n\n17.648\n\n\n41.525\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1468689D\n\n\nA1468689D\n\n\nIsabela Stokes\n\n\nChemistry\n\n\nMale\n\n\n18.366\n\n\n16.800\n\n\n35.166\n\n\n\n\n\n\nYou can invert a mask with the ~ like this.\ndf_class.loc[~(df_class[\"Major\"] == \"Life Sciences\")]\n\n\n\n\n\n\nMATRIC_NO\n\n\nName\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nA3028967J\n\n\nA3028967J\n\n\nBraiden Henson\n\n\nPhysics\n\n\nMale\n\n\n20.205\n\n\n18.960\n\n\n39.165\n\n\n\n\nA1282849W\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n13.470\n\n\n17.440\n\n\n30.910\n\n\n\n\nA5408925A\n\n\nA5408925A\n\n\nRonin Christian\n\n\nPhysics\n\n\nMale\n\n\n18.366\n\n\n15.560\n\n\n33.926\n\n\n\n\nA5410124H\n\n\nA5410124H\n\n\nKyla Young\n\n\nPhysics\n\n\nMale\n\n\n15.306\n\n\nNaN\n\n\nNaN\n\n\n\n\nA9568373Q\n\n\nA9568373Q\n\n\nWyatt Oliver\n\n\nPhysics\n\n\nMale\n\n\n12.246\n\n\n14.088\n\n\n26.334\n\n\n\n\nA3202548I\n\n\nA3202548I\n\n\nJaxon Chung\n\n\nPhysics\n\n\nMale\n\n\n14.082\n\n\n16.680\n\n\n30.762\n\n\n\n\nA7653832E\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\nNaN\n\n\n15.720\n\n\nNaN\n\n\n\n\nA9462811I\n\n\nA9462811I\n\n\nLeo Mayo\n\n\nPhysics\n\n\nFemale\n\n\n20.817\n\n\n14.680\n\n\n35.497\n\n\n\n\nA1218599T\n\n\nA1218599T\n\n\nCamden Williams\n\n\nChemistry\n\n\nFemale\n\n\n22.653\n\n\n17.648\n\n\n40.301\n\n\n\n\nA7210476B\n\n\nA7210476B\n\n\nSidney Wiggins\n\n\nPhysics\n\n\nNon-binary\n\n\n19.593\n\n\n14.680\n\n\n34.273\n\n\n\n\nA1512479K\n\n\nA1512479K\n\n\nSolomon Fletcher\n\n\nChemistry\n\n\nFemale\n\n\n18.981\n\n\n15.000\n\n\n33.981\n\n\n\n\nA7986368Y\n\n\nA7986368Y\n\n\nRiley Christensen\n\n\nChemistry\n\n\nFemale\n\n\n15.306\n\n\n16.016\n\n\n31.322\n\n\n\n\nA2727061A\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\nNaN\n\n\nNaN\n\n\n\n\nA2999472W\n\n\nA2999472W\n\n\nSkylar Hensley\n\n\nChemistry\n\n\nMale\n\n\n23.877\n\n\n17.648\n\n\n41.525\n\n\n\n\nA1643380L\n\n\nA1643380L\n\n\nCarolina Mcmahon\n\n\nPhysics\n\n\nMale\n\n\n12.858\n\n\n18.080\n\n\n30.938\n\n\n\n\nA6787293E\n\n\nA6787293E\n\n\nElian Potter\n\n\nPhysics\n\n\nMale\n\n\n23.265\n\n\n14.360\n\n\n37.625\n\n\n\n\nA5975988J\n\n\nA5975988J\n\n\nLitzy White\n\n\nPhysics\n\n\nNon-binary\n\n\n20.817\n\n\n15.920\n\n\n36.737\n\n\n\n\nA3699958T\n\n\nA3699958T\n\n\nNorah Miles\n\n\nChemistry\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nA1468689D\n\n\nA1468689D\n\n\nIsabela Stokes\n\n\nChemistry\n\n\nMale\n\n\n18.366\n\n\n16.800\n\n\n35.166\n\n\n\n\nA3217320C\n\n\nA3217320C\n\n\nKathleen Rodriguez\n\n\nPhysics\n\n\nMale\n\n\n22.653\n\n\n17.760\n\n\n40.413\n\n\n\n\nA6867791C\n\n\nA6867791C\n\n\nKatie Ayers\n\n\nComp. Biology\n\n\nFemale\n\n\n16.530\n\n\n10.280\n\n\n26.810\n\n\n\n\n\n\nLet’s create another mask for all the Chemistry students who identify as Female.\n\n# Create mask\nmask = (df_class[\"Major\"] == \"Chemistry\") & (df_class[\"Gender\"] == 'Female')\n\n# Using mask\ndf_class.loc[mask, [\"Name\", \"Major\", \"Gender\"]]    \n\n\n\n\n\n\n\nName\n\n\nMajor\n\n\nGender\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\nFemale\n\n\n\n\nA7653832E\n\n\nQuentin Kemp\n\n\nChemistry\n\n\nFemale\n\n\n\n\nA1218599T\n\n\nCamden Williams\n\n\nChemistry\n\n\nFemale\n\n\n\n\nA1512479K\n\n\nSolomon Fletcher\n\n\nChemistry\n\n\nFemale\n\n\n\n\nA7986368Y\n\n\nRiley Christensen\n\n\nChemistry\n\n\nFemale\n\n\n\n\nCool right!\n\n\nLet’s do another one. How about all students who scored less than 15% on Test 1?\n\nmask = df_class[\"Test 1\"] &lt; 15\ndf_class.loc[mask, [\"Name\", \"Major\", \"Test 1\"]]   \n\n\n\n\n\n\n\nName\n\n\nMajor\n\n\nTest 1\n\n\n\n\nMATRIC_NO\n\n\n\n\n\n\n\n\n\n\n\n\nA1282849W\n\n\nGustavo Vang\n\n\nChemistry\n\n\n13.470\n\n\n\n\nA9568373Q\n\n\nWyatt Oliver\n\n\nPhysics\n\n\n12.246\n\n\n\n\nA3202548I\n\n\nJaxon Chung\n\n\nPhysics\n\n\n14.082\n\n\n\n\nA2727061A\n\n\nMalik Becker\n\n\nPhysics\n\n\n12.858\n\n\n\n\nA1643380L\n\n\nCarolina Mcmahon\n\n\nPhysics\n\n\n12.858",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/pandas/1_pandas_need.html#the-magic-of-groupby",
    "href": "docs/knowledge_lake/pandas/1_pandas_need.html#the-magic-of-groupby",
    "title": "Pandas (Need)",
    "section": "4.3 The magic of groupby()",
    "text": "4.3 The magic of groupby()\nLet me show you how to use the mesmerising, extremely powerful function groupby(). It is absurd how simple some things become with the right tools.\nHere are some examples.\n\n\n\nWhat are the means of the scores for the various test, according to Major?\ndf_class.groupby(by=[\"Major\"]).mean(numeric_only=True)\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMajor\n\n\n\n\n\n\n\n\n\n\n\n\nChemistry\n\n\n18.7755\n\n\n16.610286\n\n\n35.534167\n\n\n\n\nComp. Biology\n\n\n16.5300\n\n\n10.280000\n\n\n26.810000\n\n\n\n\nLife Sciences\n\n\n19.2420\n\n\n14.690286\n\n\n33.932286\n\n\n\n\nPhysics\n\n\n17.7555\n\n\n16.076800\n\n\n34.567000\n\n\n\n\n:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. We use numeric_only=True to tell Pandas not to try evaluating a mean for non-numeric (‘Gender’ in this case) columns. However, I find this a tad annoying and non-intuitive for other (see agg() below) actions. So, I prefer to explicitly ask for the columns I want.\ndf_class.groupby(by=[\"Major\"])[['Test 1', 'Test 2', 'Total']].mean()\n\n\nLet’s group-by Major and Gender.\ndf_class.groupby(by=[\"Major\", \"Gender\"])[['Test 1', 'Test 2', 'Total']].mean()\n\n\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\n\n\n\n\n\n\n\n\nChemistry\n\n\nFemale\n\n\n17.602500\n\n\n16.364800\n\n\n34.128500\n\n\n\n\nMale\n\n\n21.121500\n\n\n17.224000\n\n\n38.345500\n\n\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nComp. Biology\n\n\nFemale\n\n\n16.530000\n\n\n10.280000\n\n\n26.810000\n\n\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\nFemale\n\n\n19.285875\n\n\n14.801000\n\n\n34.086875\n\n\n\n\nMale\n\n\n20.357250\n\n\n15.644000\n\n\n36.001250\n\n\n\n\nNon-binary\n\n\n16.836000\n\n\n12.340000\n\n\n29.176000\n\n\n\n\nPhysics\n\n\nFemale\n\n\n20.817000\n\n\n14.680000\n\n\n35.497000\n\n\n\n\nMale\n\n\n16.871000\n\n\n16.498286\n\n\n34.166143\n\n\n\n\nNon-binary\n\n\n20.205000\n\n\n15.300000\n\n\n35.505000\n\n\n\n\n:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\nIf you don’t want the grouping parameters as indices, you can use as_index=False.\ndf_class.groupby(by=[\"Major\", \"Gender\"], as_index=False)[['Test 1', 'Test 2', 'Total']].mean()\n\n\n\n\n\n\nMajor\n\n\nGender\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\n\n\n0\n\n\nChemistry\n\n\nFemale\n\n\n17.602500\n\n\n16.364800\n\n\n34.128500\n\n\n\n\n1\n\n\nChemistry\n\n\nMale\n\n\n21.121500\n\n\n17.224000\n\n\n38.345500\n\n\n\n\n2\n\n\nChemistry\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n3\n\n\nComp. Biology\n\n\nFemale\n\n\n16.530000\n\n\n10.280000\n\n\n26.810000\n\n\n\n\n4\n\n\nComp. Biology\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n5\n\n\nComp. Biology\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\n6\n\n\nLife Sciences\n\n\nFemale\n\n\n19.285875\n\n\n14.801000\n\n\n34.086875\n\n\n\n\n7\n\n\nLife Sciences\n\n\nMale\n\n\n20.357250\n\n\n15.644000\n\n\n36.001250\n\n\n\n\n8\n\n\nLife Sciences\n\n\nNon-binary\n\n\n16.836000\n\n\n12.340000\n\n\n29.176000\n\n\n\n\n9\n\n\nPhysics\n\n\nFemale\n\n\n20.817000\n\n\n14.680000\n\n\n35.497000\n\n\n\n\n10\n\n\nPhysics\n\n\nMale\n\n\n16.871000\n\n\n16.498286\n\n\n34.166143\n\n\n\n\n11\n\n\nPhysics\n\n\nNon-binary\n\n\n20.205000\n\n\n15.300000\n\n\n35.505000\n\n\n\n\n:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\nIf you are only interested in a specific column, you can do this:\ndf_class.groupby(by=[\"Major\", \"Gender\"])[\"Test 1\"].mean()\n\n\n\n\n\n\n\n\nTest 1\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\n\n\n\n\nChemistry\n\n\nFemale\n\n\n17.602500\n\n\n\n\nMale\n\n\n21.121500\n\n\n\n\nNon-binary\n\n\nNaN\n\n\n\n\nComp. Biology\n\n\nFemale\n\n\n16.530000\n\n\n\n\nMale\n\n\nNaN\n\n\n\n\nNon-binary\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\nFemale\n\n\n19.285875\n\n\n\n\nMale\n\n\n20.357250\n\n\n\n\nNon-binary\n\n\n16.836000\n\n\n\n\nPhysics\n\n\nFemale\n\n\n20.817000\n\n\n\n\nMale\n\n\n16.871000\n\n\n\n\nNon-binary\n\n\n20.205000\n\n\n\n\n:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n\n\nOther ‘in-built’ function you can use are count(), sum(), mean(), median(), min(), max(), mode(), std(), var(). However, you can far more out of groupby() by using agg() to apply any function. Let me show you how to apply some functions from NumPy.\ndf_class.groupby(by=[\"Major\", \"Gender\"])[['Test 1', 'Test 2', 'Total']].agg([np.mean, np.std]).round(2)\n\n\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\n\n\n\n\nmean\n\n\nstd\n\n\nmean\n\n\nstd\n\n\nmean\n\n\nstd\n\n\n\n\nMajor\n\n\nGender\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nChemistry\n\n\nFemale\n\n\n17.60\n\n\n4.07\n\n\n16.36\n\n\n1.14\n\n\n34.13\n\n\n4.33\n\n\n\n\nMale\n\n\n21.12\n\n\n3.90\n\n\n17.22\n\n\n0.60\n\n\n38.35\n\n\n4.50\n\n\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nComp. Biology\n\n\nFemale\n\n\n16.53\n\n\nNaN\n\n\n10.28\n\n\nNaN\n\n\n26.81\n\n\nNaN\n\n\n\n\nMale\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nNon-binary\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\nFemale\n\n\n19.29\n\n\n2.07\n\n\n14.80\n\n\n2.61\n\n\n34.09\n\n\n3.84\n\n\n\n\nMale\n\n\n20.36\n\n\n4.37\n\n\n15.64\n\n\n1.49\n\n\n36.00\n\n\n4.95\n\n\n\n\nNon-binary\n\n\n16.84\n\n\n2.16\n\n\n12.34\n\n\n1.90\n\n\n29.18\n\n\n0.27\n\n\n\n\nPhysics\n\n\nFemale\n\n\n20.82\n\n\nNaN\n\n\n14.68\n\n\nNaN\n\n\n35.50\n\n\nNaN\n\n\n\n\nMale\n\n\n16.87\n\n\n4.35\n\n\n16.50\n\n\n1.89\n\n\n34.17\n\n\n5.15\n\n\n\n\nNon-binary\n\n\n20.20\n\n\n0.87\n\n\n15.30\n\n\n0.88\n\n\n35.50\n\n\n1.74\n\n\n\n\n:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. :1: FutureWarning: The provided callable &lt;function mean at 0x7fc8efe08f40&gt; is currently using SeriesGroupBy.mean. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string “mean” instead. :1: FutureWarning: The provided callable &lt;function std at 0x7fc8efe09080&gt; is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string “std” instead.\n\n\nYou can even combine groupby() with a mask. For example, let’s see how all the Female students are doing.\n\nmask = df_class['Gender'] == 'Female'\ndf_class[mask].groupby(by=['Major']).mean(numeric_only=True)\n\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nMajor\n\n\n\n\n\n\n\n\n\n\n\n\nChemistry\n\n\n17.602500\n\n\n16.3648\n\n\n34.128500\n\n\n\n\nComp. Biology\n\n\n16.530000\n\n\n10.2800\n\n\n26.810000\n\n\n\n\nLife Sciences\n\n\n19.285875\n\n\n14.8010\n\n\n34.086875\n\n\n\n\nPhysics\n\n\n20.817000\n\n\n14.6800\n\n\n35.497000\n\n\n\n\n:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\nJust for comparison,\ndf_class.groupby(by=[\"Gender\", \"Major\"]).mean(numeric_only=True)\n\n\n\n\n\n\n\n\nTest 1\n\n\nTest 2\n\n\nTotal\n\n\n\n\nGender\n\n\nMajor\n\n\n\n\n\n\n\n\n\n\n\n\nFemale\n\n\nChemistry\n\n\n17.602500\n\n\n16.364800\n\n\n34.128500\n\n\n\n\nComp. Biology\n\n\n16.530000\n\n\n10.280000\n\n\n26.810000\n\n\n\n\nLife Sciences\n\n\n19.285875\n\n\n14.801000\n\n\n34.086875\n\n\n\n\nPhysics\n\n\n20.817000\n\n\n14.680000\n\n\n35.497000\n\n\n\n\nMale\n\n\nChemistry\n\n\n21.121500\n\n\n17.224000\n\n\n38.345500\n\n\n\n\nComp. Biology\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\n20.357250\n\n\n15.644000\n\n\n36.001250\n\n\n\n\nPhysics\n\n\n16.871000\n\n\n16.498286\n\n\n34.166143\n\n\n\n\nNon-binary\n\n\nChemistry\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nComp. Biology\n\n\nNaN\n\n\nNaN\n\n\nNaN\n\n\n\n\nLife Sciences\n\n\n16.836000\n\n\n12.340000\n\n\n29.176000\n\n\n\n\nPhysics\n\n\n20.205000\n\n\n15.300000\n\n\n35.505000\n\n\n\n\n:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Pandas",
      "Pandas (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/2_images_good.html#convert-the-image-to-grayscale",
    "href": "docs/knowledge_lake/image_analysis/2_images_good.html#convert-the-image-to-grayscale",
    "title": "Image Analysis (Good)",
    "section": "2.1 Convert the image to grayscale",
    "text": "2.1 Convert the image to grayscale\nGrayscale images (with just one layer) are more straightforward to analyze than RGB ones (with three layers). This is because a grayscale image has the same RGB values for each pixel. So, the first step is to convert the image into grayscale.\n\nResultCode\n\n\n \n\n\n\nfrom skimage import io\nfrom skimage.color import rgb2grey\nimg_original = io.imread('three-circles.png')\nimg_grey = rgb2grey(img_original)\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(8, 4))\nax_original, ax_grey = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape={img_original.shape}')\n\nax_grey.imshow(img_grey, cmap='gray')\nax_grey.set_title(f'Grayscale: shape={img_grey.shape}')\n\nfor a in ax.flat:\n    a.axis('off')",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/2_images_good.html#binarise",
    "href": "docs/knowledge_lake/image_analysis/2_images_good.html#binarise",
    "title": "Image Analysis (Good)",
    "section": "2.2 Binarise",
    "text": "2.2 Binarise\nThresholding, or binarising, converts an image into black and white depending on what features you want to analyse. For example, to separate the foreground (our subject, such as a cell) from the background.\nThe threshold(\\(t\\)) separates the image into background and foreground. I.e., everything below (\\(&lt;t\\)) will be black, and those values equal or above (\\(\\geq t\\)) will be white.\n\nFinding a threshold\nscikit-image offers some functions to help us find a threshold. You can pick one (I will try Otsu and Yen) or try all. Here is how it works.\nfrom skimage.filters import threshold_otsu, threshold_yen\n\nimg_original = io.imread('three-circles.png')\nimg_grey = rgb2grey(img_original)\n\nprint('{threshold_otsu(img_grey)=}')\nprint('{threshold_yen(img_grey)=}') \nWe can also try all the available methods using try_all_threshold()!\nfrom skimage.filters import try_all_threshold  \n\nfig, ax = try_all_threshold(img_grey, figsize=(10, 8), verbose=False)\nplt.show()\n\n\n\n\n\nYen seems to be the best.\n\n\nApplying a threshold\nOnce we have a threshold, we can apply it to binarise the image.\n\nResultCode\n\n\n \n\n\n\nthreshold = threshold_yen(img_grey)\nimg_binarised = img_grey &lt; threshold\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_original, ax_grey, ax_binarised = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape= {img_original.shape}')\n\nax_grey.imshow(img_grey, cmap='gray')\nax_grey.set_title(f'Grayscale: shape= {img_grey.shape}')\n\nax_binarised.imshow(img_binarised, cmap='gray')\nax_binarised.set_title(f'Binarised (Using Otsu)')",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/2_images_good.html#labelling",
    "href": "docs/knowledge_lake/image_analysis/2_images_good.html#labelling",
    "title": "Image Analysis (Good)",
    "section": "2.3 Labelling",
    "text": "2.3 Labelling\nNote that skimage function measure.label() requires an image of type int\nOnce you have a binarised image, we can label features. More specifically, labeling ‘fills’ connected areas with an integer. For example, if you have three distinct regions, one will be filled with 1s, the next with 2s, and the third with 3s. This enables us to visualize the segments by a simple heat map.\nLet me first show you what happens. I will then explain a bit more.\n\nResultCode\n\n\n \n\n\n\n# measure.label() requires an image of type int\nimg_labelled = measure.label(img_binarised.astype('uint8'))\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_original, ax_binarised, ax_labelled = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape= {img_original.shape}')\n\nax_binarised.imshow(img_binarised, cmap='gray')\nax_binarised.set_title(f'Binarised (Using Yen)')\n\n# Using jet to colour the different regions\nax_labelled.imshow(img_labelled, cmap='jet')\nax_labelled.set_title(f'Labelled Objects')\n\n\n\n\n\nMaking sense of labelling\nI mentioned that labeling simply ‘fills’ distinct regions with integer numbers. This means we should be able to use masking to isolate these regions.\n\n\n\n\n\n\n1st region\nimg_masked = img_labelled == 1\nplt.imshow(img_masked)\n\n\n2nd region\nimg_masked = img_labelled == 2\nplt.imshow(img_masked)\n\n\n3rd region\nimg_masked = img_labelled == 3\nplt.imshow(img_masked)",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image_analysis/2_images_good.html#measuring",
    "href": "docs/knowledge_lake/image_analysis/2_images_good.html#measuring",
    "title": "Image Analysis (Good)",
    "section": "2.4 Measuring",
    "text": "2.4 Measuring\nNow that we have separated and labelled the regions, we can measure important characteristics (e.g. area, centroid) of these regions. Let me show you how.\n\nResultCode\n\n\n---------- Region 0 ----------\nCentre  : (87.0, 168.0)\nArea    : 20565\n\n\n---------- Region 1 ----------\nCentre  : (317.0, 283.0)\nArea    : 15193\n\n\n---------- Region 2 ----------\nCentre  : (317.0, 53.0)\nArea    : 6793\n\n\n\n# measure.label() requires an image of type int\nimg_labelled = measure.label(img_binarised.astype('uint8'))\nregion_info = measure.regionprops(img_labelled)\n\nno_of_regions = len(region_info)\n\nfor count, region in enumerate(region_info):\n    print('-'*10, f'Region {count}', '-'*10)\n    print(f'Centre\\t: {region.centroid}')\n    print(f'Area\\t: {region.area}')             # What is the area\n    print('\\n')\n\n\n\n\nThere are many more properties you can measure. Please see here for more information.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Image Analysis",
      "Image Analysis (Good)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#convert-the-image-to-grayscale",
    "href": "docs/knowledge_lake/image/2_images_good.html#convert-the-image-to-grayscale",
    "title": "Image Analysis (Good)",
    "section": "2.1 Convert the image to grayscale",
    "text": "2.1 Convert the image to grayscale\nGrayscale images (with just one layer) are more straightforward to analyze than RGB ones (with three layers). This is because a grayscale image has the same RGB values for each pixel. So, the first step is to convert the image into grayscale.\n\nResultCode\n\n\n \n\n\n\nfig, ax = plt.subplots(nrows=1, ncols=4, figsize=(16, 4))\n\nax_original, ax_red, ax_green, ax_blue = ax\n\nax_original.imshow(img)\nax_original.set_title('Original (RGB)')\n\n# ALL row & ALL columns of layer 0\nax_red.imshow(img[:, :, 0], cmap='gray')\nax_red.set_title('Red Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 1\nax_green.imshow(img[:, :, 1], cmap='gray')\nax_green.set_title('Green Channel(in Grayscale)')\n\n# ALL row & ALL columns of layer 2\nax_blue.imshow(img[:, :, 2], cmap='gray')\nax_blue.set_title('Blue Channel(in Grayscale)')"
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#binarise",
    "href": "docs/knowledge_lake/image/2_images_good.html#binarise",
    "title": "Image Analysis (Good)",
    "section": "2.2 Binarise",
    "text": "2.2 Binarise\nThresholding, or binarising, converts an image into black and white depending on what features you want to analyse. For example, to separate the foreground (our subject, such as a cell) from the background.\nThe threshold(\\(t\\)) separates the image into background and foreground. I.e., everything below (\\(&lt;t\\)) will be black, and those values equal or above (\\(\\geq t\\)) will be white.\n\nFinding a threshold\nscikit-image offers some functions to help us find a threshold. You can pick one (I will try Otsu and Yen) or try all. Here is how it works.\nfrom skimage.filters import threshold_otsu, threshold_yen\n\nimg_original = io.imread('three-circles.png')\nimg_grey = rgb2grey(img_original)\n\nprint('{threshold_otsu(img_grey)=}')\nprint('{threshold_yen(img_grey)=}') \nWe can also try all the available methods using try_all_threshold()!\nfrom skimage.filters import try_all_threshold  \n\nfig, ax = try_all_threshold(img_grey, figsize=(10, 8), verbose=False)\nplt.show()\n\n\n\n\n\nYen seems to be the best.\n\n\nApplying a threshold\nOnce we have a threshold, we can apply it to binarise the image.\n\nResultCode\n\n\n \n\n\n\nthreshold = threshold_yen(img_grey)\nimg_binarised = img_grey &lt; threshold\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_original, ax_grey, ax_binarised = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape= {img_original.shape}')\n\nax_grey.imshow(img_grey, cmap='gray')\nax_grey.set_title(f'Grayscale: shape= {img_grey.shape}')\n\nax_binarised.imshow(img_binarised, cmap='gray')\nax_binarised.set_title(f'Binarised (Using Otsu)')"
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#labelling",
    "href": "docs/knowledge_lake/image/2_images_good.html#labelling",
    "title": "Image Analysis (Good)",
    "section": "2.3 Labelling",
    "text": "2.3 Labelling\nNote that skimage function measure.label() requires an image of type int\nOnce you have a binarised image, we can label features. More specifically, labeling ‘fills’ connected areas with an integer. For example, if you have three distinct regions, one will be filled with 1s, the next with 2s, and the third with 3s. This enables us to visualize the segments by a simple heat map.\nLet me first show you what happens. I will then explain a bit more.\n:::{.panel-tabset}"
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#result-2",
    "href": "docs/knowledge_lake/image/2_images_good.html#result-2",
    "title": "Image Analysis (Good)",
    "section": "2.4 Result",
    "text": "2.4 Result"
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#code-2",
    "href": "docs/knowledge_lake/image/2_images_good.html#code-2",
    "title": "Image Analysis (Good)",
    "section": "2.5 Code",
    "text": "2.5 Code\n\n# measure.label() requires an image of type int\nimg_labelled = measure.label(img_binarised.astype('uint8'))\n\nfig, ax = plt.subplots(nrows=1, ncols=3, figsize=(9, 3))\nax_original, ax_binarised, ax_labelled = ax\n\nax_original.imshow(img_original)\nax_original.set_title(f'Original: shape= {img_original.shape}')\n\nax_binarised.imshow(img_binarised, cmap='gray')\nax_binarised.set_title(f'Binarised (Using Yen)')\n\n# Using jet to colour the different regions\nax_labelled.imshow(img_labelled, cmap='jet')\nax_labelled.set_title(f'Labelled Objects')\n\n\nMaking sense of labelling\nI mentioned that labeling simply ‘fills’ distinct regions with integer numbers. This means we should be able to use masking to isolate these regions."
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#st-region",
    "href": "docs/knowledge_lake/image/2_images_good.html#st-region",
    "title": "Image Analysis (Good)",
    "section": "2.6 1st region",
    "text": "2.6 1st region\nimg_masked = img_labelled == 1\nplt.imshow(img_masked)"
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#nd-region",
    "href": "docs/knowledge_lake/image/2_images_good.html#nd-region",
    "title": "Image Analysis (Good)",
    "section": "2.7 2nd region",
    "text": "2.7 2nd region\nimg_masked = img_labelled == 2\nplt.imshow(img_masked)"
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#rd-region",
    "href": "docs/knowledge_lake/image/2_images_good.html#rd-region",
    "title": "Image Analysis (Good)",
    "section": "2.8 3rd region",
    "text": "2.8 3rd region\nimg_masked = img_labelled == 3\nplt.imshow(img_masked)"
  },
  {
    "objectID": "docs/knowledge_lake/image/2_images_good.html#measuring",
    "href": "docs/knowledge_lake/image/2_images_good.html#measuring",
    "title": "Image Analysis (Good)",
    "section": "2.9 Measuring",
    "text": "2.9 Measuring"
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/need/1_random_need.html#a-simple-graphical-test",
    "href": "docs/knowledge_lake/random_numbers/need/1_random_need.html#a-simple-graphical-test",
    "title": "Random Numbers (Need)",
    "section": "3.1 A simple graphical test",
    "text": "3.1 A simple graphical test\nAlternatively, we can convince ourselves of the uniformity of the PRNG by plotting the numbers as a scatter plot or a histogram.\n\n\n\n\n\nHere is the code.\n\nn = 10000\nrandom_numbers = np.random.rand(n)\n\nfig, ax = plt.subplots(nrows=1, ncols=2)\n\naxis = ax[0]\naxis.hist(random_numbers, bins=100, alpha=.25)\naxis.set_xlabel(\"Value of random number\")\naxis.set_ylabel(\"Frequency\")\n\naxis = ax[1]\naxis.scatter(range(n), random_numbers, alpha=.25)\naxis.set_xlabel(\"Position in the random number list\")\naxis.set_ylabel(\"Value of random number\")\n\nPlease stop for a moment and make sure you understand what the plots are and what each is telling you. You should talk to someone if you are not sure.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/need/1_random_need.html#uniformly-beyond-01",
    "href": "docs/knowledge_lake/random_numbers/need/1_random_need.html#uniformly-beyond-01",
    "title": "Random Numbers (Need)",
    "section": "3.2 Uniformly beyond \\([0,1)\\)",
    "text": "3.2 Uniformly beyond \\([0,1)\\)\nOften we need random numbers distributed over a range other than 0 and 1. We can use np.random.uniform() for this. Let’s generate a large set of random numbers in the interval \\([50,100]\\) using np.random.uniform() and create a histogram and scatter plot as we did earlier.\nI don’t need to show the code for plotting again. So, here is the most essential part.\nn = 10000\nrandom_numbers = np.random.uniform(low=50, high=100, size=n)\n\n\n\n\n\nNotice that the numbers are now between 50 and 100!",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/need/1_random_need.html#seeding-a-prng",
    "href": "docs/knowledge_lake/random_numbers/need/1_random_need.html#seeding-a-prng",
    "title": "Random Numbers (Need)",
    "section": "3.3 ‘seeding’ a PRNG",
    "text": "3.3 ‘seeding’ a PRNG\nSometimes, we need PRNG to generate the same set of numbers. For example, when we are debugging some code. You can achieve this by specifying a seed, the integer number that ‘kicks off’ the PRNG algorithm. You do not usually have to seed the PRNG. Instead, it does it automatically by using ‘some’ number (e.g. the number of milliseconds since January 1970) internally.\nYou will better understand what the seed does with the following code.\n\nnp.random.randint(0, 100, 10)     # Ten integers between 0 and 100\n\narray([49, 56,  3, 35, 76, 21, 94, 43, 21, 60])\n\n\n\nnp.random.randint(0, 100, 10)     # Another ten integers between 0 and 100\n\narray([84, 91, 42, 50, 40, 98, 43, 59, 93, 72])\n\n\n\nnp.random.seed(1234)              # Specifying a seed\nnp.random.randint(0, 100, 10)     # Ten integers between 0 and 100\n\narray([47, 83, 38, 53, 76, 24, 15, 49, 23, 26])\n\n\n\nnp.random.seed(1234)\nnp.random.randint(0, 100, 10)     # Same ten integers between 0 and 100\n\narray([47, 83, 38, 53, 76, 24, 15, 49, 23, 26])\n\n\nThat’s enough basic stuff. Let’s start using random numbers!",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/need/1_random_need.html#simulating-a-magic-8-ball",
    "href": "docs/knowledge_lake/random_numbers/need/1_random_need.html#simulating-a-magic-8-ball",
    "title": "Random Numbers (Need)",
    "section": "4.1 Simulating a Magic-8 Ball",
    "text": "4.1 Simulating a Magic-8 Ball\nLet me show you some examples of using random numbers. I like to start with a simple, frivolous one of simulating a Magic-8 ball.\nI will put my simulation in a function called shake_magic_8() as shown below. I borrowed the information on the 20 options of the original Magic-8 ball from the relevant Wikipedia page.\n\ndef shake_magic_8():\n    '''\n    Function to simulate a Magic-8 ball!\n    '''\n    options = ['It is certain.', 'It is decidedly so.',\n               'Without a doubt.', 'Yes definitely.',\n               'You may rely on it.', 'As I see it, yes.',\n               'Most likely.', 'Outlook good.',\n               'Yes.', 'Signs point to yes.',\n               'Reply hazy, try again.', 'Ask again later.',\n               'Better not tell you now.', 'Cannot predict now.',\n               'Concentrate and ask again.', 'Don\\'t count on it.',\n               'My reply is no.', 'My sources say no.',\n               'Outlook not so good.', 'Very doubtful.']\n\n    return np.random.choice(options)\n\nLet’s see if it works.\n\nquestions = ['Will I be pretty?',\n             'Will I be rich?',\n             'Will I be in trouble?']\n\nfor question in questions:\n    print(f'Q: {question}')\n    print(f'A: {shake_magic_8()}\\n')\n\nQ: Will I be pretty?\nA: Outlook not so good.\n\nQ: Will I be rich?\nA: Don't count on it.\n\nQ: Will I be in trouble?\nA: Yes.\n\n\nAlthough the outlook does not look too good for me, I hope you understand what is going on. np.random.choice() picks one of the options randomly. So, getting each is equally likely.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/need/1_random_need.html#flipping-coins",
    "href": "docs/knowledge_lake/random_numbers/need/1_random_need.html#flipping-coins",
    "title": "Random Numbers (Need)",
    "section": "4.2 Flipping Coins",
    "text": "4.2 Flipping Coins\nNow let us look at flipping coins.\n\nA fair coin\nI can simulate a flip of a fair coin by:\n\nnp.random.choice(['Head', 'Tails'])\n\n'Head'\n\n\nIf I want 10 flips:\n\nno_of_coins = 10\nnp.random.choice(['Head', 'Tails'], no_of_coins)\n\narray(['Head', 'Head', 'Head', 'Head', 'Tails', 'Tails', 'Head', 'Head',\n       'Head', 'Tails'], dtype='&lt;U5')\n\n\nAlternatively, if you and I agree to consider any number in (0, .5] to be Tails and any number in (.5, 1) to be Heads, then the following works too.\n\ndef flip_coins(no_of_coins=1, probability=.5):\n    '''\n    Returns the number of values greater that \n    `probability` (considered as 'Heads').\n    '''\n    results = np.random.rand(no_of_coins)\n    no_of_heads = np.sum(results &gt; probability)\n    return no_of_heads\n\n\nno_of_coins = 1_000\nno_of_heads = flip_coins(no_of_coins)\nprint(f'Number of heads: {no_of_heads/no_of_coins*100:.2f}%')\n\nNumber of heads: 50.80%\n\n\nSince I plan to flip coins a bit more, I have created a function that gives me the number of heads. I have also used probability=.5 because we are dealing with a fair coin.\n\n\nA biased coin\nThe advantage of the second way of simulating coins is that we can easily simulate a biased coin simply by messing with probability. For example, let’s say I want a probability of .7 for a Head. Since we need to increase the chance of a number being considered a Head, we have to make probability=.3. Please make sure this makes sense to you or have a chat with someone to convince yourself.\n\nno_of_coins = 1_000\nno_of_heads = flip_coins(no_of_coins, probability = .3)\nprint(f'Number of heads: {no_of_heads/no_of_coins*100:.2f}%')\n\nNumber of heads: 72.10%\n\n\n\n\nA flipping experiment\nAccess to a good PRNG will allow you to run quick experiments. These will help you gain insights into more theoretical models of the same experiments. So, you can start using computers to better understand science and sometimes even see how the cogs tick in the machine.\nLet me demonstrate this with a simple experiment. Say we flip 10 fair coins in one go. What is the probability that 7 of them will come out Heads? There is an elegant theoretical answer to this question; I will come to that later. But first, let’s see if we can get a solution using our PRNG.\nWe can get an answer if we flip 10 coins several thousand times and count the number of heads. I.e. use flip_coins(10) many times and keep score.\n\nno_of_repeats = 10_000\nresult = [flip_coins(no_of_coins=10) for _ in range(no_of_repeats)]\nno_of_heads, heads_counts = np.unique(result, return_counts=True)\n\nnp.unique() with return_counts=True returns the unique values (of Heads) in the list and how many times they occur. We can get the probabilities by dividing the array with the counts by the number of repeats.\n\nheads_probability = heads_counts/no_of_repeats\n\nLet’s plot this data.\nplt.rcParam['figure.figsize'] = (10,5)\nplt.bar(no_of_heads, heads_counts);\nplt.xlabel('No of heads')\nplt.ylabel(f'Frequency out of {no_of_repeats}')\nplt.table([no_of_heads, heads_counts, heads_probability],\n          rowLabels=['No of Heads', 'Frequency', 'PRNG Probability'],\n          loc='bottom',\n          bbox=[0, -0.5, 1, 0.3])\n\n\n\n\n\nAs you can see, I have also included the various numbers in a Matplotlib table below (I adjusted the bbox values by trial and error.)\nThe theoretical explanation of how many times each head should appear is described by the binomial distribution. Understanding the basics of distributions (i.e. what they are and how to use them) is a critical bit of knowledge for anyone in a university.\nSciPy has various functions to calculate many of these important distributions. Let me show you how to do that now. First, let’s import the machinery for the binomial distribution.\n\nfrom scipy.stats import binom\n\nThe binomial distribution is discrete (i.e. because you have Heads or Tails, no half or quarter Heads). For such distributions, you get the various probabilities using the distribution’s pmf() (probability mass function or discrete density function). Don’t get distracted by the funky names; the pmf() just gives the probabilities for the various possibilities of the discrete distributions.\nThe probability we want is:\n\nbinom.pmf(k=7, n=10, p=.5)\n\n0.11718749999999999\n\n\nI will repeat: the binomial distribution gives us the probability of getting 7 heads when you throw 10 fair (p=.5) coins.\nFor the same completion, I will also calculate the rest of the values. This is absurdly easy:\n\nbinomial_probabilities = binom.pmf(k=no_of_heads, n=10, p=.5)\n\nLet me include these values in the plot to complete the story1",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/random_numbers/need/1_random_need.html#footnotes",
    "href": "docs/knowledge_lake/random_numbers/need/1_random_need.html#footnotes",
    "title": "Random Numbers (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nIf you like to know how, please look for Matplotlib table().↩︎",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Random Numbers",
      "Random Numbers (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#getting-a-feel",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#getting-a-feel",
    "title": "Numerical Solutions (Need)",
    "section": "1.1 Getting a feel",
    "text": "1.1 Getting a feel\nLet us start with a simple system consisting of a bucket filled with a faucet. Let’s say the tap provides water at a rate of 5 L/mins. I can get a feel for the dynamics of this system by creating a table like this.\n\n\n\n\n\n\n\n\n\n\n\n\n#\nTime Step(\\(\\Delta t\\))\nElasped Time(\\(t\\))\nRate(\\(R\\))\nChange in Volume(\\(\\Delta V\\))\nTotal Volume(\\(V\\))\n\n\n\n\n0\n.5 mins\n0.0 mins\n5 L/min\n0.00\n0.0 L\n\n\n1\n.5 mins\n0.5 mins\n5 L/min\n2.5 L\n2.5 L\n\n\n2\n.5 mins\n1.0 mins\n5 L/min\n2.5 L\n5.0 L\n\n\n3\n.5 mins\n1.5 mins\n5 L/min\n2.5 L\n7.5 L\n\n\n4\n.5 mins\n2.0 mins\n5 L/min\n2.5 L\n10.0 L\n\n\n5\n.5 mins\n2.5 mins\n5 L/min\n2.5 L\n12.5 L\n\n\n\n\n\\(R\\) is the rate and \\(\\Delta V\\) is the change in volume that corresponds to a time step of \\(\\Delta V\\). I.e.\n\\[\n\\Delta V = R \\Delta t\n\\]\nLet me do all this in Python.\n\nmax_time = 5                     # Maximum time (mins)\ndt = .5                          # Time step (mins)\nrate = 5                         # Rate (L/min)\nall_volume = []                  # To keep track of all volumes\nvolume = 0                       # Starting volume\n\nall_time = np.arange(start=0, stop=max_time, step=dt)\n\nfor time in all_time:\n    all_volume.append(volume)    # Record volume\n    dV = rate * dt               # Calculate change in volume\n    volume += dV                 # Update the new volume\n\n# Because we can...\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\n\n\n\n\n\n\nYou might think I have overly complicated something simple that can be done in a spreadsheet. However, once I have this basic structure in place, I can start having fun imagining other realities.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#an-overflowing-bucket",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#an-overflowing-bucket",
    "title": "Numerical Solutions (Need)",
    "section": "1.2 An overflowing bucket",
    "text": "1.2 An overflowing bucket\nLet’s imagine that our bucket has a maximum volume of 9 L. We can impose this condition with a simple if statement.\n\nmax_time = 5                     # Maximum time (mins)\ndt = .5                          # Time step (mins)\nrate = 5                         # Rate (L/min)\nbucket_capacity = 9              # L\nall_volume = []                  # To keep track of all volumes\nvolume = 0                       # Starting volume\n\nall_time = np.arange(start=0, stop=max_time, step=dt)\n\nfor time in all_time:\n    all_volume.append(volume)\n    dV = rate * dt\n    if volume &lt;= bucket_capacity:\n        volume += dV             # Update the new volume\n\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')\n\n\n\n\n\n\nOh no, the bucket still seems to fill beyond \\(9\\) L before it stops increasing. The problem here is that my timestep is too large. So let’s make it smaller. Since I don’t know what will work best, I will try a few with a for loop.\n\nmax_time = 5                     # Maximum time (mins)\ndt = .5                          # Time step (mins)\nrate = 5                         # Rate (L/min)\nbucket_capacity = 9              # L\n\nfor dt in [0.5, 0.1, 0.05, 0.01, 0.001]:\n    all_volume = []                  # To keep track of all volumes\n    volume = 0                       # Starting volume\n\n    all_time = np.arange(start=0, stop=max_time, step=dt)\n\n    for time in all_time:\n        all_volume.append(volume)\n        dV = rate * dt\n        if volume &lt;= bucket_capacity:\n            volume += dV\n\n    plt.plot(all_time, all_volume, label=f'dt={dt}')\n\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')\nplt.legend()\n\nI hope you are following what I have done. Since I want to change dt I have pushed everything that depends on it under the for loop. The way I initially set up the code with variables defined at the top and reused elsewhere makes it easy to make quick adjustments. If I run this code, I end up with:\n\n\n\n\n\nLooks like a timestep of 0.01 or 0.001 works best. I am going to pick 0.01 because this means the for loop runs fewer times.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#a-leaky-bucket",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#a-leaky-bucket",
    "title": "Numerical Solutions (Need)",
    "section": "1.3 A leaky bucket",
    "text": "1.3 A leaky bucket\nNow, let’s imagine a hole in the bucket is causing it to leak at a rate of 1.5 L/min.\n\nmax_time = 5                     # Maximum time (mins)\ndt = .001                        # Time step (mins)\nrate = 5                         # Filling rate (L/min)\nleak_rate = 1.5                  # L/min\nbucket_capacity = 9              # L\nall_volume = []                  # To keep track of all volumes\nvolume = 0                       # Starting volume\n\nall_time = np.arange(start=0, stop=max_time, step=dt)\n\nfor time in all_time:\n    all_volume.append(volume)\n\n    dV = rate * dt\n    leak_volume = leak_rate * dt\n    volume -= leak_volume\n\n    if volume &lt;= bucket_capacity:\n        volume += dV             # Update the new volume\n\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')\n\n\n\n\n\n\nNotice how it now takes longer for the bucket to fill up. But, even then, once it is filled, the inflow is sufficient to offset the leak and keep the bucket full.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#lets-turn-off-the-tap",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#lets-turn-off-the-tap",
    "title": "Numerical Solutions (Need)",
    "section": "1.4 Let’s turn off the tap",
    "text": "1.4 Let’s turn off the tap\nWhat will happen if we turn off the tap after 3 mins? I can impose this by simply modifying the if condition!\n\ntap_off_time = 3                 # When the tap goes off\nmax_time = 5                     # Maximum time (mins)\ndt = .001                        # Time step (mins)\nrate = 5                         # Filling rate (L/min)\nleak_rate = 1.5                  # L/min\nbucket_capacity = 9              # L\nall_volume = []                  # To keep track of all volumes\nvolume = 0                       # Starting volume\n\nall_time = np.arange(start=0, stop=max_time, step=dt)\n\nfor time in all_time:\n    all_volume.append(volume)\n    dV = rate * dt\n\n    leak_volume = leak_rate * dt\n    volume -= leak_volume\n\n    if (volume &lt;= bucket_capacity) and (time &lt; tap_off_time):\n        volume += dV             \n\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')\n\n\n\n\n\n\n\nUsing while\nBefore we move on let me show you how to use a while statement to run the same simulation. I prefer while for such cases because all variables (e.g. time and volume) are treated equally. Let me show you what I mean.\n\ntap_off_time = 3                 # When the tap goes off\nmax_time = 5                     # Maximum time (mins)\ndt = .001                        # Time step (mins)\nrate = 5                         # Filling rate (L/min)\nleak_rate = 1.5                  # L/min\nbucket_capacity = 9              # L\nall_volume = []                  # To keep track of all volumes\nall_time = []                    # To keep track of all times\nvolume = 0                       # Starting volume\ntime = 0\n\nwhile time &lt;= max_time:\n    all_time.append(time)\n    all_volume.append(volume)\n    dV = rate * dt\n\n    leak_volume = leak_rate * dt\n    volume -= leak_volume\n\n    if (volume &lt;= bucket_capacity) and (time &lt; tap_off_time):\n        volume += dV    \n\n    time += dt             \n\nplt.plot(all_time, all_volume)\nplt.ylabel('Volume(L)')\nplt.xlabel('Time(mins)')\nplt.hlines(bucket_capacity, 0, max_time, colors='grey', ls='dashed')",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#a-quick-summary",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#a-quick-summary",
    "title": "Numerical Solutions (Need)",
    "section": "1.5 A quick summary",
    "text": "1.5 A quick summary\nWe started with a bucket and slowly added more details to our story. I hope you noticed how little our code had to be altered to add these details. Also, you can easily see the ‘story’ just by looking at the code. Here you have a glimpse of the power of programming (with Python) over other methods (such as spreadsheets): simplicity of syntax, transparency of the processes and ease of making changes.\nI also like to point out that irrespective of how complicated the system or problem is, the strategy you need to adopt will be the same, simple one:\n\nEstablish a relationship that connects the changes of the variables.\nPick a starting value\nTake a step, and calculate the changes.\nUpdate the variables\nKeep on going until you have the desired number of points.\nIf you want to improve accuracy, take smaller steps.\n\nI will remind you of this again after the next example.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#we-just-solved-a-differential-equation",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#we-just-solved-a-differential-equation",
    "title": "Numerical Solutions (Need)",
    "section": "1.6 We just solved a differential equation!",
    "text": "1.6 We just solved a differential equation!\nThe example with the bucket is actually one related to a simple differential equation. Namely:\n\\[\n\\dfrac{dV}{dt} = R\n\\]\nMost mathematical equations are succinct ways of telling a story. For example, the above says that how fast the volume (\\(V\\)) changes as time passes equals a constant \\(R\\). More accurately, the symbol on the LHS reads as ‘rate of change of \\(V\\) with respect to \\(t\\)’.\nWe can approximate this relationship as the following fraction:\n\\[\n\\dfrac{\\Delta V}{\\Delta t} \\approx \\dfrac{dV}{dt} = R\n\\]\nAs you noticed earlier, the approximation becomes more accurate the smaller we make \\(\\Delta t\\).\nRearranging the above equation, we end up with:\n\\[\n\\Delta V = R \\Delta t\n\\]\nWhich is where we started everything about the bucket.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#introduction",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#introduction",
    "title": "Numerical Solutions (Need)",
    "section": "2.1 Introduction",
    "text": "2.1 Introduction\n\nLet’s solve the differential equation related to radioactive decay in this section. The experimentally observed mathematical relationship that governs the decay of a sample of radioactive material is given by:\n\\[\n\\dfrac{dN}{dt}=- \\lambda N\n\\]\n\\(N\\) is the number of radioactive nuclei and \\(\\lambda\\) is a characteristic number (called the ‘decay constant’) of the radioactive species. For example, \\(\\lambda = 142\\) per million year for \\(^{87}\\)Rb.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#approximating-the-differential-equation",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#approximating-the-differential-equation",
    "title": "Numerical Solutions (Need)",
    "section": "2.2 Approximating the differential equation",
    "text": "2.2 Approximating the differential equation\nLet’s follow our recipe and recast the differential equation in an approximate form:\n\\[\n\\begin{align*}\n\\dfrac{\\Delta N}{ \\Delta t}&\\approx- \\lambda N \\\\[10pt] \\Rightarrow \\Delta N &\\approx-\\lambda N \\Delta t\n\\end{align*}\n\\]\n\nGetting a feel\n\n\n\n\n\n\n\n\n\n\n\nStep\nTime\nN(t) \\((\\times 10^9)\\)\n\\(\\Delta t\\) (million years)\n\\(\\Delta N\\) (\\(\\times10^9\\))\n\n\n\n\n0\n\\(t_0 = 0\\)\n1\n\\(0.001\\)\n\\(-0.142\\)\n\n\n1\n\\(t_1 = t_0 + \\Delta t  = 0.001\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n2\n\\(t_2 = t_1 + \\Delta t =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n3\n\\(t_3 = t_2 + \\Delta t  =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n4\n\\(t_4 = t_3 + \\Delta t  =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n5\n\\(t_5 = t_4 + \\Delta t  =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n6\n\\(t_6 = t_5 + \\Delta t  =?\\)\n\\(?\\)\n\\(0.001\\)\n\\(?\\)\n\n\n\n\nWe will re-create this data using Python in a bit. But, for the moment, if you are still not yet very confident about how we solve differential equations, try to complete the \\(?\\) of the table by hand.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#lets-write-some-code",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#lets-write-some-code",
    "title": "Numerical Solutions (Need)",
    "section": "2.3 Let’s write some code",
    "text": "2.3 Let’s write some code\n\ndecay_constant = 142       # For 85 Rb (per Myr)\nstop_fraction = 1E-3       # stop when the sample has shrunk to\n                           # this fraction of the starting value\nN0 = 1                     # Starting value of N (in billions of atoms)\ndt = .001\ntime, N = 0, N0            # Starting values\n\nall_N, all_time = [], []\n\nwhile True:\n    all_time.append(time)\n    all_N.append(N)\n\n    dN = -decay_constant*N*dt\n    N += dN\n\n    if N &lt; N0*stop_fraction:\n        break\n\n    time += dt\n\n\nplt.plot(all_time, all_N)\nplt.ylabel('$N$')\nplt.xlabel('Time(Millions of years)')\n\n\n\n\n\n\n\nSome things to note about the code\nI want to draw your attention to how I am using a True condition with the while loop. So, it will run until the end of The Universe until I break out on my own. To break out, I check if the \\(N\\) has been reduced to a negligible amount, which I have defined using stop_fraction.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/knowledge_lake/numerical/1_numerical_need.html#a-quick-summary-1",
    "href": "docs/knowledge_lake/numerical/1_numerical_need.html#a-quick-summary-1",
    "title": "Numerical Solutions (Need)",
    "section": "2.4 A quick summary",
    "text": "2.4 A quick summary\nYet, again, I draw your attention to the strategy we use to solve the differential equation.\n\nRewrite the equation in an approximate form that connects the changes of one variable to another. i.e. \\[\n\\dfrac{dN}{dt}=- \\lambda N \\Rightarrow \\Delta N \\approx - \\lambda N \\Delta t\n\\]\nPick starting values for the variables.\nStep the control variable (time in the previous case) and calculate the corresponding changes in the other variables.\nUpdate the variables\nRepeat until you reach the desired end.\nMake the step size smaller if you want greater accuracy.\n\nThis method you have been using is named the Euler Method (pronounced o-e-le).\n\n\n\n\n\n\nRemember\n\n\n\nRemember that the easiest (although not necessarily the best) way to solve a differential equation is using the Euler method.",
    "crumbs": [
      "Content",
      "Part 3| The Knowledge Base",
      "Numerical Solutions",
      "Numerical Solutions (Need)"
    ]
  },
  {
    "objectID": "docs/classes/classes_02.html",
    "href": "docs/classes/classes_02.html",
    "title": "Classes 2 (Nice)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\n\n\n\n\n\nWarning\n\n\n\nThe material in this ‘Nice’ chapter is optional. The discussion typically deals with content beyond what a novice should know. So, please finish all the ‘Need’ and ‘Good’ portions before you go through this chapter.\n\n\n\n1 Cleaning up with Loops\nIn my previous discussion on classes, I introduced a class called CParticle1D. I also mentioned how inefficient some of the code was. Now that we know loops, I can quickly clean up my code. Here is a comparison.\n\nBefore (No Loops)Now (With Loops)\n\n\n\n\n\n\nclass CParticle1D:\n    mass = None\n    position = None\n    radius = None\n\n\n# Make all the particles identical\nCParticle1D.mass = 99\nCParticle1D.radius = .01\n\n# Create a list of particles\nall_particles = [CParticle1D()]\nall_particles += [CParticle1D()]\nall_particles += [CParticle1D()]\n\n# Initialise with a random position\ni = 0\nall_particles[i].position = np.random.rand()\n\ni += 1\nall_particles[i].position = np.random.rand()\n\ni += 1\nall_particles[i].position = np.random.rand()\n\n\ni = 0\nprint(f'Particle {i}: mass={all_particles[i].mass}, position= {all_particles[i].position:.3f}.')\n## Particle 0: mass=99, position= 0.715.\ni += 1\nprint(f'Particle {i}: mass={all_particles[i].mass}, position= {all_particles[i].position:.3f}.')\n## Particle 1: mass=99, position= 0.885.\ni += 1\nprint(f'Particle {i}: mass={all_particles[i].mass}, position= {all_particles[i].position:.3f}.')\n## Particle 2: mass=99, position= 0.469.\n\n\n\n\n\n\n\nclass CParticle1D:\n    mass = None\n    position = None\n    radius = None\n\n\n# Make all the particles identical\nCParticle1D.mass = 99\nCParticle1D.radius = .01\n\n# Create a list of particles\nno_of_particles = 3\nall_particles = [CParticle1D() for _ in range(no_of_particles)]\n\n# Initialise with a random position\nfor particle in all_particles:\n    particle.position = np.random.rand()\n\n# Print stuff to check\nfor count, particle in enumerate(all_particles):\n    print(f'Particle {count}: mass={particle.mass}, position= {particle.position:.3f}.')\n\nParticle 0: mass=99, position= 0.715.\nParticle 1: mass=99, position= 0.885.\nParticle 2: mass=99, position= 0.469.\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Classes 2 (Nice)"
    ]
  },
  {
    "objectID": "docs/applications_challenge/02_hello-colab.html#accessing-colab",
    "href": "docs/applications_challenge/02_hello-colab.html#accessing-colab",
    "title": "Task 0| Hello Colab",
    "section": "1.1 Accessing Colab",
    "text": "1.1 Accessing Colab\n\nTo access Colab, please visit colab.google and Create a new Notebook.\nThe notebook will be stored/saved in your Google Drive under a folder called Colab Notebooks. If you want to quickly locate where it is stored, go to File → Locate in Drive.\nIf you like, you can directly upload (File → Upload Notebook) a Jupyter .ipynb Notebook, and it will be converted into a Colab Notebook.\nYou can also download (File → Download → Download  .ipynb) a Colab Notebook as a Jupyter .ipynb Notebook. You will need to do this to submit your work to CANVAS.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 0| Hello Colab"
    ]
  },
  {
    "objectID": "docs/applications_challenge/02_hello-colab.html#running-python",
    "href": "docs/applications_challenge/02_hello-colab.html#running-python",
    "title": "Task 0| Hello Colab",
    "section": "1.2 Running Python",
    "text": "1.2 Running Python\nColab works just like a Jupyter Notebook. Test out by:\nprint('Hello Colab!')\nThe first cell you run will be slow because Colab will take time to create and connect to a virtual (Linux) machine.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 0| Hello Colab"
    ]
  },
  {
    "objectID": "docs/applications_challenge/02_hello-colab.html#installing-package",
    "href": "docs/applications_challenge/02_hello-colab.html#installing-package",
    "title": "Task 0| Hello Colab",
    "section": "1.3 Installing package",
    "text": "1.3 Installing package\nColab uses a package manager called pip (not conda). When you want to install something (say the package Seaborn), you need to:\n!pip install seaborn",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 0| Hello Colab"
    ]
  },
  {
    "objectID": "docs/applications_challenge/02_hello-colab.html#uploading-files-to-colab",
    "href": "docs/applications_challenge/02_hello-colab.html#uploading-files-to-colab",
    "title": "Task 0| Hello Colab",
    "section": "3.1 Uploading files to Colab",
    "text": "3.1 Uploading files to Colab\n\n\n\n\n\nTo upload data to Colab you should look for the folder icon on the left, shown in the figure above.\n\n\n\n\n\n\nYour files will disappear\n\n\n\nEvery time you log out of Colab, it resets the (Linux) machine it created for you. This means you will lose any files you uploaded to the machine(instance) unless you download them or make a copy in your Google Drive.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 0| Hello Colab"
    ]
  },
  {
    "objectID": "docs/applications_challenge/02_hello-colab.html#lets-practice",
    "href": "docs/applications_challenge/02_hello-colab.html#lets-practice",
    "title": "Task 0| Hello Colab",
    "section": "3.2 Let’s Practice",
    "text": "3.2 Let’s Practice\n\nPlease upload the Complete_TAVG_daily.txt file with the Global Temperature data (from here).\nNow, let’s use this data.\ndata = np.loadtxt('Complete_TAVG_daily.txt',\n                skiprows=24)\ndate = data[:, 0]\nanomaly = data[:, -1]\n\nplt.plot(date, anomaly, alpha=.5)\nplt.ylim([-8, 8])\nplt.savefig('global-temperatures.png', dpi=150)\nYou should see the file global-temperatures.png in your folder. If not, press the Folder Refresh button.\nTo download this file, just right-click and download.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 0| Hello Colab"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/yz-streamplots.html",
    "href": "docs/applications_challenge/questions/yz-streamplots.html",
    "title": "08| All about plotting",
    "section": "",
    "text": "This challenge is about visualizing mathematical functions and vectors.\n\n\n\n\nIn case you need a reminder, we begin this problem with a recap on vectors. To put it simply, a vector is a physical quantity which consists of both magnitude and direction. Pictorially, vectors are represented by arrows, where the length of the arrow represents the magnitude and the arrowhead represents the direction. Mathematically, a vector can be represented through a combination of numbers and unit vectors (mathematical objects used to represent directions). For example, a vector \\(\\vec{v}\\) can be written as: \\[\n\\vec{v} = 2\\hat{i} - 3\\hat{j}\n\\] where \\(\\hat{i}\\) and \\(\\hat{j}\\) are unit vectors in the \\(x\\)- and \\(y\\)-axes, respectively. Physically, we can interpret \\(\\vec{v}\\) as an arrow which is equivalent to 2 steps in the direction of the positive x-axis, 3 steps in the direction of the negative y-axis. We say that 2 is the \\(x\\)-component of \\(\\vec{v}\\) while -3 is the \\(y\\)-component of \\(\\vec{v}\\). The figure below illustrates this physical picture.\n\n\n\n\n\n\n\n\nOne way to visualise vectors using Python is streamplot(). streamplot() is a function in matplotlib that draws the streamlines of a vector field. In simple terms, streamplot gives us the directions of vectors at different coordinates. It allows us to visualise many real-life phenomena including river flow, neural network, molecular velocity, and many others. This problem serves as an introduction to streamplot.\nFamiliarise yourself with streamplot(). You may read the write-up on streamplot on the matplotlib website as a start. Note that the write-up assumes that the vectors to be plotted are velocities, but all other vectors can be plotted the same way.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "08| All about plotting"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/yz-streamplots.html#a-quick-primer-in-vectors",
    "href": "docs/applications_challenge/questions/yz-streamplots.html#a-quick-primer-in-vectors",
    "title": "08| All about plotting",
    "section": "",
    "text": "In case you need a reminder, we begin this problem with a recap on vectors. To put it simply, a vector is a physical quantity which consists of both magnitude and direction. Pictorially, vectors are represented by arrows, where the length of the arrow represents the magnitude and the arrowhead represents the direction. Mathematically, a vector can be represented through a combination of numbers and unit vectors (mathematical objects used to represent directions). For example, a vector \\(\\vec{v}\\) can be written as: \\[\n\\vec{v} = 2\\hat{i} - 3\\hat{j}\n\\] where \\(\\hat{i}\\) and \\(\\hat{j}\\) are unit vectors in the \\(x\\)- and \\(y\\)-axes, respectively. Physically, we can interpret \\(\\vec{v}\\) as an arrow which is equivalent to 2 steps in the direction of the positive x-axis, 3 steps in the direction of the negative y-axis. We say that 2 is the \\(x\\)-component of \\(\\vec{v}\\) while -3 is the \\(y\\)-component of \\(\\vec{v}\\). The figure below illustrates this physical picture.\n\n\n\n\n\n\n\n\nOne way to visualise vectors using Python is streamplot(). streamplot() is a function in matplotlib that draws the streamlines of a vector field. In simple terms, streamplot gives us the directions of vectors at different coordinates. It allows us to visualise many real-life phenomena including river flow, neural network, molecular velocity, and many others. This problem serves as an introduction to streamplot.\nFamiliarise yourself with streamplot(). You may read the write-up on streamplot on the matplotlib website as a start. Note that the write-up assumes that the vectors to be plotted are velocities, but all other vectors can be plotted the same way.",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "08| All about plotting"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/roberts-gray-golgi_question.html",
    "href": "docs/applications_challenge/questions/roberts-gray-golgi_question.html",
    "title": "09| A picture is worth thousands of data points",
    "section": "",
    "text": "Introduction\nA lot of data goes into creating an image. Or, put another way, we can extract many details by analysing an image. matplotlib allows you to do this quite easily. In this question, we will use matplotlib to quickly explore the topic of image analysis. For this, please download the zip file golgi-movie_robert_frames_gray.zip, which contains 17 fluorescence images collected by Dr Robert Lieu. The 17 images are a time series of the variation of a fluorescence marker protein.\nThe original images have been converted to grayscale (black & white) images to simplify this discussion.\n\n\nTasks\n\nTask 1Task 2Task 3\n\n\n\nLock and Load\n\nUse the following code to import and display one of the images. The cmap specifies the false-colour, colour scheme used to display the data.\nimg_data = plt.imread(file-name)\nplt.imshow(img_data, cmap='jet')\nplt.colorbar()\n\n\n\n\nHow is the data stored?\nHow is the image information stored by matplotlib? Let’s find out.\nDetermine the following:\n\nType of img_data.\nShape of img_data.\nValues of maximum, minimum and sum of img_data. What do these numbers represent?\nA histogram of all the values of img_data.\nThe total counts of the image.\n\nHints:\n\nflatten() might be useful.\n\n\n\n\n\nPlotting a trend\nWrite a snippet of Python code to produce the following plot that shows the variation of the total fluorescence intensity over time for the images provided.\n\n\n\n\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "09| A picture is worth thousands of data points"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/monte-carlo-integration.html",
    "href": "docs/applications_challenge/questions/monte-carlo-integration.html",
    "title": "12| Monte Carlo Integration",
    "section": "",
    "text": "Introduction\nEvaluating integrals is necessary for most scientific modelling. So, many different integration methods have been developed. The Monte Carlo(MC) integration method is one of the most versatile. One of its charms is its ability to be scaled up to higher dimensions without much fuss. In this question, you will develop code to realise Monte Carlo integration.\n\n\nTasks\n\nTask 1Task 2Some theoryTask 3\n\n\n\nArea first\n\nThe image shows a plot of the function \\(f(x)=x^2\\sin^2(2x)\\). Let’s try to estimate the area of the region shaded in blue.\nHere is what you should do:\n\nGenerate \\((x,y)\\) coordinates for a large number (\\(n_\\text{all}\\)) of random points to evenly cover the area shaded in grey.\n\nAs you can see, this region is defined by \\(2 \\le x \\le 3\\) and \\(0 \\le y\\le 6\\).\nConsider using uniform() for this.\n\nAsk how many points you generated are below the curve (and therefore in the blue region). Let’s call this number \\(n_\\text{below}\\).\n\nNotice that all random points in the blue region satisfy \\(y_i \\leq f(x_i)\\)\n\nNow we can calculate the area of the blue region because: \\[\n  \\dfrac{\\text{Blue Area}}{\\text{Grey Area}} \\approx \\dfrac{n_\\text{below}}{n_\\text{all}}\\Rightarrow \\text{Blue Area}=\\dfrac{n_\\text{below}}{n_\\text{all}}\\times\\text{Grey Area}\n  \\]\n\n\n\n\n\nIntegration\nSince you now know the blue area, you also know the value of the following integral \\(\\displaystyle\\int_{x=2}^{x=3}f(x)dx\\)! So what you have done in this exercise is develop a numerical technique for evaluating integrals.\n\nCheck how good your estimate is by comparing it to the actual value of the integral, which is \\(4.0647\\). (I used Wolfram Alpha).\nCheck if your accuracy improves by increasing \\(n_\\text{all}\\).\n\n\n\n\n\nA Monte Carlo Estimator\n\\[\n\\newcommand\\ex[1]{\\left\\langle #1 \\right\\rangle}\n\\]\nThere is another way! Let’s play with some maths to see how.\nConsider a function \\(f(x)\\) that we want to integrate over \\([a,b]\\). If \\(\\ex{f(x)}\\) is the expectation value of \\(f(x)\\) over \\([a,b]\\), it follows that:\n\\[\n\\ex{f(x)}= \\dfrac{1}{b-a}\\int_a^bf(x)dx\n\\] But, \\[\n\\ex{f(x)}\\approx \\dfrac{1}{N}\\sum_{i=0}^{N-1}f(X_i)\n\\] Where \\(X_i\\) are \\(N\\) points in the interval \\([a,b]\\).\nWhence, for \\(X_i\\) drawn uniformly,\n\\[\n\\begin{equation}\n\\int_a^bf(x)dx \\approx (b-a)\\dfrac{1}{N}\\sum_{i=0}^{N-1}f(X_i)\n\\end{equation}\n\\]\nThe term on the right-hand side is called a Monte Carlo estimator. Notice that the Law of Large Numbers tells us that this approximation improves with large values of \\(N\\)\n\n\n\n\nUsing an estimator\nEvaluate the following integral using an MC estimator based on a Uniform probability distribution.\n\\[\n\\int_{x=2}^{x=3} x^2\\sin^2(2x)\\,dx\n\\]\n\nCompare your answer with your previous MC algorithm.\nCompare the speed of the two algorithms.\n\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "12| Monte Carlo Integration"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/bisection_question.html",
    "href": "docs/applications_challenge/questions/bisection_question.html",
    "title": "02| Bisection Method",
    "section": "",
    "text": "Introduction\nThe values of \\(x\\) that satisfy \\(f(x) = 0\\) are called the roots of \\(f(x)\\). Finding the roots of equations is important in science and engineering, but some equations, such as \\(\\cos x - x = 0\\) (called transcendental equations), cannot be solved analytically. In such cases, numerical methods are needed. One such method is the Bisection method.\nTo understand how the Bisection method works, notice that the function has opposite signs on either side of the root. The Bisection method uses this fact to ‘box in’ the root. Here’s how it works:\n\nPick two values of \\(x\\) (let’s call them \\(x_\\text{left}\\) and \\(x_\\text{right}\\)) that we know lie on opposite sides of the root.\nDetermine the midpoint \\(x_\\text{mid}\\) of \\(x_\\text{left}\\) and \\(x_\\text{right}\\), and evaluate the function at this point.\nIf the sign of \\(f(x_\\text{mid})\\) is the same as the sign \\(f(x_\\text{left})\\), then replace \\(x_\\text{left}\\) with \\(x_\\text{mid}\\). Else, replace \\(x_\\text{right}\\) with the midpoint.\nNow you have narrowed the range of the root to \\((x_\\text{left}, x_\\text{mid})\\) or \\((x_\\text{mid}, x_\\text{right})\\). Continue steps 2-4 until you have achieved the desired accuracy for the root.\n\nThe Bisection method is a simple but effective root-finding algorithm that can be implemented using only basic Python programming.\n\n\nTasks\n\nPlot for an estimate\nGet an estimate for the root of \\(\\cos x - x =0\\) by plotting the functions \\(\\cos x\\) and \\(x\\).\nUse bisection\nUse the bisection method to determine the root of \\(\\cos x - x =0\\) to 10 decimal places.\n(Answer = 0.739_085_133_2)\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "02| Bisection Method"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/yz-trapezium.html",
    "href": "docs/applications_challenge/questions/yz-trapezium.html",
    "title": "03| Integrals & Areas",
    "section": "",
    "text": "Introduction\nThe definite integral of a function, \\(f(x)\\) with respect to \\(x\\) is the area bounded by the curve of the function and the x-axis, as shown in the figure below.\n\n\n\n\n\nOne way to estimate the integral of a function is by approximating the area bounded as a trapezium as shown in the figure below, where the slanted side connects the \\(y\\) values at the lower and upper limits. The integral can then be estimated by calculating the area of the trapezium.\n\n\n\n\n\nAs you can see, the estimation using one trapezium is rather off. In this case, there’s an overestimation. We can improve the accuracy by having more trapeziums, as shown in the figure below, where three trapeziums of equal width are used. The slanted side of each trapezium connects the \\(y\\) values at the \\(x\\)-boundaries of each trapezium.\n\n\n\n\n\nFrom here, we can deduce that if we have a large number of such trapeziums, each of very thin size, we can find the numerical value of the definite integral pretty accurately. This method of approximating definite integral is known as the trapezium rule.\n\n\nTasks\n\nWrite a Python function which can estimate the definite integral of a mathematical function \\(f(x)\\) using the trapezium rule.\nUse WolframAlpha to evaluate the integrals and complete the last column.\n\n\n\n\n\n\n\n\n\n\n\n\n#\n\\(f(x)\\)\n\\(a\\)\n\\(b\\)\n\\(\\displaystyle\\int_{x=a}^{x=b} f(x)dx\\)(Wolfram Alpha)\n\n\n\n\n1\n\\(f(x)=x^2+3x+2\\)\n\\(0\\)\n\\(5\\)\n\n\n\n2\n\\(f(x)=\\sin x\\)\n\\(0\\)\n\\(\\pi\\)\n\n\n\n3\n\\(f(x)=e^{-x^2}\\)\n\\(0\\)\n\\(1\\)\n\n\n\n4\n\\(f(x)=\\sin\\left(\\dfrac{1}{x}\\right)\\)\n\\(0.01\\)\n\\(0.1\\)\n\n\n\n\n\n\nNow use your function to evaluate the integrals. Add your results as a new column.Please highlight any strategies you used to enhance the quality of your answers.\nFor the above functions, you had the benefit of knowing the answers beforehand due to Wolfram Alpha. Can you describe a strategy that can be used to judge the quality of your answer if you did not have access to the answer beforehand?\n[Optional] Considering the power of services like WolframAlpha; is there a need to write your own code.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "03| Integrals & Areas"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/butterfly.html",
    "href": "docs/applications_challenge/questions/butterfly.html",
    "title": "11| The Butterfly Effect",
    "section": "",
    "text": "Introduction\n\n\n\n\n\nI am sure you would have heard of the ‘butterfly effect’. This term is related to a phenomenon called (deterministic) chaos, where some systems exhibit strong variations in behaviour despite only minute changes in the outputs. In other words, chaotic systems are super sensitive to their input parameters.\nThe first chaotic system discovered is the Lorentz Attractor, which is related to a simple weather model created by Edward Lorentz. The system is governed by three coupled differential equations:\n\\[\n\\begin{align}\n\\dfrac{dx}{dt}&=\\sigma(y-x)\\\\\n\\dfrac{dy}{dt}&=x(\\rho-z)-y\\\\\n\\dfrac{dz}{dt}&=xy-\\beta z\\\\\n\\end{align}\n\\] Lorentz had used the values \\(\\sigma=10\\), \\(\\beta=8/3\\) and \\(\\rho=28\\).\n\n\nTasks\n\nSolve the differential equations of this system for the initial conditions \\((x,y,z) = (0,1,0)\\) from \\(t=0\\) to \\(t=50\\) using the Euler method and the SciPy’s odeint().\nUse your solutions \\((x,y,z)\\) values with the following code to get the the Lorentz’s Butterfly shown above.\nax = plt.axes(projection='3d')\nax.plot3D(x, y, z)\nplt.show()\nThis system is considered to be chaotic (i.e., highly sensitive to the initial conditions). Use your code to demonstrate this effect.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "11| The Butterfly Effect"
    ]
  },
  {
    "objectID": "docs/applications_challenge/questions/pool-sampling_question.html",
    "href": "docs/applications_challenge/questions/pool-sampling_question.html",
    "title": "04| Pool Sampling",
    "section": "",
    "text": "Introduction\nLet’s investigate a medical testing strategy that proved invaluable in coping with the huge number of COVID-19 tests required in the past pandemic. Specifically, we will be studying the strategy called Group or Pool sampling (Wikipedia). It was first proposed by the economist Robert Dorfman in 1943 to test syphilis in soldiers!\nTo get started, please download the following two files:\n\ntest_kit.py\n\nThis file contains a python function test(genome) that accepts a genome as a string (e.g., ATGAGAAT…) and returns True if there is an infection or False if not.\nThis function can only test one sample at a time.\nThere are no false positives.\nThe test is 100% accurate.\n\nperson-files.zip\n\nThis file contains (simulated ) genomics data for 500 people.\nThe files are named in the format person_###.txt where ### is a identifying number.\nJust for your information, each person’s file contains a million bases.\n\n\n\n\nTasks\n\nTask 1Task 2Task 3Task 4Task 5\n\n\n\nGetting started\n\nTo get started, import the function test() from test_kit.py.\ntest() is a straightforward function. However, you are not meant to understand how this function works. You just need to be able to use it. So, you can treat the function test() as a black-box.\nConfirm that Person 27 is infected and that person 17 and 37 are not infected. To use test() on a person, you need to:\n\nRead the person’s genomics data from her file and\nPass this genomics data into test()\n\n\n\n\n\n\nCreate a function\n\nCreate a function get_genome(person_id) that will take an (integer) person_id as input and return the corresponding genome data as output.\nUse get_genome() to apply test() to the first 100 people. (I.e. from person_00000.txt to person_00099.txt) You should see persons 1, 7, 8, 27, 47, 57, 62, 63, and 78 show infections.\n\n\n\n\n\nRandom testing\n\nUse test() on 100 random people to estimate the infection rate in this population. Print your result as a percentage.\n\n\n\n\n\nPool Sampling\n\nWrite some Python code to join/combine the genomics data of person 1 and person 2. I.e. given genome_1 and genome_2, you should end up with genome_1genome_2 What we are trying to simulate here is the mixing of blood samples.\nWrite a function called pool(list_of_id) that accepts a list of integers and returns (a string) of the joined genomes of the people identified by the integers.\nApply test() to the combined genomes of 20 and 21 and 21 and 22. Are the results as expected?\nFor the first 100 persons, use pool and test in groups of 10 to determine those infected. Please keep track of the number of tests you have performed and print it at the end.\nRepeat the previous part with groups of 5.\n\n\n\n\n\nOptimisation\nLet’s try to detect as many infections as possible using the least number of tests. Pick any grouping you like, and apply pool sampling to determine the number of infected people in the population of 500. Keep track of the number of tests you have performed.\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 2| App. Challenge",
      "Task 1| Challenges",
      "04| Pool Sampling"
    ]
  },
  {
    "objectID": "docs/applications_challenge/03_instructor-presentations.html",
    "href": "docs/applications_challenge/03_instructor-presentations.html",
    "title": "Instructor Presentations",
    "section": "",
    "text": "Back to top"
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_0_main.html",
    "href": "docs/python_basics/00_setting_up/setup_0_main.html",
    "title": "Tools of the Trade",
    "section": "",
    "text": "Overview\nIt is not surprising that 73 will have to use technology. Some of the key requirements of technology in this module are:\n\nEasy access to Python,\nEase of incorporating a scientific discussion with the Python code,\nEase of sharing Python code for feedback and collaborative work.\nEase of starting a discussion about the content.\n\nNo single platform can fulfill all these requirements, so we must use several different tools. However, I have organised the course to have an easy workflow for you to learn by doing and getting feedback. So here are the platforms we will use.\n\n\n# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\n\n\n\n\n\n\n\n\n\n\nPlatform\nHow it will help us\n\n\n\n\n\nJupyter Notebooks\nEasy access to Python with ample features for scientific discussions.\n\n\n\nGitHub Classroom\nSharing the Jupyter Notebooks\n\n\n\nHypothesis\nAnnotate, discuss centred on course notes.\n\n\n\nCanvas\nOfficial Learning Management System (LMS) of NUS\n\n\n\nGoogle Docs\nScheduling and grading.\n\n\n\nTEAMMATES\nFor within group feedback\n\n\n\n\nIn this section, I will show you how to set up three essential tools, namely:\n\nHypothesis,\nGitHub classrooms and\nJupyter Notebooks.\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Tools of the Trade"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_2_github.html",
    "href": "docs/python_basics/00_setting_up/setup_2_github.html",
    "title": "Hello, GitHub! (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\nGitHub is an online service to help develop and maintain code. It is called GitHub because it is based on a version control tool called Git. A key feature of Git and GitHub is how it helps keep track of the changes to code. You can think of GitHub as a sophisticated version of Google Drive or Dropbox. The know-how to use Git and GitHub is a plus for tech employees.\n73 will use the educational branch of GitHub called GitHub Classroom. We will only use the simplest features of GitHub Classroom that allow you to share your code and solicit instructor feedback. In this chapter, I will take you through the setup process for GitHub Classroom. If you are already familiar with GitHub, feel free to jump ahead.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, GitHub! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/00_setting_up/setup_2_github.html#footnotes",
    "href": "docs/python_basics/00_setting_up/setup_2_github.html#footnotes",
    "title": "Hello, GitHub! (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nor the End of the Universe↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "0. Setting Up",
      "Hello, GitHub! (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html",
    "title": "Using Jupyter (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#it-is-all-about-running-cells",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#it-is-all-about-running-cells",
    "title": "Using Jupyter (Need)",
    "section": "2.1 It is all about running cells",
    "text": "2.1 It is all about running cells\nThe basic unit of a Jupyter Notebook is a cell. A cell can either accept Python code or text in a format called Markdown.\nA cell ready to accept Python is called a code cell, while one ready for Markdown is called a Markdown cell. To ‘get things done’, we Run a cell by using the Run button or the keyboard shortcut CTRL + ENTER (or CMD + ENTER).\n\n\n\n\n\nRunning a code cell invokes Python while running a Markdown cell renders (i.e., makes it look pretty) your Markdown text. You will see how all this works in a bit, so don’t worry if things sound a tad cryptic at the moment.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#a-traditional-start",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#a-traditional-start",
    "title": "Using Jupyter (Need)",
    "section": "2.2 A traditional start",
    "text": "2.2 A traditional start\nLet’s follow a programming tradition and use Jupyter to print Hello World!.\n\nSelect a cell and convert it into a code cell.Actually, all new cells are, by default, code cells.\n\n\n\n\n\nThen type the following and run the command (i.e., pass the instruction to Python) by pressing the run button or using the keyboard shortcut CTRL + ENTER (or CMD + ENTER).\nprint('Hello World!')\nSurprise, surprise! You should see the words Hello World! as the output.\n\n\nHello world!\n\n\nYou will also see that the number before your code cell changes. This number is used to keep track of the history of the commands you have issued. It helps keep track of which input corresponds to which output.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#rendering-markdown-cells",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#rendering-markdown-cells",
    "title": "Using Jupyter (Need)",
    "section": "3.1 Rendering Markdown cells",
    "text": "3.1 Rendering Markdown cells\nTo render your text:\n\nSelect a cell and convert it to a Markdown cell (If you like, you can use the keyboard shortcut ESC + M),\nInput your text and\nRun.\n\nTo start, copy and paste the following (from the Guide1) and run the cell.\nThe ships hung in the sky in much the same way that bricks don’t.\nYou should see the text rendered.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#some-basic-syntax",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#some-basic-syntax",
    "title": "Using Jupyter (Need)",
    "section": "3.2 Some basic syntax",
    "text": "3.2 Some basic syntax\nThe table shows some basic Markdown syntax to modify how some text is rendered.\n\n\n\n\nStyle\nSyntax\n\n\n\n\nBold\n** ** or __ __\n\n\nItalic\n* * or _ _\n\n\nAll bold and italic\n*** ***\n\n\nSubscript\n&lt;sub&gt; &lt;/sub&gt;\n\n\nSuperscript\n&lt;sup&gt; &lt;/sup&gt;\n\n\n\n\nLet’s use it to modify our previous text as follows. (By the way, no more copying and pasting!)\nThe ships *hung in the sky* in much the same way that **bricks don’t.**&lt;sup&gt;1&lt;/sup&gt;&lt;sub&gt;QUOTE&lt;/sub&gt;\nThis will be rendered as:\nThe ships hung in the sky in much the same way that bricks don’t.1QUOTE",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#headings",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#headings",
    "title": "Using Jupyter (Need)",
    "section": "3.3 Headings",
    "text": "3.3 Headings\nMarkdown uses # for headings as follows.\n# The largest heading\n\n## The second-largest heading\n\n### The third-largest heading\n\n#### The smallest heading",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#displaying-code",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#displaying-code",
    "title": "Using Jupyter (Need)",
    "section": "3.4 Displaying Code",
    "text": "3.4 Displaying Code\nIf you want to mention code inline, you can enclose it between two backticks (`), like `print('Hello World')`. This will be rendered as print('Hello World!').\nYou can also have a block of code by using the following syntax.\n```python\nprint('Hello World!')\n```\nThis will be rendered as:\nprint('Hello World!')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#links",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#links",
    "title": "Using Jupyter (Need)",
    "section": "3.5 Links",
    "text": "3.5 Links\nCreating links with Markdown is trivial. You just enclose the display text in [ ] followed by the link-address in ( ) like\n[SP2273 Website](https://sps.nus.edu.sg/sp2273)\nThis will be rendered as SP2273 Website. Things won’t work if you don’t include the https:// part. So, be careful.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#images",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#images",
    "title": "Using Jupyter (Need)",
    "section": "3.6 Images",
    "text": "3.6 Images\nMarkdown also lets you easily include images from your computer or the web. The syntax is similar to links, except there is a ! in front.\nLet me show you by inserting the NUS logo from the University’s front page (You can get the link to any image by right-clicking and copying the image address).\nThe syntax is:\n![](https://nus.edu.sg/images/default-source/base/logo.png)\nThis will give you:\n\nYou can also similarly include images on your computer. Just put the filename instead of the address. Again, you need to give enough information (full or relative path, see chapter os) for Jupyter to be able to find the file.\n\n\n\n\n\n\nA fly in the ointment\n\n\n\nSometimes, you might have to copy the image file to the folder/directory containing the .ipynb to successfully include local images.\nI think this happens mainly for Windows users. I am sorry2.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#tables",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#tables",
    "title": "Using Jupyter (Need)",
    "section": "3.7 Tables",
    "text": "3.7 Tables\nMarkdown following syntax to create tables:\n| A    |  B   |    C |\n| :--- | :--: | ---: |\n| a1   |  b1  |   c1 |\n| a2   |  b2  |   c2 |\n| a3   |  b3  |   c3 |\nWhich will be rendered as:\n\n\n\n\nA\nB\nC\n\n\n\n\na1\nb1\nc1\n\n\na2\nb2\nc2\n\n\na3\nb3\nc3\n\n\n\n\nIn my experience, tables are the most annoying things to create and format in a document3. So I find it easier to organise the information in Excel or Sheets and then use a web tool like Table Generator to create the tables.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#lists",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#lists",
    "title": "Using Jupyter (Need)",
    "section": "3.8 Lists",
    "text": "3.8 Lists\nYou can have numbered or unnumbered lists in Markdown. Below are a few examples. I have shown the code first and then what it will look like when rendered.\n\nNumberedUnnumberedNumbered-numberedNumbered-unnumbered\n\n\n\n\n\n\n\n\n1. Master Yoda\n1. Luke Skywalker\n1. Anakin Skywalker\n\n\n\nMaster Yoda\nLuke Skywalker\nAnakin Skywalker\n\n\n\n\n\n\n\n\n\n\n\n\n- Master Yoda\n- Luke Skywalker\n- Anakin Skywalker\n\n\n\nMaster Yoda\nLuke Skywalker\nAnakin Skywalker\n\n\n\n\n\n\n\n\n\n\n\n\n1. Master Yoda\n   1. Was a Jedi\n   1. Was a bit green\n1. Luke Skywalker\n   1. Was a Jedi\n   1. Is Anakin's son.\n1. Anakin Skywalker\n   1. Was a Jedi then became a baddie\n   1. Is famous for saying 'Luke, I am your father'\n\n\n\nMaster Yoda\n\nWas a Jedi\nWas a bit green\n\nLuke Skywalker\n\nWas a Jedi\nIs Anakin’s son.\n\nAnakin Skywalker\n\nWas a Jedi then became a baddie\nIs famous for saying ‘Luke, I am your father’\n\n\n\n\n\n\n\n\n\n\n\n\n\n1. Master Yoda\n   - Was a Jedi\n   - Was a bit green\n1. Luke Skywalker\n   - Was a Jedi\n   - Is Anakin's son.\n1. Anakin Skywalker\n   - Was a Jedi then, became a baddie\n   - Is famous for saying, _'Luke, I am your father'_.\n\n\n\nMaster Yoda\n\nWas a Jedi\nWas a bit green\n\nLuke Skywalker\n\nWas a Jedi\nIs Anakin’s son.\n\nAnakin Skywalker\n\nWas a Jedi then, became a baddie\nIs famous for saying, ‘Luke, I am your father’.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#equations",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#equations",
    "title": "Using Jupyter (Need)",
    "section": "3.9 Equations",
    "text": "3.9 Equations\nMarkdown can produce phenomenal math equations4.\n\nIf you want to have inline math use two $ signs like $\\sqrt{b^2-4ac}$, which will be rendered as \\(\\sqrt{b^2-4ac}\\).\nIf you want a math block, you can use the following:\n$$\nx = \\dfrac{-b \\pm \\sqrt{b^2-4ac}}{2a}\n$$\nWhich will be rendered as:\n\n\\[\nx = \\dfrac{-b \\pm \\sqrt{b^2-4ac}}{2a}\n\\]\nHere are some helpful math commands that you can use. For more details, refer to the mathematical documentation at Overleaf.\n\n\n\n\n\n\n\n\n\n\nInput\nRendered\n\n\n\n\nFraction\n$\\dfrac{y}{x}$\n\\(\\dfrac{y}{x}\\)\n\n\nSubscript\n$x_{a}$\n\\(x_{a}\\)\n\n\nPower\n$x^{(y+z)}$\n\\(x^{(y+z)}\\)\n\n\nSquareroot\n$\\sqrt{a+b+c}$\n\\(\\sqrt{a+b+c}\\)\n\n\nSum\n$\\sum_{n=1}^{n=\\infty} x_n$\n\\(\\sum_{n=1}^{n=\\infty} x_n\\)\n\n\nIntegral\n$\\int_{x=1}^{x=\\infty} f(x)dx$\n\\(\\int_{x=1}^{x=\\infty} f(x)dx\\)\n\n\nNot equal\na \\ne b\n\\(a \\ne b\\)\n\n\nLess than\n$a \\lt b$\n\\(a \\lt b\\)\n\n\nLess than or equal to\n$a \\leq b$\n\\(a \\leq b\\)\n\n\nGreater than\n$a \\gt b$\n\\(a \\gt b\\)\n\n\nGreater than or equal to\n$a \\geq b$\n\\(a \\geq b\\)\n\n\nGreek letters\n$\\alpha, \\beta, \\gamma, \\pi, \\lambda$\n\\(\\alpha, \\beta, \\gamma, \\pi, \\lambda\\)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#footnotes",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need.html#footnotes",
    "title": "Using Jupyter (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nYou and I will have problems if you do not know about The Hitchhiker’s Guide to the Galaxy.↩︎\nthat you are using Windows.↩︎\nespecially with doubly annoying software like Word↩︎\nUsing a \\(\\LaTeX\\) engine called MathJax↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "Using Jupyter (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need_exercises.html",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need_exercises.html",
    "title": "Using Jupyter (Need), Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercises (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/01_using_jupyter/1_using-jupyter_need_exercises.html#quadratic-equations",
    "href": "docs/python_basics/01_using_jupyter/1_using-jupyter_need_exercises.html#quadratic-equations",
    "title": "Using Jupyter (Need), Exercises",
    "section": "1 Quadratic Equations",
    "text": "1 Quadratic Equations\n\nIntroduction\n\n(Image from the Wikipedia page on Quadratic equations)\nThe general form of a quadratic equation is:\n\\[\nax^2 + bx + c = 0\n\\]\n\n\nSolutions\nProvided \\(a\\ne0\\), we can use an elementary algebraic method called completing the square to show that a quadratic equation has the following solution: \\[\nx = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}\n\\]\n\n\nDiscriminant\nThe quantity \\(\\Delta = b^2-4ac\\) is called the discriminant of the equation and decides the nature of its solutions. The table below shows the various possibilities.\n\n\n\nDiscriminant\nRoots\n\n\n\n\n\\(\\Delta = b^2-4ac = 0\\)\nA single solution of \\(-b/(2a)\\)\n\n\n\\(\\Delta = b^2-4ac \\gt 0\\)\nTwo distinct solutions\n\n\n\\(\\Delta = b^2-4ac \\lt 0\\)\nNo real solutions; both are complex.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "1. Using Jupyter",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercises (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/2_loops_good_exercises.html",
    "href": "docs/python_basics/04_loops/2_loops_good_exercises.html",
    "title": "Loops (Good) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\n\nExercise 1 (Make me an odd list) ☻\nWith your knowledge of growing lists, use a for loop with range() and continue to generate a list of the squares of the odd integers from 0 to 9.\nHint: You can check for ‘evenness’ using number % 2 == 0.\n\n\nExercise 2 (Make me another odd list) ☻\nRedo the previous exercise using list comprehension.\n\n\nExercise 3 (Time me!) ☻\nUse the cell magic command %%timeit to time the previous solutions. Which of the two is faster?\n\n\nExercise 4 (A problem of decay) ☻\nThe initial quantity of a sample of a radioactive substance is 100 units, and it decays by 5% each year. Use a while loop to determine how long the sample will take to reduce to half its original amount.\n\n\nExercise 5 (Changes in CO\\(_2\\)) ☻\nThe following is data about atmospheric CO\\(_2\\) levels for several years in a (year, CO2_level) format. The units are ppm.\nco2_data = [\n    (2000, 369.55), (2001, 371.14), (2002, 373.28), \n    (2003, 375.80), (2004, 377.52), (2005, 379.80), \n    (2006, 381.90), (2007, 383.79), (2008, 385.60), \n    (2009, 387.43), (2010, 389.90), (2011, 391.65), \n    (2012, 393.85), (2013, 396.52), (2014, 398.65),\n    (2015, 400.83), (2016, 404.24), (2017, 406.55), \n    (2018, 408.52), (2019, 411.44), (2020, 414.24)\n]\nIdentify those years that showed an increase of CO\\(_2\\) of 3 ppm or more compared to the previous year.\nPlease print out these years along with the corresponding change in concentration.\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/1_loops_need.html",
    "href": "docs/python_basics/04_loops/1_loops_need.html",
    "title": "Loops (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/1_loops_need.html#for-with-a-list",
    "href": "docs/python_basics/04_loops/1_loops_need.html#for-with-a-list",
    "title": "Loops (Need)",
    "section": "1.1 for with a list",
    "text": "1.1 for with a list\nI can achieve the same result using a for loop as follows:\n\nfor name in real_names:\n    print(f\"{name} is a Marvel superhero!\")\n\nNatasha Romanoff is a Marvel superhero!\nTony Stark is a Marvel superhero!\nStephen Strange is a Marvel superhero!\n\n\nNotice the structure of the for loop;\n\nit goes through the list and assigns name the value of each element of the list.\nit then runs the code-block using this value of name.\nthe code block is deginted by using : and tabs like with if.\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember that for can be used to directly loop through a list.\n\n\nBy the way, there is nothing special about the names of the variables I have used. The following will work too. However, it will not be very readable because x is a bit cryptic in this context.\nfor x in real_names:\n    print(f\"{x} is a Marvel superhero!\")",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/1_loops_need.html#for-with-enumerate",
    "href": "docs/python_basics/04_loops/1_loops_need.html#for-with-enumerate",
    "title": "Loops (Need)",
    "section": "1.2 for with enumerate",
    "text": "1.2 for with enumerate\nLet’s say we want to do a bit more, like using the information in both of the following lists.\n\nsuper_names = [\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\nreal_names = [\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\nSince the for loop only accepts one list, we need to do something else to access the data in both lists. One option is to use enumerate(). Let me first show you how enumerate() works.\n\nfor count, name in enumerate(real_names):\n    print(f'{count}: {name} is a Marvel superhero!')\n\n0: Natasha Romanoff is a Marvel superhero!\n1: Tony Stark is a Marvel superhero!\n2: Stephen Strange is a Marvel superhero!\n\n\nYou can think of enumerate() as something that keeps count. In the above example, enumerate() not only gives the elements of the list, it also gives you a number (that is stored in count).\nOther than counting, we can use the count given by enumerate() to index the other list!\n\nfor index, name in enumerate(real_names):\n    superhero_name = super_names[index]\n    print(f'{name} is {superhero_name}!')\n\nNatasha Romanoff is Black Widow!\nTony Stark is Iron Man!\nStephen Strange is Doctor Strange!\n\n\nBefore we move on, I would like to highlight two things:\n\nNotice how I changed the variable name used with enumerate() to (count and index) to match their logical use. This makes it easy to iimediately see what you are doing (i.e., the intention) wiht the code. Python does not really care abot this, but remember that we write programmes for humans!\nAlthough by default, enumerate() starts counting from 0, we can easily change it to start at another value, say 100.\n\nfor count, name in enumerate(real_names, 100):\n    print(f'{count}: {name} is a Marvel superhero!')\n\n100: Natasha Romanoff is a Marvel superhero!\n101: Tony Stark is a Marvel superhero!\n102: Stephen Strange is a Marvel superhero!\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember that for can be combined with enumerate() to count while looping through a list.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/04_loops/1_loops_need.html#for-with-range",
    "href": "docs/python_basics/04_loops/1_loops_need.html#for-with-range",
    "title": "Loops (Need)",
    "section": "1.3 for with range",
    "text": "1.3 for with range\nYet, another way to achieve the result above is by using the function range(). But, first lets see what range() can do.\n\n\n\nfor i in range(5):\n    print(i)\n\n\n\nWe can use range() to get the for loop to run a given number of loops (5 in this example).\n\n\n\n0\n1\n2\n3\n4\n\n\n\n\n\n\nfor i in range(5, 10):\n    print(i)\n\n\n\nWe can tailor the starting and ending values…\n\n\n\n5\n6\n7\n8\n9\n\n\n\n\n\n\nfor i in range(1, 10, 3):\n    print(i)\n\n\n\nWe can even adjust the step size.\n\n\n\n1\n4\n7\n\n\n\n\n\n\n\nNote:\n\nFunctions like range() and enumerate() only work with looping structures.\nrange() always ends one short of the ending number.\n\nNow, let’s return to our initial problem of printing superhero names. We can use range() as follows:\n\nfor i in range(len(real_names)):\n    real_name = real_names[i]\n    super_name = super_names[i]        \n    print(f\"{real_name} is Marvel's {super_name}!\")\n\nNatasha Romanoff is Marvel's Black Widow!\nTony Stark is Marvel's Iron Man!\nStephen Strange is Marvel's Doctor Strange!\n\n\nNotice that I have used the len(real_names) to get how many times the loop should run.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that for can be run a given number of times using range().",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "4. Loops",
      "Loops (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/2_basics_good.html",
    "href": "docs/python_basics/02_basics/2_basics_good.html",
    "title": "Fundamentals (Good)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/2_basics_good.html#asking-math-questions",
    "href": "docs/python_basics/02_basics/2_basics_good.html#asking-math-questions",
    "title": "Fundamentals (Good)",
    "section": "2.1 Asking Math questions",
    "text": "2.1 Asking Math questions\n\nYou will find the following useful when asking mathematical questions:\n\n\n\n\n\n\n\n\n\nQuestion/Condition\nMath Symbol\nPython Symbols\n\n\n\n\nEquals?\n=\n==\n\n\nNot equal?\n≠\n!=\n\n\nLess than?\n&lt;\n&lt;\n\n\nGreater than?\n&gt;\n&gt;\n\n\nLess than or equal?\n≤\n&lt;=\n\n\nGreater than or equal?\n≥\n&gt;=\n\n\n\n\n\n\n\n\n\nPython also (thankfully) accepts all the following syntax:\n\n\n\n\n\n\nx &gt; 5 and x &lt; 15\n\n\n(x &gt; 5) and (x &lt; 15)\n\n\n5 &lt; x &lt; 15\n\n\n\nClearly, the last format is the neatest and easiest to read. Notice also how the brackets increase the readability of the statement.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/2_basics_good.html#the-problem",
    "href": "docs/python_basics/02_basics/2_basics_good.html#the-problem",
    "title": "Fundamentals (Good)",
    "section": "4.1 The Problem",
    "text": "4.1 The Problem\nwhen often need to compare numbers, especially for scientific work. Unfortunately, since computers have finite (hardware) resources, floating point numbers cannot be exactly stored in a computer3. This leads to errors called roundoff errors. Let me demonstrate:\nTry the following code which compares \\(0.1\\times 3\\) with \\(0.3\\).\n\na = 0.1\na3 = 0.3\na * 3 == a3\n\nFalse\n\n\nTo convince you further, let’s try printing \\(0.3\\) to 17 decimal places:\n\nf'{0.3:.17f}'\n\n'0.29999999999999999'",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/2_basics_good.html#a-solution",
    "href": "docs/python_basics/02_basics/2_basics_good.html#a-solution",
    "title": "Fundamentals (Good)",
    "section": "4.2 A solution",
    "text": "4.2 A solution\nTo get around these types of issues, you should check if the variable is close to the expected values instead of checking for equality.\n\neps = 1E-10\nabs(a * 3 - a3) &lt; eps\n\nTrue\n\n\nOr just use Numpy\n\nnp.isclose(a * 3, a3)\n\nTrue",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/2_basics_good.html#structure-of-f-strings",
    "href": "docs/python_basics/02_basics/2_basics_good.html#structure-of-f-strings",
    "title": "Fundamentals (Good)",
    "section": "5.1 Structure of f-strings",
    "text": "5.1 Structure of f-strings\nf-string formatting has the structure {X:&gt;0Y.ZW}. Here is more information about the letters X,Y,&gt;, 0,Z and W.\n\n\n\n\n\n\n\n\n\n\n\n\n\nLetter\nAction\nPossible Options\n\n\n\n\nX\nVariable to format\nCan be a number or a string\n\n\n&gt;\nAlignment\n\n&lt; (Left justified)\n&gt; (Right justified)\n^ (Centre justified)\n\n\n\n0\nUse 0’s to pad the spaces\nYou can use other characters like a space .\n\n\nY\nTotal number of characters\n\n\n\nZ\nNumber of decimal places\n\n\n\nW\nSpecifies the type of variable.\n\nf (float)\nd (integer)\ns (string)\ng (Asks Python to figure out)\n\n\n\n\n\n\n\n\n\nYou can refer to this website for more information about f-strings.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/2_basics_good.html#footnotes",
    "href": "docs/python_basics/02_basics/2_basics_good.html#footnotes",
    "title": "Fundamentals (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\ndespite the English phrase↩︎\nE.g. with an OCR table of numbers.↩︎\ndue to issues related to the precision of the IEEE 754 standard↩︎\ncalled augmented assignment↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/3_basics_nice.html",
    "href": "docs/python_basics/02_basics/3_basics_nice.html",
    "title": "Fundamentals (Nice)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/3_basics_nice.html#the-problem",
    "href": "docs/python_basics/02_basics/3_basics_nice.html#the-problem",
    "title": "Fundamentals (Nice)",
    "section": "6.1 The Problem",
    "text": "6.1 The Problem\nSince we use variables all the time, it is good to understand how they work. This is particularly true for Python because certain Python variables can be sneaky!\nWhat do you think will be printed if you run the following code? Try to predict the answers before running the code.\nx = [1, 2]\ny = x\ny.append(3)\n\nprint(f\"x: {x}, y: {y}\")",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/3_basics_nice.html#an-explanation",
    "href": "docs/python_basics/02_basics/3_basics_nice.html#an-explanation",
    "title": "Fundamentals (Nice)",
    "section": "6.2 An explanation",
    "text": "6.2 An explanation\nLet’s explore the root of this by first running the following code:\n\n'''CODE 1'''\n\n'CODE 1'\n\nx = 1\ny = 1\n\nprint(f\"x: {id(x)}, y: {id(y)}, 1: {id(1)}\")\n\nx: 140280593755848, y: 140280593755848, 1: 140280593755848\n\n\nThe above code tells us that x, y both have the same id as 1! The following figure tries to explain what is happening.\n\n\nBefore the code is run, Python has things or objects 1, 2 and a that have three properties type, value and id. For example, 1 can have the value 1, type int, and some id. a can have the value ‘a’, type str and some id.\nAfter the code is run, x and y are ‘looking at’ or bound to 1. So x and y are referred to as names that are bound to 11.\n\nNow run this code:\n\n'''CODE 2'''\n\n'CODE 2'\n\nx = 1\ny = x + 1\n\nprint(f\"x: {id(x)}, y: {id(y)}\")\n\nx: 140280593755848, y: 140280593755880\n\nprint(f\"1: {id(1)}, 2: {id(2)}\")\n\n1: 140280593755848, 2: 140280593755880\n\n\nSince the mathematical operation requires y to have the value 2, y now gets bound to object 2. This happens because the value of object 1 cannot be changed, so the binding is changed instead.\n\nObjects such as 1 whose values cannot be changed are called immutable. Other such immutable types are str(i.e., letters), float, bool.\nThere are also objects whose values can be changed. These types are called mutable and include lists and dictionaries and instances of classes. These behave differently, as highlighted in the problem above.\nHere is the code from the ‘problem’ with some explanations.\n# x is bound to a list object with a value [1 ,2]\nx = [1, 2]\n\n# y is bound to the SAME list object with a value [1 ,2]\ny = x\n\n# y is used to change the value of the object from  [1, 2] to [1, 2, 3]\ny.append(3)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/3_basics_nice.html#a-solution",
    "href": "docs/python_basics/02_basics/3_basics_nice.html#a-solution",
    "title": "Fundamentals (Nice)",
    "section": "6.3 A solution",
    "text": "6.3 A solution\nIf you really want y to have an independent copy of x, you should use:\ny = x.copy()\n\n\n\n\n\n\nMutable vs. immutable types\n\n\n\n\n\nBe very careful when you use mutable data types as variables.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/3_basics_nice.html#footnotes",
    "href": "docs/python_basics/02_basics/3_basics_nice.html#footnotes",
    "title": "Fundamentals (Nice)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThis is the basis of the, sometimes contentious, statement that there are no variables in Python↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Nice)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/1_basics_need.html",
    "href": "docs/python_basics/02_basics/1_basics_need.html",
    "title": "Fundamentals (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/1_basics_need.html#some-context",
    "href": "docs/python_basics/02_basics/1_basics_need.html#some-context",
    "title": "Fundamentals (Need)",
    "section": "10.1 Some Context",
    "text": "10.1 Some Context\nI now like to talk about an essential, super-powerful feature of Python. For this, I will use the example of doing mathematics using Python. Let’s say we want to calculate:\n\\[\n\\dfrac{1 \\times ((2-3) + 4)^{5}}{6}\n\\]\nWe can do this by:\n\n1 * ((2 - 3) + 4) ** 5 / 6\n\n40.5\n\n\nHow about \\(\\sqrt{4}\\)?\n\nsqrt(4)      # Will NOT work because \n             # basic Python is limited\n\nError in py_call_impl(callable, dots$args, dots$keywords): NameError: name 'sqrt' is not defined\n\n\nOh, dear! Python cannot calculate square roots! However, this is not a problem because we can imbue Python with newer functionality by using packages. For instance, I can give Python more math skills by using (importing) the math package.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/1_basics_need.html#importing-the-math-package",
    "href": "docs/python_basics/02_basics/1_basics_need.html#importing-the-math-package",
    "title": "Fundamentals (Need)",
    "section": "10.2 Importing the math package",
    "text": "10.2 Importing the math package\n\nimport math         # Adding(importing) the functions\n                    # of the 'math' package    \n\nNow we can use the sqrt() function of the math module.\n\nmath.sqrt(4)\n\n2.0",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/1_basics_need.html#importing-the-numpy-package",
    "href": "docs/python_basics/02_basics/1_basics_need.html#importing-the-numpy-package",
    "title": "Fundamentals (Need)",
    "section": "10.3 Importing the numpy package",
    "text": "10.3 Importing the numpy package\nmath is one of many modules that offer the sqrt() functionality. So let me also import the super useful Numpy package to use its sqrt() function.\n\nimport numpy as np    # Importing Numpy and giving \n                      # it an alias np \n                      # because I am lazy\n\nNow we can also use the sqrt() function of the Numpy module. Since I imported it with an alias (np) I can be lazy and use np instead of the longer numpy.\n\nnp.sqrt(4)\n\n2.0",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/1_basics_need.html#why-so-many-packages",
    "href": "docs/python_basics/02_basics/1_basics_need.html#why-so-many-packages",
    "title": "Fundamentals (Need)",
    "section": "10.4 Why so many packages?",
    "text": "10.4 Why so many packages?\nYou might wonder why we need multiple sqrt() functions. There are different versions because they have different capabilities and efficiencies. For example, the Numpy version can handle a list of numbers:\n\nnp.sqrt([4, 9, 16])\n\narray([2., 3., 4.])\n\n\nWe will talk a lot more about Numpy later. Before we move on, please note that you need to import packages only once(You do not have to teach Python the same thing twice!). Python will remember the functions until you restart the Python interpreter.\n\n\n\n\n\n\nRemember\n\n\n\n\nYou can give Python ‘superpowers’ by importing packages.\nYou must import a package only once.\nThere are different ways to import packages (e.g. with or without an ‘alias’).",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/02_basics/1_basics_need.html#footnotes",
    "href": "docs/python_basics/02_basics/1_basics_need.html#footnotes",
    "title": "Fundamentals (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe latest version of the interpreter is 3.12.↩︎\nExcept the keywords used in the Python language like if, for, while, is ↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "2. Fundamentals",
      "Fundamentals (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/2_plotting_good.html",
    "href": "docs/python_basics/07_plotting/2_plotting_good.html",
    "title": "Plotting (Good)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/2_plotting_good.html#sharing-axes",
    "href": "docs/python_basics/07_plotting/2_plotting_good.html#sharing-axes",
    "title": "Plotting (Good)",
    "section": "5.1 Sharing axes",
    "text": "5.1 Sharing axes\nNotice I have asked Matplotlib to make the plots more compact by sharing the \\(x\\) and \\(y\\) axes using sharex and sharey.\nLet’s first see what happens if I do not specify how to share.\n\n\n\n\n\n\nfig, ax = plt.subplots(\n    nrows=2, ncols=2,\n    figsize=(5, 5)\n)\nYou see that Matplotlib has auto-scaled both axes. In particular, the plots on the left go from 0 to 4, and those on the right go from 0 to 5, as these are the lengths I used for the lines.\n\n\n\n\n\n\nNow, let me specify how to share the axes. I can do this in three ways:\n\n\n\n\nOption\nResult\n\n\n\n\nTrue\nMakes all the axes use the same range.\n\n\ncol\nUse the same range for all the columns\n\n\nrow\nUse the same range for all the rows\n\n\n\n\nLet’s try the following:\n\n\n\n\n\n\nfig, ax = plt.subplots(\n    nrows=2, ncols=2,\n    figsize=(5, 5),\n    sharex=True, sharey='row'\n)\nNotice how all the plots have the same range for the \\(x\\)-axis.\n\n\n\n\n\n\n\n\n\n\n\n\nHowever, sharex='col' is more suited for the data we are plotting, so let’s use that instead.\nfig, ax = plt.subplots(\n    nrows=2, ncols=2,\n    figsize=(5, 5),\n    sharex='col', sharey='row'\n)\nBy the way, how you decide on the most correct depends on what story you are trying to communicate with your plot.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/2_plotting_good.html#accessing-all-axes",
    "href": "docs/python_basics/07_plotting/2_plotting_good.html#accessing-all-axes",
    "title": "Plotting (Good)",
    "section": "5.2 Accessing all axes",
    "text": "5.2 Accessing all axes\nYou will often want to apply changes to all the axes, like in the case of the grid. You can do this by\ntop_left.grid(alpha=.25)\ntop_right.grid(alpha=.25)\nbottom_left.grid(alpha=.25)\nbottom_right.grid(alpha=.25)\nBut this is inefficient and requires a lot of work. It is much nicer to use a for loop.\nfor a in ax.flatten():\n    a.grid(alpha=.25)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/2_plotting_good.html#histograms",
    "href": "docs/python_basics/07_plotting/2_plotting_good.html#histograms",
    "title": "Plotting (Good)",
    "section": "6.1 Histograms",
    "text": "6.1 Histograms\nA histogram is a valuable tool for showing distributions of data. For this example, I have extracted some actual data from sg.gov related to the mean monthly earnings of graduates from the various universities in Singapore.\n\nData\nHere are the links to my data files:\n\n\n\n\n\nMean basic monthly earnings by graduates\n\n\n\n\nAll\nsg-gov-graduate-employment-survey_basic_monthly_mean_all.csv\n\n\nNUS Only\nsg-gov-graduate-employment-survey_basic_monthly_mean_nus.csv\n\n\n\n\n\n\nA quick helper function\nI will need to read the data from these files several times. So, I will create a function called det_plot_data() that I can call. You must examine the file structure to understand the data and why I am skipping the first line.\n\nCodeData structure of the files\n\n\ndef get_plot_data():\n    data = {}\n    filename = 'sg-gov-graduate-employment-survey_basic_monthly_mean_all.csv'\n    data['All'] = np.loadtxt(filename, skiprows=1)\n\n    filename = 'sg-gov-graduate-employment-survey_basic_monthly_mean_nus.csv'\n    data['NUS'] = np.loadtxt(filename, skiprows=1)\n\n    return data\n\n\n\n\n\n\n\n\nsg-gov-graduate-employment-survey_basic_monthly_mean_all.csv\n\n\nbasic_monthly_mean\n3701\n2850\n3053\n3557\n3494\n2952\n3235\n3326\n3091\n\n\n\n\nsg-gov-graduate-employment-survey_basic_monthly_mean_nus.csv\n\n\nbasic_monthly_mean\n2741\n3057\n3098\n2960\n3404\n2740\n3065\n3350\n3933\n\n\n\n\n\n\n\n\n\n\nThe histogram\n\nFigureCode\n\n\n\n\n\n\nplt.style.use('bmh')\ndata = get_plot_data()\n\n# bins specifies how many bins to split the data\nplt.hist([data['All'], data['NUS']], bins=50, label=['All', 'NUS'])\nplt.xlabel('Mean of Basic Montly Earning (S$)')\nplt.ylabel('Number of Students')\nplt.legend()",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/2_plotting_good.html#scatter-plots",
    "href": "docs/python_basics/07_plotting/2_plotting_good.html#scatter-plots",
    "title": "Plotting (Good)",
    "section": "6.2 Scatter plots",
    "text": "6.2 Scatter plots\nScatter plots are created by putting a marker at an \\((x,y)\\) point you specify. They are simple yet powerful.\nI will be lazy and use the same data as the previous example. But, since I need some values for \\(x\\) I am going to use range() along with len() to generate a list [0,1,2...] appropriate to the dataset.\n\nFigureCode\n\n\n\n\n\n\nplt.style.use(\"seaborn-v0_8-darkgrid\")\n\ndata = get_plot_data()\n\nfor label, numbers in data.items():\n    x = range(len(numbers))\n    y = numbers\n    plt.scatter(x, y, label=label, alpha=.5)\n\nplt.xlabel('Position in the list')\nplt.ylabel('Mean of Basic Montly Eraning (S$)')\nplt.legend()",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/2_plotting_good.html#bar-charts",
    "href": "docs/python_basics/07_plotting/2_plotting_good.html#bar-charts",
    "title": "Plotting (Good)",
    "section": "6.3 Bar charts",
    "text": "6.3 Bar charts\nI am using some dummy data for a hypothetical class for this example. I extract the data and typecast to pass two lists to bar(). Use barh() if you want horizontal bars.\n\nFigureCode\n\n\n\n\n\n\nstudent_numbers = {'Life Sciences': 14,\n                   'Physics': 12,\n                   'Chemistry': 8,\n                   'Comp. Biology': 1}\nmajors = list(student_numbers.keys())\nnumbers = list(student_numbers.values())\n\nplt.style.use('ggplot')\nplt.bar(majors, numbers)\nplt.xlabel('Majors')\nplt.ylabel('Number of Students')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/2_plotting_good.html#pie-charts",
    "href": "docs/python_basics/07_plotting/2_plotting_good.html#pie-charts",
    "title": "Plotting (Good)",
    "section": "6.4 Pie charts",
    "text": "6.4 Pie charts\nI am not a big fan of pie charts, but they have their uses. Let me reuse the previous data from the dummy class.\n\nFigureCode\n\n\n\n\n\n\nstudent_numbers = {'Life Sciences': 14,\n                   'Physics': 12,\n                   'Chemistry': 8,\n                   'Comp. Biology': 1}\nmajors = list(student_numbers.keys())\nnumbers = list(student_numbers.values())\n\nplt.style.use('fivethirtyeight')\nplt.pie(numbers, \n        labels=majors,\n        autopct='%1.1f%%',   # How to format the percentages\n        startangle=-90                \n        )\nplt.title('Percentage of each major')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "Plotting (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/07_plotting/2_plotting_good_exercises.html",
    "href": "docs/python_basics/07_plotting/2_plotting_good_exercises.html",
    "title": "Plotting (Good) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1  \n\nPlotsTasksCode\n\n\nBefore\n\nAfter\n\n\n\nThe code shown in the Code tab generates the ‘Before’ figure shown in the Plots tab.\nYour task is to modify this code to end with the ‘After’ figure in jpg format.\nHere are some things to get you started:\n\nRemove the text ‘I am..’\nChange the colours used for filling.\nChange the limits of the filled areas.\nAdd titles to each subplot.\nShare the x axis across columns.\nAdd/Remove labels to the x-axis.\nMake the tick labels of the two bottom plots the same.\nAdd grids to all subplots.\nAdd a legend to all subplots in the upper right position.\nUse tight_layout() to improve the figure.\nSave the figure as a jpg file.\n\nYou might want to view the images in their full resolution by opening them in another tab.\n\n\n\n#--------- Generate cosine and sine values --------#\nx = np.linspace(-np.pi, np.pi, num=100, endpoint=True)\ncos_x = np.cos(x)\nsin_x = np.sin(x)\nfun1_x = np.exp(-x) * np.cos(5 * x)\nfun2_x = np.exp(-x) * np.sin(2 * x)\n\n#------- Plot the data -------#\nfig, axes = plt.subplots(nrows=2, ncols=2,\n                         figsize=(12, 8),  sharey='row')\n\n#------- Subplot 1 -------#\naxes[0, 0].plot(x, cos_x, color='r', label='$\\cos x$')\naxes[0, 0].plot(x, cos_x**2, color='r',\n                linestyle=':', label='$\\cos^2 x$')\naxes[0, 0].set_title('$\\cos x$ & $\\cos^2x$')\naxes[0, 0].set_ylabel('Cosine Value')\naxes[0, 0].fill_between(x, cos_x, -1, color='g', alpha=.125)\naxes[0, 0].set_xlabel('Angle (radians)')\naxes[0, 0].text(0, 0, 'I am [0, 0]!', fontsize=30,\n                horizontalalignment='center')\n\n#------- Subplot 2 -------#\naxes[0, 1].plot(x, sin_x, color='g', label='$\\sin x$')\naxes[0, 1].fill_between(x, cos_x, -2, color='r', alpha=.125)\naxes[0, 1].plot(x, sin_x**2, label='$\\sin^2 x$')\naxes[0, 1].set_ylabel('Cosine Value')\naxes[0, 1].set_ylim(-1.25, 1.25)\naxes[0, 1].legend(loc='lower right', frameon=False)\naxes[0, 1].text(0, 0, 'I am [0, 1]!', fontsize=30,\n                horizontalalignment='center')\n\n#------- Subplot 3 -------#\naxes[1, 0].plot(x, fun1_x, color='b', label='$e^{-x}\\cos 5x$')\naxes[1, 0].fill_between(x, fun1_x, 0, color='b', alpha=.125)\naxes[1, 0].set_title('$e^{-x}\\cos 5x$')\naxes[1, 0].set_xlabel('Angle (radians)')\naxes[1, 0].set_ylabel('Cosine Value')\naxes[1, 0].set_xticks([-np.pi, -np.pi / 2, 0, np.pi / 2, np.pi])\naxes[1, 0].set_xticklabels(['$-\\pi$', '$-\\pi/2$', '0', '$\\pi/2$', '$\\pi$'])\naxes[1, 0].legend()\naxes[1, 0].text(0, 0, 'I am [1, 0]!', fontsize=30,\n                horizontalalignment='center')\n\n#------- Subplot 4 -------#\naxes[1, 1].plot(x, fun2_x, color='y', label='$e^{-x}\\sin 2x$')\naxes[1, 1].set_title('$e^{-x}\\sin 2x$')\naxes[1, 1].fill_between(x, fun2_x, 10, color='y', alpha=.125)\naxes[1, 1].set_xticks([-np.pi, -np.pi / 2, 0, np.pi / 2, np.pi])\naxes[1, 1].legend()\naxes[1, 1].text(0, 0, 'I am [1, 1]!', fontsize=30,\n                horizontalalignment='center')\n\n# 'flatten', 'opens' the 2D array into a simple 1D array\nfor a in axes.flatten():\n    a.grid(alpha=.5)\n\n# plt.tight_layout()\nplt.show(block=False)\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "7. Plotting",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/06_this-n-that/1_os_need_exercises.html",
    "href": "docs/python_basics/06_this-n-that/1_os_need_exercises.html",
    "title": "Files, Folders & OS (Need) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (Tidying a collaboration) ☻\n\nThe scenarioTask 1Task 2Task 3Task 4Task 5Task 6Task 7\n\n\nYou are a member of an international team analysing environmental pollution. The project involves ten cities: Cairo, Dhaka, Jakarta, Karachi, Manila, Melbourne, Osaka, Shanghai, Singapore, and Tokyo.\n\nYour task is to process and organise data from various environmental measurements. The provided zip file, os-collaboration-exercise-data.zip, contains all relevant data files for the past year.\nThings to note\n\nData Files: Each data file is named in the format month-date_city.txt (e.g., may-10_singapore.txt).\nData Collection: Data was recorded sporadically; not all days of each month have corresponding data files. The dates of data collection vary across the cities.\nExclusion of Files: Ignore any non-text files, such as those in .pdf, .png, or .jpg formats.\n\n\n\n\nWe like to convert the filename to a more useful numerical format. Specifically, we want to convert month-date-city.txt. (i.e. may-10-singapore.txt) to a mm-dd-city.txt (i.e. 05-10-singapore.txt) format.\nUsing the following dictionary (or otherwise), write a snippet of Python code to convert 'oct-08_singapore.txt' to 10-08-singapore.txt.\n{\n'jan': '01', 'feb': '02', 'mar': '03',\n'apr': '04', 'may': '05', 'jun': '06',\n'jul': '07', 'aug': '08', 'sep': '09',\n'oct': '10', 'nov': '11', 'dec': '12'\n}\n\n\n\n\nIncorporate your previous code into a function named rename_my_file(old_file_name) that accepts the old filename as the argument and returns the new file name.\n\n\n\n\nUse a for loop to apply the function rename_my_file() to the file list below.\n['oct-08_singapore.txt', 'jul-10_cairo.txt', 'may-15_dhaka.txt',\n 'may-13_cairo.txt', 'oct-21_cairo.txt', 'jan-10_singapore.txt',\n 'jun-20_tokyo.txt', 'aug-06_jakarta.txt', 'dec-21_karachi.txt',\n 'jan-01_tokyo.txt']\nPrint out your progress in the form old-file-name ----&gt; new-file-name\n\n\n\n\nWith the help of glob, use rename_my_file() to rename all the .txt files in the folder.\nNote that you might have to adjust your function rename_my_file() to accommodate the already renamed files.\n\n\n\n\nUse a for loop to create a folder for each city.The list of cities is provided below for your convenience.\n['Cairo', 'Dhaka', 'Jakarta', 'Karachi', 'Manila',\n 'Melbourne', 'Osaka', 'Shanghai', 'Singapore', 'Tokyo']\n\n\n\n\nUse glob to list all the files from Cairo.\nNow use a for loop and shutil.copy() to copy all the files related to Cairo to the corresponding folder you created.\n\n\n\n\nTweak your code to move all the files to the corresponding folders of all the cities.\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "6. OS",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good.html",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good.html",
    "title": "Storing Data (Good)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good.html#lists-arrays-in-1d-subsetting-indexing",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good.html#lists-arrays-in-1d-subsetting-indexing",
    "title": "Storing Data (Good)",
    "section": "1.1 Lists & Arrays in 1D | Subsetting & Indexing",
    "text": "1.1 Lists & Arrays in 1D | Subsetting & Indexing\nSince slicing gives us a range of elements, we must specify two indices to indicate where to start and end. The various syntaxes for these are shown in the table below.\nThe following applies to both lists and arrays.\n\npy_list=[\"a1\", \"b2\", \"c3\", \"d4\", \"e5\",\n         \"f6\", \"g7\", \"h8\", \"i9\", \"j10\"]\nnp_array=np.array(py_list)\n\n# Pick one\nx = py_list  # OR\nx = np_array\n\n\n\n\n\n\n\n\n\n\nSyntax\nResult\n\nNote\n\n\n\n\nx[0]\nFirst element\n'a1'\n\n\n\nx[-1]\nLast element\n'j10'\n\n\n\nx[0:3]\nIndex 0 to 2\n['a1','b2','c3']\nGives \\(3−0=3\\) elements\n\n\nx[1:6]\nIndex 1 to 5\n['b2','c3','d4','e5','f6']\nGives \\(6−1=5\\) elements\n\n\nx[1:6:2]\nIndex 1 to 5 in steps of 2\n['b2','d4','f6']\nGives every other of \\(6−1=5\\) elements\n\n\nx[5:]\nIndex 5 to the end\n['f6','g7','h8','i9','j10']\nGives len(x)\\(−5=5\\) elements\n\n\nx[:5]\nIndex 0 to 5\n['a1','b2','c3','d4','e5']\nGives \\(5−0=5\\) elements\n\n\nx[5:2:-1]\nIndex 5 to 3 (i.e., in reverse)\n['f6','e5','d4']\nGives \\(5−2=3\\) elements\n\n\nx[::-1]\nReverses the list\n['j10','i9','h8',...,'b2','a1']\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember slicing in Python can be a bit tricky.If you slice with [i:j], the slice will start at i and end at j-1, giving you a total of j-i elements.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good.html#arrays-only-subsetting-by-masking",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good.html#arrays-only-subsetting-by-masking",
    "title": "Storing Data (Good)",
    "section": "1.2 Arrays only | Subsetting by masking",
    "text": "1.2 Arrays only | Subsetting by masking\nOne of the most powerful things you can do with NumPy arrays is subsetting by masking. To make sense of this, consider the following.\n\nnp_array = np.array([1, 2, 3, 4, 5, 6, 7, 8, 9, 10])\nmy_mask = np_array &gt; 3\nmy_mask\n\narray([False, False, False,  True,  True,  True,  True,  True,  True,\n        True])\n\n\nThe answer to my question is in the form of a ‘Yes’/‘No’ or True/False format. I can use this True/False format to ask NumPy to show me only those that are True by\n\nnp_array[my_mask]\n\narray([ 4,  5,  6,  7,  8,  9, 10])\n\n\nThis is why I used the term ‘masking’. The True/False answer acts like a mask allowing only the True subset to be seen.\n\n\n\n\n\n\nRemember\n\n\n\nRemember that subsetting by masking only works with NumPy arrays.\n\n\nInstead of creating another variable, I can also do all of this succinctly as:\n\nnp_array[np_array &gt; 3]\n\narray([ 4,  5,  6,  7,  8,  9, 10])\n\n\nLet me show you a few more quick examples\n\n\n\nnp_array[~(np_array &gt; 3)]                 # '~' means 'NOT'\n\n\n\nWe can invert our mask by using the ~.~ is called the Bitwise Not operator.\n\n\n\narray([1, 2, 3])\n\n\n\n\n\n\nnp_array[(np_array &gt; 3) & (np_array &lt; 8)] # '&' means 'AND'\n\n\n\nWe can combine one mask AND another mask.(AND will show something only if both masks are true.)\n\n\n\narray([4, 5, 6, 7])\n\n\n\n\n\n\nnp_array[(np_array &lt; 3) | (np_array &gt; 8)] # '|' means 'OR'\n\n\n\nWe can combine one mask OR another mask.(OR will show something if either mask is true.)\n\n\n\narray([ 1,  2,  9, 10])\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember:\n\nAlways use the Bitwise NOT(~), Bitwise OR(|) and Bitwise AND(&) when combining masks with NumPy.\nAlways use brackets to clarify what you are asking the mask to do.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good.html#lists-arrays-in-2d-indexing-slicing",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good.html#lists-arrays-in-2d-indexing-slicing",
    "title": "Storing Data (Good)",
    "section": "1.3 Lists & Arrays in 2D | Indexing & Slicing",
    "text": "1.3 Lists & Arrays in 2D | Indexing & Slicing\nThe differences between lists and arrays become even more apparent with higher dimensional lists and arrays. Especially when you try indexing and slicing in higher dimensions.\nLet’s consider the following 2D list.\n\npy_list_2d = [[1, \"A\"], [2, \"B\"], [3, \"C\"], [4, \"D\"],\n              [5, \"E\"], [6, \"F\"], [7, \"G\"], [8, \"H\"],\n              [9, \"I\"], [10, \"J\"]]\n\nnp_array_2d = np.array(py_list_2d)\n\n\n\n\nWhat is at position 4 (index 3)?\npy_list_2d[3]\nnp_array_2d[3]\n\n\n\n\n[4, 'D']\n\n\n\n\narray(['4', 'D'], dtype='&lt;U21')\n\n\n\n\n\n\nWhat is the FIRST element at position 4 (index 3)\npy_list_2d[3][0]\nnp_array_2d[3, 0]\n\n\n\n\n4\n\n\n\n\n\n'4'\n\n\nNotice how the syntax for arrays uses just a single pair of square brackets ([ ]).\n\n\n\n\n\nWhat are the first three elements?\npy_list_2d[:3]\nnp_array_2d[:3]\n\n\n\n\n[[1, 'A'], [2, 'B'], [3, 'C']]\n\n\n\n\narray([['1', 'A'],\n       ['2', 'B'],\n       ['3', 'C']], dtype='&lt;U21')\n\n\n\n\n\n\nHmmm…\npy_list_2d[:3][0]\nnp_array_2d[:3, 0]\n\n\n\n\n\n[1, 'A']\n\n\nYou might think that this will yield the first elements (i.e., [1, 2, 3]) of all the sub-lists up to index 2.No! Instead, it gives the first of the list you get from py_list_2d[:3].\n\n\n\n\narray(['1', '2', '3'], dtype='&lt;U21')\n\n\nNotice how differently NumPy arrays work.\n\n\n\n\n\npy_list_2d[3:6][0]\nnp_array_2d[3:6, 0]\nnp_array_2d[:, 0]\n\n\n\n\n\n[4, 'D']\n\n\n\n\n\n\narray(['4', '5', '6'], dtype='&lt;U21')\n\n\nIf you want ‘everything’ you just use :.\n\n\narray(['1', '2', '3', '4', '5', '6', '7', '8', '9', '10'], dtype='&lt;U21')",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good.html#growing-lists",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good.html#growing-lists",
    "title": "Storing Data (Good)",
    "section": "1.4 Growing lists",
    "text": "1.4 Growing lists\nNumPy arrays are invaluable, and their slicing syntax (e.g. [:3,0]) is more intuitive than lists. So, why do we even bother with lists? One advantage of lists is their ease and efficiency in growing. NumPy arrays are fantastic for fast math operations, provided you do not change their size1. So, I will not discuss how to change the size of a NumPy array. Instead, let me show you how to grow a list. This will be useful later; for instance when you try to solve differential equations numerically.\n\n\n\nCreating a larger list from a smaller one.\n\nx=[1, 2]*5\nx\n\n[1, 2, 1, 2, 1, 2, 1, 2, 1, 2]\n\n\n\n\nThree ways to grow a list by appending one element at a time.\nx=[1]\nx= x + [2]\nx= x + [3]\nx= x + [4]\nx\nx=[1]\nx+= [2]\nx+= [3]\nx+= [4]\nx\nx=[1]\nx.append(2)\nx.append(3)\nx.append(4)\nx\n\n\n\n\n[1, 2, 3, 4]\n\n\n\n\n[1, 2, 3, 4]\n\n\n\n\n[1, 2, 3, 4]\n\n\n\n\nIf you are wondering, there are differences between these three versions. Their execution speeds are different; the version with append() runs about 1.5 times faster than the rest!\n\n\nHere are three ways of incorporating multiple elements.Notice the difference between the effects of extend() and append().\nx = [1, 2, 3]\nx += [4, 5, 6]\nx\nx=[1, 2, 3]\nx.extend([4, 5, 6])\nx\nx=[1, 2, 3]\nx.append([4, 5, 6])\nx\n\n\n\n\n[1, 2, 3, 4, 5, 6]\n\n\n\n\n[1, 2, 3, 4, 5, 6]\n\n\n\n\n[1, 2, 3, [4, 5, 6]]",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good.html#tuples",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good.html#tuples",
    "title": "Storing Data (Good)",
    "section": "1.5 Tuples",
    "text": "1.5 Tuples\nBefore we end this section, I must introduce you to another data storage structure called a tuple. Tuples are similar to lists, except they use ( ) and cannot be changed after creation (i.e., they are immutable).\nLet me first create a simple tuple.\n\na=(1, 2, 3)     # Define tuple\n\nWe can access its data…\n\nprint(a[0])    # Access data\n\n1\n\n\nBut, we cannot change the data.\n# The following will NOT work\na[0]=-1\na[0]+= [10]",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good.html#be-very-careful-when-copying",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good.html#be-very-careful-when-copying",
    "title": "Storing Data (Good)",
    "section": "1.6 Be VERY careful when copying",
    "text": "1.6 Be VERY careful when copying\nVariables in Python have subtle features that might make your life miserable if you are not careful. You should be particularly mindful when making copies of lists and arrays.\nFor example, if you want to copy a list, you might be tempted to do the following; PLEASE DON’T!\nx=[1, 2, 3]\ny=x           # DON'T do this!\nz=x           # DON'T do this!\nThe correct way to do this is as follows:\nx=[1, 2, 3]\ny=x.copy()\nz=x.copy()\nNote: At this stage, you only have to know that you must use copy() to be safe; you do not have to understand why. However, if you want to, please refer to the discussion on mutable and immutable objects.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/2_storing-data_good.html#footnotes",
    "href": "docs/python_basics/03_storing-data/2_storing-data_good.html#footnotes",
    "title": "Storing Data (Good)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nThe gains in speed are due to NumPy doing things to all the elements in the array in one go. For this, the data needs to be stored in a specific order in memory. Adding or removing elements hinders this optimization. When you change the size of a NumPy array, NumPy destroys the existing array and creates a new one, making it extremely inefficient.↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html",
    "title": "Storing Data (Need)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#lets-compare",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#lets-compare",
    "title": "Storing Data (Need)",
    "section": "1.1 Let’s compare",
    "text": "1.1 Let’s compare\nLet me show you how to store the same information (in this case, some superhero data) using lists, arrays and dictionaries.\nPython Lists\n\npy_super_names = [\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\npy_real_names = [\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\nNumpy Arrays\n\nnp_super_names = np.array([\"Black Widow\", \"Iron Man\", \"Doctor Strange\"])\nnp_real_names = np.array([\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"])\n\nDictionary\n\nsuperhero_info = {\n    \"Natasha Romanoff\": \"Black Widow\",\n    \"Tony Stark\": \"Iron Man\",\n    \"Stephen Strange\": \"Doctor Strange\"\n}\n\nNotice:\n\nDictionaries use a key and an associated value separated by a :\nThe dictionary very elegantly holds the real and superhero names in one structure while we need two lists (or arrays) for the same data.\nFor lists and arrays, the order matters. I.e. ‘Iron Man’ must be in the same position as ‘Tony Stark’ for things to work.\n\nLists (and arrays) offer many features that dictionaries don’t and vice versa. I will demonstrate these in a bit. Which data storage strategy to choose will depend on the problem you are trying to solve. More on this later; for the moment…\n\n\n\n\n\n\nRemember\n\n\n\nThere are three basic ways of storing data:\n\nlists,\nNumPy arrays and\ndictionaries.\n\n\n\nBy the way,\n\nI added py and np in front of the variable for clarity. You can choose any name for the variables (provided that they are not a Python keyword like for, if).\nI am being lazy; when I say ‘arrays’, I mean ‘NumPy arrays’, and when I say ‘lists’, I mean ‘Python lists’.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#accessing-data-from-a-list-or-array",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#accessing-data-from-a-list-or-array",
    "title": "Storing Data (Need)",
    "section": "1.2 Accessing data from a list (or array)",
    "text": "1.2 Accessing data from a list (or array)\nTo access data from lists (and arrays), we need to use an index corresponding to the data’s position. Python is a zero-indexed language, meaning it starts counting at 0. So if you want to access a particular element in the list (or array), you need to specify the relevant index starting from zero. The image below shows the relationship between the position and index.\n\n\n\n\n\n\npy_super_names = [\"Black Widow\", \"Iron Man\", \"Doctor Strange\"]\npy_real_names = [\"Natasha Romanoff\", \"Tony Stark\", \"Stephen Strange\"]\n\n\n\n\n\npy_real_names[0]\n\n'Natasha Romanoff'\n\n\n\n\n\npy_super_names[0]\n\n'Black Widow'\n\n\n\n\nUsing a negative index allows us to count from the back of the list. For instance, using the index -1 will give the last element. This is super useful because we can easily access the last element without knowing the list size.\n\npy_super_names[2]    # Forward indexing \n                     # We need to know the size \n                     # beforehand for this to work.\n\n'Doctor Strange'\n\npy_super_names[-1]   # Reverse indexing\n\n'Doctor Strange'\n\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\nData in lists (and arrays) must be accessed using a zero-based index.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#accessing-data-from-a-dictionary",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#accessing-data-from-a-dictionary",
    "title": "Storing Data (Need)",
    "section": "1.3 Accessing data from a dictionary",
    "text": "1.3 Accessing data from a dictionary\nDictionaries hold data (values) paired with a key. i.e. you can access the value (in this case, the superhero name) using the real name as a key. Here is how it works:\n\nsuperhero_info = {\n    \"Natasha Romanoff\": \"Black Widow\",\n    \"Tony Stark\": \"Iron Man\",\n    \"Stephen Strange\": \"Doctor Strange\"\n}                  \n\n\nsuperhero_info[\"Natasha Romanoff\"]\n\n'Black Widow'\n\n\n\n\n\n\n\n\nRemember\n\n\n\nRemember that dictionaries have a key-value structure.\n\n\nIf you want, you can access all the keys and all the values as follows:\n\nsuperhero_info.keys()\n\ndict_keys(['Natasha Romanoff', 'Tony Stark', 'Stephen Strange'])\n\n\n\nsuperhero_info.values()\n\ndict_values(['Black Widow', 'Iron Man', 'Doctor Strange'])",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#higher-dimensional-lists",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#higher-dimensional-lists",
    "title": "Storing Data (Need)",
    "section": "1.4 Higher dimensional lists",
    "text": "1.4 Higher dimensional lists\nUnlike with a dictionary, we needed two lists to store the corresponding real and superhero names. An obvious way around the need to have two lists is to have a 2D list (or array) as follows.\npy_superhero_info = [['Natasha Romanoff', 'Black Widow'],\n                     ['Tony Stark', 'Iron Man'],\n                     ['Stephen Strange', 'Doctor Strange']]",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#size",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#size",
    "title": "Storing Data (Need)",
    "section": "2.1 Size",
    "text": "2.1 Size\nOften, you need to know how many elements there are in lists or arrays. We can use the len() function for this purpose for both lists and arrays. However, arrays also offer other options.\n\npy_list_2d = [[1, \"A\"], [2, \"B\"], [3, \"C\"], [4, \"D\"],\n              [5, \"E\"], [6, \"F\"], [7, \"G\"], [8, \"H\"],\n              [9, \"I\"], [10, \"J\"]]\n\nnp_array_2d = np.array(py_list_2d)      # Reusing the Python list \n                                        # to create a NEW\n                                        # NumPy array\n\nlen(py_list_2d)\nlen(np_array_2d)\nnp_array_2d.shape\n\n\n\nLists\n\n\n10\n\n\n\n\nArrays\n\n\n10\n\n\n\n\n(10, 2)\n\n\nNotice the absence of brackets ( ) in shape above. This is because shape is not a function. Instead, it is a property or attribute of the NumPy array.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#arrays-are-fussy-about-type",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#arrays-are-fussy-about-type",
    "title": "Storing Data (Need)",
    "section": "2.2 Arrays are fussy about type",
    "text": "2.2 Arrays are fussy about type\nPlease recall the previous discussion about data types (e.g., int, float, str). One prominent difference between lists and arrays is that arrays insist on having only a single data type; lists are more accommodating. Consider the following example and notice how the numbers are converted to English (' ') when we create the NumPy array.\n\npy_list = [1, 1.5, 'A']\nnp_array = np.array(py_list)\n\npy_list\nnp_array\n\n\n\nLists\n\n\n[1, 1.5, 'A']\n\n\n\n\nArrays\n\n\narray(['1', '1.5', 'A'], dtype='&lt;U32')\n\n\n\n\n\nWhen dealing with datasets with both numbers and text, you must be mindful of this restriction. However, this is just an annoyance and not a problem as we can easily change type (typecast) using the ‘hidden’ function astypes(). More about this in a later chapter. For the moment,\n\n\n\n\n\n\nRemember\n\n\n\nRemember that NumPy arrays tolerate only a single type.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#adding-a-number",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#adding-a-number",
    "title": "Storing Data (Need)",
    "section": "2.3 Adding a number",
    "text": "2.3 Adding a number\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)         # Reusing the Python list\n                                     # to create a NEW\n                                     # NumPy array\n\nnp_array + 10\n\n\n\nLists\npy_list + 10        # Won't work!\n\n\nArrays\n\n\narray([11, 12, 13, 14, 15])",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#adding-another-list",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#adding-another-list",
    "title": "Storing Data (Need)",
    "section": "2.4 Adding another list",
    "text": "2.4 Adding another list\n\npy_list_1 = [1, 2, 3, 4, 5]\npy_list_2 = [10, 20, 30, 40, 50]\n\nnp_array_1 = np.array(py_list_1)\nnp_array_2 = np.array(py_list_2)\n\npy_list_1 + py_list_2\nnp_array_1 + np_array_2\n\n\n\nLists\n\n\n[1, 2, 3, 4, 5, 10, 20, 30, 40, 50]\n\n\n\n\nArrays\n\n\narray([11, 22, 33, 44, 55])\n\n\n\n\n\nSo, adding lists causes them to grow while adding arrays is an element-wise operation.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#multiplying-by-a-number",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#multiplying-by-a-number",
    "title": "Storing Data (Need)",
    "section": "2.5 Multiplying by a Number",
    "text": "2.5 Multiplying by a Number\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)         \n\npy_list*2\nnp_array*2\n\n\n\nLists\n\n\n[1, 2, 3, 4, 5, 1, 2, 3, 4, 5]\n\n\n\n\nArrays\n\n\narray([ 2,  4,  6,  8, 10])\n\n\n\n\n\nSo multiplying by a number makes a list grow, whereas an array multiplies its elements by the number!",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#squaring",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#squaring",
    "title": "Storing Data (Need)",
    "section": "2.6 Squaring",
    "text": "2.6 Squaring\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)\n\nnp_array**2\n\n\n\nLists\npy_list**2                      # Won't work!  \n\n\nArrays\n\n\narray([ 1,  4,  9, 16, 25])",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#asking-questions",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#asking-questions",
    "title": "Storing Data (Need)",
    "section": "2.7 Asking questions",
    "text": "2.7 Asking questions\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)         \n\npy_list == 3     # Works, but what IS the question?\nnp_array == 3  \nnp_array &gt; 3  \n\n\n\nLists\n\n\n\n\n\nFalse\n\n\n\n\npy_list &gt; 3      # Won't work!\n\n\n\n\n\nArrays\n\n\n\n\n\narray([False, False,  True, False, False])\n\n\n\n\n\n\narray([False, False, False,  True,  True])",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#mathematics",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#mathematics",
    "title": "Storing Data (Need)",
    "section": "2.8 Mathematics",
    "text": "2.8 Mathematics\n\npy_list = [1, 2, 3, 4, 5]\nnp_array = np.array(py_list)         \n\nsum(py_list)     # sum() is a base Python function\nmax(py_list)     # max() is a base Python function\nmin(py_list)     # min() is a base Python function\nnp_array.sum()\nnp_array.max()\nnp_array.min()\nnp_array.mean()\nnp_array.std()\n\n\n\nLists\n\n\n\n\n\n15\n\n\n\n\n\n\n5\n\n\n\n\n\n\n1\n\n\n\n\npy_list.sum()   # Won't work!\n\n\n\n\n\nArrays\n\n\n\n\n\n15\n\n\n\n\n\n\n5\n\n\n\n\n\n\n1\n\n\n\n\n\n\n3.0\n\n\n\n\n\n\n1.4142135623730951\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRemember\n\n\n\n(roughly speaking) an operation on a list works on the whole list. In contrast, an operation on an array works on the individual elements of the array.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/03_storing-data/1_storing-data_need.html#footnotes",
    "href": "docs/python_basics/03_storing-data/1_storing-data_need.html#footnotes",
    "title": "Storing Data (Need)",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nFor example, think of how easy it is to do row or column manipulations of data when put into a spreadsheet format↩︎",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "3. Storing Data",
      "Storing Data (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/1_functions_need_exercises.html",
    "href": "docs/python_basics/05_functions/1_functions_need_exercises.html",
    "title": "Functions (Need) Exercises",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)\n\n\n\nExercise 1 (Do you know why?) ☻\nThe following code works as expected despite not having an else statement. Please use a Markdown cell to explain why?\ndef greeting(name):\n    if name == 'Batman':\n        return 'Hello Batman! So, nice to meet you!'\n    return f'Hello {name}!'\n\n\nExercise 2 (Chubby or not) ☻\nWrite a Python function named calculate_bmi.\n\nThe function should take two parameters:\nweight (in kilograms) and height (in meters).\nThe function should calculate the BMI (Body Mass Index) using the formula BMI = weight / (height ** 2).\nBased on the calculated BMI, the function should return a string indicating the BMI category based on the following criteria:\n\n\n\n\n\nCategory\nBMI Range\n\n\n\n\nUnderweight\nBMI less than 18.5\n\n\nNormal weight\nBMI between 18.5 and 24.9\n\n\nOverweight\nBMI between 25 and 29.9\n\n\nObesity\nBMI 30 or more\n\n\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "![](exerise_icon.png){.exercise-icon-in-toc}Exercise (Need)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good.html",
    "href": "docs/python_basics/05_functions/2_functions_good.html",
    "title": "Functions (Good)",
    "section": "",
    "text": "# | include: false\nimport numpy as np\nimport pandas as pd\n\nnp.random.seed(256852)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good.html#assert",
    "href": "docs/python_basics/05_functions/2_functions_good.html#assert",
    "title": "Functions (Good)",
    "section": "1.1 assert",
    "text": "1.1 assert\nPython has a command called assert that can check a condition and halt execution if necessary. It also gives the option of printing a message.\nThe basic syntax is as follows:\nassert condition-to-check, message\nassert stops the flow if the condition fails. Here is an example.\nassert x &gt;= 0, \"x is becoming negative!\"\nThe program will run for as long as the condition is True. If it fails, then an AssertationError is raised, and the program stops running!\n\n\n\n\n\n\nThe following will run without a problem.\nx = 10\nassert x &gt;= 0, \"x is becoming negative!\"\n\n\nThe following will throw an error and stop.\nx = -1\nassert x &gt;= 0, \"x is becoming negative!\"",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good.html#try-except",
    "href": "docs/python_basics/05_functions/2_functions_good.html#try-except",
    "title": "Functions (Good)",
    "section": "1.2 try-except",
    "text": "1.2 try-except\nA technical name for things going wrong is exceptions. For example, division by zero will raise a ZeroDivisionError. An exception left unhandled will halt the flow of the programme. However, if you are a control freak, Python offers an (absurdly) simple ‘try-except’ structure to catch and handle these exceptions yourself.\nThe try-except syntax can also ensure that your programme can handle some situations beyond your control. For example, when I use Python to speak to the Canvas server, I use try-except to handle situations when the server does not respond.\nLet me show you how to use the try-except flow control statement.\nWe can solicit a user response using the input() function. Let’s say we do this and ask for a number, as shown in the snippet below.\nnumber=input(\"Give me a number and I will calculate its square.\")\nsquare=int(number)**2              # Convert English to number\nprint(f'The square of {number} is {square}!')\nThis will work fine if the typecasting int(number) makes sense. What if the input is not a number but something else like ‘hahaha’?\nLet’s use the try-except to get around this problem.\ntry:\n    number=input(\"Give me a number and I will calculate its square.\")\n    square=int(number)**2\n    print(f'The square of {number} is {square}!')\nexcept:\n    print(f\"Oh oh! I cannot square {number}!\")\nNotice how I have enclosed (and protected) that part of the code that we think can potentially lead to trouble in the try block. If something (anything) goes wrong, Python will ignore the error and run the code in the except block.\nYou can have more control over how the expetions are handled with a try-except block. However, we do not have to worry about that at this point.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good.html#a-simple-suggestion",
    "href": "docs/python_basics/05_functions/2_functions_good.html#a-simple-suggestion",
    "title": "Functions (Good)",
    "section": "1.3 A simple suggestion",
    "text": "1.3 A simple suggestion\nWhen starting out with some code, it is always good for your code to signal to the outside world that it has finished certain milestones. A ‘soft’ way to do this is to include ‘print()’ statements here and there to let the outside world know what is happening in the innards of your program. Otherwise, you will stare at a blank cell, wondering what is happening.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good.html#positional-keyword-and-default-arguments",
    "href": "docs/python_basics/05_functions/2_functions_good.html#positional-keyword-and-default-arguments",
    "title": "Functions (Good)",
    "section": "2.1 Positional, keyword and default arguments",
    "text": "2.1 Positional, keyword and default arguments\nIn the past chapter, some of you may have noticed that I was (carelessly) switching between passing two styles of passing arguments to the function greeting(). I wrote greeting('Super Man') or greeting(name='Super Man'). We need to talk a bit more about this so that you are not bewildered when you see other people’s code.\nThere are three ‘ways’ to pass a value to an argument. I will call them positional, keyword or default. To make this clearer, consider the following function.\n\ndef side_by_side(a, b, c=42):\n    return f'{a: 2d}|{b: 2d}|{c: 2d}'\n\nHere are three ways I can use this function.\n\n\n\n\n\n\nPositional\nside_by_side(1, 2, 3)\nHere, I am telling Python to assign 1, 2, 3 to a, b, c using the positional order of the arguments.\n\n\nKeywords\nside_by_side(c=3, b=1, a=2)\nHere, I explicitly specify the keyword to assign the values to each of a, b, c. (No, the order does not matter)\n\n\nDefault\nside_by_side(1, b=2)\nHere, since c is optional, I can choose not to specify it (of course, provided I want c to be 1).\n\n\n\nBelow are some examples of how you can combine these three styles. However, one style (keyword followed by positional) confuses Python and won’t work.\n\nside_by_side(1, 2)           # Two positional, 1 default\n## ' 1| 2| 42'\nside_by_side(1, 2, 3)        # Three positional\n## ' 1| 2| 3'\nside_by_side(a=1, b=2)       # Two keyword, 1 default\n## ' 1| 2| 42'\nside_by_side(c=3, b=1, a=2)  # Three keyword\n## ' 2| 1| 3'\nside_by_side(1, c=3, b=2)    # One positional, 2 keyword\n## ' 1| 2| 3'\nside_by_side(1, b=2)         # One positional, 1 keyword, 1 default\n## ' 1| 2| 42'\n\nLet me reiterate that the following will not work because Python cannot unambiguously determine the position of 1?\n# Keywords cannot be followed \n# by positional arguments\nside_by_side(a=2, 1)      # Won't work.",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good.html#docstrings",
    "href": "docs/python_basics/05_functions/2_functions_good.html#docstrings",
    "title": "Functions (Good)",
    "section": "2.2 Docstrings",
    "text": "2.2 Docstrings\nPython has a docstring feature that allows us to document what a function does inside the function. This documentation (i.e., the docstring) is displayed when we ask Python to show us the help info using help().\nHere is a simple example.\n\ndef side_by_side(a, b, c=42):\n    '''\n    A test function to demonstrate how \n    positional, keyword and default arguments \n    work.\n    '''\n    return f'{a: 2d}|{b: 2d}|{c: 2d}'\n\nA docstring needs to be sandwiched between a pair of ''' (or \"\"\") and can span multiple lines.\nLet’s see if it works by asking for help.\n\nhelp(side_by_side)\n\nHelp on function side_by_side in module __main__:\n\nside_by_side(a, b, c=42)\n    A test function to demonstrate how \n    positional, keyword and default arguments \n    work.\n\n\nDocstrings can be used for writing multiline comments, but the practice is frowned upon by Puritans; so if you misuse it be ready for their ire!",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good.html#function-are-first-class-citizens",
    "href": "docs/python_basics/05_functions/2_functions_good.html#function-are-first-class-citizens",
    "title": "Functions (Good)",
    "section": "2.3 Function are first-class citizens",
    "text": "2.3 Function are first-class citizens\nPython functions are called first-class citizens because they have the same privileges as variables. This opens up useful possibilities for scientific programming because we can pass a function as an argument to another function!\nConsider this:\n\ndef my_function(angle, trig_function):\n        return trig_function(angle)\n\n# Let's use the function\nmy_function(np.pi/2, np.sin)        \n## 1.0\nmy_function(np.pi/2, np.cos)        \n## 6.123233995736766e-17\nmy_function(np.pi/2, lambda x: np.cos(2*x))  \n## -1.0\n\nNote: When we pass a function as an argument, we do not include the parenthesis ().",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Good)"
    ]
  },
  {
    "objectID": "docs/python_basics/05_functions/2_functions_good.html#more-about-unpacking",
    "href": "docs/python_basics/05_functions/2_functions_good.html#more-about-unpacking",
    "title": "Functions (Good)",
    "section": "2.4 More about unpacking",
    "text": "2.4 More about unpacking\nThere is more to unpacking. For example, unpacking can make extracting information from lists and arrays a breeze. Here are some examples.\n\n\n\n\nx, y, z = [1, 2, 3]\nx, y, z\n\n(1, 2, 3)\n\n\n\n\n\nx, y, z = np.array([1, 2, 3])\nx, y, z\n\n(1, 2, 3)\n\n\n\n\n\nx, *y, z = np.array([1, 2, 3, 4, 5])\nx, y, z\n\n(1, [2, 3, 4], 5)\n\n\n\n\n\nx, *_, y = [1, 2, 3, 4, 5]\nx, y\n\n(1, 5)",
    "crumbs": [
      "Content",
      "Part 1| Basics",
      "5. Functions",
      "Functions (Good)"
    ]
  },
  {
    "objectID": "docs/about_73/01_course-overview.html",
    "href": "docs/about_73/01_course-overview.html",
    "title": "Overview of 73",
    "section": "",
    "text": "Welcome to SP2273: Working on Interdisciplinary Science, Pythonically. Thank you for joining 731. My name is Chammika Udalagama, and I am the course coordinator for this course. On this page, I will quickly run through many of the important features of the course. I have greatly elaborated on these in other chapters of this part.\nIf you are wondering, inspired by one of my favourite authors2, for several years now, I have been writing all my course notes in the first person.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Overview of 73"
    ]
  },
  {
    "objectID": "docs/about_73/01_course-overview.html#highlights-of-73",
    "href": "docs/about_73/01_course-overview.html#highlights-of-73",
    "title": "Overview of 73",
    "section": "Highlights of 73",
    "text": "Highlights of 73\nThe course is broadly split into two portions. The first(Weeks 1 - 6) focuses on developing and practicing fundamental skills individually. The second(Weeks 7 - 13) focuses on working in a group to apply your fundamental skills to solve problems and broaden your learning. Let me first share some of the highlights of 73. I will explain these in greater depth later.\n\nThe module is extensively hands-on in design.\nAmple support, scaffolding, and feedback will help your learning journey.\nIn weeks 1 to 6, you have leeway to pick a pace and form of learning that suits you.\nThis dedicated website for the content.\nWe use many industry-standard platforms and tools (Git, GitHub, Jupyter).\nDifferentiated learning (see below).\nMastery learning (see below).\nWebcasting in Weeks 1 to 6.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Overview of 73"
    ]
  },
  {
    "objectID": "docs/about_73/01_course-overview.html#course-content-week-1-to-6",
    "href": "docs/about_73/01_course-overview.html#course-content-week-1-to-6",
    "title": "Overview of 73",
    "section": "Course content (Week 1 to 6)",
    "text": "Course content (Week 1 to 6)\n\nDifferentiated instruction\nOne of the exciting features of our class is diversity. Not only does the cohort come from different disciplines, but you also have varied interests and backgrounds. This means each of you will begin this course from different starting points. Moreover, some of you will naturally like the module’s content and have higher levels of motivation. These individuals will want to go through the module at lightning speed (let’s call these the racers), while the rest (let’s call them the hikers) will prefer a more leisurely pace. So, to make this module work for everyone, we need to have some form of differentiated instruction (Tomlinson (2017)) that will allow each of you to consume the course content comfortably. To facilitate this, I have designed the course in a modular fashion with some optional content.\n\nI must comment that there is nothing good or bad about being a racer or a hiker. Each of us learns different things at different rates. What is important is that you focus on the quality of your learning journey (i.e., the learning process) rather than on getting quickly to the destination (i.e., the product).\n\n\nCourse material\nI have split most of the learning units of the first half into three categories:\n\nNeed-to-Know,\nGood-to-Know, and\nNice-to-Know.\n\nYou must ensure you know everything that is Need-to-Know and are comfortable with what is Good-to-Know. The Nice-to-Know bits are the icing on the cake and are optional. These are meant for those of you with a greater appetite for content.\n\n\n\n\n\n\nRemember\n\n\n\nNice-to-Know is optional.\n\n\nIn each unit, I follow a conversational style where I walk you through topics and relevant code. These ‘walk-throughs’ will guide you into new concepts and skills and showcase how these ideas can be used. Finally, the exercises will allow you to use these new ideas to solve problems. The Learning Portfolio assessment involves working out all this material into a record of your learning.\n\n\nWorkflow\nMy plan is to go through all the (Need and Good) content of the material during the lectures together with you. You will have to work on the exercises during the tutorials. You must engage with the materials at a pace that suits you best. The pace at which I cover the material may not be ideal for everyone. So you are free to set this pace yourself by chosing to follow along with me or to do your own thing in or out of the lecture/tutorial. However, it’s crucial to ensure you have completed all the work by the end of Week 6.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Overview of 73"
    ]
  },
  {
    "objectID": "docs/about_73/01_course-overview.html#footnotes",
    "href": "docs/about_73/01_course-overview.html#footnotes",
    "title": "Overview of 73",
    "section": "Footnotes",
    "text": "Footnotes\n\n\nWe usually refer to our SPS modules with just the last two digits.↩︎\nDavid J. Griffiths↩︎",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Overview of 73"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_applications-challenge.html",
    "href": "docs/about_73/assessment/assessment_applications-challenge.html",
    "title": "App. Challenge (15%)",
    "section": "",
    "text": "Quick Summary\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nWeight\nWhen\nDeliverable\n\n\n\n\nGroup\n15%\nWeeks 7 & 8\n• Jupyter Notebook with a solution to a problem.• Submitted to CANVAS.• Submit by the end of Week 8.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "App. Challenge (15%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_applications-challenge.html#applications-segment-of-the-course",
    "href": "docs/about_73/assessment/assessment_applications-challenge.html#applications-segment-of-the-course",
    "title": "App. Challenge (15%)",
    "section": "1.1 Applications segment of the course",
    "text": "1.1 Applications segment of the course\nIn Week 6, I will release the second ‘Applications’ segment (Part 3) of the course material. This section will comprise of two things:\n\nKnowledge base: A comprehensive knowledge base comprising many diverse examples of how Python is applied in science. Some of the topics that will be covered in this knowledge base include:\n\n\n\n\n\n\n\n\nNumerical methods\nRandom Numbers\nStatistics\n\n\n\n\nNumerical Modelling\nCurve Fitting\nData Processing\n\n\n\n\nData Acquisition\nImage Processing\nAdvanced Plotting\n\n\n\n\n\nChallenge Tasks: a curated assortment of challenges based on the topics in the knowledge base.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "App. Challenge (15%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_applications-challenge.html#what-is-the-applications-challenge",
    "href": "docs/about_73/assessment/assessment_applications-challenge.html#what-is-the-applications-challenge",
    "title": "App. Challenge (15%)",
    "section": "1.2 What is the Applications Challenge",
    "text": "1.2 What is the Applications Challenge\nIn the Application Challenge, you will work as a group to:\n\nSelect a Challenge Task: Choose one challenge from the provided list that resonates with your group’s interests or curiosities.\nDevelop a Solution: By the end of Week 8, submit your group’s solution to the chosen challenge. This submission should be in the format of a Jupyter notebook.\nUtilise the Knowledge Base: Engage with the various topics in the knowledge base to inform and enhance your solution.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "App. Challenge (15%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_applications-challenge.html#significance-value-of-the-applications-challenge",
    "href": "docs/about_73/assessment/assessment_applications-challenge.html#significance-value-of-the-applications-challenge",
    "title": "App. Challenge (15%)",
    "section": "1.3 Significance & value of the Applications Challenge",
    "text": "1.3 Significance & value of the Applications Challenge\nThe Applications Challenge is designed to serve several key objectives:\n\nApplication of Fundamental Skills: This is your initial opportunity to apply the basic Python skills acquired in the first half of the semester.\nShort Burst, Goal-Oriented Learning: The Applications Challenge is structured as a short project offering practical experience in problem-solving. With a clear objective (solving a specific problem), you can concentrate on applying your skills to develop a solution.\nCollaboration and Warm-Up: It provides an excellent platform to familiarise yourself with your group members and develop effective collaboration strategies. You will also get to practice using GitHub for collaborative work.\n\nThink of the Applications Challenge as a ‘Group Project with Training Wheels.’ Completing the Applications Challenge will equip you with the confidence and readiness to embark on your own Group Mini Project.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "App. Challenge (15%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_applications-challenge.html#practicalities",
    "href": "docs/about_73/assessment/assessment_applications-challenge.html#practicalities",
    "title": "App. Challenge (15%)",
    "section": "2.1 Practicalities",
    "text": "2.1 Practicalities\nEach group will receive a new GitHub Group Repository from the Applications Challenge onwards. You must use this to develop and refine your solution to the challenge collaboratively.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "App. Challenge (15%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_applications-challenge.html#you-are-not-alone",
    "href": "docs/about_73/assessment/assessment_applications-challenge.html#you-are-not-alone",
    "title": "App. Challenge (15%)",
    "section": "2.2 You are not alone",
    "text": "2.2 You are not alone\n\nDedicated Group Mentor: For the duration of the Applications Challenge (and Mini Group Project), each group will be allocated a Group Mentor. This mentor is your go-to resource for guidance and support. You and your mentor can choose a communication method (such as Face-to-Face meetings, NBReview, WhatsApp, etc.) that best suits your schedules.\nSupport in Lectures & Tutorials: From Week 7 to Week 10, all instructors will be available during lectures and tutorials. While there won’t be conventional lectures, we will be present to provide advice and assistance with both the Applications Challenge and the Mini Group Project.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "App. Challenge (15%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_applications-challenge.html#additional-considerations",
    "href": "docs/about_73/assessment/assessment_applications-challenge.html#additional-considerations",
    "title": "App. Challenge (15%)",
    "section": "2.3 Additional Considerations",
    "text": "2.3 Additional Considerations\n\nPreparation for the Mini Group Project: Use the Applications Challenge as a training ground for the upcoming Mini Group Project. You must start discussing and thinking of the Mini Group Project with your group members while working on the Applications Challenge.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "App. Challenge (15%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/release-later.html",
    "href": "docs/about_73/assessment/release-later.html",
    "title": "SP2273 | Working on Interdisciplinary Science, Pythonically",
    "section": "",
    "text": "Later\n\n\n\nSince this information is only relevant to the second half of the semester, I will release it at the end of Week 6.\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/about_73/assessment/assessment_teammates.html",
    "href": "docs/about_73/assessment/assessment_teammates.html",
    "title": "Peer Feedback (5%)",
    "section": "",
    "text": "Quick Summary\n\n\n\n\n\n\n\n\n\n\n\n\n\nType\nWeight\nDue\nDeliverable\n\n\n\n\nIndividual\n5%\nMonday of Reading Week.\n• Submit peer review of group mates using TEAMMATES.\n\n\n\n\n\n\nAt the end of the semester, I will use the TEAMMATES platform to facilitate peer feedback among group members. This feedback exercise is an opportunity for you to provide constructive criticism and recognise the contributions of your peers.\nYour participation in this feedback process is mandatory.\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Peer Feedback (5%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/grading_instructions.html",
    "href": "docs/about_73/assessment/grading_instructions.html",
    "title": "Instructions to Graders",
    "section": "",
    "text": "In the name of transparency\n\n\n\nIn the interest of complete transparency, I have made the grading instructions available to everyone. I hope this information about the behind-the-scenes workings will help to provide a clear understanding of our assessment process.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Instructions to Graders"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/grading_instructions.html#essentials",
    "href": "docs/about_73/assessment/grading_instructions.html#essentials",
    "title": "Instructions to Graders",
    "section": "1.1 Essentials",
    "text": "1.1 Essentials\nGrading is necessary & important: Grading/assessing is a nuanced and crucial skill. It is essential in academia and in a broad decision-making context. It demands fairness, consistency, and a keen eye for detail. As instructors/mentors/teaching assistants, your role in assessing student work is instrumental in ensuring a fair and constructive learning environment.\nRubrics: Each assessment component of 73 is accompanied by detailed rubrics. These rubrics identify key criteria that reflect the skills and knowledge I aim for students to acquire, develop, and nurture throughout the course. These rubrics further delineate each criterion into five categories: Needs Improvement, Satisfactory, Good, Accomplished, and Distinguished. These categories serve as a scale to measure varying levels of student mastery and understanding, providing a clear and structured framework for evaluation.\nMultiple Graders: Even with rubrics, it is typical to have some variation between grading different graders. To mitigate discrepancies and bias of single-person evaluation, all assessment components of 73 will be graded by at least two graders.\nConfidentiality & Professionalism: The University considers grades and all matters related to grading very seriously. You need to demonstrate high professionalism in exercising your privilege as a grader. Always treat all student work and grades with the utmost confidentiality.\nConsultation: If you are uncertain about a grade or find a criterion ambiguous, do not hesitate to consult me for clarification.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Instructions to Graders"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/grading_instructions.html#key-principles",
    "href": "docs/about_73/assessment/grading_instructions.html#key-principles",
    "title": "Instructions to Graders",
    "section": "1.2 Key Principles",
    "text": "1.2 Key Principles\nWhen grading, please keep these principles in mind:\n\nAdherence to Criteria: Strictly follow the rubric to ensure fairness and uniformity in all assessments.\nConsistency: Ensure your grading is consistent across all students, guaranteeing equal evaluation for everyone.\nBenefit of the Doubt: There are so many challenges in our students’ lives that we are not aware of. So, when uncertain, please give them the benefit of the doubt and lean towards a nurturing and generous grading policy.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Instructions to Graders"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/grading_instructions.html#recommended-grading-procedure",
    "href": "docs/about_73/assessment/grading_instructions.html#recommended-grading-procedure",
    "title": "Instructions to Graders",
    "section": "1.3 Recommended Grading Procedure",
    "text": "1.3 Recommended Grading Procedure\n\nStep 1: Categorization\n\nStart by reviewing the student’s work against each criterion in the rubric.\nDetermine which category best represents the student’s performance for each criterion.\n\nStep 2: Justification\n\nProvide a clear and concise rationale for why the student did not qualify for the next higher category.\nThis step is essential as it makes the grading transparent and justifies your grade.\nRemember that constructive feedback is as important as the grade itself. It aids in the student’s learning process. Aim to provide specific, actionable feedback wherever possible.\n\nStep 3: Scoring\n\nOnce you have categorized the student’s performance, assign a numeric score within the chosen category based on the following:\n\n\n\n\n\n\nGrading Scale\nNumeric Range\nGranularity\n\n\n\n\nNeeds Improvement\n1 - 2\n0.5\n\n\nSatisfactory\n3 - 4\n0.5\n\n\nGood\n5 - 6\n0.5\n\n\nAccomplished\n7 - 8\n0.5\n\n\nDistinguished\n9 - 10\n0.5",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Instructions to Graders"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html",
    "title": "Learning Portfolio (20%)",
    "section": "",
    "text": "Quick Summary\n\n\n\n\n\n\n\n\n\n\n\n\nType\nWeight\nDeliverable\n\n\n\n\nIndividual\n20%\n• Completed Learning Portfolio.• Submitted through the Individual Repository.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html#what-is-the-learning-portfolio",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html#what-is-the-learning-portfolio",
    "title": "Learning Portfolio (20%)",
    "section": "1.1 What is the Learning Portfolio",
    "text": "1.1 What is the Learning Portfolio\nThe Learning Portfolio is a comprehensive record of what you will learn in the first six weeks of the course. Your Learning Portfolio will be maintained on your computer (locally) and a cloud platform called GitHub Classroom. The content of the Learning Portfolio will consist of various examples, walk-throughs, and exercises that I have incorporated into the learning units of the first half of the course. More specifically, you must work through and reproduce (no! not just copying and pasting) all this content in the form of Jupyter notebooks, a cool way to use Python for scientific work.\nThe material from your Learning Portfolio will also be revisited during the individual viva assessment.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html#why-this-assessment-good-for-you",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html#why-this-assessment-good-for-you",
    "title": "Learning Portfolio (20%)",
    "section": "1.2 Why this assessment good for you",
    "text": "1.2 Why this assessment good for you\nIn this assessment, the emphasis is on ‘learning by doing.’ You will actively engage with Python and computational concepts, enhancing your learning through hands-on activities. This approach will deepen your understanding and equip you with practical skills highly valued in the industry, like using Git, GitHub, and Jupyter; these will be good for your CV.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html#standard-operating-procedure",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html#standard-operating-procedure",
    "title": "Learning Portfolio (20%)",
    "section": "2.1 Standard Operating Procedure",
    "text": "2.1 Standard Operating Procedure\nThe Learning Portfolio is a way for you to quickly learn how to talk and use Python. I have implemented several strategies to help you make the most of this learning process. Specifically, there is a standard procedure of Engage \\(\\longrightarrow\\) Review \\(\\longrightarrow\\) Revise \\(\\longrightarrow\\) Finish, that you must follow in growing your Learning Portfolio.\nEngage refers to engaging with the content and reproducing and working out the exercises of a learning unit. For instance, if you are on the unit Fundamentals(Need), you will work on a corresponding file called fundamentals_need.ipynb in your Learning Portfolio.\nReview Once you have reproduced the content and worked on the exercises, you will submit it for review by a human reviewer. For this, you will use an interface called NBReviewer, embedded in GitHub Classroom.This reviewing process should be initiated by you by submitting a commit of the form ‘READY FOR REVIEW FILE_NAME’ ‘COMPLETED FILE_NAME’.\nRevise The reviewer will get back to you with suggestions and improvements. You must respond and adjust your notebook based on the feedback given to you by the reviewer.\nFinish Once you have responded to the reviewer’s comments to her satisfaction, you will have completed that unit and can then move on to the next unit Fundamentals(Good).\n\n\n\n\n\n\nImportant\n\n\n\nEveryone must complete all the Need-to-know and Good-to-know portions of the Learning Portfolio.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html#practicalities",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html#practicalities",
    "title": "Learning Portfolio (20%)",
    "section": "2.2 Practicalities",
    "text": "2.2 Practicalities\nI will highlight three ways you can work on your Learning Portfolio, depending on your preferences.\n\n\n\n\n\n\nGuided\nAttend lectures and follow along. I will cover all content, barring exercises, which you should work on in the tutorials. This option is well-suited for those who prefer structured learning and continuous guidance.\n\n\nSemi-Autonomous\nAttend both lectures and tutorials, but manage your learning independently. Should you require assistance, speak to one of the instructors. This option is tailored for those seeking a blend of independence and some support.\n\n\nAutonomous\nChoose not to attend lectures or tutorials but work through the content independently. This option demands high self-motivation and discipline, ideal for those who prefer setting their own pace.\n\n\n\n\n\n\nCaution\n\n\n\nThe downside of this option is that you might have a hard time identifying group mates. So, I recommend the previous two options instead.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html#you-are-not-alone",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html#you-are-not-alone",
    "title": "Learning Portfolio (20%)",
    "section": "2.3 You are not alone",
    "text": "2.3 You are not alone\nThere are several support systems in place to make this journey easy for you.\n\nFace-to-face feedback and assistance from the instructors during the lectures and tutorials.\nIn class, Q & A is using PollEverywhere.\nAutomated feedback from ChatGPT.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html#rubric",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html#rubric",
    "title": "Learning Portfolio (20%)",
    "section": "3.1 Rubric",
    "text": "3.1 Rubric\n\n\n\n\n\n\n\n\n\n\n\n\n#\nCriterion\nNeeds Improvement\nSatisfactory\nGood\nAccomplished\nDistinguished\n\n\n\n\n1\nCompleteness\nNotebooks are largely incomplete or missing.\nMany notebooks are incomplete or missing significant detail.\nMost notebooks are complete.\nMinor details missing in few notebooks.\nAll notebooks are complete and thoroughly detailed.\n\n\n2\nCorrectness\nMajor errors; outputs are incorrect or missing.\nFrequent errors that hinder understanding.\nSome errors that affect the outcomes.\nMinor errors present but do not affect overall understanding.\nNo errors in execution; all outputs are as expected.\n\n\n3\nUnderstanding\nMisunderstands or cannot apply concepts.\nLimited understanding; struggles to apply concepts.\nBasic understanding with noticeable gaps.\nGood understanding with minor misconceptions.\nDemonstrates deep understanding and ability to apply concepts.\n\n\n4\nResponses to Reviewer\nDoes not address reviewer comments.\nAddresses some comments but misses key issues.\nAdequately addresses most comments.\nAddresses all comments with thoughtful responses.\nEngages deeply with comments, providing comprehensive and insightful responses.\n\n\n5\nTool Proficiency\nUnable to use tools or does not use them at all.\nLimited use; struggles with basic features.\nAdequate use of tools; basic features are utilised.\nGood proficiency; uses most features effectively.\nHighly proficient with Git, GitHub, and Jupyter.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html#important-1",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html#important-1",
    "title": "Learning Portfolio (20%)",
    "section": "4.1 Important!",
    "text": "4.1 Important!\nThe primary role of the Learning Portfolio is to quickly bring students up to speed with the basics of Python. The main goal of this course is to get students to think and solve problems in science using computers (i.e Python). The Learning Portfolio is a preparatory exercise to this end. The Learning Portfolio is not meant to be an exhaustive exploration of Python’s cool features and subtleties.\nSo, in summary, when giving feedback, please remember:\n\nFocus on Essentials:\n\nYour feedback should concentrate on the basics of Python, ensuring students grasp key concepts quickly and effectively.\nSteer clear of advanced topics not covered in the course material. Please let me know if you identify any concepts you think are crucial that I have missed out.\n\nThreshold Concepts:\n\nPrioritize concepts that are critical for future application in Python. If a student struggles with such a concept, offer detailed guidance and request further revisions.\nThese foundational ideas are vital for practical coding and understanding computational methods in science. Some of these are:\n\n\n\n\n\n\n\n\n\nVariable types,\nData Structures,\nLoops,\n\n\n\n\nComprehensions,\nFunctions/encapsulation,\nBranching and decisions,",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/assessment/assessment_learning-portfolio.html#grading-procedure",
    "href": "docs/about_73/assessment/assessment_learning-portfolio.html#grading-procedure",
    "title": "Learning Portfolio (20%)",
    "section": "4.2 Grading procedure",
    "text": "4.2 Grading procedure\n\nEach Learning Portfolio mentor will be assigned a set of students and given access to their GitHub Classroom repositories.\nThe students have been instructed to submit a commit ‘READY FOR REVIEW FILE_NAME’ ‘COMPLETED FILE_NAME’ once they are ready to revise the file.\nPlease use NBReview to communicate your comments to the students.\nPlease alert me or the teaching assistant if any student finds the content too challenging and requires additional help.",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "Assessment",
      "Learning Portfolio (20%)"
    ]
  },
  {
    "objectID": "docs/about_73/02_flow.html",
    "href": "docs/about_73/02_flow.html",
    "title": "What you have to do in 73",
    "section": "",
    "text": "73 has many moving parts, and it can be overwhelming at first. I hope the following table will help you with what to do and when.\n\n\n\nWhen\n\n\nWhat to Do\n\n\nType\n\n\nNote\n\n\nMore Info\n\n\n\n\nWeek1\n\n\nSet up software.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek1 - 6\n\n\nWork on the individual Learning Portfolio.\n\n\nIndividual\n\n\nMust submit for feedback and address any concerns the reviewer raises.\n\n\nLink\n\n\n\n\nWork on end-of-lesson exercises during tutorials.\n\n\nIndividual\n\n\nMust submit for feedback and address any concerns the reviewer raises.\n\n\nLink\n\n\n\n\nLook out for potential group members.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek5\n\n\nDeclare group members.\n\n\nGroup\n\n\nUse this form.\n\n\nLink\n\n\n\n\nWeek6, Friday\n\n\nAttend lecture to see examples of presentations.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek7, 8\n\n\nWork on Application Problem.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nStart planning your mini-project.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nImplement your mini-project.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nWeek11\n\n\nPresentations.\n\n\nGroup\n\n\nUse this form to pick a slot.\n\n\nLink\n\n\n\n\nWeek12, 13\n\n\nIndividual Viva.\n\n\nIndividual\n\n\nUse this form to pick a slot.\n\n\nLink\n\n\n\n\nSubmit TEAMMATES.\n\n\nIndividual\n\n\nEmail will be sent to you.\n\n\nLink\n\n\n\n\n\n\n Back to top",
    "crumbs": [
      "Content",
      "Part 0| Course Info",
      "What you have to do in 73"
    ]
  },
  {
    "objectID": "docs/about_73/docs/people_2023.html",
    "href": "docs/about_73/docs/people_2023.html",
    "title": "SP2273 | Working on Interdisciplinary Science, Pythonically",
    "section": "",
    "text": "SPS mentors\n\n\n\n\nAlefiya\nAng Siaw Wei\nBei Yi Yang\n\n\nBharath\nChanne Chwa\nChen Mingyi\n\n\nClement Tan\nDerek Ong\nErvin Chia (H)\n\n\nGuan Xin\nHillson Hung\nJensie Low\n\n\nLee Kai Xiang\nLim Ting Wei\nMichael Lim\n\n\nNandi Shao\nNemo Chen\nNg Jing Ting\n\n\nRyan Seow\nTee Kai Ze\nTrina Tan\n\n\nYeow Xuek Qee\nKelissa Goh (H)\nKellie Wong\n\n\n\n\n\n\nTeaching assistants\n\nGenevieve Tang and\nLee Yuan Zhe\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/about_73/docs/flow_table.html",
    "href": "docs/about_73/docs/flow_table.html",
    "title": "SP2273 | Working on Interdisciplinary Science, Pythonically",
    "section": "",
    "text": "When\n\n\nWhat to Do\n\n\nType\n\n\nNote\n\n\nMore Info\n\n\n\n\nWeek1\n\n\nSet up software.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek1 - 6\n\n\nWork on the individual Learning Portfolio.\n\n\nIndividual\n\n\nMust submit for feedback and address any concerns the reviewer raises.\n\n\nLink\n\n\n\n\nWork on end-of-lesson exercises during tutorials.\n\n\nIndividual\n\n\nMust submit for feedback and address any concerns the reviewer raises.\n\n\nLink\n\n\n\n\nLook out for potential group members.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek5\n\n\nDeclare group members.\n\n\nGroup\n\n\nUse this form.\n\n\nLink\n\n\n\n\nWeek6, Friday\n\n\nAttend lecture to see examples of presentations.\n\n\nIndividual\n\n\n\n\nLink\n\n\n\n\nWeek7, 8\n\n\nWork on Application Problem.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nStart planning your mini-project.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nImplement your mini-project.\n\n\nGroup\n\n\n\n\nLink\n\n\n\n\nWeek11\n\n\nPresentations.\n\n\nGroup\n\n\nUse this form to pick a slot.\n\n\nLink\n\n\n\n\nWeek12, 13\n\n\nIndividual Viva.\n\n\nIndividual\n\n\nUse this form to pick a slot.\n\n\nLink\n\n\n\n\nSubmit TEAMMATES.\n\n\nIndividual\n\n\nEmail will be sent to you.\n\n\nLink\n\n\n\n\n\n\n Back to top"
  },
  {
    "objectID": "docs/about_73/docs/people_2024.html",
    "href": "docs/about_73/docs/people_2024.html",
    "title": "SP2273 | Working on Interdisciplinary Science, Pythonically",
    "section": "",
    "text": "SPS mentors\n\n\n\nAlefiya\nAng Siaw Wei\nBei Yi Yang\n\n\nBharath\nChanne Chwa\nChen Mingyi\n\n\nClement Tan\nDerek Ong\nErvin Chia (H)\n\n\nGuan Xin\nHillson Hung\nJensie Low\n\n\nLee Kai Xiang\nLim Ting Wei\nMichael Lim\n\n\nNandi Shao\nNemo Chen\nNg Jing Ting\n\n\nRyan Seow\nTee Kai Ze\nTrina Tan\n\n\nYeow Xuek Qee\nKelissa Goh (H)\nKellie Wong\n\n\n\n\n\nTeaching assistants\n\nLee Yuan Zhe\nChee Onn\nKellisa Goh\n\n\n\nGraduate Teaching Assistants\n\nErvin Chia Sheng Hin\nTimothy Yee Bing Lun\n\n\n\n\n\n Back to top"
  }
]